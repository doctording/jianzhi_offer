{"./":{"url":"./","title":"Introduction","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 剑指offer刷题说明 Java 技能树 大数据 请访问: https://doctording.github.io/sword_at_offer/ 欢迎star，fork，pr 剑指offer刷题说明 刷题地址: http://www.nowcoder.com/ta/coding-interviews?page=1 需要找到最优解法：参考学习牛客网左程云视频、牛客网算法讨论、《剑指offer》图书，LeetCode等。 直接编辑器敲出代码，或在纸上直接写出代码（注意时间/空间复杂度）；剑指offer整体难度都不高，不过如果手撕代码的话，还是很锻炼的。 Java 技能树 Java 文档中心: https://docs.oracle.com/en/ 基础 ArrayList, List, Map, Set等数据结构 String,StringBuffer,StringBuilder 反射 对象的几种引用类型 线程 线程基础 原理 线程池 并发基础 并发的三大性质(原子性，可见性，顺序性) volatile / synchronized / CAS / Lock AQS 原子类 java.util.concurrent(JUC)：CountDownLatch / Semaphore / CyclicBarrier / Exchanger JVM 类加载机制，双亲委派模型 JMM(内存模型)：堆，元空间；虚拟机栈，本地方法栈，程序计数器 GC，垃圾收集算法 内存泄漏，GC调优 jstack, jmap, jconsole等命令 设计模式 单例 工厂模式 迭代器模式 代理模式 IO BIO NIO AIO 网络 Socket，TCP，HTTP HTTPS 序列化 RPC 数据库 数据库引擎 事物，隔离机制 索引 主从，分库，分表 数据库锁 慢查询 & SQL优化 框架 Mybatis Spring，Spring MVC SpringBoot Spring & Mybatis 服务器 Tomcat Netty 消息中间件 Kafka 高并发 & 分布式 缓存：Redis, 持久化 负载均衡，一致性Hash原理等 数据库读写分离 zookeeper 限流：缓存击穿，雪崩等 操作系统 内存管理；页面置换算法：LRU, LFU 内核，用户态 虚拟内存； MMAP 缓冲区 进程，线程；进程间通信；同步机制 局部性原理 IO复用 算法和相关题目手写 手写单例模式 手写String 手写HashMap 手写semaphore 字典树 正则 各种排序：归并，快排，堆排 大数据 HDFS, Hadoop / Yarn, Hive, HBase Spark，Storm Flink Druid.io Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-18 15:33:11 "},"content/design_pattern/proxy.html":{"url":"content/design_pattern/proxy.html","title":"代理模式","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 代理模式 为什么要用代理模式？ 静态代理 动态代理 动态代理的几种实现方式? JDK原生动态代理(反射机制) CGLIB(Code Generator Library) cglib 底层原理 Java动态代理和cglib动态代理的区别？ [TOC] 代理模式 为什么要用代理模式？ 中介隔离作用 在某些情况下，一个客户类不想或者不能(比如找房子:某些时候找不到房东，而只能找到中介)直接引用一个委托对象，而代理类对象可以在客户类和委托对象之间起到中介的作用，其特征是代理类和委托类实现相同的接口。 开闭原则，增加功能 代理类除了是客户类和委托类的中介之外，我们还可以通过给代理类增加额外的功能来扩展委托类的功能，这样做我们只需要修改代理类而不需要再修改委托类，符合代码设计的开闭原则(软件对象（类、模块、方法等）应该对于扩展是开放的，对修改是关闭的)。代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后对返回结果的处理等。代理类本身并不真正实现服务，而是同过调用委托类的相关方法，来提供特定的服务。真正的业务功能还是由委托类来实现，但是可以在业务功能执行的前后加入一些公共的服务。例如我们想给项目加入缓存、日志这些功能，我们就可以使用代理类来完成，而没必要打开已经封装好的委托类。 静态代理 在程序运行前就已经存在代理类的字节码.class文件，代理类和委托类的关系在运行前就确定了 代理对象的一个接口只服务于一种类型的对象；且如果要代理的方法很多，势必要为每一种方法都进行代理，不易扩展 代理类 package reflect; /** * @Author mubi * @Date 2020/6/16 21:13 */ public class PayStaticProxy implements PayService{ private PayService payService; public PayStaticProxy(PayService payService) { this.payService = payService; } @Override public String payUse() { System.out.println(\"in PayStaticProxy\"); return payService.payUse(); } public PayService getPayService() { return payService; } public void setPayService(PayService payService) { this.payService = payService; } } /** * @Author mubi * @Date 2020/6/16 06:44 */ public interface PayService { String payUse(); } package reflect; /** * @Author mubi * @Date 2020/6/16 06:43 */ public class WeixinPayServiceImpl implements PayService { @Override public String payUse() { System.out.println(\"in method payUse\"); return \"WeixinPayServiceImpl\"; } } 测试代码 static void testStaticProxy() throws Exception{ PayService payService = new WeixinPayServiceImpl(); PayStaticProxy payStaticProxy = new PayStaticProxy(payService); /** * in method payUse * WeixinPayServiceImpl */ System.out.println(payService.payUse()); Class clazz = payStaticProxy.getClass(); Field[] fields = clazz.getDeclaredFields(); for(Field field: fields) { Class fieldClazz = field.getType(); /** * ---interface reflect.PayService */ System.out.println(\"---\" + fieldClazz); } PayService payService1 = payStaticProxy.getPayService(); /** * true */ System.out.println(payService1 instanceof WeixinPayServiceImpl); /** * false */ System.out.println(payService1 instanceof AliPayServiceImpl); } 动态代理 在程序运行期间由JVM根据反射等机制动态的生成，不存在代理类的字节码文件。代理类和委托类的关系是在程序运行时确定的 动态代理的几种实现方式? JDK原生动态代理(反射机制) 其中：InvocationHandler接口是proxy代理实例的调用处理程序实现的一个接口，每一个proxy代理实例都有一个关联的调用处理程序；在代理实例调用方法时，方法调用被编码分派到调用处理程序的invoke方法。 核心就是代理对象的生成，即Proxy.newProxyInstance(classLoader, proxyInterface, handler) Service package reflect; /** * @Author mubi * @Date 2020/6/16 06:44 */ public interface PayService { String payUse(); } Service的其中一个实现类 package reflect; /** * @Author mubi * @Date 2020/6/16 06:43 */ public class AliPayServiceImpl implements PayService { @Override public String payUse() { return \"AliPayServiceImpl\"; } } 代理类 package reflect; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; /** * @Author mubi * @Date 2020/6/16 21:13 */ public class PayProxy implements InvocationHandler { private PayService pay; private PayService proxy; public PayProxy(PayService pay) { this.pay = pay; // newProxyInstance方法的三个参数： // 1. 用哪个类加载器去加载代理对象 // 2. 动态代理类需要实现的接口 // 3. 动态代理方法在执行时，会调用this里面的invoke方法去执行 this.proxy = (PayService)Proxy.newProxyInstance( PayService.class.getClassLoader(), new Class[] { PayService.class }, this); } public PayService getProxy() { return proxy; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { String methodName = method.getName(); System.out.println(\"before methodName:\" + methodName); Object rs = method.invoke(pay, args); System.out.println(\"after methodName:\" + methodName); return rs; } } 测试 package reflect; /** * @Author mubi * @Date 2020/6/16 06:44 */ public class ClientTest { public static void main(String[] args) { PayService pay = new PayProxy(new AliPayServiceImpl()).getProxy(); String payStr = pay.payUse(); System.out.println(payStr); } } CGLIB(Code Generator Library) CGLIB代理主要通过对字节码的操作，为对象引入间接级别，以控制对象的访问 代理类 package reflect; import net.sf.cglib.proxy.Enhancer; import net.sf.cglib.proxy.MethodInterceptor; import net.sf.cglib.proxy.MethodProxy; import java.lang.reflect.Method; /** * @Author mubi * @Date 2020/6/16 21:13 */ public class PayProxy implements MethodInterceptor { public Object createProxyObj(Class clazz) { Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(clazz); enhancer.setCallback(this); // 代理对象 return enhancer.create(); } @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable { System.out.println(\"before methodName:\" + method.getName()); Object rs = methodProxy.invokeSuper(o, objects); System.out.println(\"after methodName:\" + method.getName()); return rs; } } 测试 package reflect; /** * @Author mubi * @Date 2020/6/16 06:44 */ public class ClientTest { public static void main(String[] args) { PayService pay = (PayService) new PayProxy().createProxyObj(AliPayServiceImpl.class); String payStr = pay.payUse(); System.out.println(payStr); } } Enhancer既能够代理普通的class，也能够代理接口。Enhancer创建一个被代理对象的子类并且拦截所有的方法调用（包括从Object中继承的toString和hashCode方法），Enhancer不能够拦截final方法 cglib 底层原理 底层使用ASM(ASM是一个Java字节码操纵框架)，可以直接产生二进制class文件；动态字节码技术，不是反射(method.invoke)执行 代理本质：增强，拦截，前后加代码逻辑 eg: 实现MethodInterceptor的intercept方法，可以任意修改目标方法 Java动态代理和cglib动态代理的区别？ JDK动态代理只能对实现了接口的类生成代理，而不能针对类 CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法 JDK动态代理类实现了InvocationHandler接口，重写的invoke方法。 JDK动态代理的基础是反射机制:method.invoke(对象，参数),Proxy.newProxyInstance() cglib动态代理原理是对指定的目标生成一个子类，并覆盖其中方法实现增强，但因为采用的是继承，所以不能对final修饰的类进行代理。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-18 14:39:36 "},"content/design_pattern/singleton.html":{"url":"content/design_pattern/singleton.html","title":"单例模式","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 单例模式 懒汉式 + 非同步 懒汉式 + synchronized同步 double-check（仍然线程不安全） double-check & volatile（懒汉式） Holder方式（静态内部类：线程安全 & 懒汉式） 回顾:什么时候需要对类进行初始化 说明 枚举 [TOC] 单例模式 单例类只能有一个实例 单例类必须自己创建自己的唯一实例 单例类必须给所有其他对象提供这一实例 懒汉：在初始化类的时候，不创建唯一的实例，而是等到真正需要用到的时候才创建。必须加上同步，否则有可能依然创建多个实例。 饿汉：在初始化的时候，就创建了唯一的实例，不管是否需要用到。不需要自己加同步，一定产生唯一的实例。 懒汉式 + 非同步 final class Singleton{ private byte[] data = new byte[1024]; private static Singleton instance = null; public static Singleton getInstance(){ if (null == instance) { System.out.println(\"new Singleton()\"); instance = new Singleton(); } return instance; } } Singleton.class初始化的时候，instance不会实例化，getInstance()方法内部会实例化，但是多线程下会出现new Singleton()多次的情况，因为某个时间可能多个线程看到的instance都是null, 这使得实例并不唯一 // 20个线程简单测试 for(int i=0;i Singleton.getInstance()).start(); } 懒汉式 + synchronized同步 getInstance同一时刻只能被一个线程访问，效率很低 final class Singleton{ private byte[] data = new byte[1024]; private static Singleton instance = null; public static synchronized Singleton getInstance(){ if(null == instance){ System.out.println(\"new Singleton\"); instance = new Singleton(); } return instance; } } double-check（仍然线程不安全） 首次初始化的时候加锁，之后多线程调用getInstance final class Singleton{ private byte[] data = new byte[1024]; private static Singleton instance = null; String conn; Socket socket; private Singleton(){ System.out.println(\"Singleton constructor init\"); try { TimeUnit.SECONDS.sleep(2); }catch (Exception e){ e.printStackTrace(); } this.conn = new String(); this.socket = new Socket(); } public static Singleton getInstance(){ if(null == instance){ synchronized (Singleton.class) { if(null == instance) { System.out.println(\"new Singleton\"); instance = new Singleton(); // new 对象 可能会指令重排 } } } return instance; } } 创建一个变量需要：一个是申请一块内存，调用构造方法进行初始化操作，另一个是分配一个指针指向这块内存。这两个操作谁在前,谁在后呢？JVM规范并没有规定。那么就存在这么一种情况，JVM是先开辟出一块内存，然后把指针指向这块内存，最后调用构造方法进行初始化。 double-check & volatile（懒汉式） volatile止指令重排，保证顺序性 private volatile static Singleton instance = null; Holder方式（静态内部类：线程安全 & 懒汉式） final class Singleton{ private Singleton(){ } private static class Holder{ private static Singleton singleton = new Singleton(); } public static Singleton getInstance(){ return Holder.singleton; } } 回顾:什么时候需要对类进行初始化 使用new该类实例化对象的时候 读取或设置类静态字段的时候（但被final修饰的字段，在编译器时就被放入常量池(static final)的静态字段除外） 调用类静态方法的时候 使用反射Class.forName(\"xxx\")对类进行反射调用的时候，该类需要初始化； 初始化一个类的时候，有父类，先初始化父类（注：1. 接口除外，父接口在调用的时候才会被初始化；2.子类引用父类静态字段，只会引发父类初始化）； 被标明为启动类的类（即包含main()方法的类）要初始化； 当使用JDK1.7的动态语言支持时，如果一个java.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 以上情况称为对一个类进行主动引用，且有且只要以上几种情况是需要对类进行初始化： 所有类变量初始化语句和静态代码块都会在编译时被前端编译器放在收集器里头，存放到一个特殊的方法中，这个方法就是方法，即类/接口初始化方法，该方法只能在类加载的过程中由JVM调用； 编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量； 如果超类还没有被初始化，那么优先对超类初始化，但在方法内部不会显示调用超类的方法，由JVM负责保证一个类的方法执行之前，它的超类方法已经被执行。 JVM必须确保一个类在初始化的过程中，如果是多线程需要同时初始化它，仅仅只能允许其中一个线程对其执行初始化操作，其余线程必须等待，只有在活动线程执行完对类的初始化操作之后，才会通知正在等待的其他线程。(所以可以利用静态内部类实现线程安全的单例模式) 如果一个类没有声明任何的类变量，也没有静态代码块，那么可以没有类方法； 说明 Singleton初始化的时候不会创建Holder实例； 当调用getInstance时，才会初始化Holder实例；而在Java程序类加载的编译时期()方法中，该方法是一个同步方法；类里面的静态变量是初始化一次放在常量池中的 枚举 枚举类型不允许被继承，同样是线程安全的且只能被实例化一次，但是枚举类型不能够实现懒加载 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-30 17:58:34 "},"content/design_pattern/factory.html":{"url":"content/design_pattern/factory.html","title":"工厂模式","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 工厂模式 简单工厂模式 抽象工厂 [TOC] 工厂模式 工厂模式 Factory Method is a creational design pattern that provides an interface for creating objects in a superclass, but allows subclasses to alter the type of objects that will be created.（Factory方法是一种创造性的设计模式，它提供了在超类中创建对象的接口，但允许子类更改将要创建的对象的类型。） 简单工厂模式 eg: car / 出行 -> 工厂 - train \\ ship 问题：突然新增了一个交通方式(比如两地可以直飞了); 则必须新增一个plane类，同时还要修改工厂方法（不符合开闭原则了） car / 出行 -> 工厂 - train \\ ship \\ plane 抽象工厂 解决开闭问题（解耦）；不过增加了不少类，代码变多了 工厂 car / 出行 -> 抽象工厂 -> 工厂 - train \\ 工厂 ship \\ 工厂 plane 这样:增加一种新的plane方式,同时再新增一个plane工厂即可；原有代码不需要修改 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-07 10:30:49 "},"content/design_pattern/template.html":{"url":"content/design_pattern/template.html","title":"模板方法","keywords":"","body":"[TOC] 模板方法 定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。模板方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 模板 public abstract class Game { abstract void initialize(); abstract void startPlay(); abstract void endPlay(); //模板 public final void play(){ //初始化游戏 initialize(); //开始游戏 startPlay(); //结束游戏 endPlay(); } } 模板的实现 public class Cricket extends Game { @Override void endPlay() { System.out.println(\"Cricket Game Finished!\"); } @Override void initialize() { System.out.println(\"Cricket Game Initialized! Start playing.\"); } @Override void startPlay() { System.out.println(\"Cricket Game Started. Enjoy the game!\"); } } public class Football extends Game { @Override void endPlay() { System.out.println(\"Football Game Finished!\"); } @Override void initialize() { System.out.println(\"Football Game Initialized! Start playing.\"); } @Override void startPlay() { System.out.println(\"Football Game Started. Enjoy the game!\"); } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-25 17:42:33 "},"content/design_pattern/strategy.html":{"url":"content/design_pattern/strategy.html","title":"策略模式","keywords":"","body":"[TOC] 策略模式 eg: public interface MemberStrategy { /** * 计算图书的价格 * @param booksPrice 图书的原价 * @return 计算出打折后的价格 */ public double calcPrice(double booksPrice); } 策略1 public class PrimaryMemberStrategy implements MemberStrategy { @Override public double calcPrice(double booksPrice) { System.out.println(\"对于初级会员的没有折扣\"); return booksPrice; } } 策略2 public class IntermediateMemberStrategy implements MemberStrategy { @Override public double calcPrice(double booksPrice) { System.out.println(\"对于中级会员的折扣为10%\"); return booksPrice * 0.9; } } 策略3 public class AdvancedMemberStrategy implements MemberStrategy { @Override public double calcPrice(double booksPrice) { System.out.println(\"对于高级会员的折扣为20%\"); return booksPrice * 0.8; } } 价格类 public class Price { //持有一个具体的策略对象 private MemberStrategy strategy; /** * 构造函数，传入一个具体的策略对象 * @param strategy 具体的策略对象 */ public Price(MemberStrategy strategy){ this.strategy = strategy; } /** * 计算图书的价格 * @param booksPrice 图书的原价 * @return 计算出打折后的价格 */ public double quote(double booksPrice){ return this.strategy.calcPrice(booksPrice); } } 客户端自主选择合适的策略 public class Client { public static void main(String[] args) { //选择并创建需要使用的策略对象 MemberStrategy strategy = new AdvancedMemberStrategy(); //创建环境 Price price = new Price(strategy); //计算价格 double quote = price.quote(300); System.out.println(\"图书的最终价格为：\" + quote); } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-24 20:48:42 "},"content/design_pattern/decorator.html":{"url":"content/design_pattern/decorator.html","title":"装饰器模式","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 装饰器模式 继承和组合？ [TOC] 装饰器模式 意图：动态地给一个对象添加一些额外的职责。就增加功能来说，装饰器模式相比生成子类更为灵活。 主要解决：一般的，我们为了扩展一个类经常使用继承方式实现，由于继承为类引入静态特征，并且随着扩展功能的增多，子类会很膨胀。 何时使用：在不想增加很多子类的情况下扩展类。 如何解决：将具体功能职责划分，同时继承装饰者模式。 eg: Shape 可以 draw public interface Shape { void draw(); } 继承方式，给draw加一个红色边框处理修饰 public class RedShapeDecorator extends ShapeDecorator { public RedShapeDecorator(Shape decoratedShape) { super(decoratedShape); } @Override public void draw() { decoratedShape.draw(); setRedBorder(decoratedShape); } private void setRedBorder(Shape decoratedShape){ System.out.println(\"Border Color: Red\"); } } 继承和组合？ 继承(Is A?) 在继承中，子类自动继承父类的非私有成员(default类型视是否同包而定)，在需要时，可选择直接使用或重写。 在继承中，创建子类对象时，无需创建父类对象，因为系统会自动完成；而在组合中，创建组合类的对象时，通常需要创建其所使用的所有类的对象。 组合(Has A?) 在组合中，组合类与调用类之间低耦合；而在继承中子类与父类高耦合。 可动态组合。 合成复用原则（Composite Reuse Principle，CRP）又叫组合/聚合复用原则（Composition/Aggregate Reuse Principle，CARP）。它要求在软件复用时，要尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-17 09:53:30 "},"content/design_pattern/observer.html":{"url":"content/design_pattern/observer.html","title":"观察者模式","keywords":"","body":"[TOC] 观察者模式 观察者模式使用三个类: Subject(被观察的主体)、Observer(观察者) 和 Client Subject的操作会通知所有注册的Observer,Subject可以添加删除Observer Subject package design; import java.util.List; import java.util.Vector; /** * @Author mubi * @Date 2020/6/17 09:27 */ public class Subject { private List observers = new Vector<>(); private int state; public int getState() { return state; } public void setState(int state) { this.state = state; notifyAllObservers(); } public void addObserver(Observer observer){ observers.add(observer); } public void delObserver(Observer observer){ observers.remove(observer); } public void notifyAllObservers(){ for (Observer observer : observers) { observer.update(); } } } Observer 抽象类 package design; /** * @Author mubi * @Date 2020/6/17 09:27 */ public abstract class Observer { protected Subject subject; public abstract void update(); } 具体的Observer类 package design; /** * @Author mubi * @Date 2020/6/17 09:27 */ public class BinaryObserver extends Observer { public BinaryObserver(Subject subject) { this.subject = subject; } @Override public void update() { System.out.println(\"Binary String: \" + Integer.toBinaryString(subject.getState())); } } package design; /** * @Author mubi * @Date 2020/6/17 09:28 */ public class OctalObserver extends Observer { public OctalObserver(Subject subject) { this.subject = subject; } @Override public void update() { System.out.println(\"Octal String: \" + Integer.toOctalString(subject.getState())); } } 测试 package design; /** * @Author mubi * @Date 2020/6/17 09:32 */ public class DesignTest { public static void main(String[] args) { Subject subject = new Subject(); Observer observer1 = new BinaryObserver(subject); Observer observer2 = new OctalObserver(subject); subject.addObserver(observer1); subject.addObserver(observer2); subject.setState(10); System.out.println(); subject.setState(12); System.out.println(); subject.delObserver(observer1); subject.setState(13); System.out.println(); } } 输出： Binary String: 1010 Octal String: 12 Binary String: 1100 Octal String: 14 Octal String: 15 // 此前删除了 BinaryObserver Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-17 09:58:57 "},"content/design_pattern/visitor.html":{"url":"content/design_pattern/visitor.html","title":"访问者模式","keywords":"","body":"[TOC] 访问者(Visitor)模式 如果访问操作在类里面，想要另外一种访问方式，不得不修改类； 将访问操作独立出来，想要另外一种访问方式直接新增一个类，设计新的访问方式 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-25 11:04:08 "},"content/design_pattern/iterator.html":{"url":"content/design_pattern/iterator.html","title":"迭代器模式","keywords":"","body":"[TOC] 迭代器模式 如：集合中常见的迭代器 定义：迭代器模式提供了一种方法顺序访问一个聚合对象中的各个元素，而又无需暴露该对象的内部实现，这样既可以做到不暴露集合的内部结构，又可让外部代码透明地访问集合内部的数据 比如LeetCode:173. 二叉搜索树迭代器,可以内部各种方式实现，但是对外就是如下两个方法 public int next() public boolean hasNext() ac /** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) { val = x; } * } */ class BSTIterator { // O(h)的存储 Stack sta; private void left2Stack(TreeNode root){ while (root != null){ sta.push(root); root = root.left; } } public BSTIterator(TreeNode root) { sta = new Stack<>(); left2Stack(root); } /** @return the next smallest number */ public int next() { TreeNode node = sta.pop(); if(node.right != null){ left2Stack(node.right); } return node.val; } /** @return whether we have a next smallest number */ public boolean hasNext() { return ! sta.isEmpty(); } } /** * Your BSTIterator object will be instantiated and called as such: * BSTIterator obj = new BSTIterator(root); * int param_1 = obj.next(); * boolean param_2 = obj.hasNext(); */ Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-28 06:29:55 "},"content/design_pattern/facade.html":{"url":"content/design_pattern/facade.html","title":"门面模式","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Facade模式 门面类 [TOC] Facade模式 n.(建筑物的) 正面，立面; (虚假的) 表面，外表; 美[fəˈsɑːd] 门面模式；外观模式 外部与一个子系统的通信必须通过一个统一的门面(Facade)对象进行，这就是门面模式。 eg1: 如果把医院作为一个子系统，按照部门职能，这个系统可以划分为挂号、门诊、划价、化验、收费、取药等。看病的病人要与这些部门打交道，就如同一个子系统的客户端与一个子系统的各个类打交道一样，不是一件容易的事情。---> 接待员 eg2: 造个房子：找水泥工，找瓦匠，木匠，装修等各样的活，也是要与这些角色意义打交道。---> 包工头 门面类 综合电话机和相机功能的门面类 public class FacadeCameraPhone { private Phone mPhone; private Camera mCamera; public FacadeCameraPhone() { mPhone = new PhoneImpl(); mCamera = new CameraImpl(); } public void deil(){ mPhone.dail(); } public void close(){ mPhone.hangup(); } public void takePicture(){ mCamera.takePicture(); } } Camera public interface Camera { //拍照片 void takePicture(); Phone public interface Phone { //打电话 void dail(); //挂电话 void hangup(); } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-17 16:34:28 "},"content/java_data_structure/java_basic_datastructure.html":{"url":"content/java_data_structure/java_basic_datastructure.html","title":"常见基础数据结构","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Java常用数据结构和原理 Map Map.EntryK,V(interface) AbstractMap(abstract class) HashMap(class) 底层实现是数组+链表（Java8中链表长度超过8个会转换为树结构） 单链表结构 树结构 null key(可以)， null val(可以) 与 实际例子 key的hash方法(null的hash值设置成了0) put 方法 非线程安全 遍历的无序性 Hashtable(class) 实现了Map，继承了Dictionary，底层数组(散列表)+链表(拉链法) null key, null value（不可以） 线程安全，基本上操作方法都加上了synchronized关键字 put方法 LinkedHashMap(class) 底层是HashMap,并维持一个双向链表 遍历的有序性 非线程安全，可以null key,null value等 SortedMap（interface） 元素遍历可以按键的排序顺序进行 NavigableMap (interface) 方法 TreeMap(类) 底层基于红黑树 不允许 null key， 可以 null value key排序，可以指定comparator List(interface) List 继承自 Collection，其添加了以下操作方法 Queue(interface) 普通队列 Queue接口的基础方法 使用例子 Deque(interface) 双向队列，继承了Queue ArrayList(class) 数组 LinkedList(class)链表(同时实现了List 和 Deque接口) 内部的Node结构(双向链表) Vector(class)线程安全的数组 线程安全,操作方法基本加上了synchronized关键字 PriorityQueue(class) 优先队列 实例 Stack(class) 继承了Vector, 基于数组，线程安全 Set(interface) HashSet(class) 底层基于 HashMap, key不同 允许元素为null (因为HasMap允许null key) LinkedHashSet(class) 具有set集合不重复的特点，同时具有可预测的迭代顺序 非线程安全 SortedSet(interface) NavigableSet(interface) 继承 SortedSet TreeSet(class) 唯一实现了SortedSet的 不允许 null 值 非线程安全，树结构 [TOC] Java常用数据结构和原理 Map Map.Entry(interface) AbstractMap(abstract class) public abstract class AbstractMap implements Map { 实现一些Map的基础方法 HashMap(class) public class HashMap extends AbstractMap implements Map, Cloneable, Serializable { 底层实现是数组+链表（Java8中链表长度超过8个会转换为树结构） /* ---------------- Fields -------------- */ /** * The table, initialized on first use, and resized as * necessary. When allocated, length is always a power of two. * (We also tolerate length zero in some operations to allow * bootstrapping mechanics that are currently not needed.) */ transient Node[] table; /** * Holds cached entrySet(). Note that AbstractMap fields are used * for keySet() and values(). */ transient Set> entrySet; /** * The number of key-value mappings contained in this map. */ transient int size; /** * The number of times this HashMap has been structurally modified * Structural modifications are those that change the number of mappings in * the HashMap or otherwise modify its internal structure (e.g., * rehash). This field is used to make iterators on Collection-views of * the HashMap fail-fast. (See ConcurrentModificationException). */ transient int modCount; /** * The next size value at which to resize (capacity * load factor). * * @serial */ // (The javadoc description is true upon serialization. // Additionally, if the table array has not been allocated, this // field holds the initial array capacity, or zero signifying // DEFAULT_INITIAL_CAPACITY.) int threshold; /** * The load factor for the hash table. * * @serial */ final float loadFactor; 单链表结构 static class Node implements Map.Entry { final int hash; final K key; V value; Node next; Node(int hash, K key, V value, Node next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + \"=\" + value; } public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry e = (Map.Entry)o; if (Objects.equals(key, e.getKey()) && Objects.equals(value, e.getValue())) return true; } return false; } } 树结构 /** * Entry for Tree bins. Extends LinkedHashMap.Entry (which in turn * extends Node) so can be used as extension of either regular or * linked node. */ static final class TreeNode extends LinkedHashMap.Entry { TreeNode parent; // red-black tree links TreeNode left; TreeNode right; TreeNode prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node next) { super(hash, key, val, next); } null key(可以)， null val(可以) 与 实际例子 Map mp = new HashMap<>(); mp.put(null, null); mp.put(null, \"a\"); mp.put(\"a\", null); mp.forEach((key,val)->{ System.out.println(String.format(\"\", key, val)); }); output key的hash方法(null的hash值设置成了0) static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16); } put 方法 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node[] tab; Node p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) & hash]) == null) // 数组的位置上是否存在元素，否则数组的位置上创建节点 tab[i] = newNode(hash, key, value, null); else { Node e; K k; if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k)))) e = p; else if (p instanceof TreeNode) // 数组的位置上节点不是单链表了，而是树 e = ((TreeNode)p).putTreeVal(this, tab, hash, key, value); else { for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); // 超过8个的链表 转换为树结构 if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) break; p = e; } } if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; if (++size > threshold) // 超过平衡因子，数组扩容 resize(); afterNodeInsertion(evict); return null; } 非线程安全 遍历的无序性 Map mp = new HashMap<>(); mp.put(null, null); mp.put(null, \"a\"); mp.put(\"b\", null); mp.put(\"a\", \"a\"); Set> entries = mp.entrySet(); Iterator> iteratorMap = entries.iterator(); while (iteratorMap.hasNext()){ Map.Entry next = iteratorMap.next(); System.out.println(next); } mp.forEach((key, val)->{ System.out.println(String.format(\"%s=%s\", key,val)); }); /* output null=a a=a b=null */ Hashtable(class) public class Hashtable extends Dictionary implements Map, Cloneable, java.io.Serializable { 实现了Map，继承了Dictionary，底层数组(散列表)+链表(拉链法) /** * The hash table data. */ private transient Entry[] table; /** * The total number of entries in the hash table. */ private transient int count; /** * The table is rehashed when its size exceeds this threshold. (The * value of this field is (int)(capacity * loadFactor).) * * @serial */ private int threshold; /** * The load factor for the hashtable. * * @serial */ private float loadFactor; /** * The number of times this Hashtable has been structurally modified * Structural modifications are those that change the number of entries in * the Hashtable or otherwise modify its internal structure (e.g., * rehash). This field is used to make iterators on Collection-views of * the Hashtable fail-fast. (See ConcurrentModificationException). */ private transient int modCount = 0; /** use serialVersionUID from JDK 1.0.2 for interoperability */ private static final long serialVersionUID = 1421746759512286392L; null key, null value（不可以） Java8程序 Map mp = new Hashtable<>(); // key value 都不能为null，否则java.lang.NullPointerException // mp.put(null, null); // mp.put(null, \"a\"); // mp.put(\"a\", null); mp.put(\"a\", \"a\"); mp.forEach((key,val)->{ System.out.println(String.format(\"\", key, val)); }); 线程安全，基本上操作方法都加上了synchronized关键字 put方法 /** * Maps the specified key to the specified * value in this hashtable. Neither the key nor the * value can be null. * * The value can be retrieved by calling the get method * with a key that is equal to the original key. * * @param key the hashtable key * @param value the value * @return the previous value of the specified key in this hashtable, * or null if it did not have one * @exception NullPointerException if the key or value is * null * @see Object#equals(Object) * @see #get(Object) */ public synchronized V put(K key, V value) { // Make sure the value is not null if (value == null) { throw new NullPointerException(); } // Makes sure the key is not already in the hashtable. Entry tab[] = table; int hash = key.hashCode(); int index = (hash & 0x7FFFFFFF) % tab.length; @SuppressWarnings(\"unchecked\") Entry entry = (Entry)tab[index]; for(; entry != null ; entry = entry.next) { if ((entry.hash == hash) && entry.key.equals(key)) { V old = entry.value; entry.value = value; return old; } } addEntry(hash, key, value, index); return null; } LinkedHashMap(class) public class LinkedHashMap extends HashMap implements Map { 底层是HashMap,并维持一个双向链表 /** * HashMap.Node subclass for normal LinkedHashMap entries. */ static class Entry extends HashMap.Node { Entry before, after; Entry(int hash, K key, V value, Node next) { super(hash, key, value, next); } } private static final long serialVersionUID = 3801124242820219131L; /** * The head (eldest) of the doubly linked list. */ transient LinkedHashMap.Entry head; /** * The tail (youngest) of the doubly linked list. */ transient LinkedHashMap.Entry tail; /** * The iteration ordering method for this linked hash map: true * for access-order, false for insertion-order. * * @serial */ final boolean accessOrder; // internal utilities // link at the end of list private void linkNodeLast(LinkedHashMap.Entry p) { LinkedHashMap.Entry last = tail; tail = p; if (last == null) head = p; else { p.before = last; last.after = p; } } // apply src's links to dst private void transferLinks(LinkedHashMap.Entry src, LinkedHashMap.Entry dst) { LinkedHashMap.Entry b = dst.before = src.before; LinkedHashMap.Entry a = dst.after = src.after; if (b == null) head = dst; else b.after = dst; if (a == null) tail = dst; else a.before = dst; } 遍历的有序性 Map mp = new LinkedHashMap<>(); mp.put(null, null); mp.put(null, \"a\"); mp.put(\"b\", null); mp.put(\"a\", \"a\"); Set> entries = mp.entrySet(); Iterator> iteratorMap = entries.iterator(); while (iteratorMap.hasNext()){ Map.Entry next = iteratorMap.next(); System.out.println(next); } mp.forEach((key, val)->{ System.out.println(String.format(\"%s=%s\", key,val)); }); /* output null=a b=null a=a */ 非线程安全，可以null key,null value等 SortedMap（interface） public interface SortedMap extends Map { 元素遍历可以按键的排序顺序进行 NavigableMap (interface) public interface NavigableMap extends SortedMap { 方法 // 找到第一个比指定的key小的值 Map.Entry lowerEntry(K key); // 找到第一个比指定的key小的key K lowerKey(K key); // 找到第一个小于或等于指定key的值 Map.Entry floorEntry(K key); // 找到第一个小于或等于指定key的key K floorKey(K key); // 找到第一个大于或等于指定key的值 Map.Entry ceilingEntry(K key); K ceilingKey(K key); // 找到第一个大于指定key的值 Map.Entry higherEntry(K key); K higherKey(K key); // 获取最小值 Map.Entry firstEntry(); // 获取最大值 Map.Entry lastEntry(); // 删除最小的元素 Map.Entry pollFirstEntry(); // 删除最大的元素 Map.Entry pollLastEntry(); //返回一个倒序的Map NavigableMap descendingMap(); // 返回一个Navigable的key的集合，NavigableSet和NavigableMap类似 NavigableSet navigableKeySet(); // 对上述集合倒序 NavigableSet descendingKeySet(); TreeMap(类) public class TreeMap extends AbstractMap implements NavigableMap, Cloneable, java.io.Serializable { 底层基于红黑树 红黑树能保证增、删、查等基本操作的时间复杂度为O(lgN) /** * The comparator used to maintain order in this tree map, or * null if it uses the natural ordering of its keys. * * @serial */ private final Comparator comparator; private transient Entry root; /** * The number of entries in the tree */ private transient int size = 0; /** * The number of structural modifications to the tree. */ private transient int modCount = 0; 不允许 null key， 可以 null value key排序，可以指定comparator Comparator comparator = (a, b) -> { int vala = ((Integer)a); int valb = ((Integer)b); if(vala > valb){ return -1; } if(vala mp = new TreeMap(comparator); mp.put(1, null); mp.put(3, \"a\"); mp.put(2, \"a\"); mp.forEach((key, val)->{ System.out.println(String.format(\"%d=%s\", key,val)); }); List(interface) public interface List extends Collection { List 继承自 Collection，其添加了以下操作方法 位置相关：List 的元素是有序的，因此有get(index)、set(index,object)、add(index,object)、remove(index) 方法。 搜索：indexOf()，lastIndexOf(); 迭代：使用 Iterator 的功能板迭代器 范围性操作：使用 subList 方法对 list 进行任意范围操作。 Queue(interface) 普通队列 public interface Queue extends Collection { Queue接口的基础方法 /** * Inserts the specified element into this queue if it is possible to do so * immediately without violating capacity restrictions, returning * {@code true} upon success and throwing an {@code IllegalStateException} * if no space is currently available. * * @param e the element to add * @return {@code true} (as specified by {@link Collection#add}) * @throws IllegalStateException if the element cannot be added at this * time due to capacity restrictions * @throws ClassCastException if the class of the specified element * prevents it from being added to this queue * @throws NullPointerException if the specified element is null and * this queue does not permit null elements * @throws IllegalArgumentException if some property of this element * prevents it from being added to this queue */ boolean add(E e); /** * Inserts the specified element into this queue if it is possible to do * so immediately without violating capacity restrictions. * When using a capacity-restricted queue, this method is generally * preferable to {@link #add}, which can fail to insert an element only * by throwing an exception. * * @param e the element to add * @return {@code true} if the element was added to this queue, else * {@code false} * @throws ClassCastException if the class of the specified element * prevents it from being added to this queue * @throws NullPointerException if the specified element is null and * this queue does not permit null elements * @throws IllegalArgumentException if some property of this element * prevents it from being added to this queue */ boolean offer(E e); /** * Retrieves and removes the head of this queue. This method differs * from {@link #poll poll} only in that it throws an exception if this * queue is empty. * * @return the head of this queue * @throws NoSuchElementException if this queue is empty */ E remove(); /** * Retrieves and removes the head of this queue, * or returns {@code null} if this queue is empty. * * @return the head of this queue, or {@code null} if this queue is empty */ E poll(); /** * Retrieves, but does not remove, the head of this queue. This method * differs from {@link #peek peek} only in that it throws an exception * if this queue is empty. * * @return the head of this queue * @throws NoSuchElementException if this queue is empty */ E element(); /** * Retrieves, but does not remove, the head of this queue, * or returns {@code null} if this queue is empty. * * @return the head of this queue, or {@code null} if this queue is empty */ E peek(); 使用例子 public static void main(String[] args) { Queue queue = new LinkedList<>(); queue.offer(1); queue.offer(null); queue.offer(2); while(!queue.isEmpty()){ Integer i = queue.poll(); System.out.println(i); } } /* output 1 null 2 */ Deque(interface) 双向队列，继承了Queue public interface Deque extends Queue { ArrayList(class) 数组 public class ArrayList extends AbstractList implements List, RandomAccess, Cloneable, java.io.Serializable { LinkedList(class)链表(同时实现了List 和 Deque接口) public class LinkedList extends AbstractSequentialList implements List, Deque, Cloneable, java.io.Serializable { 内部的Node结构(双向链表) private static class Node { E item; Node next; Node prev; Node(Node prev, E element, Node next) { this.item = element; this.next = next; this.prev = prev; } } Vector(class)线程安全的数组 public class Vector extends AbstractList implements List, RandomAccess, Cloneable, java.io.Serializable { 线程安全,操作方法基本加上了synchronized关键字 PriorityQueue(class) 优先队列 public class PriorityQueue extends AbstractQueue implements java.io.Serializable { 实例 Comparator comparator = (a, b)->{ int va = (Integer)a; int vb = (Integer)b; if(va > vb){ return -1; } if(va queue = new PriorityQueue(comparator); queue.offer(1); queue.offer(3); queue.offer(2); while (!queue.isEmpty()){ System.out.println(queue.poll()); } Stack(class) public class Stack extends Vector { 继承了Vector, 基于数组，线程安全 public class Stack extends Vector { /** * Creates an empty Stack. */ public Stack() { } /** * Pushes an item onto the top of this stack. This has exactly * the same effect as: * * addElement(item) * * @param item the item to be pushed onto this stack. * @return the item argument. * @see java.util.Vector#addElement */ public E push(E item) { addElement(item); return item; } /** * Removes the object at the top of this stack and returns that * object as the value of this function. * * @return The object at the top of this stack (the last item * of the Vector object). * @throws EmptyStackException if this stack is empty. */ public synchronized E pop() { E obj; int len = size(); obj = peek(); removeElementAt(len - 1); return obj; } /** * Looks at the object at the top of this stack without removing it * from the stack. * * @return the object at the top of this stack (the last item * of the Vector object). * @throws EmptyStackException if this stack is empty. */ public synchronized E peek() { int len = size(); if (len == 0) throw new EmptyStackException(); return elementAt(len - 1); } /** * Tests if this stack is empty. * * @return true if and only if this stack contains * no items; false otherwise. */ public boolean empty() { return size() == 0; } /** * Returns the 1-based position where an object is on this stack. * If the object o occurs as an item in this stack, this * method returns the distance from the top of the stack of the * occurrence nearest the top of the stack; the topmost item on the * stack is considered to be at distance 1. The equals * method is used to compare o to the * items in this stack. * * @param o the desired object. * @return the 1-based position from the top of the stack where * the object is located; the return value -1 * indicates that the object is not on the stack. */ public synchronized int search(Object o) { int i = lastIndexOf(o); if (i >= 0) { return size() - i; } return -1; } /** use serialVersionUID from JDK 1.0.2 for interoperability */ private static final long serialVersionUID = 1224463164541339165L; } Set(interface) public interface Set extends Collection { HashSet(class) public class HashSet extends AbstractSet implements Set, Cloneable, java.io.Serializable { 底层基于 HashMap, key不同 static final long serialVersionUID = -5024744406713321676L; private transient HashMap map; // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); /** * Constructs a new, empty set; the backing HashMap instance has * default initial capacity (16) and load factor (0.75). */ public HashSet() { map = new HashMap<>(); } 允许元素为null (因为HasMap允许null key) Set se = new HashSet<>(); se.add(null); se.add(1); se.forEach(val->{ System.out.println(val); }); LinkedHashSet(class) public class LinkedHashSet extends HashSet implements Set, Cloneable, java.io.Serializable { 具有set集合不重复的特点，同时具有可预测的迭代顺序 非线程安全 SortedSet(interface) public interface SortedSet extends Set { NavigableSet(interface) 继承 SortedSet public interface NavigableSet extends SortedSet { TreeSet(class) 唯一实现了SortedSet的 public class TreeSet extends AbstractSet implements NavigableSet, Cloneable, java.io.Serializable { 不允许 null 值 非线程安全，树结构 可以由TreeMap实现 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-18 15:07:00 "},"content/java_data_structure/array_list.html":{"url":"content/java_data_structure/array_list.html","title":"ArrayList & LinkedList","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 ArrayList （数组，非线程安全） add(E e) add(int index, E element) remove(int index) 迭代器remove报错ConcurrentModificationException LinkedList（链表） add(E e) add(int index, E element) remove(int index) get 索引 Vector [TOC] ArrayList （数组，非线程安全） get直接获取O(1) reemove都要移动元素O(n) add可能扩容(new，遍历拷贝)，或者是插入(遍历移动)O(n) add(E e) /** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return true (as specified by {@link Collection#add}) */ public boolean add(E e) { ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true; } private void ensureCapacityInternal(int minCapacity) { ensureExplicitCapacity(calculateCapacity(elementData, minCapacity)); } private void ensureExplicitCapacity(int minCapacity) { modCount++; // overflow-conscious code if (minCapacity - elementData.length > 0) grow(minCapacity); } private void grow(int minCapacity) { // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity >> 1); if (newCapacity - minCapacity 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); } 如有扩容，则需new新数组，然后遍历拷贝 add(int index, E element) /** * Inserts the specified element at the specified position in this * list. Shifts the element currently at that position (if any) and * any subsequent elements to the right (adds one to their indices). * * @param index index at which the specified element is to be inserted * @param element element to be inserted * @throws IndexOutOfBoundsException {@inheritDoc} */ public void add(int index, E element) { rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++; } 插入要System.arraycopy移动元素 remove(int index) /** * Removes the element at the specified position in this list. * Shifts any subsequent elements to the left (subtracts one from their * indices). * * @param index the index of the element to be removed * @return the element that was removed from the list * @throws IndexOutOfBoundsException {@inheritDoc} */ public E remove(int index) { rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved > 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue; } 迭代器remove报错ConcurrentModificationException mubi@mubideMacBook-Pro hotload $ vim Solution.java mubi@mubideMacBook-Pro hotload $ javac Solution.java 注: Solution.java使用了未经检查或不安全的操作。 注: 有关详细信息, 请使用 -Xlint:unchecked 重新编译。 mubi@mubideMacBook-Pro hotload $ java Solution Exception in thread \"main\" java.util.ConcurrentModificationException at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:909) at java.util.ArrayList$Itr.next(ArrayList.java:859) at Solution.main(Solution.java:13) mubi@mubideMacBook-Pro hotload $ cat Solution cat: Solution: No such file or directory mubi@mubideMacBook-Pro hotload $ cat Solution.java import java.util.*; class Solution { public static void main(String[] args) { List list = new ArrayList() {{ add(\"Java\"); add(\"Scalar\"); add(\"Kotlin\"); add(\"Groovy\"); }}; for (String item : list) { list.remove(item); } } } System.arraycopy移动元素 LinkedList（链表） addLast O(1), 插入要遍历前面的链表元素O(n) remove O(1) get 遍历O(n) 双向链表 public class LinkedList extends AbstractSequentialList implements List, Deque, Cloneable, java.io.Serializable { transient int size = 0; /** * Pointer to first node. * Invariant: (first == null && last == null) || * (first.prev == null && first.item != null) */ transient Node first; /** * Pointer to last node. * Invariant: (first == null && last == null) || * (last.next == null && last.item != null) */ transient Node last; /** * Constructs an empty list. */ public LinkedList() { } add(E e) /** * Appends the specified element to the end of this list. * * This method is equivalent to {@link #addLast}. * * @param e element to be appended to this list * @return {@code true} (as specified by {@link Collection#add}) */ public boolean add(E e) { linkLast(e); return true; } /** * Links e as last element. */ void linkLast(E e) { final Node l = last; final Node newNode = new Node<>(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++; } add(int index, E element) /** * Inserts the specified element at the specified position in this list. * Shifts the element currently at that position (if any) and any * subsequent elements to the right (adds one to their indices). * * @param index index at which the specified element is to be inserted * @param element element to be inserted * @throws IndexOutOfBoundsException {@inheritDoc} */ public void add(int index, E element) { checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index)); } remove(int index) /** * Removes the element at the specified position in this list. Shifts any * subsequent elements to the left (subtracts one from their indices). * Returns the element that was removed from the list. * * @param index the index of the element to be removed * @return the element previously at the specified position * @throws IndexOutOfBoundsException {@inheritDoc} */ public E remove(int index) { checkElementIndex(index); return unlink(node(index)); } /** * Unlinks non-null node x. */ E unlink(Node x) { // assert x != null; final E element = x.item; final Node next = x.next; final Node prev = x.prev; if (prev == null) { first = next; } else { prev.next = next; x.prev = null; } if (next == null) { last = prev; } else { next.prev = prev; x.next = null; } x.item = null; size--; modCount++; return element; } get 索引 /** * Returns the (non-null) Node at the specified element index. */ Node node(int index) { // assert isElementIndex(index); if (index > 1)) { Node x = first; for (int i = 0; i x = last; for (int i = size - 1; i > index; i--) x = x.prev; return x; } } 需要遍历链表 Vector Vector使用同步方法实现(synchronized) ArrayList不可以设置扩展的容量, 默认1.5倍; Vector可以设置, 默认2倍 ArrayList无参构造函数中初始量为0; Vector的无参构造函数初始容量为10 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-28 14:56:48 "},"content/java_data_structure/hash_map.html":{"url":"content/java_data_structure/hash_map.html","title":"HashMap","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 HashMap 链表结构和红黑树结构 为什么有链表和红黑树 put方法 扩容 删除 被 transient 所修饰 table 变量 为什么Java中的HashMap默认加载因子是0.75？ 有序? LinkedHashMap(HashMap + 双向链表) TreeMap（红黑树） [TOC] HashMap hash表 + 链表(拉链法) + 红黑树 hash冲突，拉链；链表过长，则转化为红黑树 链表结构和红黑树结构 链表结构 /** * Basic hash bin node, used for most entries. (See below for * TreeNode subclass, and in LinkedHashMap for its Entry subclass.) */ static class Node implements Map.Entry { final int hash; final K key; V value; Node next; Node(int hash, K key, V value, Node next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + \"=\" + value; } public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry e = (Map.Entry)o; if (Objects.equals(key, e.getKey()) && Objects.equals(value, e.getValue())) return true; } return false; } } 红黑树结构 /** * Entry for Tree bins. Extends LinkedHashMap.Entry (which in turn * extends Node) so can be used as extension of either regular or * linked node. */ static final class TreeNode extends LinkedHashMap.Entry { TreeNode parent; // red-black tree links TreeNode left; TreeNode right; TreeNode prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node next) { super(hash, key, val, next); } static class Node implements Map.Entry { final int hash; final K key; V value; Node next; Node(int hash, K key, V value, Node next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + \"=\" + value; } public final int hashCode() { return Objects.hashCode(key) ^ Objects.hashCode(value); } public final V setValue(V newValue) { V oldValue = value; value = newValue; return oldValue; } public final boolean equals(Object o) { if (o == this) return true; if (o instanceof Map.Entry) { Map.Entry e = (Map.Entry)o; if (Objects.equals(key, e.getKey()) && Objects.equals(value, e.getValue())) return true; } return false; } } 平衡二叉树查找很快但是插入/删除时因为保持平衡需要旋转的平均次数较多不适应于插入/删除频繁的场景，红黑树则是插入和查找都能兼顾的平衡方案 为什么有链表和红黑树 时间和空间的综合考虑 * Because TreeNodes are about twice the size of regular nodes, we * use them only when bins contain enough nodes to warrant use * (see TREEIFY_THRESHOLD). And when they become too small (due to * removal or resizing) they are converted back to plain bins. In * usages with well-distributed user hashCodes, tree bins are * rarely used. Ideally, under random hashCodes, the frequency of * nodes in bins follows a Poisson distribution * (http://en.wikipedia.org/wiki/Poisson_distribution) with a * parameter of about 0.5 on average for the default resizing * threshold of 0.75, although with a large variance because of * resizing granularity. Ignoring variance, the expected * occurrences of list size k are (exp(-0.5) * pow(0.5, k) / * factorial(k)). The first values are: put方法 public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node[] tab; Node p; int n, i; // 初始化桶数组 table，table 被延迟到插入新数据时再进行初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 如果桶中不包含键值对节点引用，则将新键值对节点的引用存入桶中即可 if ((p = tab[i = (n - 1) & hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node e; K k; // 如果键的值以及节点 hash 等于链表中的第一个键值对节点时，则将 e 指向该键值对 if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k)))) e = p; // 如果桶中的引用类型为 TreeNode，则调用红黑树的插入方法 else if (p instanceof TreeNode) e = ((TreeNode)p).putTreeVal(this, tab, hash, key, value); else { // 对链表进行遍历，并统计链表长度 for (int binCount = 0; ; ++binCount) { // 链表中不包含要插入的键值对节点时，则将该节点接在链表的最后 if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); // 如果链表长度大于或等于树化阈值，则进行树化操作 if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } // 条件为 true，表示当前链表包含要插入的键值对，终止遍历 if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) break; p = e; } } // 判断要插入的键值对是否存在 HashMap 中 if (e != null) { // existing mapping for key V oldValue = e.value; // onlyIfAbsent 表示是否仅在 oldValue 为 null 的情况下更新键值对的值 if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount; // 键值对数量超过阈值时，则进行扩容 if (++size > threshold) resize(); afterNodeInsertion(evict); return null; } 拉链超过TREEIFY_THRESHOLD=8,则链表转化为红黑树 扩容 /** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */ final Node[] resize() { Node[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 如果 table 不为空，表明已经初始化过了 if (oldCap > 0) { // 当 table 容量超过容量最大值，则不再扩容 if (oldCap >= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } // 按旧容量和阈值的2倍计算新容量和阈值的大小 else if ((newCap = oldCap = DEFAULT_INITIAL_CAPACITY) newThr = oldThr 0) // initial capacity was placed in threshold /* * 初始化时，将 threshold 的值赋值给 newCap， * HashMap 使用 threshold 变量暂时保存 initialCapacity 参数的值 */ newCap = oldThr; else { // zero initial threshold signifies using defaults /* * 调用无参构造方法时，桶数组容量为默认容量， * 阈值为默认容量与默认负载因子乘积 */ newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // newThr 为 0 时，按阈值计算公式进行计算 if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap [] newTab = (Node[])new Node[newCap]; table = newTab; if (oldTab != null) { // 如果旧的桶数组不为空，则遍历桶数组，并将键值对映射到新的桶数组中 for (int j = 0; j e; if ((e = oldTab[j]) != null) { oldTab[j] = null; if (e.next == null) newTab[e.hash & (newCap - 1)] = e; else if (e instanceof TreeNode) // 重新映射时，需要对红黑树进行拆分 ((TreeNode)e).split(this, newTab, j, oldCap); else { // preserve order Node loHead = null, loTail = null; Node hiHead = null, hiTail = null; Node next; // 遍历链表，并将链表节点按原顺序进行分组 do { next = e.next; if ((e.hash & oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); // 将分组后的链表映射到新桶中 if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } 计算新桶数组的容量 newCap 和新阈值 newThr 根据计算出的 newCap 创建新的桶数组，桶数组 table 也是在这里进行初始化的(new新hash表，遍历重新设置) 将键值对节点重新映射到新的桶数组里。如果节点是 TreeNode 类型，则需要拆分红黑树。如果是普通节点，则节点按原顺序进行分组 删除 public V remove(Object key) { Node e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; } final Node removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) { Node[] tab; Node p; int n, index; if ((tab = table) != null && (n = tab.length) > 0 && // 1. 定位桶位置 (p = tab[index = (n - 1) & hash]) != null) { Node node = null, e; K k; V v; // 如果键的值与链表第一个节点相等，则将 node 指向该节点 if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k)))) node = p; else if ((e = p.next) != null) { // 如果是 TreeNode 类型，调用红黑树的查找逻辑定位待删除节点 if (p instanceof TreeNode) node = ((TreeNode)p).getTreeNode(hash, key); else { // 2. 遍历链表，找到待删除节点 do { if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) { node = e; break; } p = e; } while ((e = e.next) != null); } } // 3. 删除节点，并修复链表或红黑树 if (node != null && (!matchValue || (v = node.value) == value || (value != null && value.equals(v)))) { if (node instanceof TreeNode) ((TreeNode)node).removeTreeNode(this, tab, movable); else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; } } return null; } 节点数量小于TREEIFY_THRESHOLD=8，红黑树转化为链表 被 transient 所修饰 table 变量 HashMap 的桶数组 table 被申明为transient。transient表示易变的意思，在 Java 中，被该关键字修饰的变量不会被默认的序列化机制序列化，而是通过实现readObject/writeObject两个方法自定义了序列化的内容 为什么Java中的HashMap默认加载因子是0.75？ static final float DEFAULT_LOAD_FACTOR = 0.75f; 加载因子是表示Hash表中元素的填满的程度。 加载因子越大,填满的元素越多,空间利用率越高，但冲突的机会加大了。 反之,加载因子越小,填满的元素越少,冲突的机会减小,但空间浪费多了。 HashMap docs As a general rule, the default load factor (.75) offers a good tradeoff between time and space costs. Higher values decrease the space overhead but increase the lookup cost (reflected in most of the operations of the HashMap class, including get and put). The expected number of entries in the map and its load factor should be taken into account when setting its initial capacity, so as to minimize the number of rehash operations. If the initial capacity is greater than the maximum number of entries divided by the load factor, no rehash operations will ever occur. 通常，默认负载因子（0.75）在时间和空间成本之间提供了一个很好的折衷方案。较高的值会减少空间开销，但会增加查找成本（在HashMap类的大多数操作中都得到体现，包括get和put）。设置映射表的初始容量时，应考虑映射中的预期条目数及其负载因子，以最大程度地减少重新哈希操作的数量。如果初始容量大于最大条目数除以负载因子，则将不会进行任何哈希操作。 有序? LinkedHashMap(HashMap + 双向链表) public class LinkedHashMap extends HashMap implements Map { 对比普通的HashMap.Node，其增加了before和after,用来顺序连接 /** * HashMap.Node subclass for normal LinkedHashMap entries. */ static class Entry extends HashMap.Node { Entry before, after; Entry(int hash, K key, V value, Node next) { super(hash, key, value, next); } } TreeMap（红黑树） public class TreeMap extends AbstractMap implements NavigableMap, Cloneable, java.io.Serializable { TreeMap 为大多数操作提供平均logN的性能，如add（），remove（）和contains（） Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-16 19:56:01 "},"content/java_data_structure/hash_table.html":{"url":"content/java_data_structure/hash_table.html","title":"HashTable","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 HashTable 链表结构 put方法 rehash [TOC] HashTable 数组 + 链表（拉链） Hashtable 继承于Dictionary，实现了Map、Cloneable、java.io.Serializable接口 Hashtable 的函数都是同步(synchronized)的，这意味着它是线程安全的。它的key、value都不可以为null。此外，Hashtable中的映射不是有序的 链表结构 /** * Hashtable bucket collision list entry */ private static class Entry implements Map.Entry { final int hash; final K key; V value; Entry next; protected Entry(int hash, K key, V value, Entry next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } @SuppressWarnings(\"unchecked\") protected Object clone() { return new Entry<>(hash, key, value, (next==null ? null : (Entry) next.clone())); } // Map.Entry Ops public K getKey() { return key; } public V getValue() { return value; } public V setValue(V value) { if (value == null) throw new NullPointerException(); V oldValue = this.value; this.value = value; return oldValue; } public boolean equals(Object o) { if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; return (key==null ? e.getKey()==null : key.equals(e.getKey())) && (value==null ? e.getValue()==null : value.equals(e.getValue())); } public int hashCode() { return hash ^ Objects.hashCode(value); } public String toString() { return key.toString()+\"=\"+value.toString(); } } put方法 public synchronized V put(K key, V value) { // Make sure the value is not null // key（如果为 null，计算哈希值时会抛异常），value 不允许为 null if (value == null) { throw new NullPointerException(); } // Makes sure the key is not already in the hashtable. Entry tab[] = table; int hash = key.hashCode(); // 计算对应的桶位置 int index = (hash & 0x7FFFFFFF) % tab.length; @SuppressWarnings(\"unchecked\") Entry entry = (Entry)tab[index]; // 如果桶位置上对应的链表不为 null，则遍历该链表 for(; entry != null ; entry = entry.next) { // key 重复，value 替换，返回老的 value if ((entry.hash == hash) && entry.key.equals(key)) { V old = entry.value; entry.value = value; return old; } } // 添加新的键值对 addEntry(hash, key, value, index); // 添加成功返回 null return null; } private void addEntry(int hash, K key, V value, int index) { modCount++; Entry tab[] = table; // 延迟 rehash？先判断是否需要扩容再 count++ if (count >= threshold) { // Rehash the table if the threshold is exceeded rehash(); tab = table; hash = key.hashCode(); // 扩容后，新的键值对对应的桶位置可能会发生变化，因此要重新计算桶位置 index = (hash & 0x7FFFFFFF) % tab.length; } // Creates the new entry. @SuppressWarnings(\"unchecked\") // 获取桶位置上的链表 Entry e = (Entry) tab[index]; // 头插法插入键值对 tab[index] = new Entry<>(hash, key, value, e); // count++ count++; } rehash protected void rehash() { // 获取老哈希表容量 int oldCapacity = table.length; Entry[] oldMap = table; // overflow-conscious code // 新哈希表容量为原容量的 2 倍 + 1，与 HashMap 不同 int newCapacity = (oldCapacity 0) { if (oldCapacity == MAX_ARRAY_SIZE) // Keep running with MAX_ARRAY_SIZE buckets return; newCapacity = MAX_ARRAY_SIZE; } // 初始化新哈希表数组 Entry[] newMap = new Entry[newCapacity]; modCount++; // 重置扩容阈值，与 HashMap 不同，HashMap 直接把 threshold 也扩大为原来的两倍 threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1); // 重置哈希表数组 table = newMap; // 从底向上进行 rehash for (int i = oldCapacity ; i-- > 0 ;) { // 获取旧哈希表对应桶位置上的链表 for (Entry old = (Entry)oldMap[i] ; old != null ; ) { // 链表 Entry e = old; // 重置继续遍历 old = old.next; // 获取在新哈希表中的桶位置，键值对逐个进行 rehash // HashMap 会构造一个新的链表然后整个链表进行 rehash int index = (e.hash & 0x7FFFFFFF) % newCapacity; // 头插法 rehash e.next = (Entry)newMap[index]; // 自己做头节点 newMap[index] = e; } } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-09 22:12:11 "},"content/java_utils/Map.html":{"url":"content/java_utils/Map.html","title":"HashMap,HashTable,ConcurrentHashMap 对比","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 HashMap 数组 + 链表 的实现方式 拉链法解决冲突 非线程安全 HashTable key,value都不能为null 线程安全 底层实现类似Hashmap，也是拉链法 HashMap, Hashtable的区别 ConcurrentHashMap(JDK 1.7) 分段的数组+链表实现，线程安全 put get size ConcurrentHashMap(JDK 1.8) Node数组,链表,红黑树 put 对比 Jdk1.7 [TOC] HashMap 数组 + 链表 的实现方式 import java.util.HashMap; import java.util.Map; import java.util.Objects; public class Main { public static void main(String[] args) throws Exception { Map mp = new HashMap<>(16); mp.put(1, \"a\"); mp.put(2, \"b\"); mp.put(null, null); mp.put(null, \"c\"); mp.put(3, null); System.out.println( Objects.hashCode(null)); mp.entrySet().stream().forEach(m -> { Map.Entry keyVal = m; System.out.println(keyVal.getKey() + \":\" + keyVal.getValue()); }); } } /*output 0 null:c 1:a 2:b 3:null */ 数组是HashMap的主体，链表则是主要为了解决哈希冲突而存在的(拉链法解决冲突) 拉链法解决冲突 /** * The number of key-value mappings contained in this map. */ transient int size; // `null`也是有`hashcode`的 static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16); } public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node[] tab; Node p; int n, i; // 是否扩容 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 数组中是否有链表 if ((p = tab[i = (n - 1) & hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node e; K k; if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode)p).putTreeVal(this, tab, hash, key, value); else { // 数组中的链表遍历 for (int binCount = 0; ; ++binCount) { if ((e = p.next) == null) { p.next = newNode(hash, key, value, null); if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k)))) break; p = e; } } // 链表中存在该key，新值替换旧值 if (e != null) { // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } // 是否需要调整数组 ++modCount; if (++size > threshold) resize(); // 不存在key，旧插入到链表中 afterNodeInsertion(evict); return null; } /** * Initializes or doubles table size. If null, allocates in * accord with initial capacity target held in field threshold. * Otherwise, because we are using power-of-two expansion, the * elements from each bin must either stay at same index, or move * with a power of two offset in the new table. * * @return the table */ final Node[] resize() { 非线程安全 建议在单线程，不需要同步的时候，用HashMap HashTable key,value都不能为null import java.util.Hashtable; import java.util.Map; import java.util.Objects; public class Main { public static void main(String[] args) throws Exception { Map mp = new Hashtable<>(16); mp.put(1, \"a\"); mp.put(2, \"b\"); // Hashtable key,value不能为null, 否则报`java.lang.NullPointerException` // mp.put(null, \"c\"); // mp.put(3, null); System.out.println( Objects.hashCode(null)); mp.entrySet().stream().forEach(m -> { Map.Entry keyVal = m; System.out.println(keyVal.getKey() + \":\" + keyVal.getValue()); }); } } /*output 0 2:b 1:a */ 线程安全 方法都加上了synchronized关键词, synchronized是针对整张Hash表的，即每次锁住整张表让线程独占 底层实现类似Hashmap，也是拉链法 public synchronized V put(K key, V value) { // Make sure the value is not null if (value == null) { throw new NullPointerException(); } // Makes sure the key is not already in the hashtable. Entry tab[] = table; int hash = key.hashCode(); int index = (hash & 0x7FFFFFFF) % tab.length; @SuppressWarnings(\"unchecked\") Entry entry = (Entry)tab[index]; for(; entry != null ; entry = entry.next) { if ((entry.hash == hash) && entry.key.equals(key)) { V old = entry.value; entry.value = value; return old; } } addEntry(hash, key, value, index); return null; } private void addEntry(int hash, K key, V value, int index) { modCount++; Entry tab[] = table; if (count >= threshold) { // Rehash the table if the threshold is exceeded rehash(); tab = table; hash = key.hashCode(); index = (hash & 0x7FFFFFFF) % tab.length; } // Creates the new entry. @SuppressWarnings(\"unchecked\") Entry e = (Entry) tab[index]; tab[index] = new Entry<>(hash, key, value, e); count++; } HashMap, Hashtable的区别 HashMap几乎可以等价于Hashtable，除了HashMap是非synchronized的，并可以接受null(HashMap可以接受为null的键值(key)和值(value)，而Hashtable则不行)。 HashMap是非synchronized，而Hashtable是synchronized，这意味着Hashtable是线程安全的，多个线程可以共享一个Hashtable；而如果没有正确的同步的话，多个线程是不能共享HashMap的。Java 5提供了ConcurrentHashMap，它是HashTable的替代，比HashTable的扩展性更好。 另一个区别是HashMap的迭代器(Iterator)是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException，但迭代器本身的remove()方法移除元素则不会抛出ConcurrentModificationException异常。但这并不是一个一定发生的行为，要看JVM。这条同样也是Enumeration和Iterator的区别。 由于Hashtable是线程安全的也是synchronized，所以在单线程环境下它比HashMap要慢。如果你不需要同步，只需要单一线程，那么使用HashMap性能要好过Hashtable。 HashMap不能保证随着时间的推移Map中的元素次序是不变的。 ConcurrentHashMap(JDK 1.7) 分段的数组+链表实现，线程安全 /** * The segments, each of which is a specialized hash table. */ final Segment[] segments; static final class Segment extends ReentrantLock implements Serializable { transient volatile HashEntry[] table; put public V put(K key, V value) { Segment s; if (value == null) throw new NullPointerException(); // 第一次 先 hash 定位到 segment 的位置 int hash = hash(key); int j = (hash >>> segmentShift) & segmentMask; if ((s = (Segment)UNSAFE.getObject // nonvolatile; recheck (segments, (j node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try { // 找 HashEntry HashEntry[] tab = table; int index = (tab.length - 1) & hash; HashEntry first = entryAt(tab, index); for (HashEntry e = first;;) { if (e != null) { K k; if ((k = e.key) == key || (e.hash == hash && key.equals(k))) { oldValue = e.value; if (!onlyIfAbsent) { e.value = value; ++modCount; } break; } e = e.next; } else { if (node != null) node.setNext(first); else node = new HashEntry(hash, key, value, first); int c = count + 1; if (c > threshold && tab.length get hash => Segment => HashEntry => 遍历链表 /** * Returns the value to which the specified key is mapped, * or {@code null} if this map contains no mapping for the key. * * More formally, if this map contains a mapping from a key * {@code k} to a value {@code v} such that {@code key.equals(k)}, * then this method returns {@code v}; otherwise it returns * {@code null}. (There can be at most one such mapping.) * * @throws NullPointerException if the specified key is null */ public V get(Object key) { Segment s; // manually integrate access methods to reduce overhead HashEntry[] tab; int h = hash(key); long u = (((h >>> segmentShift) & segmentMask) )UNSAFE.getObjectVolatile(segments, u)) != null && (tab = s.table) != null) { for (HashEntry e = (HashEntry) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) & h)) size 并发操作 第一种方案他会使用不加锁的模式去尝试多次计算ConcurrentHashMap的size，最多三次，比较前后两次计算的结果，结果一致就认为当前没有元素加入，计算的结果是准确的 第二种方案是如果第一种方案不符合，他就会给每个Segment加上锁，然后计算ConcurrentHashMap的size返回 /** * Returns the number of key-value mappings in this map. If the * map contains more than Integer.MAX_VALUE elements, returns * Integer.MAX_VALUE. * * @return the number of key-value mappings in this map */ public int size() { // Try a few times to get accurate count. On failure due to // continuous async changes in table, resort to locking. final Segment[] segments = this.segments; int size; boolean overflow; // true if size overflows 32 bits long sum; // sum of modCounts long last = 0L; // previous sum int retries = -1; // first iteration isn't retry try { for (;;) { if (retries++ == RETRIES_BEFORE_LOCK) { for (int j = 0; j seg = segmentAt(segments, j); if (seg != null) { sum += seg.modCount; int c = seg.count; if (c RETRIES_BEFORE_LOCK) { for (int j = 0; j ConcurrentHashMap(JDK 1.8) Node数组,链表,红黑树 当链表的节点数大于8时会转换成红黑树的结构 put public V put(K key, V value) { return putVal(key, value, false); } /** Implementation for put and putIfAbsent */ final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException(); //两次hash，减少hash冲突，可以均匀分布 int hash = spread(key.hashCode()); int binCount = 0; for (Node[] tab = table;;) { Node f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); // 如果i位置没有数据，就直接无锁插入 else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) { if (casTabAt(tab, i, null, new Node(hash, key, value, null))) break; // no lock when adding to empty bin } // 如果在进行扩容，则先进行扩容操作 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { V oldVal = null; // 加锁操作，存在hash冲突，锁住链表或者红黑树的头结点 synchronized (f) { if (tabAt(tab, i) == f) { // 表示该节点是链表结构 if (fh >= 0) { binCount = 1; for (Node e = f;; ++binCount) { K ek; if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node pred = e; if ((e = e.next) == null) { pred.next = new Node(hash, key, value, null); break; } } } // 红黑数 else if (f instanceof TreeBin) { Node p; binCount = 2; if ((p = ((TreeBin)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } // static final int TREEIFY_THRESHOLD = 8; 链表长度大于8转换为红黑树 if (binCount != 0) { if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } // 统计size，并且检查是否需要扩容 addCount(1L, binCount); return null; } 对比 Jdk1.7 JDK1.8的实现降低锁的粒度，JDK1.7版本锁的粒度是基于Segment的，包含多个HashEntry，而JDK1.8锁的粒度就是HashEntry（首节点） JDK1.8使用红黑树来优化链表，基于长度很长的链表的遍历是一个很漫长的过程，而红黑树的遍历效率是很快的，代替一定阈值的链表 相对而言低粒度加锁方式，synchronized并不比ReentrantLock差 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-09 13:23:43 "},"content/java_data_structure/fail_fast.html":{"url":"content/java_data_structure/fail_fast.html","title":"fail-fast,ConcurrentModificationException","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 fail-fast（快速失败） fail-safe（安全失败） [TOC] fail-fast（快速失败） fail-fast,即快速失败机制，它是Java集合中的一种错误检测机制，它只能被用来检测错误，因为JDK并不保证fail-fast机制一定会发生 当多个线程在结构上对集合进行改变时，就有可能会产生fail-fast机制。 如：在使用迭代器对集合对象进行遍历的时候，如果 A 线程正在对集合进行遍历，此时 B 线程对集合进行修改（增加、删除、修改），或者 A 线程在遍历过程中对集合进行修改，都会导致 A 线程抛出 ConcurrentModificationException 异常。 eg： import java.util.ArrayList; import java.util.Iterator; import java.util.List; public class Main { private static List list = new ArrayList<>(); // 添加 private static class ThreadA extends Thread{ ThreadA(){ this.setName(\"A\"); } @Override public void run() { Iterator iterator = list.iterator(); while(iterator.hasNext()){ int i = iterator.next(); System.out.println(\"ThreadOne 遍历:\" + i); try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } } } // 修改 private static class ThreadB extends Thread{ ThreadB(){ this.setName(\"B\"); } @Override public void run(){ int i = 0 ; while(i output ThreadOne 遍历:0 ThreadTwo run：0 ThreadTwo run：1 ThreadTwo run：2 ThreadTwo run：3 ThreadTwo run：4 ThreadTwo run：5 Exception in thread \"A\" java.util.ConcurrentModificationException at java.util.ArrayList$Itr.checkForComodification(ArrayList.java:909) at java.util.ArrayList$Itr.next(ArrayList.java:859) at Main$ThreadA.run(Main.java:24) fail-safe（安全失败） 采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。 由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，故不会抛 ConcurrentModificationException 异常 import java.util.Iterator; import java.util.List; import java.util.concurrent.CopyOnWriteArrayList; public class Main { private static List list = new CopyOnWriteArrayList<>(); // 添加 private static class ThreadA extends Thread{ ThreadA(){ this.setName(\"A\"); } @Override public void run() { Iterator iterator = list.iterator(); while(iterator.hasNext()){ int i = iterator.next(); System.out.println(\"ThreadOne 遍历:\" + i); try { Thread.sleep(10); } catch (InterruptedException e) { e.printStackTrace(); } } } } // 修改 private static class ThreadB extends Thread{ ThreadB(){ this.setName(\"B\"); } @Override public void run(){ int i = 0 ; while(i output ThreadOne 遍历:0 ThreadTwo run：0 ThreadTwo run：1 ThreadTwo run：2 ThreadTwo run：3 ThreadTwo run：4 ThreadTwo run：5 ThreadOne 遍历:1 ThreadOne 遍历:2 ThreadOne 遍历:3 ThreadOne 遍历:4 ThreadOne 遍历:5 ThreadOne 遍历:6 ThreadOne 遍历:7 ThreadOne 遍历:8 ThreadOne 遍历:9 0 1 2 4 5 6 7 8 9 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-09 13:00:27 "},"content/java_utils/quick_sort.html":{"url":"content/java_utils/quick_sort.html","title":"快排(没事手写写)","keywords":"","body":"[TOC] Java快排 int partion(int[] arr, int left, int right){ int pivot = arr[left]; int i = left; int j = right; while(i = pivot){ j --; } arr[i] = arr[j]; while(i = right){ return; } int pos = partion(arr, left, right); quickSort(arr, left, pos - 1); quickSort(arr, pos + 1, right); } public static void main(String[] args) throws Exception { Solution solution = new Solution(); int[] arr = {4,3,5, 6,8,1, 4, 2,7,9}; int n = arr.length; for(int i=0;i Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-04 18:49:56 "},"content/java_data_structure/concurrent_datastructure.html":{"url":"content/java_data_structure/concurrent_datastructure.html","title":"concurrent数据结构","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 concurrent数据结构 ConcurrentMap(interface) ConcurrentHashMap(class) 底层:数组+链表/红黑树，CAS + synchronized控制并发 put方法 获取size 对比Java7分段锁优劣 Java7分段锁的实现 锁粒度小 扩容不足与改进 ConcurrentLinkedQueue(class) 无界线程安全 CopyOnWriteArrayList(class) 适合读多写少的并发场景 add方法使用ReentrantLock 缺点 CopyOnWriteArraySet(class 基于 CopyOnWriteArrayList) ArrayBlockingQueue(class) 基于数组的阻塞队列 LinkedBlockingDeque(class) 基于链表的阻塞队列 链表 put方法，添加元素 offer方法，添加元素 take 方法，取元素 基于LinkedBlockingQueue的生产者和消费者 TODO [TOC] concurrent数据结构 ConcurrentMap(interface) public interface ConcurrentMap extends Map { ConcurrentHashMap(class) public class ConcurrentHashMap extends AbstractMap implements ConcurrentMap, Serializable { 每个桶可能是链表结构或者红黑树结构，锁针对桶的头节点加，锁粒度小 底层:数组+链表/红黑树，CAS + synchronized控制并发 /* ---------------- Fields -------------- */ /** * The array of bins. Lazily initialized upon first insertion. * Size is always a power of two. Accessed directly by iterators. */ transient volatile Node[] table; /** * The next table to use; non-null only while resizing. */ private transient volatile Node[] nextTable; /** * Base counter value, used mainly when there is no contention, * but also as a fallback during table initialization * races. Updated via CAS. */ private transient volatile long baseCount; /** * Table initialization and resizing control. When negative, the * table is being initialized or resized: -1 for initialization, * else -(1 + the number of active resizing threads). Otherwise, * when table is null, holds the initial table size to use upon * creation, or 0 for default. After initialization, holds the * next element count value upon which to resize the table. */ private transient volatile int sizeCtl; /** * The next table index (plus one) to split while resizing. */ private transient volatile int transferIndex; /** * Spinlock (locked via CAS) used when resizing and/or creating CounterCells. */ private transient volatile int cellsBusy; /** * Table of counter cells. When non-null, size is a power of 2. */ private transient volatile CounterCell[] counterCells; // views private transient KeySetView keySet; private transient ValuesView values; private transient EntrySetView entrySet; put方法 /** Implementation for put and putIfAbsent */ final V putVal(K key, V value, boolean onlyIfAbsent) { // key, value 都不能为null if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node[] tab = table;;) { Node f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) { // CAS方式进行添加结点 if (casTabAt(tab, i, null, new Node(hash, key, value, null))) break; // no lock when adding to empty bin } else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); else { V oldVal = null; // synchronized 同步操作 synchronized (f) { if (tabAt(tab, i) == f) { if (fh >= 0) { binCount = 1; for (Node e = f;; ++binCount) { K ek; if (e.hash == hash && ((ek = e.key) == key || (ek != null && key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node pred = e; if ((e = e.next) == null) { pred.next = new Node(hash, key, value, null); break; } } } else if (f instanceof TreeBin) { Node p; binCount = 2; if ((p = ((TreeBin)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } } if (binCount != 0) { if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } addCount(1L, binCount); return null; } 先判断key和value是否为null，为null则抛出异常 判断table是否初始化，如果没有则进行初始化 计算key的hash值，并得到插入的数组索引。 找到table[i]的位置，如果为null直接插入，如果不为null判断此key是否存在，如果存在直接覆盖，如果不存在进行判断如果head节点是树节点，按照红黑树的方式插入新的节点，如果不是则按照链表的方式插入，同时会判断当前的链表长度是否大于TREEIFY_THRESHOLD=8，如果大于则转为红黑树再插入，否则直接插入，插入采用的CAS自旋的方式。 最后判断table的size是否需要扩容，如果需要则扩容，否则就结束。在扩容的时候会在链表头部插入forward，如果其他线程检测到需要插入的位置被forward节点占有，就帮助进行扩容。 获取size /** * Returns the number of mappings. This method should be used * instead of {@link #size} because a ConcurrentHashMap may * contain more mappings than can be represented as an int. The * value returned is an estimate; the actual count may differ if * there are concurrent insertions or removals. * * @return the number of mappings * @since 1.8 */ public long mappingCount() { long n = sumCount(); return (n 一个大概的数值，因为可能在统计的时候有其他线程正在执行插入或删除操作 对比Java7分段锁优劣 Java7分段锁的实现 eg, new ConcurrentHashMap(): Segment 数组长度为 16，不可以扩容 Segment[i] 的默认大小为 2，负载因子是 0.75，得出初始阈值为 1.5，也就是以后插入第一个元素不会触发扩容，插入第二个会进行第一次扩容 这里初始化了 segment[0]，其他位置还是 null put操作是，先根据 hash 值很快就能找到相应的 Segment，之后就是 Segment 内部的 put 操作了 锁粒度小 只需要锁住这个链表/红黑树的head节点，并不会影响其他的table元素的读写，影响更小 扩容不足与改进 在于并发扩容的时候，由于操作的table都是同一个，不像JDK7中分段控制，所以这里需要等扩容完之后，所有的读写操作才能进行，所以扩容的效率就成为了整个并发的一个瓶颈点 引入了一个ForwardingNode类，在一个线程发起扩容的时候，就会改变sizeCtl这个值 sizeCtl ：默认为0，用来控制table的初始化和扩容操作，具体应用在后续会体现出来。 -1 代表table正在初始化 -N 表示有N-1个线程正在进行扩容操作 其余情况： 1、如果table未初始化，表示table需要初始化的大小。 2、如果table初始化完成，表示table的容量，默认是table大小的0.75倍 扩容时候会判断这个值，如果超过阈值就要扩容，首先根据运算得到需要遍历的次数i，然后利用tabAt方法获得i位置的元素f，初始化一个forwardNode实例fwd，如果f == null，则在table中的i位置放入fwd，否则采用头插法的方式把当前旧table数组的指定任务范围的数据给迁移到新的数组中，然后 给旧table原位置赋值fwd。直到遍历过所有的节点以后就完成了复制工作，把table指向nextTable，并更新sizeCtl为新数组大小的0.75倍 ，扩容完成。在此期间如果其他线程的有读写操作都会判断head节点是否为forwardNode节点，如果是就帮助扩容。 参考 作者：葬月魔帝 来源：CSDN 原文：理解Java7和8里面HashMap+ConcurrentHashMap的扩容策略 版权声明：本文为博主原创文章，转载请附上博文链接！ ConcurrentLinkedQueue(class) 无界线程安全 public class ConcurrentLinkedQueue extends AbstractQueue implements Queue, java.io.Serializable { private static final long serialVersionUID = 196745693267521676L; CopyOnWriteArrayList(class) 适合读多写少的并发场景 public class CopyOnWriteArrayList implements List, RandomAccess, Cloneable, java.io.Serializable { CopyOnWriteArrayList是线程安全的ArrayList, 读方法不加锁，写方法加锁 读写分离，写时复制出一个新的数组，完成插入、修改或者移除操作后将新数组赋值给array 如果读的时候有多个线程正在向CopyOnWriteArrayList添加数据，读还是会读到旧的数据，因为写的时候不会锁住旧的 volatile 修饰的成员变量在每次被线程访问时，都强迫从共享内存中重读该成员变量的值。而且，当成员变量发生变 化时，强迫线程将变化值回写到共享内存。这样在任何时刻，两个不同的线程总是看到某个成员变量的同一个值。 add方法使用ReentrantLock public boolean add(E e) { final ReentrantLock lock = this.lock; lock.lock(); try { Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; } finally { lock.unlock(); } } 缺点 内存占用问题 因为CopyOnWrite的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存，旧的对象和新写入的对象（注意:在复制的时候只是复制容器里的引用，只是在写的时候会创建新对象添加到新容器里，而旧容器的对象还在使用，所以有两份对象内存）。如果这些对象占用的内存比较大，比如说200M左右，那么再写入100M数据进去，内存就会占用300M，那么这个时候很有可能造成频繁的Yong GC和Full GC。之前我们系统中使用了一个服务由于每晚使用CopyOnWrite机制更新大对象，造成了每晚15秒的Full GC，应用响应时间也随之变长。针对内存占用问题，可以通过压缩容器中的元素的方法来减少大对象的内存消耗，比如，如果元素全是10进制的数字，可以考虑把它压缩成36进制或64进制。或者不使用CopyOnWrite容器，而使用其他的并发容器，如ConcurrentHashMap。 数据一致性问题(只保证最终一致性) CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。 CopyOnWriteArraySet(class 基于 CopyOnWriteArrayList) public class CopyOnWriteArraySet extends AbstractSet implements java.io.Serializable { private static final long serialVersionUID = 5457747651344034263L; private final CopyOnWriteArrayList al; /** * Creates an empty set. */ public CopyOnWriteArraySet() { al = new CopyOnWriteArrayList(); } /** * Creates a set containing all of the elements of the specified * collection. * * @param c the collection of elements to initially contain * @throws NullPointerException if the specified collection is null */ public CopyOnWriteArraySet(Collection c) { if (c.getClass() == CopyOnWriteArraySet.class) { @SuppressWarnings(\"unchecked\") CopyOnWriteArraySet cc = (CopyOnWriteArraySet)c; al = new CopyOnWriteArrayList(cc.al); } else { al = new CopyOnWriteArrayList(); al.addAllAbsent(c); } } add操作采用CopyOnWriteArrayList的addIfAbsent方法，加了锁保护，并创建一个新的Object数组；每次add都要进行数组的遍历，性能低 ArrayBlockingQueue(class) 基于数组的阻塞队列 public class ArrayBlockingQueue extends AbstractQueue implements BlockingQueue, java.io.Serializable { 基于数组，先进先出，现场安全的集合类，特点是：可执行时间的阻塞读写，并且容量有限 LinkedBlockingDeque(class) 基于链表的阻塞队列 public class LinkedBlockingDeque extends AbstractQueue implements BlockingDeque, java.io.Serializable { 链表 /** * Linked list node class */ static class Node { E item; /** * One of: * - the real successor Node * - this Node, meaning the successor is head.next * - null, meaning there is no successor (this is the last node) */ Node next; Node(E x) { item = x; } } /** The capacity bound, or Integer.MAX_VALUE if none */ private final int capacity; /** Current number of elements */ private final AtomicInteger count = new AtomicInteger(); /** * Head of linked list. * Invariant: head.item == null */ transient Node head; /** * Tail of linked list. * Invariant: last.next == null */ private transient Node last; put方法，添加元素 /** * Inserts the specified element at the tail of this queue, waiting if * necessary for space to become available. * * @throws InterruptedException {@inheritDoc} * @throws NullPointerException {@inheritDoc} */ public void put(E e) throws InterruptedException { if (e == null) throw new NullPointerException(); // Note: convention in all put/take/etc is to preset local var // holding count negative to indicate failure unless set. int c = -1; Node node = new Node(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { /* * Note that count is used in wait guard even though it is * not protected by lock. This works because count can * only decrease at this point (all other puts are shut * out by lock), and we (or some other waiting put) are * signalled if it ever changes from capacity. Similarly * for all other uses of count in other wait guards. */ while (count.get() == capacity) { notFull.await(); } enqueue(node); c = count.getAndIncrement(); if (c + 1 使用了ReentrantLock,若向队尾添加元素的时候发现队列已经满了会发生阻塞一直等待空间，以加入元素。 offer方法，添加元素 public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException { if (e == null) throw new NullPointerException(); long nanos = unit.toNanos(timeout); int c = -1; final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try { while (count.get() == capacity) { if (nanos (e)); c = count.getAndIncrement(); if (c + 1 如果发现队列已满无法添加的话，等待指定时间后会直接返回false take 方法，取元素 public E take() throws InterruptedException { E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try { while (count.get() == 0) { notEmpty.await(); } x = dequeue(); c = count.getAndDecrement(); if (c > 1) notEmpty.signal(); } finally { takeLock.unlock(); } if (c == capacity) signalNotFull(); return x; } 若队列为空，则发生阻塞，一直等待有元素 基于LinkedBlockingQueue的生产者和消费者 import java.util.Random; import java.util.concurrent.LinkedBlockingQueue; import java.util.concurrent.TimeUnit; class Basket{ LinkedBlockingQueue linkedBlockingQueue; public Basket(int size){ linkedBlockingQueue = new LinkedBlockingQueue<>(size); } public void addToBasket(String s) throws InterruptedException{ linkedBlockingQueue.put(s); } public String getFromBasket() throws InterruptedException{ return linkedBlockingQueue.take(); } } class Producer{ private Basket basket; public Producer(Basket basket){ this.basket = basket; } public void produce(String s){ try { this.basket.addToBasket(s); }catch (Exception e){ e.printStackTrace(); } } public void print(){ System.out.println(this.basket.linkedBlockingQueue); } } class Consumer{ private Basket basket; public Consumer(Basket basket){ this.basket = basket; } public String consume(){ try { return this.basket.getFromBasket(); }catch (Exception e){ e.printStackTrace(); } return null; } public void print(){ System.out.println(this.basket.linkedBlockingQueue); } } class Main { public static void main(String[] args) throws Exception { Basket basket = new Basket(3); Producer producer = new Producer(basket); Consumer consumer = new Consumer(basket); new Thread(()->{ while (true) { try{ TimeUnit.SECONDS.sleep(2); }catch (Exception e){ } int r = new Random().nextInt(10); String s = \"\" + r; producer.produce(s); System.out.print(\"produce:\" + s + \" queue: \"); producer.print(); } }).start(); new Thread(()->{ while (true) { try { TimeUnit.SECONDS.sleep(3); } catch (Exception e) { } String s = consumer.consume(); System.out.print(\"consumer:\" + s + \" queue: \"); consumer.print(); } }).start(); } } TODO Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-24 11:35:45 "},"content/java_data_structure/advanced_structure.html":{"url":"content/java_data_structure/advanced_structure.html","title":"高级数据结构","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 高级数据结构 Hash表，Hash索引 hash索引的限制 B Tree 局部性原理与磁盘预读 磁盘IO 与 B Tree 应用 B+ Tree 定义 B+ tree 数据库索引 B+ tree 优势 红黑树 Trie Tree(字典树) Log Structured Merge Trees（日志结构的合并树） 磁盘的读写快慢问题 LSM Tree 分析 适用场景 // TODO [TOC] 高级数据结构 Hash表，Hash索引 数据库Hash索引参考：https://blog.csdn.net/olizxq/article/details/82313489 Hash索引不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash索引的查询效率要远高于 B-Tree 索引 hash索引的限制 哈希索引只包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行。 哈希索引数据并不是按照索引值顺序存储的，所以也就无法用于排序。 哈希索引也不支持部分索引列匹配查找，因为哈希索引始终是使用索引列的全部内容来计算哈希值的。 哈希索引只支持等值比较查询，包括=、IN()、<>（注意<>和是不同的操作）。也不支持任何范围查询，例如WHERE price>100。 访问哈希索引的数据非常快，除非有很多哈希冲突（不同的索引列值却有相同的哈希值）。当出现哈希冲突的时候，存储引擎必须遍历链表中所有的行指针，逐行进行比较，直到找到所有符合条件的行。 如果哈希冲突很多的话，一些索引维护操作的代价也会很高。例如，如果在某个选择性很低（哈希冲突很多）的列上建立哈希索引，那么当从表中删除一行时，存储引擎需要遍历对应哈希值的链表中的每一行，找到并删除对应行的引用，冲突越多，代价越大。 B Tree 多路搜索树, 关键字集合分布在整棵树中(非叶子节点和叶子节点都有关键字) 局部性原理与磁盘预读 由于磁盘的存取速度与内存之间鸿沟,为了提高效率,要尽量减少磁盘I/O.磁盘往往不是严格按需读取，而是每次都会预读,磁盘读取完需要的数据,会顺序向后读一定长度的数据放入内存。 磁盘IO 与 B Tree 应用 磁盘读取依靠的是机械运动，分为寻道时间、旋转延迟、传输时间三个部分，这三个部分耗时相加就是一次磁盘IO的时间 数据库索引是存储在磁盘上，当表中的数据量比较大时，索引的大小也跟着增长，达到几个G甚至更多。当我们利用索引进行查询的时候，不可能把索引全部加载到内存中，只能逐一加载每个磁盘页，这里的磁盘页就对应索引树的节点。当访问一个地址数据的时候，与其相邻的数据很快也会被访问到。每次磁盘IO读取的数据我们称之为一页（page）。一页的大小与操作系统有关，一般为4k或者8k。这也就意味着读取一页内数据的时候，实际上发生了一次磁盘IO。 减少磁盘IO的次数就必须要压缩树的高度 B树主要应用于文件系统以及部分数据库索引 B+ Tree 定义 树中每个非叶结点最多有 m 棵子树； 根结点 (非叶结点) 至少有 2 棵子树。除根结点外, 其它的非叶结点至少有 ém/2ù 棵子树；有 n 棵子树的非叶结点有 n-1 个关键码。 所有叶结点都处于同一层次上，包含了全部关键码及指向相应数据对象存放地址的指针，且叶结点本身按关键码从小到大顺序链接； 每个叶结点中的子树棵数 n 可以多于 m，可以少于 m，视关键码字节数及对象地址指针字节数而定。 若设结点可容纳最大关键码数为 m1，则指向对象的地址指针也有 m1 个。 结点中的子树棵数 n 应满足 n 属于[m1/2, m1] 若根结点同时又是叶结点，则结点格式同叶结点。 所有的非叶结点可以看成是索引部分，结点中关键码 Ki 与指向子树的指针 Pi 构成对子树 (即下一层索引块) 的索引项 ( Ki, Pi )，Ki 是子树中最小的关键码。 特别地，子树指针 P0 所指子树上所有关键码均小于 K1。结点格式同B树。 叶结点中存放的是对实际数据对象的索引。 在B+树中有两个头指针：一个指向B+树的根结点，一个指向关键码最小的叶结点。 B+ tree 与 B tree 的不同之处 所有关键字存储在叶子节点，非叶子节点不存储真正的data 为所有叶子节点增加了一个链指针 B+ tree 数据库索引 B+ tree 优势 B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大 B+树更适合外部存储,由于内节点无 data 域,一个结点可以存储更多的内结点,每个节点能索引的范围更大更精确,也意味着 B+树单次磁盘IO的信息量大于B-树,I/O效率更高。 关系数据库的区间访问是常见的一种情况，B+树叶节点增加的链指针,加强了区间访问性，可使用在范围区间查询等，而B-树每个节点 key 和 data 在一起，则无法区间查找(或者说，B树的区间查找代价太大)。 红黑树 性质1. 节点是红色或黑色。 性质2. 根节点是黑色。 性质3. 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点) 性质4. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。 从根到叶子的最长的可能路径不多于最短的可能路径的两倍长 红黑树高度依然是平均log(n)，且最坏情况高度不会超过2log(n)。 任何不平衡都会在3次旋转之内解决， 红黑树能够以O(log2(N))的时间复杂度进行搜索、插入、删除操作 Trie Tree(字典树) 参考：https://blog.csdn.net/qq_26437925/article/category/5773761 Log Structured Merge Trees（日志结构的合并树） 磁盘的读写快慢问题 顺序读写磁盘（不管是SATA还是SSD）快于随机读写主存，而且快至少三个数量级 LSM Tree 分析 适用场景 // TODO Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-24 11:35:58 "},"content/java_data_structure/b_tree.html":{"url":"content/java_data_structure/b_tree.html","title":"B/B+ Tree","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 B Tree(多路搜索树) 磁盘相关 B+ Tree 对比B树 红黑树 Hash hash索引 [TOC] B Tree(多路搜索树) 关键字集合分布在整颗树中 任何一个关键字出现且只出现在一个结点中 搜索有可能在非叶子结点结束 其搜索性能等价于在关键字全集内做一次二分查找 磁盘相关 磁盘读取依靠的是机械运动，分为寻道时间、旋转延迟、传输时间三个部分，这三个部分耗时相加就是一次磁盘IO的时间，大概9ms左右。这个成本是访问内存的10w倍左右 预读: 每一次IO时，不仅仅把当前磁盘地址的数据加载到内存，同时也把相邻数据也加载到内存缓冲区中(程序局部性原理) 每次磁盘IO读取的数据我们称之为一页（page）。一页的大小与操作系统有关，一般为4k或者8k。这也就意味着读取一页内数据的时候，实际上发生了一次磁盘IO 数据库索引是存储在磁盘上，当表中的数据量比较大时，索引的大小也跟着增长，达到几个G甚至更多。当我们利用索引进行查询的时候，不可能把索引全部加载到内存中，只能逐一加载每个磁盘页，这里的磁盘页就对应索引树的节点 **减少磁盘IO**的次数就必须要**压缩树的高度** B+ Tree 红点表示是指向卫星数据的指针，指针指向的是存放实际数据的磁盘页，卫星数据就是数据库中一条数据记录 叶子节点中还有一个指向下一个叶子节点的next指针，所以叶子节点形成了一个有序的链表，方便遍历B+树 对比B树 所有数据存在叶子节点，其它节点不存储数据，只存储索引。那么同样大小的磁盘页可以容纳更多的节点元素，如此一来，相同数量的数据下，B+树就相对来说要更加矮胖些，磁盘IO的次数更少。 由于只有叶子节点才保存卫星数据，B+树每次查询都要到叶子节点；而B树每次查询则不一样，最好的情况是根节点，最坏的情况是叶子节点，没有B+树稳定 叶子节点形成有顺链表，范围查找性能更优 红黑树 查找，插入和删除等操作都是平均O(logn)时间内 从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。结果是这个树大致上是平衡的。因为操作比如插入、删除和查找某个值的最坏情况时间都要求与树的高度成比例，这个在高度上的理论上限允许红黑树在最坏情况下都是高效的，而不同于普通的二叉查找树。 Hash hash索引 哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快 对比B+树 如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据 如果是范围查询检索，这时候哈希索引就毫无用武之地了，因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索 哈希索引也没办法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询） 哈希索引也不支持多列联合索引的最左匹配规则 B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题（如：Java8 HashMap 拉链法后又补充了红黑树转换） Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-30 13:13:48 "},"content/java_data_structure/System_arraycopy.html":{"url":"content/java_data_structure/System_arraycopy.html","title":"System.arraycopy, Array.copyOf","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 System.arraycopy 浅拷贝 对比for效率高 非线程安全 Array.copyOf [TOC] System.arraycopy 使用说明： /* * @param src the source array. 源数组 * @param srcPos starting position in the source array. 源数组要复制的起始位置 * @param dest the destination array. 目标数组 * @param destPos starting position in the destination data. 目标数组放置的起始位置； * @param length the number of array elements to be copied. 要复制的长度 * @exception IndexOutOfBoundsException if copying would cause * access of data outside array bounds. dest数组大小比src数组大小小会报IndexOutOfBoundsException * @exception ArrayStoreException if an element in the src * array could not be stored into the dest array * because of a type mismatch. * @exception NullPointerException if either src or * dest is null. */ public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); 浅拷贝 public static void testArraycopy(){ class Obj{ int a; String b; public Obj(){ a=0; b=\"\"; } public Obj(int _a, String _b){ a= _a; b=_b; } } int N = 3; Obj obj1 = new Obj(1, \"a\"); Obj obj2 = new Obj(2, \"b\"); Obj obj3 = new Obj(3, \"c\"); Obj[] st = {obj1, obj2, obj3}; Obj[] dt = new Obj[N]; System.arraycopy(st, 0, dt, 0, N); // false System.out.println(\"两个数组地址是否相同：\" + (st == dt)); for(int i=0;i 对比for效率高 public static void testArrayCopyOfEfficient(){ final int N = 10000; String[] srcArray = new String[N]; String[] forArray = new String[srcArray.length]; String[] arrayCopyArray = new String[srcArray.length]; //初始化数组 for(int index = 0 ; index 非线程安全 import java.util.Arrays; /** * @Author mubi * @Date 2018/11/24 6:00 PM */ public class ArrayCopyThreadSafe { private static int[] arrayOriginal = new int[1024 * 1024 * 10]; private static int[] arraySrc = new int[1024 * 1024 * 10]; private static int[] arrayDist = new int[1024 * 1024 * 10]; private void modify() { for (int i = 0; i Array.copyOf new 新的长度，调用了System.arraycopy /** * Copies the specified array, truncating or padding with nulls (if necessary) * so the copy has the specified length. For all indices that are * valid in both the original array and the copy, the two arrays will * contain identical values. For any indices that are valid in the * copy but not the original, the copy will contain null. * Such indices will exist if and only if the specified length * is greater than that of the original array. * The resulting array is of exactly the same class as the original array. * * @param the class of the objects in the array * @param original the array to be copied * @param newLength the length of the copy to be returned * @return a copy of the original array, truncated or padded with nulls * to obtain the specified length * @throws NegativeArraySizeException if newLength is negative * @throws NullPointerException if original is null * @since 1.6 */ @SuppressWarnings(\"unchecked\") public static T[] copyOf(T[] original, int newLength) { return (T[]) copyOf(original, newLength, original.getClass()); } public static T[] copyOf(U[] original, int newLength, Class newType) { @SuppressWarnings(\"unchecked\") T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy; } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-11 23:15:57 "},"content/java_utils/equals_hashcode.html":{"url":"content/java_utils/equals_hashcode.html","title":"== & equals方法 & hashcode方法","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 操作符== 作用于基本数据类型的变量，则直接比较其存储的值是否相等 作用于引用类型的变量，则比较的是所指向的对象的地址 equals方法 equals方法是基类Object中的方法，因此对于所有的继承于Object的类都会有该方法。 对象的hashcode方法 例子，需要重写 hashcode 方法 hash函数 Java 对象 hashcode的作用 [TOC] 操作符== 作用于基本数据类型的变量，则直接比较其存储的值是否相等 基本数据类型 包装类 byte Byte short Short int Integer long Long char Char float Float double Double boolean Boolean 作用于引用类型的变量，则比较的是所指向的对象的地址 Java8程序验证 int a = 1; int b = 1; Integer ia = new Integer(a); Integer ib = new Integer(b); // true System.out.println(a == b); // false, idea编译器插件提示包装类使用equals比较 // Integer类的equals方法重写就是比较的 int value System.out.println(ia == ib); String s0 = \"helloworld\"; String s1 = \"helloworld\"; String s2 = \"hello\" + \"world\"; // true s0跟s1是指向同一个对象,字符串常量 System.out.println(s0 == s1); // true s2也指向同一字符串常量 System.out.println(s0 == s2); String s3 = new String(s0); String s4 = new String(s0); // false s3, s4是不同的对象，地址不同, 只是内容相同 System.out.println(s3 == s4); // true，用String的`equals`方法是判断的字符串内容是否相等 System.out.println(s3.equals(s4)); equals方法 equals方法是基类Object中的方法，因此对于所有的继承于Object的类都会有该方法。 equals方法不能作用于基本数据类型的变量 如果没有对equals方法进行重写，则比较的是引用类型的变量所指向的对象的地址 诸如String、Date等类对equals方法进行了override的话，比较的是所指向的对象的内容 equals默认实现是==, 不过大部分是要重写的 对象的hashcode方法 /** * Returns a hash code value for the object. This method is * supported for the benefit of hash tables such as those provided by * {@link java.util.HashMap}. * * The general contract of {@code hashCode} is: * * Whenever it is invoked on the same object more than once during * an execution of a Java application, the {@code hashCode} method * must consistently return the same integer, provided no information * used in {@code equals} comparisons on the object is modified. * This integer need not remain consistent from one execution of an * application to another execution of the same application. * If two objects are equal according to the {@code equals(Object)} * method, then calling the {@code hashCode} method on each of * the two objects must produce the same integer result. * It is not required that if two objects are unequal * according to the {@link java.lang.Object#equals(java.lang.Object)} * method, then calling the {@code hashCode} method on each of the * two objects must produce distinct integer results. However, the * programmer should be aware that producing distinct integer results * for unequal objects may improve the performance of hash tables. * * * As much as is reasonably practical, the hashCode method defined by * class {@code Object} does return distinct integers for distinct * objects. (This is typically implemented by converting the internal * address of the object into an integer, but this implementation * technique is not required by the * Java&trade; programming language.) * * @return a hash code value for this object. * @see java.lang.Object#equals(java.lang.Object) * @see java.lang.System#identityHashCode */ public native int hashCode(); 说对于两个对象，如果调用equals方法得到的结果为true，则两个对象的hashcode值必定相等； 如果equals方法得到的结果为false，则两个对象的hashcode值不一定不同 如果两个对象的hashcode值不等，则equals方法得到的结果必定为false； 如果两个对象的hashcode值相等，则equals方法得到的结果未知。 设计hashCode()时最重要的因素就是：无论何时，对同一个对象调用hashCode()都应该产生同样的值。如果在将一个对象用put()添加进HashMap时产生一个hashCdoe值，而用get()取出时却产生了另一个hashCode值，那么就无法获取该对象了。所以如果你的hashCode方法依赖于对象中易变的数据，用户就要当心了，因为此数据发生变化时，hashCode()方法就会生成一个不同的散列码 例子，需要重写 hashcode 方法 class People{ private String name; private int age; public People(String name,int age) { this.name = name; this.age = age; } public void setAge(int age){ this.age = age; } @Override public boolean equals(Object obj) { return this.name.equals(((People)obj).name) && this.age == ((People)obj).age; } @Override public int hashCode() { return name.hashCode()*101+age; } } public static void main(String[] args) throws Exception { People p1 = new People(\"Jack\", 12); System.out.println(p1.hashCode()); HashMap hashMap = new HashMap(); hashMap.put(p1, 1); System.out.println(hashMap.get(p1)); // 1 People p2 = new People(\"Jack\", 12); System.out.println(p2.hashCode()); System.out.println(hashMap.get(p2)); // 1 p2.setAge(99); System.out.println(hashMap.get(p2)); // null } hash函数 特点 单向函数，反向运算无法完成 任务一长度输入，得到 固定长度输出 输入不变，输出就不会变（Whenever it is invoked on the same object more than once during an execution of a Java application, the {@code hashCode} method must consistently return the same integer） 常见的有数百种hash函数，eg: MD5加密 + salt Java 对象 hashcode的作用 记录在markword中 与hash table密切相关 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-16 14:00:44 "},"content/java_utils/Calendar.html":{"url":"content/java_utils/Calendar.html","title":"Calendar & Date","keywords":"","body":"[TOC] Calendar & Date Date基本是Deprecated的，建议使用Calendar Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2019-05-29 23:05:41 "},"content/java_utils/Compare.html":{"url":"content/java_utils/Compare.html","title":"Comparison method violates its general contract","keywords":"","body":"[TOC] 报错：Comparison method violates its general contract! package com.mb; import java.util.ArrayList; import java.util.Comparator; import java.util.List; import java.util.Random; import java.util.stream.Collectors; class Size implements Comparable{ private Integer size; public Size(Integer size) { this.size = size; } @Override public int compareTo(Object o) { if(this == o){ return 0; }else if (o != null && o instanceof Size) { Size s2 = (Size) o; if(this.size sizeList = new ArrayList<>(16); int n = 100; for(int i=0;i sizeListSorted = sizeList .stream() .sorted(Comparator.comparing(Size::getSize)) .collect(Collectors.toList()); System.out.println(sizeListSorted); sizeList.sort((c1, c2)->{ int size1 = c1.getSize(); int size2 = c2.getSize(); if(size1 output /Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/bin/java \"-javaagent:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar=52278:/Applications/IntelliJ IDEA.app/Contents/bin\" -Dfile.encoding=UTF-8 -classpath /Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/charsets.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/deploy.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/ext/cldrdata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/ext/dnsns.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/ext/jaccess.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/ext/jfxrt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/ext/localedata.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/ext/nashorn.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/ext/sunec.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/ext/sunjce_provider.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/ext/sunpkcs11.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/ext/zipfs.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/javaws.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/jce.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/jfr.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/jfxswt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/jsse.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/management-agent.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/plugin.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/resources.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/jre/lib/rt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/lib/ant-javafx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/lib/dt.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/lib/javafx-mx.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/lib/jconsole.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/lib/packager.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/lib/sa-jdi.jar:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/lib/tools.jar:/Users/mubi/IdeaProjects/untitled/out/production/untitled:/Users/mubi/IdeaProjects/untitled/mysql-connector-java-5.1.39.jar com.mb.Main [2, 2, 2, 1, 0, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 0, 2, 1, 1, 1, 1, 0, 2, 1, 1, 0, 2, 1, 1, 2, 2, 2, 1, 0, 1, 1, 1, 2, 1, 2, 0, 0, 1, 2, 2, 1, 2, 0, 2, 0, 0, 0, 2, 1, 0, 0, 0, 1, 0, 0, 2, 2, 1, 1, 2, 2, 0, 2, 2, 1, 2, 0, 1, 2, 1, 1, 0, 1, 0, 0, 1, 2, 2, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 2, 1, 2, 0, 1] Exception in thread \"main\" java.lang.IllegalArgumentException: Comparison method violates its general contract! [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2] at java.util.TimSort.mergeHi(TimSort.java:899) at java.util.TimSort.mergeAt(TimSort.java:516) at java.util.TimSort.mergeCollapse(TimSort.java:441) at java.util.TimSort.sort(TimSort.java:245) at java.util.Arrays.sort(Arrays.java:1512) at java.util.ArrayList.sort(ArrayList.java:1462) at com.mb.Main.main(Main.java:59) Process finished with exit code 1 修改如下： 区分等于 sizeList.sort((c1, c2)->{ int size1 = c1.getSize(); int size2 = c2.getSize(); if(size1 当x == y时，sgn(compare(x, y)) = -1，-sgn(compare(y, x)) = 1，这违背了sgn(compare(x, y)) == -sgn(compare(y, x))约束 或者虚拟机参数设置: -Djava.util.Arrays.useLegacyMergeSort=true Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2019-05-29 23:06:33 "},"content/java_utils/int_Integer.html":{"url":"content/java_utils/int_Integer.html","title":"int(基本类型) & Integer(包装类类型)","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 int & Integer 源码分析（Java 8） valueOf(int i) 源码（享元模式） equals(Object obj)源码 自动装箱 & 拆箱 基本类型与包装类型的异同 [TOC] int & Integer Java8程序验证 package com.mb; public class Main { public static void main(String[] args) throws Exception { int i = 128; Integer i2 = 128; Integer i3 = new Integer(128); //Integer会自动拆箱为int，所以为true System.out.println(i == i2); // true System.out.println(i == i3); // true System.out.println(\"**************\"); Integer i5 = 127;//java在编译的时候,被翻译成-> Integer i5 = Integer.valueOf(127); Integer i6 = 127; System.out.println(i5 == i6); //true, 127走了缓存，i5 i6是同一个对象 Integer i5_1 = 128; Integer i6_1 = 128; System.out.println(i5_1 == i6_1);//false, 128不走缓存，i5_1 i6_1不是同一个对象 Integer ii5 = new Integer(127); System.out.println(i5 == ii5); // false， ii5是new出来的新对象 Integer i7 = new Integer(128); Integer i8 = new Integer(123); System.out.println(i7 == i8); // false } } /*output true true ************** true false false false */ 建议是：包装类型间的判断使用equals, 而不是== 源码分析（Java 8） valueOf(int i) 源码（享元模式） /** * Cache to support the object identity semantics of autoboxing for values between * -128 and 127 (inclusive) as required by JLS. * * The cache is initialized on first usage. The size of the cache * may be controlled by the {@code -XX:AutoBoxCacheMax=} option. * During VM initialization, java.lang.Integer.IntegerCache.high property * may be set and saved in the private system properties in the * sun.misc.VM class. */ private static class IntegerCache { static final int low = -128; static final int high; static final Integer cache[]; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k = 127; } private IntegerCache() {} } // valueOf 会使用 IntegerCache public static Integer valueOf(int i) { if (i >= IntegerCache.low && i 对于-128到127之间的数，会进行缓存，Integer i = 127时，会将127进行缓存，下次再写Integer j = 127时，就会直接从缓存中取，就不会new了 eg: public class Main { public static void main(String[] args) { Integer i1 = 100; Integer i2 = 100; Integer i3 = 200; Integer i4 = 200; System.out.println(i1==i2); System.out.println(i3==i4); } } 输出： true false equals(Object obj)源码 public boolean equals(Object obj) { if (obj instanceof Integer) { return value == ((Integer)obj).intValue(); } return false; } 自动装箱 & 拆箱 int的自动装箱都是通过Integer.valueOf()方法来实现的 Integer的自动拆箱都是通过Integer.intValue来实现的 基本类型与包装类型的异同 存储方式及位置的不同，基本类型是直接存储变量的值，保存在堆栈中能高效的存取；封装类型需要通过引用指向实例，具体的实例保存在堆中； 初始值的不同，封装类型的初始值为null，基本类型的的初始值视具体的类型而定，比如int类型的初始值为0，boolean类型为false； 使用方式的不同，比如与集合类合作使用时只能使用包装类型。 什么时候该用包装类，什么时候该用基本类型，看基本的业务来定：这个字段允不允许null值，如果允许，则必然要用封装类；否则，基本类型就可以了。如果用到比如泛型和反射调用函数，就需要用包装类！ Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-16 19:44:57 "},"content/java_utils/exception.html":{"url":"content/java_utils/exception.html","title":"Java异常&错误","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Java Throwable checked exception unchecked exceptions finally块和return finally 一定会执行, try中也return了 finally中的return会抑制（消灭）前面try或者catch块中的异常或return finally throw 异常 建议 继承 Exception, IOException [TOC] Java Throwable Throwable / \\ / \\ Error Exception / \\ / \\ checked unchkecked | | | | IOException RuntimeException checked exception 编译器要求必须处置的异常，正确的程序在运行中，很容易出现的、情理可容的异常状况。可查异常虽然是异常状况，但在一定程度上它的发生是可以预计的，而且一旦发生这种异常状况，就必须采取某种方式进行处理。 除了RuntimeException及其子类以外，其它的Exception类及其子类都属于checked异常。这种异常的特点是Java编译器会检查它，也就是说，当程序中可能出现这类异常，要么用try-catch语句捕获它，要么用throws子句声明抛出它，否则编译不会通过。如SQLException , IOException,ClassNotFoundException 等。 unchecked exceptions javac在编译时，不会提示和发现这样的异常，不要求在程序处理这些异常。所以如果愿意，我们可以编写代码处理（使用try…catch…finally）这样的异常，也可以不处理。对于这些异常，我们应该修正代码，而不是去通过异常处理器处理 。这样的异常发生的原因多半是代码写的有问题。如除0错误ArithmeticException，错误的强制类型转换错误ClassCastException，数组索引越界ArrayIndexOutOfBoundsException，使用了空对象NullPointerException等等。 finally块和return finally 一定会执行, try中也return了 class Main { public static void main(String[] args) { int re = bar(); System.out.println(re); } private static int bar() { try { return 5; } finally { System.out.println(\"finally\"); } } } /*输出： finally 5 */ finally中的return会抑制（消灭）前面try或者catch块中的异常或return class Main { public static void main(String[] args) { int re = bar(); System.out.println(re); } private static int bar() { try { return 5; } finally { System.out.println(\"finally\"); return 15; } } } /*输出： finally 15 */ finally throw 异常 class Main { public static void main(String[] args) { int result = -1; try{ result = foo(); } catch (Exception e){ System.out.println(e.getMessage()); //输出：我是finaly中的Exception }finally { System.out.println(result); // -1 } try{ result = bar(); } catch (Exception e){ System.out.println(e.getMessage()); //输出：我是finaly中的Exception }finally { System.out.println(result); // -1 } } //catch中的异常被抑制 @SuppressWarnings(\"finally\") public static int foo() throws Exception { try { int a = 5/0; return 1; }catch(ArithmeticException amExp) { throw new Exception(\"foo 我将被忽略，因为下面的finally中抛出了新的异常\"); }finally { throw new Exception(\"foo 我是finaly中的Exception\"); } } //try中的异常被抑制 @SuppressWarnings(\"finally\") public static int bar() throws Exception { try { int a = 5/0; return 1; }finally { throw new Exception(\"bar 我是finaly中的Exception\"); } } } /*输出： foo 我是finaly中的Exception -1 bar 我是finaly中的Exception -1 */ 建议 不要在fianlly中使用return。 不要在finally中抛出异常。 减轻finally的任务，不要在finally中做一些其它的事情，finally块仅仅用来释放资源是最合适的。 将尽量将所有的return写在函数的最后面，而不是try … catch … finally中 继承 Exception, IOException public class IOException extends Exception { static final long serialVersionUID = 7818375828146090155L; /** * Constructs an {@code IOException} with {@code null} * as its error detail message. */ public IOException() { super(); } /** * Constructs an {@code IOException} with the specified detail message. * * @param message * The detail message (which is saved for later retrieval * by the {@link #getMessage()} method) */ public IOException(String message) { super(message); } /** * Constructs an {@code IOException} with the specified detail message * and cause. * * Note that the detail message associated with {@code cause} is * not automatically incorporated into this exception's detail * message. * * @param message * The detail message (which is saved for later retrieval * by the {@link #getMessage()} method) * * @param cause * The cause (which is saved for later retrieval by the * {@link #getCause()} method). (A null value is permitted, * and indicates that the cause is nonexistent or unknown.) * * @since 1.6 */ public IOException(String message, Throwable cause) { super(message, cause); } /** * Constructs an {@code IOException} with the specified cause and a * detail message of {@code (cause==null ? null : cause.toString())} * (which typically contains the class and detail message of {@code cause}). * This constructor is useful for IO exceptions that are little more * than wrappers for other throwables. * * @param cause * The cause (which is saved for later retrieval by the * {@link #getCause()} method). (A null value is permitted, * and indicates that the cause is nonexistent or unknown.) * * @since 1.6 */ public IOException(Throwable cause) { super(cause); } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-26 20:26:52 "},"content/java_utils/String.html":{"url":"content/java_utils/String.html","title":"String,StringBuffer,StringBuilder","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Java字符串相关 String StringBuffer 线程安全 对于大量的字符串操作，StringBuffer优于String StringBuilder StringBuffer String 非线程安全 append字符串 对比 String + Java String类为什么是final的？ [TOC] Java字符串相关 String String是个Final类 Final类的对象是只读的，可以在多线程环境下安全的共享，不用额外的同步开销等。 public final class String implements java.io.Serializable, Comparable, CharSequence { /** The value is used fo r character storage. */ private final char value[]; /** Cache the hash code for the string */ private int hash; // Default to 0 /** use serialVersionUID from JDK 1.0.2 for interoperability */ private static final long serialVersionUID = -6849794470754667710L; /** * Class String is special cased within the Serialization Stream Protocol. * * A String instance is written into an ObjectOutputStream according to * * Object Serialization Specification, Section 6.2, \"Stream Elements\" */ private static final ObjectStreamField[] serialPersistentFields = new ObjectStreamField[0]; /** * Initializes a newly created {@code String} object so that it represents * an empty character sequence. Note that use of this constructor is * unnecessary since Strings are immutable. */ public String() { this.value = \"\".value; } charAt方法,throw StringIndexOutOfBoundsException public char charAt(int index) { if ((index = value.length)) { throw new StringIndexOutOfBoundsException(index); } return value[index]; } String的equals方法 判断了两个String对象，首先是否同一个对象，然后是否长度相等，接着判断每一个字符是否相等。 public boolean equals(Object anObject) { if (this == anObject) { return true; } if (anObject instanceof String) { String anotherString = (String)anObject; int n = value.length; if (n == anotherString.value.length) { char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) { if (v1[i] != v2[i]) return false; i++; } return true; } } return false; } String的substring、concat,replace都是返回新的String对象，原有对象不会被改变 public String substring(int beginIndex, int endIndex) { if (beginIndex value.length) { throw new StringIndexOutOfBoundsException(endIndex); } int subLen = endIndex - beginIndex; if (subLen public String concat(String str) { int otherLen = str.length(); if (otherLen == 0) { return this; } int len = value.length; char buf[] = Arrays.copyOf(value, len + otherLen); str.getChars(buf, len); return new String(buf, true); } public String replace(char oldChar, char newChar) { if (oldChar != newChar) { int len = value.length; int i = -1; char[] val = value; /* avoid getfield opcode */ while (++i \b比较字符串的大小compareTo public int compareTo(String anotherString) { int len1 = value.length; int len2 = anotherString.value.length; int lim = Math.min(len1, len2); char v1[] = value; char v2[] = anotherString.value; int k = 0; while (k StringBuffer final类，继承了AbstractStringBuilder 线程安全 StringBuffer基本上所有的操作方法都加上了synchronized修饰，保证线程安全 public final class StringBuffer extends AbstractStringBuilder implements java.io.Serializable, CharSequence { /** * A cache of the last value returned by toString. Cleared * whenever the StringBuffer is modified. */ private transient char[] toStringCache; /** use serialVersionUID from JDK 1.0.2 for interoperability */ static final long serialVersionUID = 3388685877147921107L; /** * Constructs a string buffer with no characters in it and an * initial capacity of 16 characters. */ public StringBuffer() { super(16); } /** * Constructs a string buffer with no characters in it and * the specified initial capacity. * * @param capacity the initial capacity. * @exception NegativeArraySizeException if the {@code capacity} * argument is less than {@code 0}. */ public StringBuffer(int capacity) { super(capacity); } /** * Constructs a string buffer initialized to the contents of the * specified string. The initial capacity of the string buffer is * {@code 16} plus the length of the string argument. * * @param str the initial contents of the buffer. */ public StringBuffer(String str) { super(str.length() + 16); append(str); } /** * Constructs a string buffer that contains the same characters * as the specified {@code CharSequence}. The initial capacity of * the string buffer is {@code 16} plus the length of the * {@code CharSequence} argument. * * If the length of the specified {@code CharSequence} is * less than or equal to zero, then an empty buffer of capacity * {@code 16} is returned. * * @param seq the sequence to copy. * @since 1.5 */ public StringBuffer(CharSequence seq) { this(seq.length() + 16); append(seq); } append方法之一 @Override public synchronized StringBuffer append(String str) { toStringCache = null; super.append(str); return this; } public AbstractStringBuilder append(String str) { if (str == null) return appendNull(); int len = str.length(); ensureCapacityInternal(count + len); str.getChars(0, len, value, count); count += len; return this; } public void getChars(int srcBegin, int srcEnd, char dst[], int dstBegin) { if (srcBegin value.length) { throw new StringIndexOutOfBoundsException(srcEnd); } if (srcBegin > srcEnd) { throw new StringIndexOutOfBoundsException(srcEnd - srcBegin); } System.arraycopy(value, srcBegin, dst, dstBegin, srcEnd - srcBegin); } 对于大量的字符串操作，StringBuffer优于String final static int time = 10000; public static void testString () { String s=\"\"; long begin = System.currentTimeMillis(); for(int i=0; i StringBuilder > StringBuffer > String 非线程安全 适用于单线程下在字符缓冲区进行大量操作的情况 append字符串 对比 String + // 对于String，会不断的创建、回收对象，速度会很慢。 static void testStringAdd(){ int num = 10000; String[] arrs = new String[num]; for(int i=0; i Java String类为什么是final的？ 为了实现字符串池 字符串池的实现可以在运行时节约很多heap空间，因为不同的字符串变量都指向池中的同一个字符串。但如果字符串是可变的，那么String intern将不能实现，因为这样的话，如果变量改变了它的值，那么其它指向这个值的变量的值也会一起改变 为了安全 & 线程安全 final不可变,安全 为了实现String可以创建HashCode不可变性，提高效率 因为字符串是不可变的，所以在它创建的时候HashCode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键，字符串的处理速度要快过其它的键对象。这就是HashMap中的键往往都使用字符串。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-26 20:29:17 "},"content/java_utils/reflect.html":{"url":"content/java_utils/reflect.html","title":"反射机制","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 反射 获得Class对象的方式 获得Class对象的例子代码 Class 对象 反射例子(仿Spring) Class.forName()和ClassLoader.loadClass()的区别 Class.forName() ClassLoader.loadClass [TOC] 反射 Java的反射（reflection）机制是指在程序的运行状态中，可以构造任意一个类的对象，可以了解任意一个对象所属的类，可以了解任意一个类的成员变量和方法，可以调用任意一个对象的属性和方法。这种动态获取程序信息以及动态调用对象的功能称为Java语言的反射机制。 对于一个字节码文件.class，虽然表面上我们对该字节码文件一无所知，但该文件本身却记录了许多信息。Java在将.class字节码文件载入时，JVM将产生一个java.lang.Class对象代表该.class字节码文件，从该Class对象中可以获得类的许多基本信息，这就是反射机制。 获得Class对象的方式 Class.forName(“类的全限定名”) 实例对象.getClass() 类名.class （类字面常量） 获得Class对象的例子代码 static void test() throws Exception{ Class clazz = Class.forName(\"reflect.PayService\"); Class clazz2 = PayService.class; PayService payService = new AliPayServiceImpl(); Class clazz3 = payService.getClass(); // interface reflect.PayService System.out.println(clazz); // interface reflect.PayService System.out.println(clazz2); // class reflect.AliPayServiceImpl System.out.println(clazz3); // class java.lang.Object Class clazz4 = clazz3.getSuperclass(); System.out.println(clazz4); // true System.out.println(clazz == clazz2); // false System.out.println(clazz2 == clazz3); } PayService package reflect; /** * @Author mubi * @Date 2020/6/16 06:44 */ public interface PayService { String payUse(); } AliPayServiceImpl package reflect; /** * @Author mubi * @Date 2020/6/16 06:43 */ public class AliPayServiceImpl implements PayService { @Override public String payUse() { System.out.println(\"in method payUse\"); return \"AliPayServiceImpl\"; } } Class 对象 /** * Instances of the class {@code Class} represent classes and * interfaces in a running Java application. An enum is a kind of * class and an annotation is a kind of interface. Every array also * belongs to a class that is reflected as a {@code Class} object * that is shared by all arrays with the same element type and number * of dimensions. The primitive Java types ({@code boolean}, * {@code byte}, {@code char}, {@code short}, * {@code int}, {@code long}, {@code float}, and * {@code double}), and the keyword {@code void} are also * represented as {@code Class} objects. * * {@code Class} has no public constructor. Instead {@code Class} * objects are constructed automatically by the Java Virtual Machine as classes * are loaded and by calls to the {@code defineClass} method in the class * loader. * * The following example uses a {@code Class} object to print the * class name of an object: * * * void printClassName(Object obj) { * System.out.println(\"The class of \" + obj + * \" is \" + obj.getClass().getName()); * } * * * It is also possible to get the {@code Class} object for a named * type (or for void) using a class literal. See Section 15.8.2 of * The Java&trade; Language Specification. * For example: * * * {@code System.out.println(\"The name of class Foo is: \"+Foo.class.getName());} * * * @param the type of the class modeled by this {@code Class} * object. For example, the type of {@code String.class} is {@code * Class}. Use {@code Class} if the class being modeled is * unknown. * * @author unascribed * @see java.lang.ClassLoader#defineClass(byte[], int, int) * @since JDK1.0 */ public final class Class implements java.io.Serializable, GenericDeclaration, Type, AnnotatedElement { 反射例子(仿Spring) UserController package reflect; /** * @Author mubi * @Date 2020/6/16 06:43 */ public class UserController { @Autoware private UserService userService; public UserService getUserService() { return userService; } } UserService package reflect; /** * @Author mubi * @Date 2020/6/16 06:44 */ public class UserService { } Autoware package reflect; import java.lang.annotation.*; @Retention(RetentionPolicy.RUNTIME) @Target({ElementType.FIELD}) @Documented public @interface Autoware { } 测试程序 package reflect; import java.util.Arrays; /** * @Author mubi * @Date 2020/6/16 06:44 */ public class ClientTest { public static void main(String[] args) { UserController userController = new UserController(); Arrays.stream(userController.getClass().getDeclaredFields()).forEach(field -> { // 是否有 @Autoware Autoware autoware = field.getAnnotation(Autoware.class); if (autoware != null) { field.setAccessible(true); // 获取 filed 的 类型 Class clazzType = field.getType(); try { // new filed 并注入给 userController Object o = clazzType.newInstance(); field.set(userController, o); } catch (Exception e){ } } }); // userService:reflect.UserService@2aafb23c System.out.println(\"userService:\" + userController.getUserService()); } } userController的userService属性不是自己new出来，而是通过反射注入 Class.forName()和ClassLoader.loadClass()的区别 加载：通过类的全限定名获取二进制字节流，将二进制字节流转换成方法区中的运行时数据结构，在内存中生成Java.lang.class对象 链接：执行下面的校验、准备和解析步骤，其中解析步骤是可以选择的； 校验：检查导入类或接口的二进制数据的正确性；（文件格式验证，元数据验证，字节码验证，符号引用验证） 准备：给类的静态变量分配并初始化存储空间； 解析：将常量池中的符号引用转成直接引用； 初始化：激活类的静态变量的初始化Java代码和静态Java代码块，并初始化程序员设置的变量值。 Class.forName() /** * Returns the {@code Class} object associated with the class or * interface with the given string name. Invoking this method is * equivalent to: * * * {@code Class.forName(className, true, currentLoader)} * * * where {@code currentLoader} denotes the defining class loader of * the current class. * * For example, the following code fragment returns the * runtime {@code Class} descriptor for the class named * {@code java.lang.Thread}: * * * {@code Class t = Class.forName(\"java.lang.Thread\")} * * * A call to {@code forName(\"X\")} causes the class named * {@code X} to be initialized. * * @param className the fully qualified name of the desired class. * @return the {@code Class} object for the class with the * specified name. * @exception LinkageError if the linkage fails * @exception ExceptionInInitializerError if the initialization provoked * by this method fails * @exception ClassNotFoundException if the class cannot be located */ @CallerSensitive public static Class forName(String className) throws ClassNotFoundException { Class caller = Reflection.getCallerClass(); return forName0(className, true, ClassLoader.getClassLoader(caller), caller); } 将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块(静态成员初始化，静态代码块) ClassLoader.loadClass /** * Loads the class with the specified binary name. * This method searches for classes in the same manner as the {@link * #loadClass(String, boolean)} method. It is invoked by the Java virtual * machine to resolve class references. Invoking this method is equivalent * to invoking {@link #loadClass(String, boolean) loadClass(name, * false)}. * * @param name * The binary name of the class * * @return The resulting Class object * * @throws ClassNotFoundException * If the class was not found */ public Class loadClass(String name) throws ClassNotFoundException { return loadClass(name, false); } 第2个boolean参数，表示目标对象是否进行链接，false表示不进行链接，不进行链接意味着就不会进行包括初始化等的一系列步骤，那么静态块和静态成员就不会得到执行 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-12 10:56:25 "},"content/java_utils/call_back.html":{"url":"content/java_utils/call_back.html","title":"回调 & 事件机制","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 同步 / 非同步调用 客户端同步调用 客户端异步调用 异步回调 回调 事件机制 [TOC] 同步 / 非同步调用 服务端 package com.thirdpart; import java.text.SimpleDateFormat; import java.util.Date; import java.util.Random; import java.util.concurrent.TimeUnit; /** * @Author mubi * @Date 2019/4/11 7:25 PM */ public class ServerBlock { private static SimpleDateFormat df = new SimpleDateFormat(\"yyyy-MM-dd hh:mm:ss,SSS\"); String result = null; public int createJob(){ int jobId = new Random().nextInt(100); System.out.println(\"Server do job start \" + df.format(new Date())); try{ TimeUnit.SECONDS.sleep(2); }catch (Exception e){ e.printStackTrace(); } System.out.println(\"Server do job end \" + df.format(new Date())); result = \"job done success\"; return jobId; } public String getJobResultByJobId(int jobId){ return result; } } 客户端同步调用 static void sync(){ ServerBlock server = new ServerBlock(); try { // 阻塞在这里，直到返回JobId，期间什么都做不了 int jobId = server.createJob(); System.out.println(\"Job Id: \" + jobId); System.out.println(\"Job Result:\" + server.getJobResultByJobId(jobId)); } catch (Exception e){ e.printStackTrace(); } System.out.println(\"==== end\"); } 客户端异步调用 开启新线程去执行调用，自己做别的事去(不需要阻塞的等待调用结果)，之后再去获取调用的返回结果 static void async(){ ServerBlock server = new ServerBlock(); //创建Executor- Service，通 过它你可以 向线程池提 交任务 ExecutorService executor = Executors.newCachedThreadPool(); //向Executor- Service提交一个 Callable对象 final Future future = executor.submit(new Callable() { @Override public Integer call() { //以异步方式在新的线程中执行耗时的操作 return server.createJob(); } }); //异步操作进行的同时你可以做其他的事情 System.out.println(\"=====do something else\"); try { // 获取异步操作的结果，如果最终被阻塞，无法得到结果，那么在最多等待 timeout 秒钟之后退出 int jobId = future.get(3, TimeUnit.SECONDS); System.out.println(\"Job Id: \" + jobId ); System.out.println(\"Job Result:\" + server.getJobResultByJobId(jobId)); } catch (ExecutionException e) { // 计算抛出一个异常 e.printStackTrace(); } catch (InterruptedException ie) { // 当前线程在等待过程中被中断 ie.printStackTrace(); } catch (TimeoutException te) { // 在Future对象完成之前超过已过期 te.printStackTrace(); } executor.shutdown(); System.out.println(\"==== end\"); } 注意： 调用Future的get()方法就能直接得到任务的返回值，该方法会一直阻塞直到任务的结果出来为止，我们可以调用Future的isDone()方法来判断该任务的结果是否准备就绪。 Future 是一种异步阻塞式的API，即没有通知回调。 异步回调 补充google guava的一种增强的 Future 为 ListenableFuture static void asyncNotBlock(){ ServerBlock server = new ServerBlock(); ListeningExecutorService service = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(10)); ListenableFuture future = service.submit(new Callable() { @Override public Integer call() { return server.createJob(); } }); Futures.addCallback(future, new FutureCallback() { @Override public void onSuccess(Integer result) { // 回调执行 int jobId = result; System.out.println(\"Job Id: \" + jobId); System.out.println(\"Job Result:\" + server.getJobResultByJobId(jobId)); } @Override public void onFailure(Throwable t) { } }); service.shutdown(); System.out.println(\"==== end\"); } 回调 对象a的方法methodA()中调用对象b的methodB()方法，在对象b的methodB()方法中反过来调用对象a的callBack()方法，这个callBack()方法称为回调函数，这种调用方法称为回调。 回调的核心在于：回调方将本身对象传给调用方，调用方在本身代码逻辑执行完之后，调用回调方的回调方法。 package com.callback; class A { public void methodA() { B b = new B(); b.methodB(new A()); System.out.println(\"this is class A method : methodA\"); } public void callBack() { System.out.println(\"this is class A method : callBack\"); } } class B { public void methodB(A a) { System.out.println(\"this is class B method : methodB\"); a.callBack(); } } /** * @Author mubi * @Date 2019/4/11 11:41 PM */ public class MainTest { public static void main(String[] args){ A a = new A(); a.methodA(); } } 事件机制 event object（事件类，事件触发/发布）：事件状态对象，用于listener的相应的方法之中，作为参数，一般存在于listerner的方法之中 event source（事件源类）：具体的事件源，比如说，你点击一个button，那么button就是event source，要想使button对某些事件进行响应，你就需要注册特定的listener。 event listener（监听类）：对每个明确的事件的发生，都相应地定义一个明确的Java方法。这些方法都集中定义在事件监听者（EventListener）接口中，这个接口要继承 java.util.EventListener。 实现了事件监听者接口中一些或全部方法的类就是事件监听者。 import java.text.SimpleDateFormat; import java.util.*; /** * 状态枚举类 */ enum JobStatus{ JOB_NONE(\"none\"), JOB_RUNNING(\"running\"), JOB_FINISHED(\"finished\"); JobStatus(String msg){ this.msg = msg; } String msg; public String getMsg() { return msg; } } /** * 事件对象 */ class JobEvent extends EventObject { private static final long serialVersionUID = 6496098798146410884L; private JobStatus state; public JobEvent(Object source, JobStatus state) { super(source); this.state = state; } public JobStatus getState() { return state; } } /** * 事件监听器 interface */ interface JobListener extends EventListener { void jobEventDeal(JobEvent event); } /** * 具体监听器 实现1 */ class JobListener1 implements JobListener{ @Override public void jobEventDeal(JobEvent event) { String s = null; if(null != event.getState() && event.getState().equals(JobStatus.JOB_NONE)){ s = String.format(\"%s 监听到: Job 不存在\", this.getClass().getName()); } if(null != event.getState() && event.getState().equals(JobStatus.JOB_RUNNING)){ s = String.format(\"%s 监听到: 有 Job 运行中\", this.getClass().getName()); } if(null != event.getState() && event.getState().equals(JobStatus.JOB_FINISHED)){ s = String.format(\"%s 监听到: Job 已结束\", this.getClass().getName()); } System.out.println(s); } } /** * 事件源 */ class JobSource{ private Collection listeners; public void addListener(JobListener listener){ if(null == listeners){ this.listeners = new HashSet(4); } if(null != listener){ String s = String.format(\"添加了一个监听器：%s\", listener.getClass().getName()); System.out.println(s); listeners.add(listener); } } public void removeListener(JobListener listener) { if(null == listener) { return; } if(null != listeners) { String s = String.format(\"删除了一个监听器：%s\", listener.getClass().getName()); System.out.println(s); listeners.remove(listener); } } /** * 触发 Job Running 事件 */ protected void fireJobRunning() { if (null == listeners) { return; } String s = String.format(\"产生新事件：%s\", JobStatus.JOB_RUNNING.getMsg()); System.out.println(s); JobEvent event = new JobEvent(this, JobStatus.JOB_RUNNING); notifyListeners(event); } /** * 通知所有的 Listener */ private void notifyListeners(JobEvent event) { Iterator iterator = listeners.iterator(); while (iterator.hasNext()) { JobListener listener = (JobListener) iterator.next(); listener.jobEventDeal(event); } } } /** * @Author mubi * @Date 2019/4/11 11:18 PM */ public class ClientMain { private static SimpleDateFormat df = new SimpleDateFormat(\"yyyy-MM-dd hh:mm:ss,SSS\"); public static void main(String[] args){ // 事件源 JobSource jobSource = new JobSource(); // 给 时间源 注册 事件监听器 JobListener jobListener = new JobListener1(); jobSource.addListener(jobListener); // 产生事件 jobSource.fireJobRunning(); // 移除监听器 jobSource.removeListener(jobListener); } } output 添加了一个监听器：com.client.JobListener1 产生新事件：running com.client.JobListener1 监听到: 有 Job 运行中 删除了一个监听器：com.client.JobListener1 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-15 23:09:40 "},"content/java_utils/array_collection.html":{"url":"content/java_utils/array_collection.html","title":"数组，集合转换等问题","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 数组，二维数组，集合 ListInteger 与 int[] 与 Integer[] [TOC] 数组，二维数组，集合 List 与 int[] 与 Integer[] List list = Arrays.asList(1, 3, 2); Integer[] arr = new Integer[list.size()]; list.toArray(arr); for(int i=0;i Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-18 15:13:43 "},"content/java_utils/annotation.html":{"url":"content/java_utils/annotation.html","title":"注解 Annotation","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 注解 元注解 注解的用途 [TOC] 注解 @interface TestAnnotation{ } @TestAnnotation class Test{ } 理解为 Test 具有了 TestAnnotation 标签 元注解 @Retention RetentionPolicy.SOURCE 注解只在源码阶段保留，在编译器进行编译时它将被丢弃忽视。 RetentionPolicy.CLASS 注解只被保留到编译进行的时候，它并不会被加载到 JVM 中。 RetentionPolicy.RUNTIME 注解可以保留到程序运行的时候，它会被加载进入到 JVM 中，所以在程序运行时可以获取到它们。 @Documented @Target ElementType.ANNOTATION_TYPE 可以给一个注解进行注解 ElementType.CONSTRUCTOR 可以给构造方法进行注解 ElementType.FIELD 可以给属性进行注解 ElementType.LOCAL_VARIABLE 可以给局部变量进行注解 ElementType.METHOD 可以给方法进行注解 ElementType.PACKAGE 可以给一个包进行注解 ElementType.PARAMETER 可以给一个方法内的参数进行注解 ElementType.TYPE 可以给一个类型进行注解，比如类、接口、枚举 @Inherited @Repeatable @interface Persons { Person[] value(); } @Repeatable(Persons.class) @interface Person{ String role() default \"\"; } @Person(role=\"artist\") @Person(role=\"coder\") @Person(role=\"PM\") class SuperMan{ } 注解的用途 提供信息给编译器： 编译器可以利用注解来探测错误和警告信息 编译阶段时的处理： 软件工具可以用来利用注解信息来生成代码、Html文档或者做其它相应处理。 运行时的处理： 利用反射对注解提取进行相应操作 当开发者使用了Annotation 修饰了类、方法、Field 等成员之后，这些 Annotation 不会自己生效，必须由开发者提供相应的代码来提取并处理 Annotation 信息。这些处理提取和处理 Annotation 的代码统称为 APT（Annotation Processing Tool)。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-16 13:02:02 "},"content/java_jvm/jvm_runtime.html":{"url":"content/java_jvm/jvm_runtime.html","title":"Runtime类","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Runtime类 内存相关的方法 addShutdownHook, jvm shutdown的钩子函数 availableProcessors，可用的cpu核心数 [TOC] Runtime类 内存相关的方法 /** * Every Java application has a single instance of class * Runtime that allows the application to interface with * the environment in which the application is running. The current * runtime can be obtained from the getRuntime method. * * An application cannot create its own instance of this class. * * @author unascribed * @see java.lang.Runtime#getRuntime() * @since JDK1.0 */ public class Runtime { totalMemory /** * Returns the total amount of memory in the Java virtual machine. * The value returned by this method may vary over time, depending on * the host environment. * * Note that the amount of memory required to hold an object of any * given type may be implementation-dependent. * * @return the total amount of memory currently available for current * and future objects, measured in bytes. */ public native long totalMemory(); freeMemory /** * Returns the amount of free memory in the Java Virtual Machine. * Calling the * gc method may result in increasing the value returned * by freeMemory. * * @return an approximation to the total amount of memory currently * available for future allocated objects, measured in bytes. */ public native long freeMemory(); maxMemory /** * Returns the maximum amount of memory that the Java virtual machine will * attempt to use. If there is no inherent limit then the value {@link * java.lang.Long#MAX_VALUE} will be returned. * * @return the maximum amount of memory that the virtual machine will * attempt to use, measured in bytes * @since 1.4 */ public native long maxMemory(); usedMemory totalMemory - freeMemory; 测试程序 和 jvm参数设置 // -Xms20M -Xmx20M -Xss512K -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=2 -XX:ConcGCThreads=1 -XX:InitiatingHeapOccupancyPercent=70 -XX:-OmitStackTraceInFastThrow -XX:MaxMetaspaceSize=500m -XX:+PrintGCDetails public static final int _1MB = 1024 * 1024; public static void main(String[] args){ Runtime r = Runtime.getRuntime(); System.out.println(\"=======init\"); System.out.println(\"freeMemory:\" + r.freeMemory()); System.out.println(\"maxMemory:\" + r.maxMemory()); System.out.println(\"totalMemory:\" + r.totalMemory()); byte[] alloc1, alloc2, alloc3, alloc4; alloc1 = new byte[3 * _1MB]; alloc2 = new byte[3 * _1MB]; alloc3 = new byte[3 * _1MB]; // alloc4 = new byte[3 * _1MB]; // System.out.println(alloc4.length); System.out.println(\"=======used 9M\"); System.out.println(\"freeMemory:\" + r.freeMemory()); System.out.println(\"maxMemory:\" + r.maxMemory()); System.out.println(\"totalMemory:\" + r.totalMemory()); System.out.println(\"main end\"); } addShutdownHook, jvm shutdown的钩子函数 public void addShutdownHook(Thread hook) { SecurityManager sm = System.getSecurityManager(); if (sm != null) { sm.checkPermission(new RuntimePermission(\"shutdownHooks\")); } ApplicationShutdownHooks.add(hook); } availableProcessors，可用的cpu核心数 /** * Returns the number of processors available to the Java virtual machine. * * This value may change during a particular invocation of the virtual * machine. Applications that are sensitive to the number of available * processors should therefore occasionally poll this property and adjust * their resource usage appropriately. * * @return the maximum number of processors available to the virtual * machine; never smaller than one * @since 1.4 */ public native int availableProcessors(); Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-18 15:53:09 "},"content/java_data_structure/unsafe.html":{"url":"content/java_data_structure/unsafe.html","title":"unsafe","keywords":"","body":"[TOC] unsafe cas & unsage Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-24 20:50:17 "},"content/java_thinking_in_Java/basic.html":{"url":"content/java_thinking_in_Java/basic.html","title":"《Java编程思想》第3章：操作符，第4章：控制执行流程","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 8种基本类型 类型转换 switch [TOC] 8种基本类型 System.out.println(\"=================\"); /* Byte: 8 Short: 16 Character: 16 Integer: 32 Float: 32 Long: 64 Double: 64 Boolean: false */ System.out.println(\"Byte: \" + Byte.SIZE); System.out.println(\"Short: \" + Short.SIZE); System.out.println(\"Character: \" + Character.SIZE); System.out.println(\"Integer: \" + Integer.SIZE); System.out.println(\"Float: \" + Float.SIZE); System.out.println(\"Long: \" + Long.SIZE); System.out.println(\"Double: \" + Double.SIZE); System.out.println(\"Boolean: \" + Boolean.toString(false)); System.out.println(\"=================\"); /* Byte: [-128,127] Short: [-32768,32767] Integer: [-2147483648,2147483647] Float: [1.401298e-45,3.402823e+38] Double: [4.900000e-324,1.797693e+308] */ System.out.println(String.format(\"Byte: [%d,%d]\", Byte.MIN_VALUE, Byte.MAX_VALUE)); System.out.println(String.format(\"Short: [%d,%d]\", Short.MIN_VALUE, Short.MAX_VALUE)); System.out.println(String.format(\"Integer: [%d,%d]\", Integer.MIN_VALUE, Integer.MAX_VALUE)); System.out.println(String.format(\"Float: [%e,%e]\", Float.MIN_VALUE, Float.MAX_VALUE)); System.out.println(String.format(\"Double: [%e,%e]\", Double.MIN_VALUE, Double.MAX_VALUE)); 类型转换 类型转换（cast）， 在适当的时候,Java会将一种数据类型自动的转换为另一种。 窄化转化（narrowing conversion） 即：将能容纳更多信息的数据类型转换成无法容纳那么多信息的类型，这可能面临信息丢失的危险 switch byte，short，char能够隐含的转化为int，可以作为switch； long 不能隐含转换为int，不能switch switch enum 可结合使用 不同Java版本可能支持不一样，目前Java8也支持String的switch Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2019-03-22 12:58:05 "},"content/java_thinking_in_Java/constructor.html":{"url":"content/java_thinking_in_Java/constructor.html","title":"《Java编程思想》第5章：初始化和清理(重点)","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 初始化和清理 构造函数 方法重载 static 与 this 清理： 终结处理和垃圾回收 finalize() 成员初始化 静态数据与初始化 初始化顺序（包含构造函数） 例子代码理解 总结一个对象的创建过程(class & class实例 = 对象)（实例化的顺序问题？） 数组的初始化 抽象类初始化问题 [TOC] 初始化和清理 构造函数 调用构造函数是编译器的责任，必须要让编译器知道调用的是哪个方法；分配内存空间后，就会调用构造函数，确保使用对象前，对象已经被初始化了。 函数名是类名 无参数的构造函数称为默认构造器 没有返回类型(不是返回类型为void，而是没有返回类型）（new返回了新建对象的引用） this(所操作对象的引用) 能在类的内部方法使用（static不能使用），表示\"调用方法的那个对象\"的引用，编译器默认隐式的将this作为普通方法的第一个参数 尽管可以用this调用一个构造器，但是不能调用两个且必须置于起始的语句，否则会报错,类似Error:(25, 13) java: 对this的调用必须是构造器中的第一个语句 方法重载 名字相同，有不同的参数类型列表 不以返回值作区分 基本类型作为参数，编译器会选择部分类型提升和窄化 static 与 this static方法是没有this的方法 static方法不能调用普通的方法，但普通的方法能调用static方法 清理： 终结处理和垃圾回收 对象可能不被垃圾回收 垃圾回收并不等于析构 垃圾回收只与内存有关：垃圾回收只对程序不再使用对内存进行回收 JVM未面临内存耗尽对情形，它是不会浪费时间去执行垃圾回收以恢复内存的 finalize() 成员初始化 Java尽力保证： 所有变量在使用前都能得到恰当的初始化。对于方法的局部变量，Java以编译时错误的形式来贯彻这种保证 void f(){ int i; i++; // Error, i not initiallized } 对于类数据成员(即字段)是基本类型，即便没有初始化，会被默认为0值, 如果定义一个对象引用，却没有赋予初始值，则会出现null的情况 静态数据与初始化 无论有多少个实例对象，静态数据都只占用一份存储，static关键字不能应用于局部变量，只能作用于域，其数据没有被初始化则会称为0或者null 初始化顺序（包含构造函数） 单个类的初始化顺序： 静态数据成员 -> 静态代码块 -> 非静态数据成员 -> 非静态代码块 -> 构造方法 代码执行从上到下（当然，不同类型的成员不受顺序影响，需要遵循初始化顺序），不合理的顺序会导致某些错误 例子代码理解 class Bowl{ Bowl(int marker) { System.out.println(String.format(\"Bowl(marker:%d)\", marker)); } void f1(int marker) { System.out.println(String.format(\"f1(marker:%d)\", marker)); } } class Table{ static Bowl bowl1 = new Bowl(1); public Table() { System.out.print(\"Table()\"); bowl2.f1(1); } void f2(int marker){ System.out.println(String.format(\"f2(marker:%d)\", marker)); } static Bowl bowl2 = new Bowl(2); } class Cupboard{ Bowl boel3 = new Bowl(3); static Bowl bowl4 = new Bowl(4); public Cupboard() { System.out.println(\"Cupboard()\"); bowl4.f1(2); } void f3(int marker){ System.out.println(String.format(\"f3(marker:%d)\", marker)); } static Bowl bowl5 = new Bowl(5); } class Main { static Table table = new Table(); static Cupboard cupboard = new Cupboard(); public static void main(String[] args) throws Exception { System.out.println(\"Creating new Cupboard() in main()\"); new Cupboard(); System.out.println(\"Creating new Cupboard() in main()\"); new Cupboard(); table.f2(1); cupboard.f3(1); } } // output Bowl(marker:1) // Main的静态成员Table对象的静态成员`Bowl bowl1` Bowl(marker:2) // 同上，与代码位置无关的able对象的静态成员`Bowl bowl2` Table()f1(marker:1) // Table的构造函数 Bowl(marker:4) // Cupboard对象的静态成员`Bowl bowl4` Bowl(marker:5) // Cupboard对象的静态成员`Bowl bowl4` Bowl(marker:3) // Cupboard对象的普通成员`Bowl bowl3` Cupboard() // Cupboard构造函数 f1(marker:2) Creating new Cupboard() in main() // main方法 Bowl(marker:3) Cupboard() f1(marker:2) Creating new Cupboard() in main() Bowl(marker:3) Cupboard() f1(marker:2) f2(marker:1) f3(marker:1) 总结一个对象的创建过程(class & class实例 => 对象)（实例化的顺序问题？） 假设有一个名为Dog的类 即使没有显示地使用static关键字，构造器其实也可以看成静态方法。首次创建Dog类的对象时，或者Dog类的静态方法/静态域首次被访问时，Java解释器必须查找类路径，以定位Dog.class文件 然后载入Dog.class(这将创建一个Dog对象)，有关静态初始化的所有动作都会执行。因此，静态初始化只在Class对象首次加载的时候执行一次 当用new Dog()创建对象的时候，首先将在堆上为Dog对象分配足够的存储空间 这块存储空间会被清零，这就自动地将Dog对象中的所有基本类型都设置成了默认值（0，flase，null等默认值） 执行所有出现于字段定义外的初始化动作 执行构造器 静态数据成员 -> 静态代码块 -> 非静态数据成员 -> 非静态代码块 -> 构造方法 按照代码中的顺序，所以也可能是： 静态代码块 -> 静态数据成员 -> 非静态代码块 -> 非静态数据成员 -> 构造方法 总是先静态，再非静态，最后构造方法 数组的初始化 int[] a1; // int a1[]; 编译器不允许制定数组的大小，只是个引用，并为该引用分配了足够的存储空间；为了给数组创建相应的存储空间，必须写初始化表达式。 数组的初始化动作可以出现在代码的任何地方，但也可以使用特殊的初始化表达式，但必须是在创建数组的地方出现，这种特殊的表达式是用{}扩起来的值组成的。 // 正确写法 int[] a1 = {1, 2, 3, 4, 5} // 错误写法 int[] a1; a1 = {1, 2, 3, 4, 5} 如果忘记了创建对象，并且试图使用数组中的空引用，就会出现runtime exception 由于所有的类都继承自Object类，所以也可以用Object数组 抽象类初始化问题 可以初始化,但是不能直接初始化(即new，即不能实例化),要么通过多态,要么通过静态的内存来指向一块区域让你去调用抽象类的某个方法(即局部初始化) abstract class Abs_A{ int a; //这是一个抽象方法， public abstract void run(); Abs_A(){ System.out.println(\"Abs_A()\"); } void test(){ System.out.println(\"test\"); } } class A extends Abs_A{ @Override public void run() { System.out.println(\"run\"); } } A a = new A(); a.test(); /* Abs_A() test */ Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-16 20:12:52 "},"content/java_thinking_in_Java/public_private_protect.html":{"url":"content/java_thinking_in_Java/public_private_protect.html","title":"《Java编程思想》第6章：访问权限控制(重要)","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 访问权限控制 访问权限修饰词 接口和实现 例子 [TOC] 访问权限控制 访问权限修饰词 Java访问控制符的含义和使用情况(不注明权限，默认是default) - 类内部 本包 子类 外部包 public ✓ ✓ ✓ ✓ protected ✓ ✓ ✓ x default \b✓ ✓ x x private ✓ x x x package public: 接口访问权限 private: 你无法访问 protected: 继承访问权限 接口和实现 访问权限的控制常被称为是具体实现的隐藏。把数据和方法包装进类中，以及具体实现的隐藏，常共同被称作是封装。其结果是一个同时带有特征和行为的数据类型。 设定客户端程序员可以使用和不可以使用的界限 接口和具体实现进行分离 例子 package other; /** * @Author mubi * @Date 2019/6/1 9:15 PM */ public class Bowl { private int private_a; // 默认权限，defalt int b; public int public_c; protected int protected_d; public Bowl(int marker) { System.out.println(String.format(\"Bowl(marker:%d)\", marker)); } } 外部包子类 package com; import other.Bowl; public class BowlSonOther extends Bowl{ public BowlSonOther(int marker) { super(marker); System.out.println(String.format(\"BowlSon(marker:%d)\", marker)); } public void funA(){ System.out.println(super.public_c); System.out.println(super.protected_d); } } 同一个包的子类 package other; public class BowlSon extends Bowl{ public BowlSon(int marker) { super(marker); System.out.println(String.format(\"BowlSon(marker:%d)\", marker)); } public void funA(){ System.out.println(super.b); System.out.println(super.public_c); System.out.println(super.protected_d); } } 外部包Main package com; import other.Bowl; class Main { public static void main(String[] args) throws Exception { Bowl bowl = new Bowl(1); System.out.println(bowl.public_c); BowlSonOther bowlSonOther = new BowlSonOther(2); bowlSonOther.funA(); System.out.println(bowlSonOther.public_c); } } 同包的main package other; public class Main2 { public static void main(String[] args) throws Exception { Bowl bowl = new Bowl(1); System.out.println(bowl.b); System.out.println(bowl.public_c); System.out.println(bowl.protected_d); BowlSon bowlSon = new BowlSon(2); bowlSon.funA(); System.out.println(bowlSon.b); System.out.println(bowlSon.public_c); System.out.println(bowlSon.protected_d); } } 不同包，子类方法能访问protected的成员，子类方法不能访问default的成员 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-15 18:29:49 "},"content/java_thinking_in_Java/class_final.html":{"url":"content/java_thinking_in_Java/class_final.html","title":"《Java编程思想》第7章：复用类","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 protected 继承 与 权限 向上转型 final（无法改变的）- 设计或效率 final 参数 final 方法 final 类 初始化及类的加载 [TOC] Java中问题的解决是围绕类展开的 组合 has-a 继承(extends，super) is-a 代理 protected 继承 与 权限 包，类，子类 package com.test; /** * @Author mubi * @Date 2019/2/11 6:53 PM */ public class Bowl { private int a; public Bowl(int _a) { a = _a; } protected void set(int _a){ this.a = _a; } @Override public String toString() { return \"Bowl{\" + \"a=\" + a + '}'; } } package com.test; /** * @Author mubi * @Date 2019/2/11 6:54 PM */ public class BowlSon extends Bowl{ int b; public BowlSon(int _a, int _b) { super(_a); this.b = _b; } public void change(int _a, int _b){ // 子类方法能够访问基类的set方法，因为set方法在子类中是protected set(_a); this.b = _b; } @Override public String toString() { return \"BowlFa{\" + \"b=\" + b + '}' + super.toString(); } } package com.other; import com.test.Bowl; import com.test.BowlSon; /** * @Author mubi * @Date 2019/2/11 6:57 PM */ public class MainOther { public static void main(String[] args) throws Exception { Bowl b1 = new Bowl(1); BowlSon bowlSon = new BowlSon(1,2); bowlSon.change(3,4); System.out.println(b1); System.out.println(bowlSon); } } 向上转型 如下：Wind继承Instrument,将Wind转换成Instrument引用的动作，称为向上转型； 同理：向下转型 Instrument ^ | Wind 继承和组合的选择： 如果需要从新类到基类的向上转型，那么继承是必要的，否则需要考虑用继承还是用组合 final（无法改变的）- 设计或效率 final 数据认识 import java.util.Random; class Value{ int i; public Value(int i) { this.i = i; } } public class FinalData{ private static Random rand = new Random(47); private String id; public FinalData(String id) { this.id = id; } // can be compile-time constants private final int valueOne = 9; private static final int VALUE_TWO = 99; // Typical public constant // final 说明是个常量， static 强调只有一份 （编译期常量） public static final int VALUE_THREE = 39; // can not be compile-time constants // 不能因为是final，就认为在编译时可以知道它的值； 在运行时使用随机生产的数值来初始化 private final int i4 = rand.nextInt(20); // 装载时已经初始化了，而不是每次创建一个对象时都初始化 static final int INT_5 = rand.nextInt(20); private Value v1 = new Value(11); private final Value v2 = new Value(22); private static final Value VAL_3 = new Value(33); // Arrays private final int[] a = {1,2,3,4,5}; @Override public String toString() { return \"id:\" + id + \" i4:\" + i4 + \" INT_5:\" + INT_5; } public static void main(String[] args) throws Exception { FinalData fd1 = new FinalData(\"fd1\"); // fd1.valueOne++; // error: cannot change value fd1.v2.i ++; //Object is not constant fd1.v1 = new Value(9); // ok , not final for(int i=0;i final 和 static final 的区别 static属于类，不属于实例，静态区域 final 参数 在参数列表中以声明的方式将参数指明为final, 这意味着你无法在方法中更改参数引用所指向的对象 void with(final int a){ a = 10; // illegal, a is final } final 方法 final 方法的使用的两个原因 将方法锁定，以防止任何继承类修改它的含义 效率：Java早期实现中，如果将一个方法指明为final, 就是同意编译器将针对该方法的所有调用都转为内嵌调用，以代码副本代替方法调用，可能消除方法调用的开销。如果一个方法很大，则程序代码就会膨胀，可能看不到内嵌带来的任何性能提高，因为，所带来的性能提高会话费于防范诶的时间量而被压缩。（最近的Java版本已经优化此过程） private 由于无法使用，所以 private 加上 final 修饰词，并没有实际的意义 class WithFinalMethod { final void f() {} } public class E21_FinalMethod extends WithFinalMethod { void f() {} // 报错,final方法无法override public static void main(String[] args) {} } final 类 不允许继承，不能有子类 初始化及类的加载 加载类的动作仅发生一次 类的第一个实例的创建或者对static成员的访问都有可能引起加载 定义为static的东西，只会被初始化一次 class LoadTest { // The static clause is executed // upon class loading: static { System.out.println(\"Loading LoadTest\"); } static void staticMember() {} } public class MainTest { public static void main(String args[]) { System.out.println(\"Calling static member\"); LoadTest.staticMember(); System.out.println(\"Creating an object\"); new LoadTest(); } } /*output Calling static member Loading LoadTest Creating an object */ 巩固学习：第5章，总结一个对象的创建过程 class LoadTest { public LoadTest(){ System.out.println(\"LoadTest constructor\"); } static { System.out.println(\"Loading LoadTest\"); } static void staticMember() {} } public class MainTest { public static void main(String args[]) { System.out.println(\"Calling static member\"); LoadTest.staticMember(); System.out.println(\"Creating an object\"); new LoadTest(); new LoadTest(); } } /*output Calling static member Loading LoadTest Creating an object LoadTest constructor LoadTest constructor */ Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-04-14 11:12:42 "},"content/java_thinking_in_Java/polymorphism.html":{"url":"content/java_thinking_in_Java/polymorphism.html","title":"《Java编程思想》第8章：多态","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 面向对象的3个基本特征 向上转型 方法调用绑定 缺陷: 域与静态方法 向下转型 [TOC] 面向对象的3个基本特征 多态，封装(抽象)，继承 向上转型 class Cycle { public void play(){ Sxystem.out.println(\"Cycle\"); } } class Unicycle extends Cycle { @Override public void play() { System.out.println(\"Unicycle\"); } } class Bicycle extends Cycle { @Override public void play() { System.out.println(\"Bicycle\"); } } public class MainTest { public static void ride(Cycle c) { System.out.println(c.getClass()); c.play(); } public static void main(String args[]) { ride(new Cycle()); // No upcasting ride(new Unicycle()); // Upcast ride(new Bicycle()); // Upcast } } /*output class com.test.Cycle Cycle class com.test.Unicycle Unicycle class com.test.Bicycle Bicycle */ 方法调用绑定 将一个方法调用同一个方法主体关联起来被称作绑定,当绑定发生在程序运行之前时（如果有的话，由编译器和连接器负责，C就是一种前绑定的语言）称为前期绑定（early binding ）。 在运行时，根据对象的类型来决定运行哪个方法称为后期绑定（late binding),后期绑定也被称为动态绑定（dynamic binding ）或运行时绑定(run-time binding). Java中除了static方法和final方法（private方法也属于final方法）之外，其它所有方法都是后期绑定。当方法声明为final类型时，因为方法不会被继承或改变，也就无谓多态啦，这时就是使用的前期绑定。 缺陷: 域与静态方法 只有普通的方法调用可以是多态的；如果直接访问某个域，这个访问将在编译期进行解析，不是多态 class Super { public int field = 0; public int getField() { return field; } } class Sub extends Super { public int field = 1; @Override public int getField() { return field; } public int getSuperField() { // 显示的说明为：super.field return super.field; } } public class MainTest { public static void main(String[] args) { Super sup = new Sub(); // Upcast System.out.println(\"sup.field:\" + sup.field + \" sup.getField():\" + sup.getField()); Sub sub = new Sub(); System.out.println(\"sub.field:\" + sub.field + \" sub.getField():\" + sub.getField() + \" sub.getSuperField():\" + sub.getSuperField()); } } /*output sup.field:0 sup.getField():1 sub.field:1 sub.getField():1 sub.getSuperField():0 */ class Super { public static String staticGet() { return \"Super static get()\"; } public String dynamicGet() { return \"Super dynamic get()\"; } } class Sub extends Super { public static String staticGet() { return \"Sub static get()\"; } @Override public String dynamicGet() { return \"Sub dynamic get()\"; } } public class MainTest { public static void main(String[] args) { Super sup = new Sub(); // Upcast System.out.println(sup.staticGet()); // 这里会警告：不应该通过类实例访问静态成员 System.out.println(sup.dynamicGet()); } } /*output Super static get() Sub dynamic get() */ 向下转型 向上转型可能会丢失信息，但向上转型是安全的，因为基类不会出现大于导出类的接口。 向下转型可能是不安全的，java在运行期间会检查转型，必要时返回ClassCastException，这种运行期间对类型进行检查的行为称为\"运行是类型识别（RTTI）\" class Useful { public void f() { } public void g() { } } class MoreUseful extends Useful { @Override public void f() { super.f(); } @Override public void g() { super.g(); } public void u() { } public void v() { } } public class MainTest { public static void main(String[] args) { Useful[] x = {new Useful(), new MoreUseful()}; x[0].f(); x[1].g(); ((MoreUseful)x[1]).u(); // DownCast / RTTI ((MoreUseful)x[0]).u(); // java.lang.ClassCastException throw } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2019-05-05 14:30:26 "},"content/java_thinking_in_Java/innner_class.html":{"url":"content/java_thinking_in_Java/innner_class.html","title":"《Java编程思想》第10章：内部类","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 概述 为什么需要内部类 一种隐藏和组织代码的模式 匿名内部类 闭包和回调 同步回调 异步回调 事件驱动系统 内部类标识符 [TOC] 概述 可以将一个类的定义放到另一类的定义的内部，这就是内部类 为什么需要内部类 一般来说，内部类继承自某个类或实现某个接口，内部类的代码操作创建它的外围类的对象。所以可以认为内部类提供了某种进入其外围类的窗口。 内部类必须要回答的一个问题是： 如果知识需要一个对接口的引用，为什么部通过外围类实现那个接口呢？答案是：“如果这能满足需求，那么句应该这样做。” 那么内部类实现一个接口和外围类实现这个接口有什么区别吗？答案是：后者不是总能享用到接口带来的方便，有时需要用到接口的实现。所有，使用内部类最吸引人的原因是： 每个内部类都能独立的继承自一个（接口的）实现，所以无论外围类是否已经继承了某个（接口的）实现，对内部类都没有影响 一种隐藏和组织代码的模式 interface Contents { int value(); } interface Destination { String readLabel(); } class Goods { private class Content implements Contents { private int i = 11; @Override public int value() { return i; } } protected class GDestination implements Destination { private String label; private GDestination(String whereTo) { label = whereTo; } @Override public String readLabel() { return label; } } public Destination dest(String s) { return new GDestination(s); } public Contents cont() { return new Content(); } } public class MainTest { public static void main(String[] args) { Goods p = new Goods(); Contents c = p.cont(); System.out.println(c.value()); Destination d = p.dest(\"Beijing\"); System.out.println(d.readLabel()); } } /* Output: 11 Beijing *///:~ 匿名内部类 匿名内部类没有构造器的行为（因为没有类名），但能够通过实例初始化，达到构造行为 interface Contents { int value(); } interface Destination { String readLabel(); } abstract class Destination2 { Destination2(String s){ System.out.println(\"Constructor s=\" + s); } abstract String readLabel(); } class Goods3 { public Contents cont() { // 匿名内部类 return new Contents() { private int i = 11; @Override public int value() { return i; } }; } public Destination dest(String s) { // 匿名内部类使用参数，外围必须是final的 // String dest 不是final 也ok(Java8) ? return new Destination(){ private String label = s; @Override public String readLabel(){ return label; } }; } public static Destination2 dest2(String dest) { return new Destination2(dest){ @Override public String readLabel(){ return dest; } }; } } public class MainTest { public static void main(String[] args) { Goods3 p = new Goods3(); Contents c = p.cont(); System.out.println(c.value()); Destination d = p.dest(\"shanghai\"); System.out.println(d.readLabel()); Destination2 d2 = Goods3.dest2(\"beijing\"); System.out.println(d2.readLabel()); } } /* Output: 11 shanghai Constructor s=beijing beijing *///:~ 闭包和回调 闭包(closure)是一个可调用的对象，它记录了一些信息，这些信息用来创建它的作用域。通过这个定义，可以看出内部类是面向对象的闭包，因为它不仅包含外围类对象（创建内部类的作用域）的信息，还自动拥有一个指向此外围类对象的引用，在此作用域内，内部类有权操作所有的成员，包括private成员。 回调(callback), 通过回调，对象能够携带一些信息，这些信息允许它在稍后的某个时刻调用初始的对象。 简单来说，就是我调用你的函数，你调用我的函数。正规一点的说法就是类A的a()函数调用类B的b()函数，当类B的b()函数的执行时又去调用类A里的函数。是一种双向的调用方式。一般情况下，回调分两种，分别是同步回调和异步回调。 同步回调 一种双向调用模式，被调用方在函数被调用时也会调用对方的函数。 参考： 作者：Bro__超 地址：https://www.cnblogs.com/heshuchao/p/5376298.html class Calculator { public int add(int a, int b) { return a + b; } } class SuperCalculator { public void add(int a, int b, Student xiaoming) { int result = a + b; xiaoming.fillBlank(a, b, result); } } class Student { private String name = null; public Student(String name) { // TODO Auto-generated constructor stub this.name = name; } public void setName(String name) { this.name = name; } @SuppressWarnings(\"unused\") private int calcADD(int a, int b) { return a + b; } // public void fillBlank(int a, int b) // { // int result = calcADD(a, b); // System.out.println(name + \"心算:\" + a + \" + \" + b + \" = \" + result); // } // private int useCalculator(int a, int b) // { // return new Calculator().add(a, b); // } // // public void fillBlank(int a, int b) // { // int result = useCalculator(a, b); // System.out.println(name + \"使用计算器:\" + a + \" + \" + b + \" = \" + result); // } public void callHelp(int a, int b) { new SuperCalculator().add(a, b, this); } // 类似回调函数 public void fillBlank(int a, int b, int result) { System.out.println(name + \"求助小红计算:\" + a + \" + \" + b + \" = \" + result); } } public class MainTest { public static void main(String[] args) { int a = 1; int b = 1; Student s = new Student(\"小明\"); s.callHelp(a, b); } } Student调用了SuperCalculator的add方法, add方法在执行的时候，反过来调用了Studdent的fillBlank方法 异步回调 一种类似消息或事件的机制，被调用方在函数在收到某种讯息或发生某种事件时，才去调用对方的函数,即通过异步消息进行通知。简单来说，类A的a()函数调用类B的b()函数，但是b()函数很耗时，不确定什么时候执行完毕，如果是同步调用的话会等b()执行完成后才往下执行回调类A中的函数，如果是异步回调的话调用了b()函数，虽然b()函数没有执行完,但仍然继续往下执行，为了完成这点，就需要另开一个线程了。 参考： 作者：O水冰O 来源：CSDN 原文：https://blog.csdn.net/o15277012330o/article/details/79271385 interface doJob { void fillBlank(int a, int b, int result); } class SuperCalculator { public void add(int a, int b, doJob customer) { int result = a + b; //让线程等待3秒 try { Thread.sleep(3 * 1000); } catch (InterruptedException e) { e.printStackTrace(); } customer.fillBlank(a, b, result); } } class Student { private String name = null; public Student(String name) { this.name = name; } public void setName(String name) { this.name = name; } public class DoHomeWork implements doJob { @Override public void fillBlank(int a, int b, int result) { System.out.println(name + \"求助小红计算:\" + a + \" + \" + b + \" = \" + result); } } public void callHelp (int a, int b) { //开启另一个子线程 new Thread(new Runnable() { @Override public void run(){ new SuperCalculator().add(a, b, new DoHomeWork()); } }).start(); } } class Seller { private String name = null; public Seller(String name) { this.name = name; } public void setName(String name) { this.name = name; } public class DoHomeWork implements doJob { @Override public void fillBlank(int a, int b, int result) { System.out.println(name + \"求助小红算账:\" + a + \" + \" + b + \" = \" + result + \"元\"); } } public void callHelp (int a, int b) { new SuperCalculator().add(a, b, new DoHomeWork()); } } public class MainTest { public static void main(String[] args) { int a = 56; int b = 31; int c = 26497; int d = 11256; Student s1 = new Student(\"小明\"); Seller s2 = new Seller(\"老婆婆\"); s1.callHelp(a, b); System.out.println(\"/========================1/\"); s2.callHelp(c, d); System.out.println(\"/========================2/\"); } } /* output, 其中一次的输出如下， 小明的执行耗时，导致回调是迟输出的 /========================1/ 老婆婆求助小红算账:26497 + 11256 = 37753元 小明求助小红计算:56 + 31 = 87 /========================2/ */ /* output, 其中一次的输出如下， 小明的执行耗时，导致回调是迟输出的 /========================1/ 小明求助小红计算:56 + 31 = 87 老婆婆求助小红算账:26497 + 11256 = 37753元 /========================2/ */ 事件驱动系统 内部类标识符 每个类都会产生.class文件 内部类： 外围类名字 + $ + 内部类但名字 Contents.class Destination.class Destination2.class Goods3$1.class Goods3$2.class Goods3$3.class Goods3.class Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-05-18 10:00:22 "},"content/java_thread_concurrent/aqs.html":{"url":"content/java_thread_concurrent/aqs.html","title":"AQS","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 AbstractQueuedSynchronizer Aqs核心思想归纳 同步器 AbstractQueuedSynchronizer 相关概念 阻塞 同步操作 FIFO队列(CLH 队列，双向链表) acquireQueued方法中会使线程自旋阻塞，直到获取到锁 addWaiter方法会将当前线程封装成Node节点，CAS操作追加在队尾，并返回该节点 自己实现AbstractQueuedSynchronizer抽象类和Lock接口 [TOC] AbstractQueuedSynchronizer 锁的实现框架 参考：美团技术文章：从ReentrantLock的实现看AQS的原理及应用 参考：《The java.util.concurrent Synchronizer Framework》 JUC同步器框架（AQS框架）原文翻译 论文地址 docs api Provides a framework for implementing blocking locks and related synchronizers (semaphores, events, etc) that rely on first-in-first-out (FIFO) wait queues. This class is designed to be a useful basis for most kinds of synchronizers that rely on a single atomic int value to represent state. Subclasses must define the protected methods that change this state, and which define what that state means in terms of this object being acquired or released. Given these, the other methods in this class carry out all queuing and blocking mechanics. Subclasses can maintain other state fields, but only the atomically updated int value manipulated using methods getState(), setState(int) and compareAndSetState(int, int) is tracked with respect to synchronization. Aqs核心思想归纳 AQS核心思想是：如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中 CLH：Craig、Landin and Hagersten队列，链表结构，AQS中的队列是CLH变体的虚拟双向队列（FIFO），AQS是通过将每条请求共享资源的线程封装成一个节点来实现锁的分配。 AQS使用一个volatile的int类型的成员变量来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，通过CAS完成对State值的修改。 同步器 两个操作 acquire操作：阻塞调用的线程，直到或除非同步状态允许其继续执行。 release操作：则是通过某种方式改变同步状态，使得一或多个被acquire阻塞的线程继续执行。 同步器需要支持如下： 阻塞和非阻塞（例如tryLock）的同步 可选的超时设置，让调用者可以放弃等待 通过中断实现的任务取消，通常是分为两个版本，一个acquire可取消，而另一个不可以 同步器的实现根据其状态是否独占而有所不同。独占状态的同步器，在同一时间只有一个线程可以通过阻塞点，而共享状态的同步器可以同时有多个线程在执行。一般锁的实现类往往只维护独占状态，但是，例如计数信号量在数量许可的情况下，允许多个线程同时执行。为了使框架能得到广泛应用，这两种模式都要支持。 j.u.c包里还定义了Condition接口，用于支持监控形式的await/signal操作，这些操作与独占模式的Lock类有关，且Condition的实现天生就和与其关联的Lock类紧密相关 AbstractQueuedSynchronizer 相关概念 AbstractQueuedSynchronizer 抽象类的注释说明 AbstractQueuedSynchronizer 提供了一个框架，用来实现blocking locks 和 一些同步器，且是基于一个FIFO队列的 AbstractQueuedSynchronizer 被设计为使用一个single atomic {@code int} value来表示状态 AbstractQueuedSynchronizer的子类必须去定义状态，并提供protected方法去操作状态：getState、setState以及compareAndSet 基于AQS的具体实现类必须根据暴露出的状态相关的方法定义tryAcquire和tryRelease方法，以控制acquire和release操作。当同步状态满足时，tryAcquire方法必须返回true，而当新的同步状态允许后续acquire时，tryRelease方法也必须返回true。这些方法都接受一个int类型的参数用于传递想要的状态 阻塞 j.u.c包有一个LockSuport类，这个类中包含了解决这个问题的方法。方法LockSupport.park阻塞当前线程除非/直到有个LockSupport.unpark方法被调用（unpark方法被提前调用也是可以的）。unpark的调用是没有被计数的，因此在一个park调用前多次调用unpark方法只会解除一个park操作。另外，它们作用于每个线程而不是每个同步器。一个线程在一个新的同步器上调用park操作可能会立即返回，因为在此之前可能有“剩余的”unpark操作。但是，在缺少一个unpark操作时，下一次调用park就会阻塞。虽然可以显式地消除这个状态但并不值得这样做。在需要的时候多次调用park会更高效。 park: n. 公园; 专用区; 园区; (英国) 庄园，庭院; v. 停(车); 泊(车); 坐下(或站着); 把…搁置，推迟(在以后的会议上讨论或处理); 同步操作 独占模式 共享模式 AbstractQueuedSynchronizer 的变量： 有CLH队列的头部，尾部，以及同步器状态的int变量 //用于标识共享锁 static final Node SHARED = new Node(); //用于标识独占锁 static final Node EXCLUSIVE = null; /** * 因为超时或者中断，节点会被设置为取消状态，被取消的节点时不会参与到竞争中的，他会一直保持取消状态不会转变为其他状态； */ static final int CANCELLED = 1; /** * 当前节点释放锁的时候，需要唤醒下一个节点 */ static final int SIGNAL = -1; /** * 节点在等待队列中，节点线程等待Condition唤醒 */ static final int CONDITION = -2; /** * 表示下一次共享式同步状态获取将会无条件地传播下去 */ static final int PROPAGATE = -3; /** 等待状态 */ volatile int waitStatus; /** 前驱节点 */ volatile Node prev; /** 后继节点 */ volatile Node next; /** 节点线程 */ volatile Thread thread; // Node nextWaiter; FIFO队列(CLH 队列，双向链表) 整个框架的关键就是如何管理被阻塞的线程的队列，该队列是严格的FIFO队列，因此，框架不支持基于优先级的同步。 自旋判断前驱节点是否释放了锁：如果前驱没有释放锁，那么就一直自旋；否则就能获取到锁，结束自旋 acquireQueued方法中会使线程自旋阻塞，直到获取到锁 /** * Acquires in exclusive uninterruptible mode for thread already in * queue. Used by condition wait methods as well as acquire. * * @param node the nodxe * @param arg the acquire argument * @return {@code true} if interrupted while waiting */ final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); if (p == head && tryAcquire(arg)) { setHead(node); p.next = null; // help GC failed = false; return interrupted; } if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); } } addWaiter方法会将当前线程封装成Node节点，CAS操作追加在队尾，并返回该节点 /** * Creates and enqueues node for current thread and given mode. * * @param mode Node.EXCLUSIVE for exclusive, Node.SHARED for shared * @return the new node */ private Node addWaiter(Node mode) { Node node = new Node(Thread.currentThread(), mode); // 将该线程节点加入到队列的尾部,头尾指针变化 // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) { node.prev = pred; if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } enq(node); return node; } 在`addWaiter`方法处理失败的时候进一步会调用`enq`方法 #### `enq`方法会将将node加入队尾，不断的进行CAS操作 /** * Inserts node into queue, initializing if necessary. See picture above. * @param node the node to insert * @return node's predecessor */ private Node enq(final Node node) { for (;;) { Node t = tail; if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } } } 通过自旋(CAS操作)来保证该节点能顺利的加入到队列尾部，只有加入成功才会退出循环，否则会一直自旋直到成功。 自己实现AbstractQueuedSynchronizer抽象类和Lock接口 class Sync extends AbstractQueuedSynchronizer { // Reports whether in locked @Override protected boolean isHeldExclusively() { return getState() == 1; } // status 为0能获取锁；自旋设置为1，表示获取到锁了 // Acquires the lock if state is zero @Override public boolean tryAcquire(int acquires) { assert acquires == 1; // Otherwise unused if (compareAndSetState(0, 1)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } // 释放锁，要把状态设置为0 // Releases the lock by setting state to zero @Override protected boolean tryRelease(int releases) { assert releases == 1; // Otherwise unused if (getState() == 0) { throw new IllegalMonitorStateException(); } setExclusiveOwnerThread(null); setState(0); return true; } // Provides a Condition Condition newCondition() { return new ConditionObject(); } // Deserializes properly private void readObject(ObjectInputStream s) throws IOException, ClassNotFoundException { s.defaultReadObject(); setState(0); // reset to unlocked state } } class SelfLock implements Lock{ private final Sync sync = new Sync(); @Override public void lock() { sync.acquire(1); } @Override public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1); } @Override public boolean tryLock() { return sync.tryAcquire(1); } @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, unit.toNanos(time)); } @Override public void unlock() { sync.release(1); } @Override public Condition newCondition() { return sync.newCondition(); } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 21:58:12 "},"content/java_thread_concurrent/cas.html":{"url":"content/java_thread_concurrent/cas.html","title":"CAS(Conmpare And Swap/Exchange) & unsafe","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 CAS CAS 的缺点 AtomicInteger 使用 CAS volatile 非原子性 AtomicInteger使用例子 incrementAndGet() unsafe 的一些方法 unsafe.objectFieldOffset() compareAndSwapInt getIntVolatile unsafe线程安全操作例子程序 原子引用（AtomicReference） AtomicStampedReference（用版本解决ABA） ABA问题 ABA问题的解决（加上版本） [TOC] CAS 用于实现多线程同步的原子指令，非阻塞算法，是由CPU硬件实现（比较并交换） CAS通过调用JNI(java native interface)的代码来操作底层指令来实现。 Unsafe: compareAndSwap public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); jdk8u: unsafe.cpp cmpxchg = compare and exchange jdk8u atomic_linux_x86.inline.hpp is_MP = Multi Processor 多CPU情况下会加上Lock（Lock是确保原子性的） 结论：cmpxchg = cas修改变量值， lock cmpxchg 指令；硬件层面：lcok指令在执行后面指令的时候会锁定一个北桥芯片（确保只有一个CPU访问内存） 乐观锁 CAS 的缺点 Java CAS有什么优点和问题 ABA问题。因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A （取出内存中某时刻的数据并在当下时刻比较并替换，那么在这个时间差异类会导致数据的变化，内存是变化过的，有中间这个过程） 自旋问题。循环时间长开销大:自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一:它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二:它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率 只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作 AtomicInteger 使用 CAS volatile 非原子性 import java.util.Random; import java.util.concurrent.TimeUnit; public class Main { public volatile static int num = 0; public static void add() { num++; } public synchronized static void addSync() { num++; } private final static int N = 30; public static void main(String[] args) throws Exception { Thread[] threads = new Thread[N]; for(int i=0;i{ try{ TimeUnit.MILLISECONDS.sleep(new Random().nextInt(10)); int addCnt = 100; for(int j=0;j AtomicInteger使用例子 package com.mb; import java.text.SimpleDateFormat; import java.util.Date; import java.util.Random; import java.util.concurrent.TimeUnit; import java.util.concurrent.atomic.AtomicInteger; public class Main { static SimpleDateFormat ft = new SimpleDateFormat (\"yyyy.MM.dd HH:mm:ss SSS\"); public static int num = 0; public static AtomicInteger atomicInteger = new AtomicInteger(0); public static void atomicAdd() { atomicInteger.incrementAndGet(); } public static void add() { num++; } public synchronized static void addSync() { num++; } private final static int N = 30; public static void main(String[] args) throws Exception { Thread[] threads = new Thread[N]; System.out.println(ft.format(new Date())); for(int i=0;i{ try{ TimeUnit.MILLISECONDS.sleep(new Random().nextInt(10)); int addCnt = 100; for(int j=0;j incrementAndGet() public final int incrementAndGet() { return unsafe.getAndAddInt(this, valueOffset, 1) + 1; } public final int getAndAddInt(Object var1, long var2, int var4) { int var5; do { var5 = this.getIntVolatile(var1, var2); } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5; } public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 参考:Java为何能将读与写封装为一个原子操作 unsafe 的一些方法 Unsafe提供了一些低层次操作，如直接内存访问、线程调度等(不安全，不推荐) unsafe.objectFieldOffset() private static Unsafe unsafe = null; private static long valueOffset; static { try{ Class clazz = Unsafe.class; Field f; f = clazz.getDeclaredField(\"theUnsafe\"); f.setAccessible(true); unsafe = (Unsafe) f.get(clazz); valueOffset = unsafe.objectFieldOffset(Main.class.getDeclaredField(\"value\")); } catch (IllegalAccessException e) { e.printStackTrace(); }catch (SecurityException e) { e.printStackTrace(); } catch (NoSuchFieldException e) { e.printStackTrace(); } } JVM的实现可以自由选择如何实现Java对象的\"布局\"，也就是在内存里Java对象的各个部分放在哪里，包括对象的实例字段和一些元数据之类。sun.misc.Unsafe里关于对象字段访问的方法把对象布局抽象出来，它提供了objectFieldOffset()方法用于获取某个字段相对Java对象的“起始地址”的偏移量，也提供了getInt、getLong、getObject之类的方法可以使用前面获取的偏移量来访问某个Java对象的某个字段 参考： 作者：世界屋顶 来源：CSDN 原文：url地址 compareAndSwapInt public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 即: boolean compareAndSwapInt(Object obj,long fieldoffset, int expect, int update); 内存值V、旧的预期值A、要修改的值B 当且仅当预期值A和内存值V相同时，将内存值修改为B并返回true，否则什么都不做并返回false。 即 当要修改obj对象的（fieldoffset）Int属性值与expect相同时,则修改（fieldoffset）Int为update，并返回true,否则什么都不做，返回false getIntVolatile public native int getIntVolatile(Object var1, long var2); getIntVolatile方法用于在对象指定偏移地址处volatile读取一个int。 unsafe线程安全操作例子程序 public class Main { private static Unsafe unsafe = null; private static long valueOffset; static { try{ Class clazz = Unsafe.class; Field f; f = clazz.getDeclaredField(\"theUnsafe\"); f.setAccessible(true); unsafe = (Unsafe) f.get(clazz); valueOffset = unsafe.objectFieldOffset(Main.class.getDeclaredField(\"value\")); } catch (IllegalAccessException e) { e.printStackTrace(); }catch (SecurityException e) { e.printStackTrace(); } catch (NoSuchFieldException e) { e.printStackTrace(); } } private volatile int value; public final int get() { return value; } public final void set(int newValue) { value = newValue; } public void addAndIncrease() { int var5; do { var5 = unsafe.getIntVolatile(this, valueOffset); } while(!unsafe.compareAndSwapInt(this, valueOffset, var5, var5 + 1)); } public void add() { value ++; } public synchronized void addSync() { value ++; } private final static int N = 30; public static void main(String[] args) throws Exception { Main m = new Main(); m.set(2); Thread[] threads = new Thread[N]; for(int i=0;i{ try{ TimeUnit.MILLISECONDS.sleep(new Random().nextInt(10)); int addCnt = 100; for(int j=0;j 原子引用（AtomicReference） 对对象进行原子操作,提供了一种读和写都是原子性的对象引用变量。原子意味着多个线程试图改变同一个AtomicReference(例如比较和交换操作)将不会使得AtomicReference处于不一致的状态。 AtomicReference和AtomicInteger非常类似，不同之处就在于AtomicInteger是对整数的封装，底层采用的是compareAndSwapInt实现CAS，比较的是数值是否相等，而AtomicReference则对应普通的对象引用，底层使用的是compareAndSwapObject实现CAS，比较的是两个对象的地址是否相等。也就是它可以保证你在修改对象引用时的线程安全性。 class User{ String userName; int age; public User(String userName, int age) { this.userName = userName; this.age = age; } public String getUserName() { return userName; } public void setUserName(String userName) { this.userName = userName; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } @Override public String toString() { return \"User{\" + \"userName='\" + userName + '\\'' + \", age=\" + age + '}'; } } public class Main { public static void main(String[] args) { User z3 = new User(\"z3\", 12); User l4 = new User(\"l4\", 15); AtomicReference atomicReference = new AtomicReference<>(); atomicReference.set(z3); boolean b = atomicReference.compareAndSet(z3, l4); System.out.println(b); System.out.println(atomicReference.get().toString()); b = atomicReference.compareAndSet(z3, l4); System.out.println(b); System.out.println(atomicReference.get().toString()); } } AtomicStampedReference（用版本解决ABA） ABA问题 public class Main { static AtomicReference atomicReference = new AtomicReference<>(100); public static void main(String[] args) { new Thread(()->{ boolean b = atomicReference.compareAndSet(100, 101); // A B A System.out.println(Thread.currentThread().getName() + \" \" + b + \" \" + atomicReference.get().toString()); b = atomicReference.compareAndSet(101, 100); System.out.println(Thread.currentThread().getName() + \" \" + b + \" \" + atomicReference.get().toString()); }, \"t1\").start(); new Thread(()->{ try{ TimeUnit.SECONDS.sleep(1); }catch (Exception e){ } // t2 修改成功, 另外一个线程从 100 变成 101 又变成了 100， b比较判断是100，所以能修改成功 boolean b = atomicReference.compareAndSet(100, 102); System.out.println(Thread.currentThread().getName() + \" \" + b + \" \" + atomicReference.get().toString()); }, \"t2\").start(); } } ABA问题的解决（加上版本） public class Main { static AtomicStampedReference atomicStampedReference = new AtomicStampedReference<>(100, 1); public static void main(String[] args) { new Thread(()->{ int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + \" \" + stamp); try{ TimeUnit.SECONDS.sleep(1); }catch (Exception e){ } boolean b = atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); // A B A System.out.println(Thread.currentThread().getName() + \" \" + b + \" \" + atomicStampedReference.getStamp()); b = atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(), atomicStampedReference.getStamp() + 1); System.out.println(Thread.currentThread().getName() + \" \" + b + \" \" + atomicStampedReference.getStamp()); }, \"t1\").start(); new Thread(()->{ // t2 修改成功 int stamp = atomicStampedReference.getStamp(); System.out.println(Thread.currentThread().getName() + \" \" + stamp); try{ TimeUnit.SECONDS.sleep(4); }catch (Exception e){ } boolean b = atomicStampedReference.compareAndSet(100, 102, stamp, stamp + 1); System.out.println(Thread.currentThread().getName() + \" \" + b + \" \" + atomicStampedReference.getStamp()); }, \"t2\").start(); } } output t1 1 t2 1 t1 true 2 t1 true 3 t2 false 3 t1,t2某时候同一版本 然后t1执行 A->B->A, 不过加上了版本 然后t2判断是有版本变更的，所以CAS操作失败 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 10:18:08 "},"content/java_thread_concurrent/volatile.html":{"url":"content/java_thread_concurrent/volatile.html","title":"volatile 关键字","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 volatile & synchronized 回顾并发的三大性质 原子性 可见性 volatile 可见性例子 导致共享变量在线程间不可见的原因 有序性 指令乱序例子 double check 单例模式需要 volatile吗 回顾 Java 内存模型 volatile 使用场景 利用可见性 进行开关控制 利用顺序性 Singleton 设计模式的 double-check 也是利用了顺序性的特点 [TOC] volatile & synchronized 回顾并发的三大性质 原子性 一个操作或者多个操作，要么全部执行并 且执行的过程不会被任何因素打断，要么就都不执行。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其它线程干扰. volatile：不能保证原子性， synchronized：在作用对象的作用范围内，依赖JVM实现操作的原子性。 Lock：依赖特殊的CPU指令，代码实现，如ReentrantLock 可见性 当多个线程访问同一个变量的时候，一旦线程修改了这个变量的值，其它线程能够立即看到修改的值。 volatile 可见性例子 public class Main { private static volatile Boolean flag = true; public static void main(String[] args) throws Exception{ new Thread(new Runnable() { @Override public void run() { while (flag) { } System.out.println(\"A end\"); } }).start(); try{ TimeUnit.SECONDS.sleep(2); }catch (Exception e){ } flag = false; System.out.println(\"main end\"); } } 导致共享变量在线程间不可见的原因 线程交叉执行 代码重排序结合线程交叉执行 共享变量更新后的值没有在工作内存与主内存之间及时更新 volatile 通过加入内存屏障,禁止指令重排优化来实现可见性 即被volatile关键字修饰的变量，在每个写操作之后，都会加入一条store内存屏障命令，此命令强制工作内存将此变量的最新值保存至主内存；在每个读操作之前，都会加入一条load内存屏障命令，此命令强制工作内存从主内存中加载此变量的最新值至工作内存。 synchronized monitor enter exit 确保可见性 有序性 程序执行的顺序按照代码的先后顺序执行，内存屏障（JVM规范要求） 每个volatile写操作的前面插入一个StoreStore屏障； 在每个volatile写操作的后面插入一个StoreLoad屏障； StoreStoreBarrier =》 写操作 =》 StoreStoreLoadBarrier 在每个volatile读操作的后面插入一个LoadLoad屏障； 在每个volatile读操作的后面插入一个LoadStore屏障。 LoadLoadBarrier =》 读操作 =》 LoadStoreBarrier Java内存模型中，允许编译器和处理器对指令进行重排序，但重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性(CPU指令流水线) volatile、syncronized、Lock都可保证有序性。 参考 指令乱序例子 public class Main { static int x, y, a, b; public static void main(String[] args) throws Exception{ int i = 0; while (true) { x = 0; y = 0; b = 0; a = 0; Thread A = new Thread(new Runnable() { @Override public void run() { a = 1; x = b; } }); Thread B = new Thread(new Runnable() { @Override public void run() { b = 1; y = a; } }); A.start(); B.start(); A.join(); B.join(); i++; if(x == 0 && y == 0){ System.err.println(i + \" \" + x + \" \" + y); break; } } System.out.println(\"main end\"); } } double check 单例模式需要 volatile吗 正确答案：需要 Object o = new Object();的汇编指令 0 new #2 3 dup 4 invokespecial #1 > 7 astore_1 8 return 隐含一个对象创建的过程：(记住3步) 堆内存中申请了一块内存 （new指令）【半初始化状态，成员变量初始化为默认值】 这块内存 构造方法执行（invokespecial指令） 把栈中变脸，建立连接到这块内存（astore_1指令） 问题：由于指令重排和半初始化状态，导致多线程会使用半初始化的对象 附：单例模式 回顾 Java 内存模型 CPU -> 缓存 -> 主存 -> 线程工作内存 参考 volatile 使用场景 volatile 无原子性，需要充分利用其的可见性和顺序性 利用可见性 进行开关控制 一个线程改变共享遍历，其它线程立刻能感知到，并根据其值执行各自的逻辑 利用顺序性 线程A： content = initContent(); //(1) isInit = true; //(2) 线程B while (isInit) { //(3) content.operation(); //(4) } Singleton 设计模式的 double-check 也是利用了顺序性的特点 参考:单例模式 instance= new Singleton() memory = allocate(); //1：分配对象的内存空间 ctorInstance(memory); //2：初始化对象 instance = memory; //3：设置instance指向刚分配的内存地址 可能指令重排 memory = allocate(); //1：分配对象的内存空间 instance = memory; //3：instance指向刚分配的内存地址，此时对象还未初始化 ctorInstance(memory); //2：初始化对象 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-28 17:47:40 "},"content/java_thread_concurrent/synchronized.html":{"url":"content/java_thread_concurrent/synchronized.html","title":"synchronized 关键字","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Synchronized & monitor指令 回顾并发的三大性质 原子性 可见性 有序性 synchronized的几个性质 反编译查看(字节码层级的实现) JVM层级(Hotspot实现)的实现 基本用法 synchronized(this/Object) 实际例子 多个锁的交叉导致的死锁 this monitor class monitor synchronized 的缺陷? 为什么有其它的各种锁? synchronized 缺陷例子 synchronized使用原则 synchronized 可重入吗？ synchronized 锁升级 为什么会有偏向锁？ 多线程竞争，抢锁（CAS完成） 偏向锁 什么时候升级为 轻量级锁？ 轻量级锁 什么时候升级为 重量级锁？ [TOC] Synchronized & monitor指令 回顾并发的三大性质 原子性 一个操作或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。即使是在多个线程一起执行的时候，一个操作一旦开始，就不会被其它线程干扰. volatile 不能保证原子性， synchronized 在作用对象的作用范围内，依赖JVM实现操作的原子性。 Lock 依赖特殊的CPU指令，代码实现，如ReentrantLock 可见性 当多个线程访问同一个变量的时候，一旦线程修改了这个变量的值，其他线程能够立即看到修改的值。 导致共享变量在线程间不可见的原因： 线程交叉执行 代码重排序结合线程交叉执行 共享变量更新后的值没有在工作内存与主内存之间及时更新 volatile 通过加入内存屏障和禁止重排序优化来实现可见性 synchronized monitor enter exit 确保可见性 有序性 程序执行的顺序按照代码的先后顺序执行 Java内存模型中，允许编译器和处理器对指令进行重排序，但重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性 volatile、syncronized、Lock都可保证有序性。 参考：https://blog.csdn.net/qq_30948019/article/details/80193392 synchronized的几个性质 synchronized 提供了一种锁对机制，能确保共享变量的互斥访问，从而防止数据不一致问题的出现 synchronized 包括了monitor enter和monitor exit两个JVM指令，他能确保在任何时候，任何线程执行到monitor enter成功之前都必须从主内存中获取数据，而不是从缓存中，在monitor exit运行成功之后，共享变量被更新后的值必须刷入主内存内 synchronized 严格准守Java happends-before规则，一个monitor exit指令之前必定要有一个monitor enter 反编译查看(字节码层级的实现) public class SynchronizedDemo { public void method (){ synchronized (this) { System.out.println(\"method 1 start!!!!\"); } } } javac -encoding utf-8 SynchronizedDemo.java javap -c SynchronizedDemo Compiled from \"SynchronizedDemo.java\" public class SynchronizedDemo { public SynchronizedDemo(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"\":()V 4: return public void method(); Code: 0: aload_0 1: dup 2: astore_1 3: monitorenter 4: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 7: ldc #3 // String method 1 start!!!! 9: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 12: aload_1 13: monitorexit 14: goto 22 17: astore_2 18: aload_1 19: monitorexit 20: aload_2 21: athrow 22: return Exception table: from to target type 4 14 17 any 17 20 17 any } 参考：https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-3.html#jvms-3.14 JVM层级(Hotspot实现)的实现 // TODO 基本用法 synchronized 可用于代码块或方法进行修饰，而不能对class以及变量进行修饰, eg: public synchronized void sync(){} public synchronized static void sync(){} private final Object Mutex = new Object() public void sync(){ // Mutex 一定不能为null synchronized(Mutex){ } } synchronized(this/Object) package com.thread; import java.text.SimpleDateFormat; import java.util.ArrayList; import java.util.Date; import java.util.List; import java.util.concurrent.TimeUnit; public class Main { private final static Object Mutex = new Object(); public int num; static int n = 5; void add() { synchronized (this) { try { TimeUnit.SECONDS.sleep(1); } catch (Exception e) { e.printStackTrace(); } this.num++; System.out.println(Thread.currentThread().getName()+ \":\" + num + new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\").format(new Date()) ); } } void sub(){ synchronized (Mutex) { try { TimeUnit.SECONDS.sleep(2); } catch (Exception e) { e.printStackTrace(); } this.num--; System.out.println(Thread.currentThread().getName()+ \":\" + num + new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\").format(new Date()) ); } } void add2(){ synchronized (Main.class) { try { TimeUnit.SECONDS.sleep(2); } catch (Exception e) { e.printStackTrace(); } this.num += 2; System.out.println(Thread.currentThread().getName()+ \":\" + num + new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\").format(new Date()) ); } } void printNum(){ System.out.println(\"num:\" + this.num); } public static void main(String[] args) throws Exception{ Main main = new Main(); main.num = 1; List threadList = new ArrayList<>(n); for(int i=0;i main.add(), \"add\" + i); Thread t2 = new Thread(()-> main.sub(), \"sub\" + i); threadList.add(t); threadList.add(t2); } threadList.forEach(t->t.start()); threadList.forEach(t->{ try{ t.join(); }catch (Exception e){ e.printStackTrace(); } }); System.out.println(\"main===\"); main.printNum(); } } this指代当前类的实例 synchronized 锁住的不同，决定两个方法(代码块)是否能同时运行，即是同步而不是相互阻塞的 实际例子 package com.thread; import java.util.ArrayList; import java.util.List; import java.util.concurrent.TimeUnit; public class Main { private final static Object Mutex = new Object(); public int num; static int n = 16; void add(){ try { TimeUnit.SECONDS.sleep(1); }catch (Exception e){ e.printStackTrace(); } this.num++; } void addSync(){ synchronized (Mutex){ this.num++; } } void printNum(){ System.out.println(\"num:\" + this.num); } public static void main(String[] args) throws Exception{ Main main = new Main(); main.num = 1; List threadList = new ArrayList<>(n); for(int i=0;i main.add(), \"myname\" + i); // Thread t = new Thread(()-> main.addSync()); threadList.add(t); } threadList.forEach(t->t.start()); threadList.forEach(t->{ try{ t.join(); }catch (Exception e){ e.printStackTrace(); } }); main.printNum(); } } synchronized存在排它性，所有的线程必须串行的经过synchronized保护的共享区域；synchronized作用域越大，则代表着其效率越低，甚至还会丧失并发的优势 注意到 Mutex 是如下定义的，static的, 如果非static则根本不是一个共享区域 private final static Object Mutex = new Object(); 多个锁的交叉导致的死锁 package com.thread; import java.util.ArrayList; import java.util.List; import java.util.concurrent.TimeUnit; public class Main { private final static Object ReadMutex = new Object(); private final static Object WriteMutex = new Object(); public int num; int read(){ synchronized (ReadMutex){ synchronized (WriteMutex){ return this.num; } } } void write(){ synchronized (WriteMutex){ synchronized (ReadMutex){ this.num ++; } } } void printNum(){ System.out.println(\"num:\" + this.num); } public static void main(String[] args) throws Exception{ Main main = new Main(); main.num = 0; int n = 15; List threadList = new ArrayList<>(n); int j = 0; int k = 0; for(int i=0;i main.read(), \"read-\" + j++); threadList.add(t); }else { Thread t = new Thread( ()-> main.write(), \"write-\" + k++); threadList.add(t); } } threadList.forEach(t->t.start()); threadList.forEach(t->{ try{ System.out.println(t.getName()); t.join(); }catch (Exception e){ e.printStackTrace(); } }); main.printNum(); } } this monitor package com.thread; import java.util.concurrent.TimeUnit; public class Main { public synchronized void method1(){ System.out.println(Thread.currentThread().getName() + \" enter to method 1 \"); while (true) { try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } } } public synchronized void method2(){ System.out.println(Thread.currentThread().getName() + \" enter to method 2 \"); while (true) { try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) throws Exception{ Main main = new Main(); new Thread(main::method1, \"T1\").start(); new Thread(main::method2, \"T2\").start(); } } output如下，然后程序暂停，jstack查看如下 T1 enter to method 1 两个synchronized方法挣抢的是同一个monitor的lock,而与之关联的引用则是This Monitor的实例引用 方法2等同如下： public void method2(){ synchronized (this){ System.out.println(Thread.currentThread().getName() + \" enter to method 2 \"); while (true) { try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } } } } class monitor package com.thread; import java.util.concurrent.TimeUnit; public class Main { public synchronized static void method1(){ System.out.println(Thread.currentThread().getName() + \" enter to method 1 \"); while (true) { try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } } } public synchronized static void method2(){ System.out.println(Thread.currentThread().getName() + \" enter to method 2 \"); while (true) { try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { e.printStackTrace(); } } } public static void main(String[] args) throws Exception{ new Thread(Main::method1, \"T1\").start(); new Thread(Main::method2, \"T2\").start(); } } output如下，然后程序暂停 T1 enter to method 1 synchronized 的缺陷? 为什么有其它的各种锁? 无法控制阻塞时长 阻塞不可被中断 public class Main { public synchronized void syncMethod() { try { TimeUnit.HOURS.sleep(1); } catch (InterruptedException e) { e. printStackTrace(); } } public static void main(String[] args) throws Exception{ Main defect=new Main(); Thread thread1 = new Thread(defect:: syncMethod,\"T1\"); // thread1 将先于 thread2 执行 thread1. start(); TimeUnit.MILLISECONDS.sleep(2); Thread thread2 = new Thread(defect::syncMethod,\"T2\"); thread2.start(); } } thread1 先执行进入同步方法，然后sleep 接着 thread2 进入同步方法，会阻塞，其获得执行权取决于 thread1 何时释放 monitor (如果thread2计划最多1分钟获得执行权，否则就放弃，使用 synchronized 无法做到) thread2 竞争 monitor 而陷入阻塞状态，那么 thread2 会无法中断（因为synchronized 无法被打断） public class Main { public synchronized void syncMethod() { try { TimeUnit.HOURS.sleep(1); } catch (InterruptedException e) { e. printStackTrace(); } } public static void main(String[] args) throws Exception{ Main defect=new Main(); Thread thread1 = new Thread(defect:: syncMethod,\"T1\"); // thread1 将先于 thread2 执行 thread1. start(); TimeUnit.MILLISECONDS.sleep(2); Thread thread2 = new Thread(defect::syncMethod,\"T2\"); thread2.start(); TimeUnit.MILLISECONDS.sleep(2); thread2.interrupt(); // true System.out.println(thread2.isInterrupted()); // BLOCKED System.out.println(thread2.getState()); // TIMED_WAITING System.out.println(thread1.getState()); } } synchronized是基于JVM层面实现的，如果一个代码块被synchronized修饰了，当一个线程获取了对应的锁，并执行该代码块时，其它线程便只能一直等待，等待获取锁的线程释放锁，而这里获取锁的线程释放锁会有三种情况： 获取锁的线程执行完了该代码块，然后线程释放对锁的占有； 线程执行发生异常，此时JVM会让线程自动释放锁。 wait()方法释放锁，方便其它的线程使用锁。而且被唤醒时，就在此处唤醒 synchronized 缺陷例子 当有多个线程读写文件时，读操作和写操作，写操作和写操作会发生冲突现象，但是读操作和读操作不会发生冲突现象。如果采用synchronized关键字来实现同步的话，就会导致一个问题： 当一个线程在进行读操作时，其它线程只能等待无法进行读操作。(因为使用synchronized，一个线程占用了monitor,其它线程就只能等) 参考：lock synchronized使用原则 sychronized的对象最好选择引用不会变化的对象（例如被标记为final,或初始化后永远不会变），原因显而易见的，虽然synchronized是在对象上加锁，但是它首先要通过引用来定位对象，如果引用会变化，可能带来意想不到的后果，对于需要synchronized不同对象的情况，建议的做法是为每个对象构建一个Object锁来synchronized（不建议对同一个引用反复赋值）。当然将synchronized作为修饰符修饰方法就不会有引用变化的问题，但是这种做法在方法体较大时容易违反第二个原则。 尽可能把synchronized范围缩小，线程互斥是以牺牲并发度为代价的 尽量不要在可变引用上wait()和notify()，例如: synchronized (a) { a.wait() // (1) } 若其他线程在线程1进入(1)时更改了a值，那么线程1会直接抛出一个IllegalMonitorStateException，表示在a.wait()前没有获得a的对象锁。推荐的做法还是声明一个专门用于线程同步的Object，这个Object永远不变。 import java.util.ArrayList; import java.util.List; import java.util.Random; import java.util.concurrent.TimeUnit; public class Main { private Object Mutex = new Object(); public int num; static int n = 16; void add(){ try { TimeUnit.SECONDS.sleep(1); }catch (Exception e){ e.printStackTrace(); } this.num++; } void addSync(){ synchronized (Mutex){ try { System.out.println(\"addSync\" + this.num); Mutex.wait(); TimeUnit.SECONDS.sleep(new Random().nextInt(5)); }catch (Exception e){ e.printStackTrace(); } this.num++; } } void change(){ try { TimeUnit.SECONDS.sleep(1); }catch (Exception e){ e.printStackTrace(); } System.out.println(\"change\"); Mutex.notify(); Mutex = new Object(); } void printNum(){ System.out.println(\"num:\" + this.num); } public static void main(String[] args) throws Exception{ Main main = new Main(); main.num = 1; Thread tChange = new Thread(()-> main.change()); tChange.start(); List threadList = new ArrayList<>(n); for(int i=0;i main.add(), \"myname\" + i); Thread t = new Thread(()-> main.addSync()); threadList.add(t); } threadList.forEach(t->t.start()); threadList.forEach(t->{ try{ t.join(); }catch (Exception e){ e.printStackTrace(); } }); main.printNum(); } } output Exception in thread \"Thread-0\" java.lang.IllegalMonitorStateException at java.lang.Object.notify(Native Method) at Main.change(Main.java:45) at Main.lambda$main$0(Main.java:57) at java.lang.Thread.run(Thread.java:748) 参考：synchronized锁分析 synchronized 可重入吗？ synchronized具有重入性。每个对象拥有一个计数器，当线程获取该对象monitor锁后，计数器就会加一，释放锁后就会将计数器减一。 synchronized 锁升级 JDK早期synchronized直接重量级锁(操作系统层面) JDK1.6对synchronized做了优化，synchronized锁有一个升级的过程，升级到最后才会变成重量级锁！ 【偏向锁】 / \\ 对象new出来(无锁) \\ \\ \\ \\ \\ \\ \\ \\ \\ 【轻量级锁】 \\ \\ \\ 【重量级锁】 偏向锁默认启动，会延迟启动(普通对象，有了偏向锁就是个匿名偏向) 为什么会有偏向锁？ 实践中发现：多数sychronized方法，在很多情况下，只有一个线程在运行，例如 StringBUffer中的一些sync方法 Vector中的一些sync方法 重量级锁没必要，不需要操作系统，直接用户态搞定 多线程竞争，抢锁（CAS完成） 轻量级锁/自旋锁，Java对象头markword记录：指向线程栈中的Lock Record的指针（不需要操作系统） (乐观锁，忙等待) 偏向锁 什么时候升级为 轻量级锁？ 只要有线程竞争 轻量级锁 什么时候升级为 重量级锁？ JDK1.6之前：自旋次数10次；或者多个线程等待(超过CPU核心树1/2) 就会发生升级;目前是JVM自适应自旋的升级 轻量级锁:消耗CPU（用户态，不经过操作系统） 重量级锁:不消耗CPU，有一个等待队列（阻塞）; 涉及到用户态/内核态切换 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 10:49:59 "},"content/java_thread_concurrent/thread_basic.html":{"url":"content/java_thread_concurrent/thread_basic.html","title":"线程基础","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Thread 类 & Runnable 接口 interface Runnale 源码 class Thread 源码 init Thread 的 start() & run() 需要注意的点 stackSize(线程所需栈空间) 线程的状态 Java线程的6种状态 验证6种状态 jvisualvm的线程状态 操作系统定义线程的5种状态 线程的上下文切换（Thread Context Switch） Monitor 对象的wait,notify方法 wait方法的底层原理 wait 和 sleep 的区别？ ThreadGroup线程组 线程组认识 ThreadGroup源码 守护(Daemon)线程 Thread API sleep yield sleep与yield的区别 线程的优先级 线程ID 获取当前线程(Thread.currentThread()) 设置线程上下文类加载器 线程interrupt 和 可中断方法 thread.interrupt() join(线程的join方法) join源码分析 关闭一个线程 正常结束 捕获中断信号关闭线程 使用volatile开关控制 异常退出 进程假死 [TOC] Thread 类 & Runnable 接口 interface Runnale 源码 一个FunctionalInterface @FunctionalInterface public interface Runnable { /** * When an object implementing interface Runnable is used * to create a thread, starting the thread causes the object's * run method to be called in that separately executing * thread. * * The general contract of the method run is that it may * take any action whatsoever. * * @see java.lang.Thread#run() */ public abstract void run(); } 显然可以利用Java8 lambda 其次一个类实现了Runnable接口，而不是继承Thread, 那么其只是有run()方法，没有所谓的start()方法 线程真正的执行逻辑是在run(), 通常称为线程的执行单元 class Thread 源码 class Thread implements Runnable { // 成员变量 /* Java thread status for tools, * initialized to indicate thread 'not yet started' */ private volatile int threadStatus = 0; /* The group of this thread */ private ThreadGroup group; /* For autonumbering anonymous threads. */ private static int threadInitNumber; private static synchronized int nextThreadNum() { return threadInitNumber++; } // 常见构造方法 public Thread(Runnable target) { init(null, target, \"Thread-\" + nextThreadNum(), 0); } public Thread(ThreadGroup group, String name) { init(group, null, name, 0); } init 一个线程的创建肯定是由另一个线程完成的(线程的父子关系) 被创建线程的父线程是创建它的线程 /** * Initializes a Thread. * * @param g the Thread group * @param target the object whose run() method gets called * @param name the name of the new Thread * @param stackSize the desired stack size for the new thread, or * zero to indicate that this parameter is to be ignored. * @param acc the AccessControlContext to inherit, or * AccessController.getContext() if null * @param inheritThreadLocals if {@code true}, inherit initial values for * inheritable thread-locals from the constructing thread */ private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { if (name == null) { throw new NullPointerException(\"name cannot be null\"); } this.name = name; Thread parent = currentThread(); SecurityManager security = System.getSecurityManager(); if (g == null) { /* Determine if it's an applet or not */ /* If there is a security manager, ask the security manager what to do. */ if (security != null) { g = security.getThreadGroup(); } /* If the security doesn't have a strong opinion of the matter use the parent thread group. */ if (g == null) { g = parent.getThreadGroup(); } } /* checkAccess regardless of whether or not threadgroup is explicitly passed in. */ g.checkAccess(); /* * Do we have the required permissions? */ if (security != null) { if (isCCLOverridden(getClass())) { security.checkPermission(SUBCLASS_IMPLEMENTATION_PERMISSION); } } g.addUnstarted(); this.group = g; this.daemon = parent.isDaemon(); this.priority = parent.getPriority(); if (security == null || isCCLOverridden(parent.getClass())) this.contextClassLoader = parent.getContextClassLoader(); else this.contextClassLoader = parent.contextClassLoader; this.inheritedAccessControlContext = acc != null ? acc : AccessController.getContext(); this.target = target; setPriority(priority); if (inheritThreadLocals && parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); /* Stash the specified stack size in case the VM cares */ this.stackSize = stackSize; /* Set thread ID */ tid = nextThreadID(); } Thread 的 start() & run() run() @Override public void run() { if (target != null) { target.run(); } } start() public synchronized void start() { /** * This method is not invoked for the main method thread or \"system\" * group threads created/set up by the VM. Any new functionality added * to this method in the future may have to also be added to the VM. * * A zero status value corresponds to state \"NEW\". */ if (threadStatus != 0) throw new IllegalThreadStateException(); // 加入到线程组中 /* Notify the group that this thread is about to be started * so that it can be added to the group's list of threads * and the group's unstarted count can be decremented. */ group.add(this); boolean started = false; try { start0(); started = true; } finally { try { if (!started) { group.threadStartFailed(this); } } catch (Throwable ignore) { /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ } } } // start0()会新运行一个线程，新线程会调用run()方法 private native void start0(); 需要注意的点 start方法用synchronized修饰，为同步方法；表示真正的去执行线程 虽然为同步方法，但不能避免多次调用问题；所以用threadStatus来记录线程状态，如果线程被多次start调用会抛出异常；threadStatus的状态由JVM控制。 使用Runnable时，主线程无法捕获子线程中的异常状态。线程的异常，应在线程内部解决。 区别：start()是让另一个新线程开启，并执行其中的run方法；run()是直接当前线程执行其run方法.run方法一般称为线程的执行单元 when program calls start() method, a new thread is created and code inside run() is executed in new thread.Thread.start() calls the run() method asynchronousl（异步的）,which changes the state of new Thread to Runnable. call run() method directly no new thread will be created and code inside run() will execute in the current thread directly. native方法start0():调用JVM方法创建一个本地线程，并处于可运行状态；获取到CPU时间片就能执行run方法 start0(); method: is responsible for low processing (stack creation for a thread and allocating thread in processor queue) at this point we have a thread in Ready/Runnable state. stackSize(线程所需栈空间) /* * The requested stack size for this thread, or 0 if the creator did * not specify a stack size. It is up to the VM to do whatever it * likes with this number; some VMs will ignore it. */ private long stackSize; 操作系统对一个进程的最大内存是有限制的 虚拟机栈是线程私有的，即每个线程都会占有指定大小的内存(-Xss，默认1M) JVM能创建多少个线程，与堆内存，栈内存的大小有直接的关系，只不过栈内存更明显一些； 线程数目还与操作系统的一些内核配置有很大的关系；生产上要监控线程数量，可能会由于bug导致线程数异常增多，引发心跳,OutOfMemory告警 线程的状态 Java线程的6种状态 NEW RUNNABLE(可运行状态，运行状态，阻塞状态) BLOCKED WAITING TIMED WAITING TERMINATED Thread类源码 /** * A thread state. A thread can be in one of the following states: * * {@link #NEW} * A thread that has not yet started is in this state. * * {@link #RUNNABLE} * A thread executing in the Java virtual machine is in this state. * * {@link #BLOCKED} * A thread that is blocked waiting for a monitor lock * is in this state. * * {@link #WAITING} * A thread that is waiting indefinitely for another thread to * perform a particular action is in this state. * * {@link #TIMED_WAITING} * A thread that is waiting for another thread to perform an action * for up to a specified waiting time is in this state. * * {@link #TERMINATED} * A thread that has exited is in this state. * * * * * A thread can be in only one state at a given point in time. * These states are virtual machine states which do not reflect * any operating system thread states. * * @since 1.5 * @see #getState */ public enum State { /** * Thread state for a thread which has not yet started. */ NEW, /** * Thread state for a runnable thread. A thread in the runnable * state is executing in the Java virtual machine but it may * be waiting for other resources from the operating system * such as processor. */ RUNNABLE, /** * Thread state for a thread blocked waiting for a monitor lock. * A thread in the blocked state is waiting for a monitor lock * to enter a synchronized block/method or * reenter a synchronized block/method after calling * {@link Object#wait() Object.wait}. */ BLOCKED, /** * Thread state for a waiting thread. * A thread is in the waiting state due to calling one of the * following methods: * * {@link Object#wait() Object.wait} with no timeout * {@link #join() Thread.join} with no timeout * {@link LockSupport#park() LockSupport.park} * * * A thread in the waiting state is waiting for another thread to * perform a particular action. * * For example, a thread that has called Object.wait() * on an object is waiting for another thread to call * Object.notify() or Object.notifyAll() on * that object. A thread that has called Thread.join() * is waiting for a specified thread to terminate. */ WAITING, /** * Thread state for a waiting thread with a specified waiting time. * A thread is in the timed waiting state due to calling one of * the following methods with a specified positive waiting time: * * {@link #sleep Thread.sleep} * {@link Object#wait(long) Object.wait} with timeout * {@link #join(long) Thread.join} with timeout * {@link LockSupport#parkNanos LockSupport.parkNanos} * {@link LockSupport#parkUntil LockSupport.parkUntil} * */ TIMED_WAITING, /** * Thread state for a terminated thread. * The thread has completed execution. */ TERMINATED; } 阻塞(blocked)：阻塞状态是指线程因为某种原因放弃了cpu使用权，也即让出了cpu时间片，暂时停止运行。直到线程进入可运行(runnable)状态，才有机会再次获得cpu时间片，转到运行(running)状态。阻塞的情况分三种： 等待阻塞：运行(running)的线程执行o.wait()方法，JVM会把该线程放入等待队列(waitting queue)中。 同步阻塞：运行(running)的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。 其它阻塞：运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。 验证6种状态 public class Main { public static void main(String[] args) throws Exception{ Thread t1 = new Thread(()->{ System.out.println(\"t1 running\"); },\"t1\"); Thread t2 = new Thread(()->{ while (true){ } },\"t2\"); t2.start(); Thread t3 = new Thread(()->{ // do sth // System.out.println(\"t3 running\"); }, \"t3\"); t3.start(); Thread t4 = new Thread(()->{ synchronized (Main.class){ try{ // 有限时间的等待 TimeUnit.SECONDS.sleep(100); // TIMED_WAITING }catch (Exception e){ e.printStackTrace(); } } }, \"t4\"); t4.start(); Thread t5 = new Thread(()->{ try{ // 无限时间的等待 t2.join(); // WAITING }catch (Exception e){ e.printStackTrace(); } }, \"t5\"); t5.start(); Thread t6 = new Thread(()->{ synchronized (Main.class){ // 竞争锁，竞争不到，BLOCKED try{ TimeUnit.SECONDS.sleep(100); }catch (Exception e){ e.printStackTrace(); } } }, \"t6\"); t6.start(); TimeUnit.SECONDS.sleep(1); System.out.println(\"t1 status:\" + t1.getState()); System.out.println(\"t2 status:\" + t2.getState()); System.out.println(\"t3 status:\" + t3.getState()); System.out.println(\"t4 status:\" + t4.getState()); System.out.println(\"t5 status:\" + t5.getState()); System.out.println(\"t6 status:\" + t6.getState()); } } 输出 t1 status:NEW t2 status:RUNNABLE t3 status:TERMINATED t4 status:TIMED_WAITING t5 status:WAITING t6 status:BLOCKED jvisualvm的线程状态 操作系统定义线程的5种状态 初始状态（new） 可运行状态/就绪状态（与操作系统关联，有了CPU时间片就可以运行起来，准备就绪中） 运行状态（获取到CPU时间片，则在运行中；如果CPU时间片用完，则会变成[可运行状态]） 阻塞状态（等待/阻塞/睡眠，操作系统不考虑给这种状态线程分配CPU时间片，唤醒后变成[可运行状态]） 终止状态（结束） 线程的上下文切换（Thread Context Switch） 由于某些原因CPU不执行当前线程，转而去执行其它线程 当前线程的CPU时间片用完 垃圾回收（STW） 有比该线程更高优先级的线程需要运行 线程调用了sleep,yield,wait,join,park,synchronized,lock等方法导致等待/阻塞等 当Context Switch发生时，需要有操作系统保存当前线程的状态，并恢复另一个线程的状态；每个线程都有一个程序计数器（Program Counter Register）,它的作用是记住下一条JVM指令的地址，这个程序计数器是线程独有的 状态包括程序计数器，虚拟机栈中每个线程栈帧的信息，如局部变量，操作数栈，返回地址等 Context Switch频繁发生会影响性能 Monitor Monitors – The Basic Idea of Java Synchronization 对象的wait,notify方法 wait: 在其它线程调用此对象的notify()方法或notifyAll()方法前，导致当前线程等待 notify: 唤醒在此对象监视器上等待的单个线程,如果所有线程都在此对象上等待，则会选择唤醒其中一个线程。选择是任意性的，并在对实现做出决定时发生。线程通过调用其中一个 wait 方法，在对象的监视器上等待。 sleep方法没有释放锁，而wait方法释放了锁，使得其他线程可以使用同步控制块或方法 参考文档： https://www.baeldung.com/java-wait-notify Simply put, when we call wait() – this forces the current thread to wait until some other thread invokes notify() or notifyAll() on the same object.(当调用wait()后，当前线程将等待其它线程调用notity()) For this, the current thread must own the object's monitor. According to Javadocs, this can happen when: we've executed synchronized instance method for the given object we've executed the body of a synchronized block on the given object by executing synchronized static methods for objects of type Class Note that only one active thread can own an object's monitor at a time. The wait() method causes the current thread to wait indefinitely until another thread either invokes notify() for this object or notifyAll(). class ThreadA extends Thread{ public ThreadA(String name) { super(name); } public void run() { synchronized (this) { try { Thread.sleep(1000); // 使当前线阻塞 1 s，确保主程序的 t1.wait(); 执行之后再执行 notify() } catch (Exception e) { e.printStackTrace(); } System.out.println(Thread.currentThread().getName()+\" call notify()\"); // 唤醒当前的wait线程 this.notify(); } } } // main 线程 public static void main(String[] args) { ThreadA t1 = new ThreadA(\"t1\"); synchronized(t1) { try { // 启动“线程t1” System.out.println(Thread.currentThread().getName()+\" start t1\"); t1.start(); // 主线程等待t1通过notify()唤醒。 System.out.println(Thread.currentThread().getName()+\" wait()\"); t1.wait(); // 不是使t1线程等待，而是当前执行wait的线程等待 System.out.println(Thread.currentThread().getName()+\" continue\"); } catch (InterruptedException e) { e.printStackTrace(); } } } /* 执行结果 main start t1 main wait() t1 call notify() main continue */ wait方法的底层原理 Java中每一个对象都可以成为一个监视器（Monitor）, 该Monitor由一个锁(lock), 一个等待队列(WaitingQueue，阻塞状态，等待被唤醒调度), 一个入口队列(EntryQueue,要去竞争获取锁). waiting进入_waitSet等待中(底层通过执行thread_ParkEvent->park来挂起线程)，等待被唤醒，不会占用CPU waiting被唤醒后，不是直接执行，而是进入_EntryList(没有获取到锁的Blocking状态，要继续竞争锁)，去竞争monitor来获得机会去执行 wait 和 sleep 的区别？ wait()方法属于Object类,sleep()属于Thread类； wait()方法让自己让出锁资源进入等待池等待，会让出CPU；sleep是继续占用锁(依赖于系统时钟和CPU调度机制)，处于阻塞状态，会让出CPU； sleep()必须指定时间，wait()可以指定时间也可以不指定；sleep()时间到，线程处于阻塞或可运行状态； wait()方法会释放持有的锁，调用notify(),notifyAll()方法来唤醒线程；sleep方法不会释放持有的锁，设置sleep的时间是确定的会按时执行的，超时或者interrupt()能唤醒 wait()方法只能在同步方法或同步代码块中调用，否则会报illegalMonitorStateException异常，如果没有设定时间，使用notify()来唤醒；而sleep()能在任何地方调用； ThreadGroup线程组 线程组认识 ThreadGroup tg = new ThreadGroup(\"tg\"); Thread tr = new Thread(tg, \"tr\"); // 不断获取上一级的 线程组 ThreadGroup tg_parent = tr.getThreadGroup(); while(tg_parent != null){ System.out.println(tg_parent); tg_parent = tg_parent.getParent(); } output java.lang.ThreadGroup[name=tg,maxpri=10] java.lang.ThreadGroup[name=main,maxpri=10] java.lang.ThreadGroup[name=system,maxpri=10] ThreadGroup tg = new ThreadGroup(\"tg\"); Thread tr = new Thread(tg,\"tr\"); // 不断获取上一级的 线程组 ThreadGroup tg_parent = tr.getThreadGroup(); while(tg_parent.getParent() != null){ tg_parent = tg_parent.getParent(); } // 打印 线程组 的树 tg_parent.list(); output java.lang.ThreadGroup[name=system,maxpri=10] Thread[Reference Handler,10,system] Thread[Finalizer,8,system] Thread[Signal Dispatcher,9,system] java.lang.ThreadGroup[name=main,maxpri=10] Thread[main,5,main] Thread[Monitor Ctrl-Break,5,main] java.lang.ThreadGroup[name=tg,maxpri=10] Thread tr = new Thread(\"tr\"); ThreadGroup tg_parent = tr.getThreadGroup(); System.out.println(tg_parent); output java.lang.ThreadGroup[name=main,maxpri=10] ThreadGroup源码 /** * A thread group represents a set of threads. In addition, a thread * group can also include other thread groups. The thread groups form * a tree in which every thread group except the initial thread group * has a parent. * * A thread is allowed to access information about its own thread * group, but not to access information about its thread group's * parent thread group or any other thread groups. * * @author unascribed * @since JDK1.0 */ /* The locking strategy for this code is to try to lock only one level of the * tree wherever possible, but otherwise to lock from the bottom up. * That is, from child thread groups to parents. * This has the advantage of limiting the number of locks that need to be held * and in particular avoids having to grab the lock for the root thread group, * (or a global lock) which would be a source of contention on a * multi-processor system with many thread groups. * This policy often leads to taking a snapshot of the state of a thread group * and working off of that snapshot, rather than holding the thread group locked * while we work on the children. */ public class ThreadGroup implements Thread.UncaughtExceptionHandler { 线程组表示一个线程的集合。线程组也可以包含其它线程组。 守护(Daemon)线程 The Java Virtual Machine exits when the only threads running are all daemon threads 如果一个JVM进程中一个非守护线程都没有，那么JVM会退出，即守护线程具备自动结束生命周期的特性。 守护线程的优先级比较低，用于为系统中的其它对象和线程提供服务；线程对象创建之前，用线程对象的setDaemon(true)方法。 典型的守护线程如：Java垃圾回收线程 class DaemonThread extends Thread{ @Override public void run() { while (true){ try{ System.out.println(this.getClass().getName()); Thread.sleep(1_000L); }catch (Exception e){ e.printStackTrace(); } } } } public class Main { public static void main(String[] args) throws Exception{ DaemonThread daemonThread = new DaemonThread(); daemonThread.setName(\"DaemonThread\"); daemonThread.setDaemon(true); daemonThread.start(); System.out.println(daemonThread.isDaemon()); Thread.sleep(2_000L); System.out.println(\"Main thread finished\"); } } output com.parallel.DaemonThread true com.parallel.DaemonThread Main thread finished Java的两类Thread 用户线程：Java虚拟机在它所有非守护线程已经离开后自动离开 守护线程：守护线程则是用来服务用户线程的，如果没有其它用户线程在运行，那么就没有可服务对象，也就没有理由继续下去 Thread API sleep public static native void sleep(long millis) throws InterruptedException public static void sleep(long millis, int nanos) hrows InterruptedException // 人性化设置休眠时间的sleep package java.util.concurrent TimeUnit sleep休眠不会放弃monitor锁的所有权，各个线程的休眠不会相互影响，sleep只会导致当前线程休眠 yield vt.屈服，投降; 生产; 获利; 不再反对; vi.放弃，屈服; 生利; 退让，退位; n.产量，产额; 投资的收益; 屈服，击穿; 产品; 启发式的方式：提醒调度器愿意放弃当前CPU资源，如果CPU资源不紧张，则会忽略这种提醒 /** * A hint to the scheduler that the current thread is willing to yield * its current use of a processor. The scheduler is free to ignore this * hint. * * Yield is a heuristic attempt to improve relative progression * between threads that would otherwise over-utilise a CPU. Its use * should be combined with detailed profiling and benchmarking to * ensure that it actually has the desired effect. * * It is rarely appropriate to use this method. It may be useful * for debugging or testing purposes, where it may help to reproduce * bugs due to race conditions. It may also be useful when designing * concurrency control constructs such as the ones in the * {@link java.util.concurrent.locks} package. */ public static native void yield(); 测试程序 class MyThread extends Thread { int id; public MyThread() { } public MyThread(int _id) { id = _id; } @Override public void run() { if(id == 0){ Thread.yield(); } System.out.println(\"id:\" + id); } } public class Main { static void test(){ MyThread[] ts = new MyThread[2]; for(int i=0;i 输出顺序无规律,如下是其中的一次输出，所以并不总是直接让出CPU id:0 id:1 Main thread finished sleep与yield的区别 yield会使RUNNING状态的线程进入Runnable状态（如果CPU调度器没有忽略这个提示的话） 一个线程sleep,另一个线程调用interrupt会捕获到中断信号，而yield则不会 线程的优先级 理论上，线程优先级高的会获得优先被CPU调度的机会，但实际上这也是个hint操作 如果CPU比较忙，设置优先级可能会获得更多的CPU时间片；但是CPU闲时, 优先级的高低几乎不会有任何作用 对于root用户，它会hint操作系统你想要设置的优先级别，否则它会被忽略 /** * Changes the priority of this thread. * * First the checkAccess method of this thread is called * with no arguments. This may result in throwing a * SecurityException. * * Otherwise, the priority of this thread is set to the smaller of * the specified newPriority and the maximum permitted * priority of the thread's thread group. * * @param newPriority priority to set this thread to * @exception IllegalArgumentException If the priority is not in the * range MIN_PRIORITY to * MAX_PRIORITY. * @exception SecurityException if the current thread cannot modify * this thread. * @see #getPriority * @see #checkAccess() * @see #getThreadGroup() * @see #MAX_PRIORITY * @see #MIN_PRIORITY * @see ThreadGroup#getMaxPriority() */ public final void setPriority(int newPriority) { ThreadGroup g; checkAccess(); if (newPriority > MAX_PRIORITY || newPriority g.getMaxPriority()) { newPriority = g.getMaxPriority(); } setPriority0(priority = newPriority); } } 线程ID 线程的ID在整个JVM进程中都会是唯一的，并且是从0开始逐次增加 /** * Returns the identifier of this Thread. The thread ID is a positive * long number generated when this thread was created. * The thread ID is unique and remains unchanged during its lifetime. * When a thread is terminated, this thread ID may be reused. * * @return this thread's ID. * @since 1.5 */ public long getId() { return tid; } 获取当前线程(Thread.currentThread()) class MyThread extends Thread { @Override public void run() { Thread thread1 = Thread.currentThread(); // true System.out.println( this == thread1); } } 设置线程上下文类加载器 public void setContextClassLoader(ClassLoader cl) public ClassLoader getContextClassLoader() 线程上下文类加载器破坏了双亲委派模型，例如com.mysql.jdbc.Driver 线程interrupt 和 可中断方法 如下方法的调用会使得当前线程进入阻塞状态，而另外的一个线程调用被阻塞线程的interrupt方法，可以打断这种阻塞。这些方法有时会被称为可中断方法 wait sleep join InterruptibleChannel的io操作 Selector的wakeup方法 打断一个线程并不等于该线程的生命周期结束，仅仅是打断当前线程的阻塞状态 public class Main { public static void main(String[] args) throws Exception{ Thread thread = new Thread(()-> { try { System.out.println(\"thread start sleep\"); // sleep（可中断方法）使得线程进入阻塞状态 TimeUnit.MINUTES.sleep(2); System.out.println(\"thread sleep over\"); }catch (InterruptedException e){ System.out.println(\"Interrupted\"); } }); Thread thread2 = new Thread(()-> { System.out.println(\"thread2 start\"); // 打断thread的阻塞 // 一个线程在阻塞的情况下会抛出一个`InterruptedException`,类似一个信号`signal` thread.interrupt(); System.out.println(\"thread2 end\"); }); thread.start(); TimeUnit.SECONDS.sleep(2); thread2.start(); } } output thread start sleep thread2 start thread2 end Interrupted thread.interrupt() public class Main { public static void main(String[] args) throws Exception{ Thread thread = new Thread(()-> { while (true){ // 非 可中断的 } }); Thread thread2 = new Thread(()-> { System.out.println(thread.isInterrupted()); // false System.out.println(\"thread2 start\"); // 可中断方法 捕获到 中断 信号之后，为了不影响线程中其它方法的执行 // 将线程的 interrupt 标识复位 thread.interrupt(); System.out.println(\"thread2 end\"); System.out.println(thread.isInterrupted()); // true }); thread.start(); TimeUnit.SECONDS.sleep(2); thread2.start(); } } join(线程的join方法) 与sleep一样也是一个可中断的方法，底层是调用对象的wait方法 在线程B中执行A.join()，会使得当前线程B进入等待，直到线程A结束生命周期或者到达给定的时间，在此期间B线程是处于Blocked的 join源码分析 判断线程是否alive,否则一直wait() public final void join() throws InterruptedException { join(0); } public final synchronized void join(long millis) throws InterruptedException { long base = System.currentTimeMillis(); long now = 0; if (millis 关闭一个线程 正常结束 捕获中断信号关闭线程 使用volatile开关控制 public class Main { static class Mythread extends Thread{ private volatile boolean close = false; @Override public void run() { System.out.println(\"start\"); while(!close && ! isInterrupted()){ System.out.println(\"running...\"); } System.out.println(\"end\"); } public void close(){ this.close = true; this.interrupt(); } } public static void main(String[] args) throws Exception{ Mythread mythread = new Mythread(); mythread.start(); TimeUnit.SECONDS.sleep(1); mythread.close(); System.out.println(\"main end\"); } } 异常退出 进程假死 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 12:44:38 "},"content/java_thread_concurrent/thread_condition.html":{"url":"content/java_thread_concurrent/thread_condition.html","title":"Condition","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Condition 实现原理 为什么要有Condition？ Condition接口方法 仿写ArrayBlockingQueue，使用ReentrantLock & Condition [TOC] Condition 实现原理 与Object.wait()\\Object.notify()功能很类似。 以AQS非静态内部类的方式实现，因此Condition初始化的前提是先要有Lock实例，并且要先获取到锁 每个Condition对象都包含一个队列(等待队列)。等待队列是一个FIFO的队列，在队列中的每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程 调用condition的await()方法后，会将当前线程加入到等待队列中，然后释放锁，然后循环判断节点是否在同步队列中，再获取锁，否则一直阻塞 调用signal()方法后，先判断当前线程是否有锁，然后调用doSignal()方法，并唤醒线程，被唤醒的线程，再调用acquireQueude()方法，重新开始竞争锁，得到锁后返回，退出该方法 为什么要有Condition？ Condition是在JDK5中出现的技术，使用它有更好的灵活性，比如可以实现选择性通知功能，也就是在一个Lock对象里可以创建多个Condition实例，线程对象可以注册在指定的Condition中从而选择性的进行线程通知，在调度线程上更加灵活。而在使用notify()/notifuAll()方法进行通知时，被调度的线程却是由JVM随机选择的。 Condition接口方法 await() ：造成当前线程在接到信号或被中断之前一直处于等待状态。 await(long time, TimeUnit unit) ：造成当前线程在接到信号、被中断或到达指定等待时间之前一直处于等待状态。 awaitNanos(long nanosTimeout) ：造成当前线程在接到信号、被中断或到达指定等待时间之前一直处于等待状态。返回值表示剩余时间，如果在nanosTimesout之前唤醒，那么返回值 = nanosTimeout - 消耗时间，如果返回值 awaitUninterruptibly() ：造成当前线程在接到信号之前一直处于等待状态。【注意：该方法对中断不敏感】。 awaitUntil(Date deadline) ：造成当前线程在接到信号、被中断或到达指定最后期限之前一直处于等待状态。如果没有到指定时间就被通知，则返回true，否则表示到了指定时间，返回返回false。 signal() ：唤醒一个等待线程。该线程从等待方法返回前必须获得与Condition相关的锁。 signal()All ：唤醒所有等待线程。能够从等待方法返回的线程必须获得与Condition相关的锁。 仿写ArrayBlockingQueue，使用ReentrantLock & Condition import java.util.Arrays; import java.util.Random; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.ReentrantLock; class BoundedArrayQueue { Object[] items; /** items index for next take, poll, peek or remove */ int takeIndex; /** items index for next put, offer, or add */ int putIndex; /** Number of elements in the queue */ int count; /** Main lock guarding all access */ final ReentrantLock lock; /** Condition for waiting takes */ private final Condition notEmpty; // 可理解为 读线程 锁 /** Condition for waiting puts */ private final Condition notFull; // 可理解为 写线程 锁 public BoundedArrayQueue(int size) { items = new Object[size]; lock = new ReentrantLock(); notEmpty = lock.newCondition(); notFull = lock.newCondition(); } private void enqueue(E x) { // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) { putIndex = 0; } count++; notEmpty.signal(); } private E dequeue() { // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; E x = (E) items[takeIndex]; items[takeIndex] = null; if (++takeIndex == items.length) { takeIndex = 0; } count--; notFull.signal(); return x; } public void put(E e) throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == items.length) { System.out.println(\"now Array is Full. notFull await ...\"); notFull.await(); } enqueue(e); } finally { lock.unlock(); } } public E take() throws InterruptedException { final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try { while (count == 0) { System.out.println(\"now Array is Empty. notEmpty await ...\"); notEmpty.await(); } return dequeue(); } finally { lock.unlock(); } } public void print() { System.out.println(Arrays.toString(items)); } } class Main { private static final Random random = new Random(System.currentTimeMillis()); public static void main(String[] args) throws Exception { BoundedArrayQueue boundedArrayQueue = new BoundedArrayQueue<>(3); // boundedArrayQueue.put(\"\" + random.nextInt(10)); System.out.print(\"producer: \"); boundedArrayQueue.print(); // boundedArrayQueue.take(); System.out.print(\"consumer: \"); boundedArrayQueue.print(); // boundedArrayQueue.take(); System.out.print(\"consumer: \"); boundedArrayQueue.print(); } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 21:54:11 "},"content/java_thread_concurrent/semaphore.html":{"url":"content/java_thread_concurrent/semaphore.html","title":"Semaphore","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Semaphore Java Semaphore 常用API \"公平信号量\"和\"非公平信号量\" 构造函数(默认非公平) 例子代码 [TOC] Semaphore 信号量(Semaphore)，有时被称为信号灯，是在多线程环境下使用的一种设施，是可以用来保证两个或多个关键代码段不被并发调用。在进入一个关键代码段之前，线程必须获取一个信号量；一旦该关键代码段完成了，那么该线程必须释放信号量。其它想进入该关键代码段的线程必须等待直到第一个线程释放信号量。为了完成这个过程，需要创建一个信号量VI，然后将Acquire Semaphore VI以及Release Semaphore VI分别放置在每个关键代码段的首末端。确认这些信号量VI引用的是初始创建的信号量。（百度百科） Java Semaphore 常用API 名称 用法 acquire() 获取一个信号量（许可） acquire(int permits) 获取 permits 数量的信号量，在获取到 permits 数量的信号量之前会一直阻塞等待，并且数量必须小于等于 Semaphore 允许的总信号量，否则会出现死锁 acquireUninterruptibly() 获取一个不可被中断的信号量 tryAcquire() 尝试去回去一个信号量，获取到了，返回 true，否则 false tryAcquire(long timeout, TimeUnit unit) 在限定时间内尝试去回去一个信号量，获取到了，返回 true，否则 false release() 释放当前的信号量 release(int permits) 同样，上面获取了多少个信号量，这里就需要释放多少个，否则容易出现死锁一直等待的情况 \"公平信号量\"和\"非公平信号量\" Semaphore类采用AQS的共享模式，里面的两个内部类FairSync和NonfairSync都继承自AbstractQueuedSynchronizer \"公平信号量\"和\"非公平信号量\"的释放信号量的机制是一样的！不同的是它们获取信号量的机制：线程在尝试获取信号量许可时，对于公平信号量而言，如果当前线程不在CLH队列(CLH即Craig, Landin, and Hagersten (CLH)。AQS内部维护着一个FIFO的队列，即CLH队列。AQS的同步机制就是依靠CLH队列实现的。CLH队列是FIFO的双端双向队列，实现公平锁。线程通过AQS获取锁失败，就会将线程封装成一个Node节点，插入队列尾。当有线程释放锁时，后尝试把队头的next节点占用锁。)的头部，则排队等候；而对于非公平信号量而言，无论当前线程是不是在CLH队列的头部，它都会直接获取信号量。该差异具体的体现在，它们的tryAcquireShared()函数的实现不同。 非公平获取的源码 final int nonfairTryAcquireShared(int acquires) { for (;;) { int available = getState(); int remaining = available - acquires; if (remaining 无限循环，获取状态，然后CAS操作保证state确实减少acquires 构造函数(默认非公平) /** * Creates a {@code Semaphore} with the given number of * permits and nonfair fairness setting. * * @param permits the initial number of permits available. * This value may be negative, in which case releases * must occur before any acquires will be granted. */ public Semaphore(int permits) { sync = new NonfairSync(permits); } /** * Creates a {@code Semaphore} with the given number of * permits and the given fairness setting. * * @param permits the initial number of permits available. * This value may be negative, in which case releases * must occur before any acquires will be granted. * @param fair {@code true} if this semaphore will guarantee * first-in first-out granting of permits under contention, * else {@code false} */ public Semaphore(int permits, boolean fair) { sync = fair ? new FairSync(permits) : new NonfairSync(permits); } 例子代码 import java.text.SimpleDateFormat; import java.util.Calendar; import java.util.concurrent.*; /** * @Author mubi * @Date 2019/6/28 11:38 AM * * Semaphore 测试 */ public class ContextTest { static SimpleDateFormat df = new SimpleDateFormat(\"yyyy-MM-dd hh:mm:ss,SSS\"); // 限定进入线程的并发数量 private static final Semaphore semaphore = new Semaphore(3); static class TestThread1 implements Runnable { @Override public void run() { try { semaphore.acquire(1); Calendar cal = Calendar.getInstance(); System.out.println( df.format(cal.getTime()) + \" :\" + Thread.currentThread().getName()); Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } finally { semaphore.release(1); } } } static class TestThread2 implements Runnable { @Override public void run() { try { semaphore.acquire(2); Calendar cal = Calendar.getInstance(); System.out.println( df.format(cal.getTime()) + \" :\" + Thread.currentThread().getName()); Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } finally { semaphore.release(2); } } } void test1(){ ExecutorService exec = new ThreadPoolExecutor(10, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue<>()); int n = 10; for(int i=0;i()); int n = 10; for(int i=0;i Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 10:51:33 "},"content/java_thread_concurrent/hook_thread.html":{"url":"content/java_thread_concurrent/hook_thread.html","title":"Hook线程","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Hook线程以及捕获线程执行异常 获取线程运行时异常 例子代码 注入钩子线程 Hook线程的应用 Hook线程应用场景以及注意事项 [TOC] Hook线程以及捕获线程执行异常 获取线程运行时异常 当线程在运行过程中出现异常时，JVM会调用dispatchUncaughtException方法，该方法会将对应的线程实例以及异常信息传递给会调接口 例子代码 import java.util.concurrent.TimeUnit; /** * @Author mubi * @Date 2020/6/25 11:07 */ public class CaptureThreadException { public static void main(String[] args) { Thread.setDefaultUncaughtExceptionHandler((t,e)->{ System.out.println(\"thread:\" + t.getName() + \" occur exception\"); e.printStackTrace(); }); final Thread thread = new Thread(()->{ try{ TimeUnit.SECONDS.sleep(2); }catch (InterruptedException e){ } // 有异常抛出 System.out.println(1 / 0); }, \"test-e\"); thread.start(); } } 程序输出（捕获到线程异常） thread:test-e occur exception java.lang.ArithmeticException: / by zero at com.thread.CaptureThreadException.lambda$main$1(CaptureThreadException.java:24) at java.lang.Thread.run(Thread.java:748) 异常不断的往上抛：【线程异常】->【MainGroup】->【SystemGroup】->【System.err】 public class CaptureThreadException { public static void main(String[] args) { // 获取当前线程的线程组 ThreadGroup mainGroup = Thread.currentThread().getThreadGroup(); System.out.println(mainGroup.getName()); System.out.println(mainGroup.getParent()); System.out.println(mainGroup.getParent().getParent()); // Thread.setDefaultUncaughtExceptionHandler((t,e)->{ // System.out.println(\"thread:\" + t.getName() + \" occur exception\"); // e.printStackTrace(); // }); final Thread thread = new Thread(()->{ try{ TimeUnit.SECONDS.sleep(2); }catch (InterruptedException e){ } // 有异常抛出 System.out.println(1 / 0); }, \"test-e\"); thread.start(); } } 注入钩子线程 JVM进程的退出是由于JVM进程中没有活跃的非守护线程，或者收到了系统终端信号，向JVM程序注入一个Hook线程，在JVM进程退出的时候，Hook线程会启动执行，通过Runtime可以为JVM注入多个Hook线程 public static void main(String[] args) { Runtime.getRuntime().addShutdownHook(new Thread(()->{ try { System.out.println(\"the hook thread 1 is running.\"); TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"the hook thread 1 will exit.\"); })); // 钩子线程可以注册多个 Runtime.getRuntime().addShutdownHook(new Thread(()->{ try { System.out.println(\"the hook thread 2 is running.\"); TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"the hook thread 2 will exit.\"); })); System.out.println(\"the program will is stopping.\"); } Hook线程的应用 防止重复启动，启动的时候创建lock文件，进程中断或退出的时候删除lock文件 public class PreventDupStart { private final static String LOCK_PATH = \".\"; private final static String LOCK_FILE = \".lock\"; private final static String PERMISSION = \"rw-------\"; public static void main(String[] args) throws Exception{ Runtime.getRuntime().addShutdownHook(new Thread(()->{ try { System.out.println(\"the program received kill SIGNAL.\"); getLockFile().toFile().delete(); } catch (Exception e) { e.printStackTrace(); } System.out.println(\"the hook thread 1 will exit.\"); })); // 检查是否存在.lock文件 checkRunning(); // 模拟程序运行 for (;;){ try{ TimeUnit.MILLISECONDS.sleep(100); System.out.println(\"program is running\"); }catch (InterruptedException e){ e.printStackTrace(); } } } private static void checkRunning() throws IOException { Path path = getLockFile(); if(path.toFile().exists()){ throw new RuntimeException(\"the program already start\"); } Set perms = PosixFilePermissions.fromString(PERMISSION); Files.createFile(path, PosixFilePermissions.asFileAttribute(perms)); } private static Path getLockFile() { return Paths.get(LOCK_PATH, LOCK_FILE); } } Hook线程应用场景以及注意事项 Hook线程只有在收到退出信号的时候会被执行，如果在kill的时候使用了参数9,那么Hook线程不会得到执行，进程将会立刻退出，因此.lock文件将得不到清理 Hook线程也可以执行一些资源释放的工作，比如关闭文件句炳，socket链接，数据库connection等 尽量不要在Hook线程中执行一些耗时非常长的操作，因为其会导致程序迟迟不能退出 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-25 13:15:58 "},"content/java_thread_concurrent/countdownlatch_cyclicBarrier.html":{"url":"content/java_thread_concurrent/countdownlatch_cyclicBarrier.html","title":"CountDownLatch & CyclicBarrier","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 CountDownLatch (做减法，例子：六国逐一灭，秦统一) CountDownLatch源码 CyclicBarrier（做加法，例子：召唤神龙，要收集到七龙珠） Semaphore [TOC] CountDownLatch (做减法，例子：六国逐一灭，秦统一) A synchronization aid that allows one or more threads to wait until a set of operations being performed in other threads completes. public class Main { public static void main(String[] args) throws Exception { CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 1; i { System.out.println(Thread.currentThread().getName() + \"国，被灭\"); countDownLatch.countDown(); // count 减一 }, \"\" + i).start(); } // 一直等待，直到数字达到0，放行。 countDownLatch.await(); System.out.println(Thread.currentThread().getName() + \"\\t **************秦帝国，统一华夏\"); closeDoor(); } private static void closeDoor() throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(6); for (int i = 1; i { System.out.println(Thread.currentThread().getName()+\"\\t上完自习，离开教室\"); countDownLatch.countDown(); }, \"thread\"+String.valueOf(i)).start(); } // 等待，减少数字达到0，放行。 countDownLatch.await(); System.out.println(Thread.currentThread().getName()+\"\\t **************班长最后关门走人\"); } } CountDownLatch源码 自定义Sync类继承AbstractQueuedSynchronizer，利用AQS自身的状态变量state代表数量(初始化的时候指定),countdown操作让状态只减1(具体是CAS操作compareAndSetState方法让state减少1) public class CountDownLatch { /** * Synchronization control For CountDownLatch. * Uses AQS state to represent count. */ private static final class Sync extends AbstractQueuedSynchronizer { private static final long serialVersionUID = 4982264981922014374L; Sync(int count) { setState(count); } int getCount() { return getState(); } protected int tryAcquireShared(int acquires) { return (getState() == 0) ? 1 : -1; } protected boolean tryReleaseShared(int releases) { // Decrement count; signal when transition to zero for (;;) { int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; } } } private final Sync sync; public void countDown() { sync.releaseShared(1); } unsafe.compareAndSwapInt方法 /** * Atomically sets synchronization state to the given updated * value if the current state value equals the expected value. * This operation has memory semantics of a {@code volatile} read * and write. * * @param expect the expected value * @param update the new value * @return {@code true} if successful. False return indicates that the actual * value was not equal to the expected value. */ protected final boolean compareAndSetState(int expect, int update) { // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update); } await方法 /** 当前线程一直等待直到countDown到0，或者线程有interrupted异常抛出； 如果count本来就是0，那么该方法直接返回 * Causes the current thread to wait until the latch has counted down to * zero, unless the thread is {@linkplain Thread#interrupt interrupted}. * * If the current count is zero then this method returns immediately. * * If the current count is greater than zero then the current * thread becomes disabled for thread scheduling purposes and lies * dormant until one of two things happen: * * The count reaches zero due to invocations of the * {@link #countDown} method; or * Some other thread {@linkplain Thread#interrupt interrupts} * the current thread. * * * If the current thread: * * has its interrupted status set on entry to this method; or * is {@linkplain Thread#interrupt interrupted} while waiting, * * then {@link InterruptedException} is thrown and the current thread's * interrupted status is cleared. * * @throws InterruptedException if the current thread is interrupted * while waiting */ public void await() throws InterruptedException { sync.acquireSharedInterruptibly(1); } public final void acquireSharedInterruptibly(int arg) throws InterruptedException { if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) Aqs的doAcquireSharedInterruptibly方法 /** * Acquires in shared interruptible mode. * @param arg the acquire argument */ private void doAcquireSharedInterruptibly(int arg) throws InterruptedException { // 添加共享模式节点， final Node node = addWaiter(Node.SHARED); boolean failed = true; try { for (;;) { // 拿到当前节点的前驱节点 final Node p = node.predecessor(); if (p == head) { // 尝试获取资源 int r = tryAcquireShared(arg); // 大于等于0，说明有资源获取 if (r >= 0) { // 把当前节点设置成head节点，并传播唤醒后面的节点。 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; } } // 这里和独占模式一样，如果没资源申请，封装节点，并park等待 if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt()) throw new InterruptedException(); } } finally { if (failed) cancelAcquire(node); } } CyclicBarrier（做加法，例子：召唤神龙，要收集到七龙珠） A synchronization aid that allows a set of threads to all wait for each other to reach a common barrier point. CyclicBarriers are useful in programs involving a fixed sized party of threads that must occasionally wait for each other. The barrier is called cyclic because it can be re-used after the waiting threads are released. cyclic: adj. 循环的; 周期的; barrier: n. 屏障; 障碍物; 障碍; 阻力; 关卡; 分界线; 隔阂; public class Main { public static void main(String[] args) { CyclicBarrier cyclicBarrier = new CyclicBarrier(7,()->{ System.out.println(\"****召唤神龙****\"); }); for (int i = 1; i { System.out.println(Thread.currentThread().getName()+\"\\t收集到第七颗龙珠：\"+tempInt+\"龙珠\"); try { cyclicBarrier.await(); // 找到了，就继续等其它龙珠收集 } catch (InterruptedException | BrokenBarrierException e) { e.printStackTrace(); } }, String.valueOf(i)).start(); } } } Semaphore import java.util.concurrent.Semaphore; import java.util.concurrent.TimeUnit; public class Main { public static void main(String[] args) { Semaphore semaphore = new Semaphore(3); // 模拟3个停车位 for(int i=1;i{ try{ semaphore.acquire(); System.out.println(Thread.currentThread().getName() + \" 抢到车位\"); TimeUnit.SECONDS.sleep(3); System.out.println(Thread.currentThread().getName() + \" 停车3s后离开\"); }catch (Exception e){ }finally { semaphore.release(); } }, String.valueOf(i)).start(); } } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 10:52:05 "},"content/java_thread_concurrent/longAdder.html":{"url":"content/java_thread_concurrent/longAdder.html","title":"LongAdder","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 LongAdder 源码分析 unsafe int 操作的一些方法 Cell 对象(Striped64类的静态内部类) add(long x) longAccumulate(x, null, uncontended) sum() LongAdder和AtomicLong [TOC] LongAdder LongAdder内部将一个long分成多个cell，每个线程可以对一个cell操作，如果需要取出long数据则求和即可，这样增强了在高并发情况下的效率 /** * One or more variables that together maintain an initially zero * {@code long} sum. When updates (method {@link #add}) are contended * across threads, the set of variables may grow dynamically to reduce * contention. Method {@link #sum} (or, equivalently, {@link * #longValue}) returns the current total combined across the * variables maintaining the sum. * 只能做累加，或者自增自减操作，不能做其它操作 用一个Cell数组来存放分段数据值大小，Cell数组元素只有一个volatile long value表示存放的值 sum方法用于返回当前计数值，返回所有Cell中value的和 多个线程会进行hash，对不同的Cell元素进行操作 内部有扩容方法，增加更多的Cell元素 英语单词 probe: v. 盘问; 追问; 探究; (用细长工具) 探查，查看;n.探究; 详尽调查; (不载人) 航天探测器，宇宙探测航天器; (医生用的) 探针; contention: n. 争吵; 争执; 争论; (尤指争论时的) 看法，观点; 源码分析 unsafe int 操作的一些方法 public native int getInt(Object o, long offset);//获得给定对象偏移量上的int值 public native void putInt(Object o, long offset, int x);//设置给定对象偏移量上的int值 public native long objectFieldOffset(Field f);//获得字段在对象中的偏移量 public native void putIntVolatile(Object o, long offset, int x);//设置给定对象的int值，使用volatile语义 public native int getIntVolatile(Object o, long offset);//获得给定对象对象的int值，使用volatile语义 public native void putOrderedInt(Object o, long offset, int x);//和putIntVolatile()一样，但是它要求被操作字段就是volatile类型的 Cell 对象(Striped64类的静态内部类) 使用了@sun.misc.Contended注解(缓存行使用,解决伪共享) /** * Padded variant of AtomicLong supporting only raw accesses plus CAS. * * JVM intrinsics note: It would be possible to use a release-only * form of CAS here, if it were provided. */ @sun.misc.Contended static final class Cell { volatile long value; Cell(long x) { value = x; } final boolean cas(long cmp, long val) { return UNSAFE.compareAndSwapLong(this, valueOffset, cmp, val); } // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long valueOffset; static { try { UNSAFE = sun.misc.Unsafe.getUnsafe(); Class ak = Cell.class; valueOffset = UNSAFE.objectFieldOffset (ak.getDeclaredField(\"value\")); } catch (Exception e) { throw new Error(e); } } } Striped64静态初始化 // Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long BASE; private static final long CELLSBUSY; private static final long PROBE; static { try { UNSAFE = sun.misc.Unsafe.getUnsafe(); Class sk = Striped64.class; BASE = UNSAFE.objectFieldOffset (sk.getDeclaredField(\"base\")); CELLSBUSY = UNSAFE.objectFieldOffset (sk.getDeclaredField(\"cellsBusy\")); Class tk = Thread.class; PROBE = UNSAFE.objectFieldOffset (tk.getDeclaredField(\"threadLocalRandomProbe\")); } catch (Exception e) { throw new Error(e); } } base：为非竞争状态下的一个值 PROBE：一个随机的hashCode一样，每个线程有一个自己的probe，可以标示cells数组下标 add(long x) /** * Adds the given value. * * @param x the value to add */ public void add(long x) { Cell[] as; long b, v; int m; Cell a; if ((as = cells) != null || !casBase(b = base, b + x)) { boolean uncontended = true; if (as == null || (m = as.length - 1) casBase就是一个CAS操作(一般自旋锁这里是whille(!cas){})，当有竞争的时候，CAS可能操作失败 /** * CASes the base field. */ final boolean casBase(long cmp, long val) { return UNSAFE.compareAndSwapLong(this, BASE, cmp, val); } as == null， (m = as.length - 1) (a = as[getProbe() & m]) == null !(uncontended = a.cas(v = a.value, v + x)) if中判断1和判断2是判断cells是否为空 判断3是判断当前线程的cell是否是null 判断4是当前线程进行cas操作 最后是longAccumulate(x, null, uncontended); longAccumulate(x, null, uncontended) 如果Cell[]数组未初始化，会调用父类的longAccumelate去初始化Cell[]，如果Cell[]已经初始化但是冲突发生在Cell单元内，则也调用父类的longAccumelate，此时可能就需要对Cell[]扩容了。 sum() base + cells数组中各内容值 public long sum() { Cell[] as = cells; Cell a; long sum = base; if (as != null) { for (int i = 0; i LongAdder和AtomicLong 性能对比 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-28 09:56:30 "},"content/java_thread_concurrent/thread_design.html":{"url":"content/java_thread_concurrent/thread_design.html","title":"多线程设计模式","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 多线程设计模式 Immutable 模式 可以synchronized解决(互斥，效率低) DateTimeFormatter对象(immutable and thread-safe) 不可变设计模式 Flyweight pattern(享元模式) Integer.valueOf 例子 Single Thread Execution Future设计模式 work-stealing算法 [TOC] 多线程设计模式 Immutable 模式 eg: SimpleDateFormat线程不安全问题 void test(){ SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd\"); for (int i = 0; i { try { Date date = dateFormat.parse(\"1999-09-09\"); System.out.println(date); }catch (Exception e){ e.printStackTrace(); } }).start(); } } 某次运行输出如下，会报错:NumberFormatException Thu Sep 09 00:00:00 CST 1999 java.lang.NumberFormatException: For input string: \".909E.9092E\" Thu Sep 09 00:00:00 CST 1999 at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043) at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110) at java.lang.Double.parseDouble(Double.java:538) at java.text.DigitList.getDouble(DigitList.java:169) at java.text.DecimalFormat.parse(DecimalFormat.java:2056) at java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1869) at java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1514) at java.text.DateFormat.parse(DateFormat.java:364) at Main.lambda$test$0(Main.java:351) at java.lang.Thread.run(Thread.java:748) java.lang.NumberFormatException: For input string: \".909E.9092E2\" Thu Sep 09 00:00:00 CST 1999 at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043) Thu Sep 09 00:00:00 CST 1999 at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110) at java.lang.Double.parseDouble(Double.java:538) at java.text.DigitList.getDouble(DigitList.java:169) at java.text.DecimalFormat.parse(DecimalFormat.java:2056) at java.text.SimpleDateFormat.subParse(SimpleDateFormat.java:1869) at java.text.SimpleDateFormat.parse(SimpleDateFormat.java:1514) at java.text.DateFormat.parse(DateFormat.java:364) at Main.lambda$test$0(Main.java:351) at java.lang.Thread.run(Thread.java:748) Thu Sep 09 00:00:00 CST 1999 Thu Sep 09 00:00:00 CST 1999 Thu Sep 09 00:00:00 CST 1999 Thu Sep 09 00:00:00 CST 1999 可以synchronized解决(互斥，效率低) void test(){ SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd\"); for (int i = 0; i { synchronized (dateFormat) { try { Date date = dateFormat.parse(\"1999-09-09\"); System.out.println(date); } catch (Exception e) { e.printStackTrace(); } } }).start(); } } DateTimeFormatter对象(immutable and thread-safe) void test(){ DateTimeFormatter dateTimeFormatter = DateTimeFormatter.ofPattern(\"yyyy-MM-dd\"); for (int i = 0; i { try { TemporalAccessor date = dateTimeFormatter.parse(\"1999-09-09\"); System.out.println(date); } catch (Exception e) { e.printStackTrace(); } }).start(); } } 不可变设计模式 eg: String类是不可变的（final类），char[] value也是final的 final 保证 引用不能修改，值是可更改的； String保护性的拷贝(深拷贝) 矛盾： 对象会创建的比较多 Flyweight pattern(享元模式) Integer.valueOf 例子 Integer.valueOf 会有一个缓存，数字在一定范围内不会创建新的对象 /** * Returns an {@code Integer} instance representing the specified * {@code int} value. If a new {@code Integer} instance is not * required, this method should generally be used in preference to * the constructor {@link #Integer(int)}, as this method is likely * to yield significantly better space and time performance by * caching frequently requested values. * * This method will always cache values in the range -128 to 127, * inclusive, and may cache other values outside of this range. * * @param i an {@code int} value. * @return an {@code Integer} instance representing {@code i}. * @since 1.5 */ public static Integer valueOf(int i) { if (i >= IntegerCache.low && i Interger缓存 private static class IntegerCache { static final int low = -128; static final int high; static final Integer cache[]; static { // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(\"java.lang.Integer.IntegerCache.high\"); if (integerCacheHighPropValue != null) { try { int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); } catch( NumberFormatException nfe) { // If the property cannot be parsed into an int, ignore it. } } high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k = 127; } private IntegerCache() {} } Single Thread Execution 单线程模式：保证在同一时刻只能有一个线程访问共享资源 Future设计模式 public static void delay(int sec) { try { TimeUnit.SECONDS.sleep(sec); } catch (InterruptedException e) { throw new RuntimeException(e); } } public static Future getPrice(double df){ ExecutorService executor = Executors.newSingleThreadExecutor(); Future future = executor.submit(new Callable() { @Override public Double call() throws Exception { delay(2); return df * 10; } }); executor.shutdown(); return future; } public static void priceTest(){ Future futurePrice = getPrice(10.0f); Double price = null; try { int timeOut = 3; price = futurePrice.get(timeOut, TimeUnit.SECONDS); } catch (Exception e) { System.out.println(\"cannot get within 1 sec\"); futurePrice.cancel(false); throw new RuntimeException(e); } System.out.println(\"get price:\" + price); } work-stealing算法 一个大任务分割为若干个互不依赖的子任务，为了减少线程间的竞争，把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应。 线程1 - 队列1（任务1，任务2，任务3，...） 线程2 - 队列2（任务1，任务2，任务3，...） 比如线程1早早的把队列中任务都处理完了有空闲，但是队列2执行任务较慢；这样队列2中任务可以让线程1帮忙执行（即窃取线程1） Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-16 20:57:30 "},"content/java_thread_concurrent/thread_pool.html":{"url":"content/java_thread_concurrent/thread_pool.html","title":"线程池","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 线程池 常见类 interface Executor interface ExecutorService extends Executor abstract class AbstractExecutorService implements ExecutorService class ThreadPoolExecutor extends AbstractExecutorService ThreadFactory ThreadPoolExecutor 构造函数和成员含义 线程池的处理流程图 拒绝策略 线程添加到线程池中被拒绝的原因 常见的几种拒绝策略 ThreadPoolExecutor 的使用 ThreadPoolExecutor 实例1 线程池使用后关闭问题？ 固定线程池 CachedThreadPool 线程池shutdown，shutdownNow FutureTask & 线程池 线程池新进来的任务被拒绝 ForkJoinPool(java.util.concurrent;) new ForkJoinPool() ForkJoinTask 使用例子 [TOC] 线程池 为什么需要线程池 ？ 线程池的应用范围 ？ 线程的创建销毁是个消耗系统的操作 线程资源的复用 线程池应该具备哪些功能 ？ 线程池的实现需要注意哪些细节 ？ 常见类 interface Executor public interface Executor { /** * Executes the given command at some time in the future. The command * may execute in a new thread, in a pooled thread, or in the calling * thread, at the discretion of the {@code Executor} implementation. * * @param command the runnable task * @throws RejectedExecutionException if this task cannot be * accepted for execution * @throws NullPointerException if command is null */ void execute(Runnable command); } interface ExecutorService extends Executor execute() 执行任务 shutdown() 调用后不再接收新任务，如果里面有任务，就执行完 shutdownNow() 调用后不再接受新任务，如果有等待任务，移出队列；有正在执行的，尝试停止之 isShutdown() 判断线程池是否关闭 isTerminated() 判断线程池中任务是否执行完成 submit() 提交任务 invokeAll() 执行一组任务 abstract class AbstractExecutorService implements ExecutorService class ThreadPoolExecutor extends AbstractExecutorService ThreadFactory 工厂模式 ThreadFactory /** * The default thread factory */ static class DefaultThreadFactory implements ThreadFactory { private static final AtomicInteger poolNumber = new AtomicInteger(1); private final ThreadGroup group; private final AtomicInteger threadNumber = new AtomicInteger(1); private final String namePrefix; DefaultThreadFactory() { SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; } public Thread newThread(Runnable r) { Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; } } ThreadPoolExecutor 构造函数和成员含义 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, ThreadFactory threadFactory) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler); } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, RejectedExecutionHandler handler) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler); } public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize corePoolSize: 指定了线程池中的基本线程数量，即在没有任务需要执行的时候线程池的大小，并且只有在工作队列满了的情况下才会创建超出这个数量的线程；在刚刚创建ThreadPoolExecutor的时候，线程并不会立即启动，而是要等到有任务提交时才会启动，除非调用了prestartCoreThread/prestartAllCoreThreads事先启动核心线程。再考虑到keepAliveTime和allowCoreThreadTimeOut超时参数的影响，所以没有任务需要执行的时候，线程池的大小不一定是corePoolSize maximumPoolSize: 指定了线程池中的最大线程数量，这个参数会根据你使用的workQueue任务队列的类型，决定线程池会开辟的最大线程数量 keepAliveTime: 当线程池中空闲线程数量超过corePoolSize时，多余的线程会在多长时间内被销毁； unit: keepAliveTime的单位 workQueue: 阻塞任务队列，被添加到线程池中，但尚未被执行的任务；它一般分为:1.直接提交队列、2.有界任务队列、3.无界任务队列、4.优先任务队列(特殊的无界队列)几种； threadFactory: 线程工厂，用于创建线程，一般用默认即可； handler: 拒绝策略；当任务太多来不及处理时，如何拒绝任务； workerCount: 当前活跃的线程数(也即线程池中的线程数量) 线程池的处理流程图 1、如果当前线程池的线程数还没有达到基本大小(poolSize = corePoolSize) 且任务队列未满时，就将新提交的任务提交到阻塞队列排队，等候处理workQueue.offer(command)； 3、如果当前线程池的线程数大于或等于基本大小(poolSize >= corePoolSize) 且任务队列满时； 3.1、当前poolSize 拒绝策略 线程池的拒绝策略:是指当任务添加到线程池中被拒绝而采取的处理措施 线程添加到线程池中被拒绝的原因 当任务添加到线程池中之所以被拒绝，可能是由于：第一线程池异常关闭。第二，任务数量超过线程池的最大限制,并设置有界的workeQueue 常见的几种拒绝策略 ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。（默认） ThreadPoolExecutor.DiscardPolicy：丢弃任务，但是不抛出异常。 ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新提交被拒绝的任务 ThreadPoolExecutor.CallerRunsPolicy：由调用线程（提交任务的线程）自己处理该任务 ThreadPoolExecutor 的使用 当线程池小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程 当线程池达到corePoolSize时，新提交任务将被放入workQueue中，等待线程池中任务调度执行 当workQueue已满，如果workerCount >= corePoolSize && workerCount 当workQueue已满，且workerCount超过maximumPoolSize时，新提交任务由RejectedExecutionHandler处理 当线程池中有超过corePoolSize线程，当空闲时间达到keepAliveTime时，会关闭空闲线程 当设置allowCoreThreadTimeOut(true)时，线程池中corePoolSize线程空闲时间达到keepAliveTime也将关闭 ThreadPoolExecutor 实例1 package com.threadpool; import java.util.concurrent.*; import java.util.concurrent.atomic.AtomicInteger; /** * @Author mubi * @Date 2019/4/8 10:52 PM */ public class ThreadPoolUse { static class MyThreadFactory implements ThreadFactory { private AtomicInteger count = new AtomicInteger(0); @Override public Thread newThread(Runnable r) { Thread t = new Thread(r); String threadName = \"MyThread\" + count.addAndGet(1); System.out.println(threadName); t.setName(threadName); return t; } } static class MyTask implements Runnable{ int id; MyTask(int id){ this.id = id; } @Override public void run() { try{ System.out.println(\"myTask id:\" + id); TimeUnit.SECONDS.sleep(10); }catch (Exception e){ e.printStackTrace(); } } } public static void main(String[] args){ int corePoolSize = 2; int maximumPoolSize = 4; int keepAliveTime = 2; TimeUnit timeUnit = TimeUnit.SECONDS; BlockingQueue workQueue = new ArrayBlockingQueue<>(1); RejectedExecutionHandler handler = new ThreadPoolExecutor.AbortPolicy(); ThreadFactory threadFactory = new MyThreadFactory(); ThreadPoolExecutor executor = new ThreadPoolExecutor( corePoolSize, maximumPoolSize, keepAliveTime, timeUnit, workQueue, threadFactory, handler); for(int i=0;i 线程池使用后关闭问题？ 是否需要关闭？如何关闭？ A pool that is no longer referenced in a program and has no remaining threads will be shutdown automatically. 如果程序中不再持有线程池的引用，并且线程池中没有线程时，线程池将会自动关闭。 注：线程池中没有线程是指线程池中的所有线程都已运行完自动消亡。然而我们常用的FixedThreadPool的核心线程没有超时策略，所以并不会自动关闭。 固定线程池 static void testFixPool(){ while(true) { ExecutorService executorService = Executors.newFixedThreadPool(8); executorService.execute(() -> System.out.println(\"running\")); executorService = null; } } public static void main(String[] args){ testFixPool(); System.out.println(\"main end\"); } 因为固定线程池不会自己销毁，最终会耗尽内存（需要在合适的时候shutdown） running running running running running Exception in thread \"main\" java.lang.OutOfMemoryError: unable to create new native thread at java.lang.Thread.start0(Native Method) at java.lang.Thread.start(Thread.java:717) at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:957) at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1367) at com.threadpool.ThreadPoolUse.testFixPool(ThreadPoolUse.java:71) at com.threadpool.ThreadPoolUse.main(ThreadPoolUse.java:77) CachedThreadPool static void testCachedThreadPool(){ while(true) { // 默认keepAliveTime为 60s ExecutorService executorService = Executors.newCachedThreadPool(); ThreadPoolExecutor threadPoolExecutor = (ThreadPoolExecutor) executorService; // 为了更好的模拟，动态修改为1纳秒 threadPoolExecutor.setKeepAliveTime(1, TimeUnit.NANOSECONDS); threadPoolExecutor.execute(() -> System.out.println(\"running\")); executorService = null; } } public static void main(String[] args){ testCachedThreadPool(); System.out.println(\"main end\"); } CachedThreadPool 的线程 keepAliveTime 默认为 60s ，核心线程数量为 0 ，所以不会有核心线程存活阻止线程池自动关闭。 详见 线程池之ThreadPoolExecutor构造 ；为了更快的模拟，构造后将 keepAliveTime 修改为1纳秒，相当于线程执行完马上会消亡，所以线程池可以被回收。实际开发中，如果CachedThreadPool确实忘记关闭，在一定时间后是可以被回收的。但仍然建议显示关闭。 线程池shutdown，shutdownNow package com.threadpool; import java.util.concurrent.*; import java.util.concurrent.atomic.AtomicInteger; /** * @Author mubi * @Date 2019/4/8 10:52 PM */ public class ThreadPoolUse { static class MyThreadFactory implements ThreadFactory { private AtomicInteger count = new AtomicInteger(0); @Override public Thread newThread(Runnable r) { Thread t = new Thread(r); String threadName = \"MyThread\" + count.addAndGet(1); System.out.println(threadName); t.setName(threadName); return t; } } static class MyTask implements Runnable{ int id; MyTask(int id){ this.id = id; } @Override public void run() { try{ System.out.println(\"myTask id:\" + id); TimeUnit.SECONDS.sleep(10); }catch (Exception e){ e.printStackTrace(); } } } static void testFixPool(){ while(true) { ExecutorService executorService = Executors.newFixedThreadPool(8); executorService.execute(() -> System.out.println(\"running\")); executorService = null; } } static void testCachedThreadPool(){ while(true) { // 默认keepAliveTime为 60s ExecutorService executorService = Executors.newCachedThreadPool(); ThreadPoolExecutor threadPoolExecutor = (ThreadPoolExecutor) executorService; // 为了更好的模拟，动态修改为1纳秒 threadPoolExecutor.setKeepAliveTime(1, TimeUnit.NANOSECONDS); threadPoolExecutor.execute(() -> System.out.println(\"running\")); executorService = null; } } static class MyRejectPolicy implements RejectedExecutionHandler{ @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) { if (r instanceof MyTask) { MyTask r1 = (MyTask) r; //直接打印 System.out.println(\"Reject Thread:\" + r1.id); } } } static void test(){ int corePoolSize = 2; int maximumPoolSize = 5; int keepAliveTime = 60 * 1; TimeUnit timeUnit = TimeUnit.SECONDS; BlockingQueue workQueue = new ArrayBlockingQueue<>(2); // RejectedExecutionHandler handler = new ThreadPoolExecutor.AbortPolicy(); RejectedExecutionHandler handler = new MyRejectPolicy(); ThreadFactory threadFactory = new MyThreadFactory(); ThreadPoolExecutor executor = new ThreadPoolExecutor( corePoolSize, maximumPoolSize, keepAliveTime, timeUnit, workQueue, threadFactory, handler); MyTask task = new MyTask(1); executor.execute(task); executor.shutdown(); // 已经关闭的线程池，引用还在，再有新任务，会执行拒绝策略 MyTask task2 = new MyTask(2); executor.execute(task2); } public static void main(String[] args){ test(); System.out.println(\"main end\"); } } FutureTask & 线程池 import java.util.ArrayList; import java.util.List; import java.util.Random; import java.util.concurrent.Callable; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; import java.util.concurrent.FutureTask; class Task implements Callable{ String name; public Task(String name) { this.name = name; } @Override public Integer call() throws Exception { Integer res = new Random().nextInt(100); Thread.sleep(1000); System.out.println(\"任务执行:获取到结果 :\"+res); return res; } public String getName() { return name; } } public class Solution { public void testFutureAndThreadPool(){ // 线程池 ExecutorService executorService = Executors.newFixedThreadPool(10); //进行异步任务列表 List> futureTasks = new ArrayList<>(); long start = System.currentTimeMillis(); int n = 10; for(int i=0;i futureTask = new FutureTask<>(task); futureTasks.add(futureTask); //提交异步任务到线程池，让线程池管理任务。 //由于是异步并行任务，所以这里并不会阻塞 executorService.submit(futureTask); } int count = 0; for (FutureTask futureTask : futureTasks) { // get() // get(long timeout, TimeUnit unit) 第一个参数为最大等待时间，第二个为时间的单位 try{ count += futureTask.get(); }catch (Exception e){ e.printStackTrace(); } } //清理线程池 executorService.shutdown(); long end = System.currentTimeMillis(); System.out.println(\"线程池的任务全部完成:结果为:\"+count+\"，main线程关闭，进行线程的清理\"); System.out.println(\"使用时间：\"+(end-start)+\"ms\"); } public void testLine(){ long start = System.currentTimeMillis(); int n = 10; int count = 0; for(int i=0;i 线程池新进来的任务被拒绝 线程池shutdown了，新进来的任务会被拒绝 线程池用满了，且新进来的任务超过了任务队列大小，任务被拒绝 import java.text.SimpleDateFormat; import java.util.concurrent.*; import java.util.concurrent.atomic.AtomicInteger; /** * @Author mubi * @Date 2019/9/2 21:38 */ public class ThreadPoolTest { static SimpleDateFormat df = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss,SSS\"); static RejectedExecutionHandler defaultHandler = new RejectedExecutionHandler() { @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor e) { throw new RejectedExecutionException(\"MyTest Task \" + r.toString() + \" rejected from \" + e.toString()); } }; static AtomicInteger atomicInteger = new AtomicInteger(0); ThreadFactory threadFactory = new ThreadFactory() { @Override public Thread newThread(Runnable r) { Thread thread = new Thread(r); thread.setName(\"mythread-\" + atomicInteger.get()); atomicInteger.incrementAndGet(); return thread; } }; void test1(){ ThreadPoolExecutor EXECUTOR = new ThreadPoolExecutor(5, 10, 3000L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<>(2), threadFactory, defaultHandler); int n = 2; for (int i = 0; i (2), threadFactory, defaultHandler ); int n = 15; for (int i = 0; i ForkJoinPool(java.util.concurrent;) @sun.misc.Contended public class ForkJoinPool extends AbstractExecutorService ForkJoin思想：把一个任务拆分成多个“小任务”，把多个“小任务”放到多个处理器核心上并行执行；当多个“小任务”执行完成之后，再将这些执行结果合并起来即可 fork n. 餐叉; 叉(挖掘用的园艺工具); (道路、河流等的) 分岔处，分流处，岔口，岔路; v. 分岔; 岔开两条分支; 走岔路中的一条; 叉运; 叉掘; join v. 连接; 接合; 联结; 结合; 联合; 汇合; 成为…的一员; 参加; 加入; n. 结合; 连接; 接合点; new ForkJoinPool() public ForkJoinPool() { this(Math.min(MAX_CAP, Runtime.getRuntime().availableProcessors()), defaultForkJoinWorkerThreadFactory, null, false); } /** * Creates a {@code ForkJoinPool} with the given parameters, without * any security checks or parameter validation. Invoked directly by * makeCommonPool. */ private ForkJoinPool(int parallelism, ForkJoinWorkerThreadFactory factory, UncaughtExceptionHandler handler, int mode, String workerNamePrefix) { this.workerNamePrefix = workerNamePrefix; this.factory = factory; this.ueh = handler; this.config = (parallelism & SMASK) | mode; long np = (long)(-parallelism); // offset ctl counts this.ctl = ((np 默认线程数量是：Runtime.getRuntime().availableProcessors()(1个cpu，2核，超线程数2，返回4) ForkJoinTask public abstract class ForkJoinTask implements Future, Serializable { Abstract base class for tasks that run within a ForkJoinPool. A ForkJoinTask is a thread-like entity that is much lighter weight than a normal thread. Huge numbers of tasks and subtasks may be hosted by a small number of actual threads in a ForkJoinPool, at the price of some usage limitations. 使用例子 public class ForkJoinTaskExample extends RecursiveTask { public static final int threshold = 2; private int start; private int end; public ForkJoinTaskExample(int start, int end) { this.start = start; this.end = end; } @Override protected Integer compute() { int sum = 0; boolean canCompute = (end - start) result = forkjoinPool.submit(task); System.out.println(\"result:\" + result.get()); } public static void main(String[] args) throws Exception{ testForkJoinPool(); TimeUnit.SECONDS.sleep(1); } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 08:47:32 "},"content/java_thread_concurrent/concurrency_problems.html":{"url":"content/java_thread_concurrent/concurrency_problems.html","title":"常见的多线程题目","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 三个线程：怎么能实现依次打印ABC的功能 方法1: ReentrantLock & Condition（条件锁） 方法2: synchronized & wait() notify() notifyAll()（状态同步 + wait/notify） 方法3: 信号量 现在有T1、T2、T3三个线程，你怎样保证T2在T1执行完后执行，T3在T2执行完后执行？ 用Java实现阻塞队列？ [TOC] 三个线程：怎么能实现依次打印ABC的功能 方法1: ReentrantLock & Condition（条件锁） package com.thread; import java.util.concurrent.TimeUnit; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.ReentrantLock; /** * @Author mubi * @Date 2019/3/12 10:34 AM * lock & condition 对比 synchronized wait notify */ public class Main { final static int N = 5; static int count = 0; static int flag = 1; public static void main(String[] args) throws Exception{ ReentrantLock lock = new ReentrantLock(); Condition conditionA = lock.newCondition(); Condition conditionB = lock.newCondition(); Condition conditionC = lock.newCondition(); Thread threadA = new Thread(new Runnable() { @Override public void run() { while(count { while(count { while (count 方法2: synchronized & wait() notify() notifyAll()（状态同步 + wait/notify） public class Main{ static int N = 2; static int flag = 3; static Object object = new Object(); public static void main(String[] args) throws Exception { Thread A = new Thread(()-> { synchronized (object) { for(int i=0;i { synchronized (object) { for(int i=0;i { synchronized (object) { for(int i=0;i 方法3: 信号量 class FooBar { private int n; Semaphore fooSemaphore = new Semaphore(1); Semaphore barSemaphore = new Semaphore(0); public FooBar(int n) { this.n = n; } public void foo(Runnable printFoo) throws InterruptedException { for (int i = 0; i 现在有T1、T2、T3三个线程，你怎样保证T2在T1执行完后执行，T3在T2执行完后执行？ public class Main { public static void main(String[] args) throws Exception{ Thread t1 = new Thread(()->{ System.out.println(Thread.currentThread().getName() + \" running\"); },\"t1\"); Thread t2 = new Thread(()->{ try{ t1.join(); }catch (Exception e){ } System.out.println(Thread.currentThread().getName() + \" running\"); },\"t2\"); Thread t3 = new Thread(()->{ try{ t2.join(); }catch (Exception e){ } System.out.println(Thread.currentThread().getName() + \" running\"); },\"t3\"); t1.start(); t2.start(); t3.start(); TimeUnit.SECONDS.sleep(1); System.out.println(\"main end\"); } } 用Java实现阻塞队列？ 阻塞队列与普通队列的不同在于。当队列是空的时候，从队列中获取元素的操作将会被阻塞，或者当队列满时，往队列里面添加元素将会被阻塞。需要保证多个线程可以安全的访问队列 ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列 LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列 PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列 DelayQueue：一个使用优先级队列实现的无界阻塞队列 SynchronousQueue：一个不存储元素的阻塞队列 LinkedTransferQueue：一个由链表结构组成的无界阻塞队列 LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-28 09:05:37 "},"content/java_thread_concurrent/thread_pool_self.html":{"url":"content/java_thread_concurrent/thread_pool_self.html","title":"自定义线程池","keywords":"","body":"[TOC] 自定义线程池步骤 自定义一个阻塞队列 线程池：工作线程核心数，任务的接收执行（没有最大线程数量） 自定义队列满时新增任务的拒绝策略 测试验证 class SelfBlockingQueue { // 任务队列 Deque queue = new ArrayDeque<>(); Lock lock = new ReentrantLock(); Condition notFull = lock.newCondition(); Condition notEmpty = lock.newCondition(); // 容量 private int capcity; SelfBlockingQueue(int cap){ capcity = cap; } public void put(T val){ lock.lock(); try { while (getSize() == capcity) { System.out.println(\"queue is Full now. notFull await ...\"); try { System.out.println(\"等待加入任务队列...\" + val); notFull.await(); } catch (Exception e) { } } System.out.println(\"加入任务队列...\" + val); queue.addLast(val); notEmpty.signal(); } finally { lock.unlock(); } } public boolean offer(T task, long timeout, TimeUnit timeUnit){ long time = timeUnit.toNanos(timeout); lock.lock(); try { while (getSize() == capcity) { System.out.println(\"queue is Full now. notFull await ...\"); try { System.out.println(\"等待加入任务队列...\" + task); if(time { void reject(SelfBlockingQueue queue, T task); } class SelfThreadPool{ // 任务队列 private SelfBlockingQueue taskQueue; // 任务对列大小 int capcity; // 工作线程集合 private HashSet workers = new HashSet(); // 核心线程数 int coreSize; // 超时时间，销毁线程 long timeout; TimeUnit timeUnit; RejectPolicy rejectPolicy; public SelfThreadPool(int coreSize, long timeout, TimeUnit timeUnit, int capcity, RejectPolicy rejectPolicy) { this.coreSize = coreSize; this.timeout = timeout; this.timeUnit = timeUnit; this.taskQueue = new SelfBlockingQueue<>(capcity); this.rejectPolicy = rejectPolicy; } // 执行某个任务 public void execute(Runnable task){ synchronized (workers) { // 小于 coreSize 则直接Worker执行，否则加入任务队列 if (workers.size() { // try { // TimeUnit.MILLISECONDS.sleep(500); // System.out.println(\"running over...\" + num[0]); // } catch (Exception e) { // // } // }; // selfThreadPool.execute(r); // } // } // static void testPool2(){ // SelfThreadPool selfThreadPool = new SelfThreadPool(2, 1, TimeUnit.SECONDS, 3); // for(int i=0;i { // try { // TimeUnit.MILLISECONDS.sleep(2000); // System.out.println(\"running over...\" + num[0]); // } catch (Exception e) { // // } // }; // selfThreadPool.execute(r); // } // } static void testPool3(){ RejectPolicy rejectPolicy1 = new RejectPolicy() { @Override public void reject(SelfBlockingQueue queue, Object task) { queue.put(task); } }; RejectPolicy rejectPolicy2 = new RejectPolicy() { @Override public void reject(SelfBlockingQueue queue, Object task) { queue.offer(task, 500, TimeUnit.MILLISECONDS); } }; RejectPolicy rejectPolicy3 = new RejectPolicy() { @Override public void reject(SelfBlockingQueue queue, Object task) { throw new RuntimeException(\"任务被拒绝执行...\" + task); } }; RejectPolicy rejectPolicy4 = new RejectPolicy() { @Override public void reject(SelfBlockingQueue queue, Runnable task) { task.run(); } }; SelfThreadPool selfThreadPool = new SelfThreadPool(2, 1, TimeUnit.SECONDS, 3, rejectPolicy4); for(int i=0;i { try { TimeUnit.MILLISECONDS.sleep(1000); System.out.println(\"running over...\" + num[0]); } catch (Exception e) { } }; selfThreadPool.execute(r); } } public static void main(String[] args) throws Exception{ testPool3(); } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 08:49:13 "},"content/java_thread_concurrent/thread_lock.html":{"url":"content/java_thread_concurrent/thread_lock.html","title":"Java Lock","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Lock Lock基本用法例子 等待/通知机制(Lock & Condition) lock 对比 synchronized 线程同步概念 乐观锁&悲观锁 乐观锁 悲观锁 自旋锁 自旋锁存在的意义与使用场景 AtomicReference实现一个公平的自旋锁 得不到锁的线程让出CPU 得不到锁，线程sleep, 睡眠时间不确定？ LockSupport.park() & unpark() 适应性自旋锁 ReentrantLock (可重入锁) 公平&非公平锁 公平锁 非公平锁 什么是可重入？ 对比synchronized, ReentrantLock的一些高级功能 锁申请等待限时实际例子 读写锁(例:ReentrantReadWriteLock) 伪代码 实际例子 分布式锁 什么是分布式锁？ 分布式锁的实现方式 共享锁(读锁) 和 排它锁(写锁) Exclusive locks Shared locks 偏向锁（Biased Locking） 轻量级锁 重量级锁（内核控制） 为什么说重量级锁开销大呢？ AQS [TOC] Lock Lock基本用法例子 Lock是Java中的一个interface lock, unlock import java.util.ArrayList; import java.util.List; import java.util.concurrent.TimeUnit; import java.util.concurrent.locks.ReentrantLock; public class Main { private final static Object Mutex = new Object(); public int num; static int n = 16; public static ReentrantLock lock = new ReentrantLock(); void add(){ try { TimeUnit.SECONDS.sleep(1); }catch (Exception e){ e.printStackTrace(); } this.num++; } void addSync(){ synchronized (Mutex){ this.num++; } } void addLock(){ //获取锁 lock.lock(); try{ this.num++; }catch (Exception e){ e.printStackTrace(); }finally { lock.unlock(); } } void printNum(){ System.out.println(\"num:\" + this.num); } public static void main(String[] args) throws Exception{ Main main = new Main(); main.num = 0; List threadList = new ArrayList<>(n); for(int i=0;i main.add(), \"myname\" + i); Thread t = new Thread( ()-> main.addLock(), \"myname\" + i); // Thread t = new Thread(()-> main.addSync()); threadList.add(t); } threadList.forEach(t->t.start()); threadList.forEach(t->{ try{ t.join(); }catch (Exception e){ e.printStackTrace(); } }); main.printNum(); } } tryLock(long time, TimeUnit unit) package com.thread; import java.util.ArrayList; import java.util.List; import java.util.concurrent.TimeUnit; import java.util.concurrent.locks.ReentrantLock; public class Main { private final static Object Mutex = new Object(); public int num; static int n = 16; public static ReentrantLock lock = new ReentrantLock(); void addLock(){ try{ lock.lock(); System.out.println(Thread.currentThread().getName()+\"获得锁\"); TimeUnit.SECONDS.sleep(2); this.num ++; }catch (Exception e){ e.printStackTrace(); }finally { lock.unlock(); System.out.println(Thread.currentThread().getName() + \"释放锁\"); } } void subLock(){ try{ if(lock.tryLock(1, TimeUnit.SECONDS)){ System.out.println(Thread.currentThread().getName()+\"获得锁\"); this.num --; }else{ System.out.println(Thread.currentThread().getName()+\"未获得锁\"); } }catch (Exception e){ e.printStackTrace(); }finally { if(lock.isHeldByCurrentThread()){ lock.unlock(); } } } void printNum(){ System.out.println(\"num:\" + this.num); } public static void main(String[] args) throws Exception{ Main main = new Main(); main.num = 0; List threadList = new ArrayList<>(n); for(int i=0;i main.addLock(), \"myname\" + i); threadList.add(t); }else { Thread t = new Thread(() -> main.subLock(), \"myname\" + i); threadList.add(t); } } threadList.forEach(t->t.start()); threadList.forEach(t->{ try{ t.join(); }catch (Exception e){ e.printStackTrace(); } }); main.printNum(); } } 等待/通知机制(Lock & Condition) 在Java中，对于任意一个Java对象，它都拥有一组定义在java.lang.Object上监视器方法，包括wait()，wait(long timeout)，notify()，notifyAll()，这些方法配合synchronized关键字一起使用可以实现等待/通知模式。 同样，Condition接口也提供了类似Object监视器的方法，通过与Lock配合来实现等待/通知模式。 lock condition.signal() condition.await() package com.thread; import java.util.concurrent.TimeUnit; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.ReentrantLock; /** * @Author mubi * @Date 2019/3/12 10:34 AM * lock & condition 对比 synchronized wait notify */ public class Main { public static void main(String[] args) throws Exception{ ReentrantLock lock = new ReentrantLock(); Condition condition = lock.newCondition(); Thread threadA = new Thread(new Runnable() { @Override public void run() { try { lock.lock(); System.out.println(\"A start\"); TimeUnit.SECONDS.sleep(3); System.out.println(\"A notify\"); condition.signal(); } catch (Exception e) { e.printStackTrace(); }finally { lock.unlock(); } System.out.println(\"A end\"); } }); Thread threadB = new Thread(()-> { try { lock.lock(); System.out.println(\"B start\"); // 使得当前执行的线程B等待 // 即：当前线程B 进入到 threadA对象的等待集合中 并等待唤醒。 // B 释放其cpu给其它线程，自己让出资源进入等待池(A的等待集合中)等待 condition.await(); System.out.println(\"B wait end, restart running\"); } catch (Exception e) { System.out.println(\"B Exception\"); e.printStackTrace(); }finally { lock.unlock(); } System.out.println(\"B end\"); }); threadB.start(); // 确保B 先于A 运行 TimeUnit.SECONDS.sleep(1); threadA.start(); threadA.join(); threadB.join(); System.out.println(\"main end\"); } } output B start A start A notify A end B wait end, restart running B end main end lock 对比 synchronized Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现。 synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生。Lock在发生异常时，如果没有主动通过unLock()方法去释放锁，则很可能造成死锁的现象，因此使用Lock时需要在finally块中释放锁。 Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断。 通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。 Lock可以提高多个线程进行读操作的效率。 作者：TomyZhang 链接：https://www.jianshu.com/p/1927e60f358f 来源：简书 简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。 线程同步概念 多线程对共享资源的操作按照一定次序，避免出现不可预知的结局 Synchronization_(computer_science) 乐观锁&悲观锁 乐观锁 乐观锁是一种乐观思想，即认为读多写少，遇到并发竞争写的可能性很低，每次去读数据的时候都认为别人不会修改，所以不会上锁，但是在写操作的时候会判断一下在此期间别人有没有去更新(写操作)这个数据：采取在写时先读出当前版本号，然后加锁比较（即比较跟上一次的版本号，如果一样则进行写操作），如果失败则要重复读-比较-写的操作(不断CAS操作，CAS就是典型的乐观锁)。 悲观锁 悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性很高，每次去拿数据的时候都认为别人会修改，所以每次在读/写数据的时候都会上锁，这样别人想读/写这个数据就会被Block住，直到锁释放且自己抢到锁。Java中的悲观锁如synchronized,AQS框架下的锁则一般是先尝试CAS乐观锁去获取锁，获取不到，才会转换为悲观锁，如偏向锁(RetreenLock)。 自旋锁 Spinlock WikiPedia 自旋锁是采用让当前线程不停地的在循环体内执行实现的，只有当循环的条件被其它线程改变时，才能进入临界区；否则一直自旋，消耗CPU 自旋锁存在的意义与使用场景 阻塞与唤醒线程需要操作系统切换CPU状态，需要消耗一定时间；自旋只是当前线程自己循环，没有线程状态的改变，稍快 AtomicReference实现一个公平的自旋锁 /** * 使用了CAS原子操作，lock函数将owner设置为当前线程，并且预测原来的值为空。unlock函数将owner设置为null，并且预测值为当前线程 * * 该例子为非公平锁，获得锁的先后顺序，不会按照进入lock的先后顺序进行 * */ class SpinLock { private AtomicReference sign = new AtomicReference<>(); public void lock(){ Thread current = Thread.currentThread(); // 如果是null，设置为current；设置失败，就一直自旋，直到能设置成功 while(!sign.compareAndSet(null, current)){ } } public void unlock (){ Thread current = Thread.currentThread(); // 如果是current,设置为null sign.compareAndSet(current, null); } } public class Solution { static int cnt = 0; static SpinLock spinLock = new SpinLock(); static void add(){ for(int i=0;i threadList = new ArrayList<>(n); for(int i=0;i Solution.add(), \"add\" + i); threadList.add(t); } threadList.forEach(t->t.start()); threadList.forEach(t->{ try{ t.join(); }catch (Exception e){ e.printStackTrace(); } }); System.out.println(Solution.cnt); } } 由于自旋锁只是将当前线程不停地执行循环体，不进行线程状态的改变，所以响应速度更快。但当线程数不停增加时，性能下降明显，因为每个线程都需要执行类似一个空for循环，占用CPU时间。如果线程竞争不激烈，并且保持锁的时间短，则适合使用自旋锁。 In software engineering, a spinlock is a lock which causes a thread trying to acquire it to simply wait in a loop (\"spin\") while repeatedly checking if the lock is available. Since the thread remains active but is not performing a useful task, the use of such a lock is a kind of busy waiting. Once acquired, spinlocks will usually be held until they are explicitly released, although in some implementations they may be automatically released if the thread being waited on (the one which holds the lock) blocks, or \"goes to sleep\". Because they avoid overhead from operating system process rescheduling or context switching, spinlocks are efficient if threads are likely to be blocked for only short periods. For this reason, operating-system kernels often use spinlocks. However, spinlocks become wasteful if held for longer durations, as they may prevent other threads from running and require rescheduling. The longer a thread holds a lock, the greater the risk that the thread will be interrupted by the OS scheduler while holding the lock. If this happens, other threads will be left \"spinning\" (repeatedly trying to acquire the lock), while the thread holding the lock is not making progress towards releasing it. The result is an indefinite postponement until the thread holding the lock can finish and release it. This is especially true on a single-processor system, where each waiting thread of the same priority is likely to waste its quantum (allocated time where a thread can run) spinning until the thread that holds the lock is finally finished. 线程状态不变，不导致上线文切换，适合短时间自旋 长时间会耗CPU，影响其它线程的调度 得不到锁的线程让出CPU 竞争锁失败的线程让出CPU(可以使用yield()让出CPU,这是CPU控制的)，可能出现每次都是某一个线程让出CPU，得不到执行 class SpinLock{ private AtomicReference sign = new AtomicReference<>(0); void lock(){ while (!sign.compareAndSet(0, 1)){ Thread.yield(); } } void unlock(){ // 解锁就是设置为 sign.set(0); } } 得不到锁，线程sleep, 睡眠时间不确定？ class SpinLock{ private AtomicReference sign = new AtomicReference<>(0); void lock(){ while (!sign.compareAndSet(0, 1)){ try{ TimeUnit.MILLISECONDS.sleep(10); }catch (Exception e){ } } } void unlock(){ // 解锁就是设置为 sign.set(0); } } LockSupport.park() & unpark() class SpinLock{ Queue parkQueue = new LinkedList<>(); private AtomicReference sign = new AtomicReference<>(null); void lock(){ while (!sign.compareAndSet(null, Thread.currentThread())){ park(); } } void unlock(){ sign.set(null); // 同时唤醒其它线程 lockNotify(); } void park(){ // System.out.println(\"park thread:\" + Thread.currentThread().getName()); parkQueue.add(Thread.currentThread()); LockSupport.park(); } void lockNotify(){ if(parkQueue.isEmpty()){ return; } // 先进先出 Thread t = parkQueue.poll(); // System.out.println(\"unpark thread:\" + t.getName()); unpark(t); } void unpark(Thread t){ LockSupport.unpark(t); } } 适应性自旋锁 自旋锁的目的是为了占着CPU的资源不释放，等到获取到锁立即进行处理。但是如何去选择自旋的执行时间呢？如果自旋执行时间太长，会有大量的线程处于自旋状态占用CPU资源，进而会影响整体系统的性能。 自旋的时间不在是固定的了，而是由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定，基本认为一个线程上下文切换的时间是最佳的一个时间，同时JVM还针对当前CPU的负荷情况做了较多的优化: 如果平均负载小于CPUs则一直自旋 如果有超过(CPUs/2)个线程正在自旋，则后来线程直接阻塞 如果正在自旋的线程发现Owner发生了变化则延迟自旋时间（自旋计数）或进入阻塞 如果CPU处于节电模式则停止自旋 自旋时间的最坏情况是CPU的存储延迟（CPU A存储了一个数据，到CPU B得知这个数据直接的时间差） 自旋时会适当放弃线程优先级之间的差异 ReentrantLock (可重入锁) 公平&非公平锁 公平锁每次获取到锁为同步队列中的第一个节点，保证请求资源时间上的绝对顺序，而非公平锁有可能刚释放锁的线程下次继续获取该锁，则有可能导致其他线程永远无法获取到锁，造成饥饿现象。 公平锁为了保证时间上的绝对顺序，需要频繁的上下文切换，而非公平锁会降低了一定的上下文切换，降低性能开销。 公平锁 表示线程获取锁的顺序是按照线程申请锁的顺序来分配的，即FIFO, 队列结构 /** * Sync object for fair locks */ static final class FairSync extends Sync { private static final long serialVersionUID = -3000897897090466540L; final void lock() { acquire(1); } /** * Fair version of tryAcquire. Don't grant access unless * recursive call or no waiters or is first. */ protected final boolean tryAcquire(int acquires) { final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) { if (!hasQueuedPredecessors() && compareAndSetState(0, acquires)) { setExclusiveOwnerThread(current); return true; } } else if (current == getExclusiveOwnerThread()) { int nextc = c + acquires; if (nextc 公平锁每次获取到锁为同步队列中的第一个节点，保证请求资源时间上的绝对顺序，而非公平锁有可能刚释放锁的线程下次继续获取该锁，则有可能导致其它线程永远无法获取到锁，造成饥饿现象。 公平锁为了保证时间上的绝对顺序，需要频繁的上下文切换；而非公平锁会降低了一定的上下文切换，降低性能开销。 非公平锁 就是一种获取锁的抢占机制，是随机获得锁的，和公平锁不一样的就是先来的不一定先得到锁，这个方式可能造成某些线程一直拿不到锁，结果也就是不公平。尝试抢占失败，就再采用公平锁的那种方式，吞吐量大于公平锁 什么是可重入？ 同一个线程可以反复获取锁多次，然后需要释放多次 同一个线程在外层函数获得锁之后，内层递归函数仍能获取该锁的代码，在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁，即：线程可以进入任何一个它已经拥有的锁所同步的代码块，防止死锁 synchronized是可重入锁 import java.util.concurrent.TimeUnit; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; class Phone implements Runnable { public synchronized void sendSMS() { System.out.println(Thread.currentThread().getName()+ \"\\t invoked sendSMS()\"); sendEmail(); } public synchronized void sendEmail(){ System.out.println(Thread.currentThread().getName()+ \"\\t #####invoked sendEmail()\"); } // ============================================================== /** * 可重入锁底层原理：公平锁和非公平锁(默认) * 公平锁：是指多个线程按照申请锁的顺序来获取锁，类似排队打饭，先来后到。 * 非公平锁：是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁 * 在高并发的情况下，有可能会造成优先级反转或者饥饿现象。优点：吞吐量比公平锁大。 */ private Lock lock = new ReentrantLock(false); @Override public void run() { getd(); } private void getd() { lock.lock(); try { System.out.println(Thread.currentThread().getName()+ \"\\t invoked getd()\"); setd(); } finally { lock.unlock(); } } private void setd() { lock.lock(); // 这里注释掉会出现：java.lang.IllegalMonitorStateException，所以锁一定要配对 try { System.out.println(Thread.currentThread().getName()+ \"\\t ### invoked setd()\"); } finally { lock.unlock(); } } } /** * @author doinb * 可重入锁（也叫做递归锁） 作用：避免死锁 * * 指的是同一线程外层函数获得锁之后，内层函数仍然能获取该锁代码， * 在同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁 * * 也就是说，线程可以进入任何一个它已经拥有的锁所同步的代码块。 * * case 1 Synchronized就是一个典型的可重入锁 * t1 invoked sendSMS() t1线程在外层方法获取锁的时候 * t1 #####invoked sendEmail() t1在进入内层方法会自动获取锁 * t2 invoked sendSMS() * t2 #####invoked sendEmail() * * case 2 ReentrantLock也是一个典型的可重入锁 * t3 invoked getd() * t3 ### invoked setd() * t4 invoked getd() * t4 ### invoked setd() * */ public class Main { public static void main(String[] args) throws Exception { Phone phone = new Phone(); new Thread(() -> { try { phone.sendSMS(); } catch (Exception e) { e.printStackTrace(); } }, \"t1\").start(); new Thread(() -> { try { phone.sendSMS(); } catch (Exception e) { e.printStackTrace(); } }, \"t2\").start(); // 暂停一会 TimeUnit.SECONDS.sleep(1); System.out.println(); System.out.println(); System.out.println(\"### lock的启动方式，因为实现了Runnable接口 ###\"); // lock的启动方式，因为实现了Runnable接口 Thread t3 = new Thread(phone, \"t3\"); Thread t4 = new Thread(phone, \"t4\"); t3.start(); t4.start(); } } ReentrantLock继承父类AQS（AQS内部维护了一个同步状态status来计数重入次数，初始为0） 当线程尝试获取锁时，可重入锁先尝试获取并更新state值，如果state == 0表示没有其它线程在执行同步代码，则将state设置为1,当前线程开始执行；非可重入锁同 如果state > 0，则判断当前线程是否是获取到这个锁的线程，如果是则state = state + 1；如果是非重入锁，则直接去获取并更新当前status，此时如果state > 0则会导致其获取锁失败，当前线程会阻塞 可重前state == 1 可重入操作，state = state + 1 可重入后 state = state - 1 对比synchronized, ReentrantLock的一些高级功能 等待可中断 持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，这相当于Synchronized来说可以避免出现死锁的情况。 公平锁 ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁，但公平锁表现的性能不是很好。 synchronized是非公平锁（因为synchronized是不公平竞争，后来的线程可能先得到锁，进而可能导致先到的线程持续饥饿，非公平竞争在很大程度上提升了synchronized吞吐率）；synchronized是可以重入的。 锁绑定多个条件 一个ReentrantLock对象可以同时绑定对个对象。 锁申请等待限时实际例子 申请锁，一定时间内获取不到，选择放弃 package com.thread; import java.util.concurrent.TimeUnit; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; /** * @Author mubi * @Date 2019/3/15 7:24 AM */ public class Main { public static void main(String[] args) throws Exception{ Lock lock = new ReentrantLock(); Condition condition = lock.newCondition(); Thread threadA = new Thread(new Runnable() { @Override public void run() { try { lock.lock(); System.out.println(\"A start\"); TimeUnit.SECONDS.sleep(3); } catch (Exception e) { e.printStackTrace(); }finally { lock.unlock(); } } }); Thread threadB = new Thread(()-> { try { if(lock.tryLock(1, TimeUnit.SECONDS)) { System.out.println(\"B get lock start\"); }else{ System.err.println(Thread.currentThread().getName() + \" tryLock error\"); } } catch (Exception e) { System.out.println(\"B Exception\"); e.printStackTrace(); }finally { if ( ((ReentrantLock) lock).isHeldByCurrentThread()) { lock.unlock(); } } }); threadA.start(); // 让A 先于B 运行 TimeUnit.SECONDS.sleep(1); threadB.start(); threadA.join(); threadB.join(); System.out.println(\"main end\"); } } 读写锁(例:ReentrantReadWriteLock) 读写锁实际是一种特殊的自旋锁，它把对共享资源的访问者划分成读者和写者，读者只对共享资源进行读访问，写者则需要对共享资源进行写操作。 一次只有一个线程可以占有写模式的读写锁, 但是可以有多个线程同时占有读模式的读写锁. 伪代码 count_mutex = mutex_init(); write_mutex = mutex_init(); read_count = 0; void read_lock{ lock(count_mutex); read_count++; if (read_count == 1) { // 第一个读者开始读时获得写锁 lock(write_mutex); } unlock(count_mutex); } void read_unlock{ lock(count_mutex); read_count--; if (read_count == 0) { // 最后一个读者离开时释放写锁 unlock(write_mutex); } unlock(count_mutex); } void write_lock{ lock(write_mutex); } void write_unlock{ unlock(write_mutex); } 实际例子 package com.thread; import java.text.SimpleDateFormat; import java.util.Date; import java.util.Random; import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantReadWriteLock; /** * @Author mubi * @Date 2019/3/17 7:56 PM */ public class Main { private static ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock(); Lock readLock = rwLock.readLock(); Lock writeLock = rwLock.writeLock(); private double data = 0; public void read(){ readLock.lock(); try { TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread().getName() + \"读数据：\" + data + \" \" + new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\").format(new Date())); }catch (Exception e){ e.printStackTrace(); }finally { readLock.unlock(); } } public void write(){ writeLock.lock(); try { TimeUnit.SECONDS.sleep((long) (Math.random() * 10)); this.data = new Random().nextDouble(); System.out.println(Thread.currentThread().getName() + \" ........写入数据: \" + data + \" \" + new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\").format(new Date())); } catch (Exception e) { e.printStackTrace(); } finally { writeLock.unlock(); } } public static void main(String[] args) throws InterruptedException { Main main = new Main(); ThreadPoolExecutor pool = new ThreadPoolExecutor(5, 10, 200, TimeUnit.MILLISECONDS, new ArrayBlockingQueue(5), new ThreadPoolExecutor.DiscardOldestPolicy()); for(int i=0;i main.read()); pool.submit(()-> main.write()); } pool.shutdown(); } } output 某个时刻可以有多个读，但只能有一个写，写的时候不能读，读的时候不能写 pool-1-thread-1读数据：0.0 2019-03-17 19:53:43 pool-1-thread-3读数据：0.0 2019-03-17 19:53:43 pool-1-thread-1 ........写入数据: 0.14383955312719565 2019-03-17 19:53:48 pool-1-thread-2 ........写入数据: 0.36604507657651075 2019-03-17 19:53:57 pool-1-thread-4 ........写入数据: 0.24110141917904238 2019-03-17 19:54:03 pool-1-thread-4 ........写入数据: 0.6412197875946629 2019-03-17 19:54:08 pool-1-thread-6读数据：0.6412197875946629 2019-03-17 19:54:09 pool-1-thread-5读数据：0.6412197875946629 2019-03-17 19:54:09 pool-1-thread-7 ........写入数据: 0.3115143131633106 2019-03-17 19:54:12 pool-1-thread-8读数据：0.3115143131633106 2019-03-17 19:54:13 pool-1-thread-9 ........写入数据: 0.08244939010952534 2019-03-17 19:54:21 pool-1-thread-3读数据：0.08244939010952534 2019-03-17 19:54:22 pool-1-thread-10读数据：0.08244939010952534 2019-03-17 19:54:22 pool-1-thread-1 ........写入数据: 0.7060105583988802 2019-03-17 19:54:31 pool-1-thread-2读数据：0.7060105583988802 2019-03-17 19:54:32 分布式锁 很多时候我们需要保证一个方法在同一时间内只能被同一个线程执行。在单机环境中，通过 Java 提供的并发 API 我们可以解决，分布式环境下 分布式与单机情况下最大的不同在于其不是多线程而是多进程 多线程由于可以共享堆内存，因此可以简单的采取内存作为标记存储位置。而进程之间甚至可能都不在同一台物理机上，因此需要将标记存储在一个所有进程都能看到的地方 参考 什么是分布式锁？ 在分布式的部署环境下，通过锁机制来让多客户端互斥的对共享资源进行访问 排它性：在同一时间只会有一个客户端能获取到锁，其它客户端无法同时获取 避免死锁：这把锁在一段有限的时间之后，一定会被释放（正常释放或异常释放） 高可用：获取或释放锁的机制必须高可用且性能佳 分布式锁的实现方式 基于数据库实现 基于缓存 基于ZooKeeper实现 共享锁(读锁) 和 排它锁(写锁) Exclusive locks Exclusive locks protect updates to file resources, both recoverable and non-recoverable. They can be owned by only one transaction at a time. Any transaction that requires an exclusive lock must wait if another task currently owns an exclusive lock or a shared lock against the requested resource. 独占锁保护文件资源(包括可恢复和不可恢复的文件资源)的更新。它们一次只能由一个事务拥有。如果另一个任务当前拥有对所请求资源的独占锁或共享锁，则任何需要对该资源申请独占锁的事务都必须等待。 Shared locks Shared locks support read integrity. They ensure that a record is not in the process of being updated during a read-only request. Shared locks can also be used to prevent updates of a record between the time that a record is read and the next syncpoint. 共享锁支持读完整性。它们确保在只读请求期间不会更新记录。共享锁还可用于防止在读取记录和下一个同步点之间进行更新操作。 A shared lock on a resource can be owned by several tasks at the same time. However, although several tasks can own shared locks, there are some circumstances in which tasks can be forced to wait for a lock: 资源上的共享锁可以同时由多个任务拥有。 但是，尽管有几个任务可以拥有共享锁，但在某些情况下可以强制任务等待锁： A request for a shared lock must wait if another task currently owns an exclusive lock on the resource. A request for an exclusive lock must wait if other tasks currently own shared locks on this resource. A new request for a shared lock must wait if another task is waiting for an exclusive lock on a resource that already has a shared lock. 即： 如果另一个任务当前拥有资源上的独占锁，则对共享锁的请求必须等待。 如果其他任务当前拥有此资源上的共享锁，则必须等待对独占锁的请求。 如果另一个任务正在等待已经具有共享锁的资源的独占锁，则对共享锁的新请求必须等待。 偏向锁（Biased Locking） 锁的实现机制与Java对象头息息相关，锁的所有信息，都记录在Java的对象头中。 大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，这个线程就是锁的偏向线程。 为了让线程获得锁的代价更低而引入偏向锁。那么只需要在锁第一次被拥有的时候，记录下偏向线程ID。这样偏向线程就一直持有着锁，直到竞争发生才释放锁。以后每次同步，检查锁的偏向线程ID与当前线程ID是否一致，如果一致则直接进入同步/退出同步;无需每次加锁/解锁都去CAS更新对象头；如果不一致意味着发生了竞争，锁已经不是总是偏向于同一个线程了，这时候需要锁膨胀为轻量级锁，才能保证线程间公平竞争锁。 轻量级锁 轻量级锁是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁竞争的时候，偏向锁就会升级为轻量级锁。（轻量级锁是用户态的，通常会自旋占用CPU） 轻量锁与偏向锁不同的是： 轻量级锁每次退出同步块都需要释放锁，而偏向锁是在竞争发生时才释放锁 每次进入/退出同步块都需要CAS更新对象头 争夺轻量级锁失败时，自旋尝试抢占锁 可以看到轻量锁适合在竞争情况下使用，其自旋锁可以保证响应速度快，但自旋操作会占用CPU，所以一些计算时间长的操作不适合使用轻量级锁。 当竞争线程尝试占用轻量级锁失败多次之后，轻量级锁就会膨胀为重量级锁，重量级线程指针指向竞争线程，竞争线程也会阻塞，等待轻量级线程释放锁后唤醒他。 重量级锁（内核控制） 当竞争线程尝试占用轻量级锁失败多次之后，轻量级锁就会膨胀为重量级锁，重量级线程指针指向竞争线程，竞争线程也会阻塞，等待轻量级线程释放锁后唤醒他。 重量级锁是依赖对象内部的monitor锁来实现的，而monitor又依赖操作系统的MutexLock(互斥锁)来实现的，所以重量级锁也被成为互斥锁。（带wait队列，把没有获取锁的线程放队列，冷冻着，不占用CPU；内核让执行了，用户态/内核态切换，然后执行） 为什么说重量级锁开销大呢？ 主要是：当系统检查到锁是重量级锁之后，会把等待想要获得锁的线程进行阻塞，被阻塞的线程不会消耗cpu。但是阻塞或者唤醒一个线程时，都需要操作系统来帮忙，这需要把线程从用户态转换到内核态，而转换状态是需要消耗很多时间的，有可能比用户执行代码的时间还要长。这就是说为什么重量级线程开销很大的。 AQS AbstractQuenedSynchronizer抽象的队列式同步器,是除了Java自带的synchronized关键字之外的锁机制 同步工具 同步工具与AQS的关联 ReentrantLock 使用AQS保存锁重复持有的次数。当一个线程获取锁时，ReentrantLock记录当前获得锁的线程标识，用于检测是否重复获取，以及错误线程试图解锁操作时异常情况的处理。 Semaphore 使用AQS同步状态来保存信号量的当前计数。tryRelease会增加计数，acquireShared会减少计数。 CountDownLatch 使用AQS同步状态来表示计数。计数为0时，所有的Acquire操作（CountDownLatch的await方法）才可以通过。 ReentrantReadWriteLock 使用AQS同步状态中的16位保存写锁持有的次数，剩下的16位用于保存读锁的持有次数。 ThreadPoolExecutor Worker利用AQS同步状态实现对独占线程变量的设置（tryAcquire和tryRelease）。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 22:06:02 "},"content/java_thread_concurrent/thread_deadlock.html":{"url":"content/java_thread_concurrent/thread_deadlock.html","title":"死锁问题","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 死锁 死锁的4个必要条件（操作系统） 程序死锁的可能原因 死锁代码例子(需要手写) 输出和死锁现象 信号量解决死锁代码 [TOC] 死锁 死锁的4个必要条件（操作系统） 互斥：某种资源一次只允许一个进程访问，即该资源一旦分配给某个进程，其他进程就不能再访问，直到该进程访问结束。 不可剥夺：进程所获得的资源在未使用完毕之前，不被其他进程强行剥夺，而只能由获得该资源的进程资源释放。 请求和保持：进程每次申请它所需要的一部分资源，在申请新的资源的同时，继续占用已分配到的资源。 循环等待：存在一个进程循环链，使得每个进程都占有下一个进程所需的至少一种资源。 程序死锁的可能原因 交叉锁 内存不足 例如线程T1获得了10M内存,线程T2获得了20M内存，每个线程都需要30M的运行内存，但是此时剩余可用的内存刚好为20M,那么两个线程有可能都在等待彼此能够释放的内存资源 一问一答式的数据交换 服务端，客户端都在等待对方 数据库锁 文件锁 某个线程获得了文件锁意外退出，其它读取该文件的线程也将会进入死锁直到系统释放文件句柄资源 死循环引起的死锁 系统假死 死锁代码例子(需要手写) class DeadLock { // 创建资源 private static Object resourceA = new Object(); private static Object resourceB = new Object(); // 测试 public static void test() { //启动线程A,B new Thread(new A(), \"threadA\").start(); new Thread(new B(), \"threadB\").start(); } static class A implements Runnable{ @Override public void run() { synchronized (resourceA) { // 持有资源A System.out.println(Thread.currentThread() + \" get ResourceA\"); try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { System.err.print(e); } System.out.println(Thread.currentThread() + \" waiting get ResourceB\"); // 想获取资源B synchronized (resourceB) { System.out.println(Thread.currentThread() + \" get ResourceB\"); } } } } static class B implements Runnable{ @Override public void run() { synchronized (resourceB) { // 持有资源B System.out.println(Thread.currentThread() + \" get ResourceB\"); try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { System.err.print(e); } System.out.println(Thread.currentThread() + \" waiting get ResourceA\"); // 想获取资源A synchronized (resourceA) { System.out.println(Thread.currentThread() + \" get ResourceA\"); } } } } public static void main(String[] args) { test(); } } 输出和死锁现象 输出如下，然后会一直卡住 Thread[threadA,5,main] get ResourceA Thread[threadB,5,main] get ResourceB Thread[threadA,5,main] waiting get ResourceB Thread[threadB,5,main] waiting get ResourceA jvisualvm 可查看到死锁现象 信号量解决死锁代码 class DeadLock { // 创建资源 private static Object resourceA = new Object(); private static Object resourceB = new Object(); private static Semaphore semaphoreA = new Semaphore(1); private static Semaphore semaphoreB = new Semaphore(1); //测试 public static void test() { //启动线程A,B new Thread(new A(), \"threadA\").start(); new Thread(new B(), \"threadB\").start(); } static class A implements Runnable { @Override public void run() { try { if(semaphoreA.tryAcquire(1, TimeUnit.SECONDS)) { System.out.println(Thread.currentThread() + \" get ResourceA\"); TimeUnit.SECONDS.sleep(2); System.out.println(Thread.currentThread() + \" waiting get ResourceB\"); // 想获取资源B if(semaphoreB.tryAcquire(1, TimeUnit.SECONDS)) { System.out.println(Thread.currentThread() + \" get ResourceB\"); System.out.println(\"A do sth\"); semaphoreB.release(); }else { System.out.println(\"A get ResourceB failed\"); } semaphoreA.release(); }else{ System.out.println(\"A get ResourceA failed\"); } }catch (Exception e){ e.printStackTrace(); } } } static class B implements Runnable{ @Override public void run() { try { if(semaphoreB.tryAcquire(1, TimeUnit.SECONDS)) { System.out.println(Thread.currentThread() + \" get ResourceB\"); TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread() + \" waiting get ResourceA\"); // 想获取资源B if(semaphoreA.tryAcquire(1, TimeUnit.SECONDS)) { System.out.println(Thread.currentThread() + \" get ResourceA\"); System.out.println(\"B do sth\"); semaphoreA.release(); }else{ System.out.println(\"B get ResourceA failed\"); } semaphoreB.release(); }else{ System.out.println(\"B get ResourceB failed\"); } }catch (Exception e){ e.printStackTrace(); } } } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 21:55:50 "},"content/java_thread_concurrent/threadLocal.html":{"url":"content/java_thread_concurrent/threadLocal.html","title":"ThreadLocal对象","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 ThreadLocal 实现思路 set源码 使用场景 自己项目中使用到的实际例子? ThreadLocal会产生内存泄漏吗? [TOC] ThreadLocal ThreadLocal并不是一个线程，而是线程的一个局部变量(属于线程) ThreadLocal用于保存某个线程共享变量：对于同一个static ThreadLocal，不同线程只能从中get，set，remove自己的变量，而不会影响其他线程的变量 实现思路 Thread类有一个类型为ThreadLocal.ThreadLocalMap的实例变量threadLocals，也就是说每个线程有一个自己的ThreadLocalMap(是线程自己拥有的一个map)。 使用例子 public class ThreadLocalTest { private static ThreadLocal threadLocal = new ThreadLocal<>(); public static void main(String[] args) { set(); System.out.println(get()); // 打印 abc } private static String get() { return threadLocal.get(); } private static void set() { threadLocal.set(\"abc\"); } } new ThreadLocal<>();就仅仅实例化一个ThreadLocal对象，会作为线程ThreadLocal.ThreadLocalMap的key set源码 public void set(T value) { Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); } this 是ThreadLocal对象自身，即set到Map的也即set 只有一个key，new几个ThreadLocal就能有多少个键值对 private void set(ThreadLocal key, Object value) { // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode & (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) { ThreadLocal k = e.get(); if (k == key) { e.value = value; return; } if (k == null) { replaceStaleEntry(key, value, i); return; } } tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) && sz >= threshold) rehash(); } static class Entry extends WeakReference> { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal k, Object v) { super(k); value = v; } } Entry是个弱引用WeakReference 当定义出来的threadLocal不用了，即指向ThreadLocal的引用没了，那么ThreadLocal要被回收 假如说this是个强引用，那么显然只要线程不结束，ThreadLocalMap就存在，引用关系就存在；那么ThreadLocal就永远不会被回收，即有内存泄漏了 所以this被设计成为一个弱引用，只要gc发现不用了，就会进行回收；但是当ThreadLocal被回收时，ThreadLocalMap里面的key是个null被回收；不过这使得value就访问不到，会出现内存泄漏 所以需要显示的remove掉value，即执行tl1.remove(); 使用场景 在进行对象跨层传递的时候，可以考虑ThreadLocal，避免方法多次传递，打破层次间的约束 线程间数据隔离 进行事务操作，用于存储线程事务信息 自己项目中使用到的实际例子? 比如一个查询，要经过一层一层处理，最后还有记录此次的查询记录； 其中有个queryId，可以放到ThreadLocal中，这样打点&记录随时可以取出queryId ThreadLocal会产生内存泄漏吗? 会 弱引用做了一道工作 但是仍需要显示的remove掉ThreadLocal的value Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 10:50:10 "},"content/java8/java8_completableFuture.html":{"url":"content/java8/java8_completableFuture.html","title":"CompletableFuture","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Future 接口 同步API 与 异步API 实际例子 错误处理 使用工厂方法supplyAsync创建CompletableFuture 让代码免受阻塞之苦 顺序查询各个商店的某个商品的价格 并行流操作 使用CompletableFuture: 组合式异步编程 当把shops增加到5个,9个 使用定制的执行器 并行 -- 使用流还是CompletableFutures ? 对多个异步任务进行流水线操作 Discount Quote Shop MainTest 构造同步和异步操作 合并两个独立的CompletableFuture对象 响应CompletableFuture的completion事件 总结 [TOC] Future 接口 Future接口在Java 5中被引入，设计初衷是对将来某个时刻会发生的结果进行建模。它建模了一种异步计算，返回一个执行运算结果的引用，当运算结束后，这个引用被返回给调用方。在Future中触发那些潜在耗时的操作把调用线程解放出来，让它能继续执行其他有价值的工作， 不再需要呆呆等待耗时的操作完成。打个比方，你可以把它想象成这样的场景:你拿了一袋子衣服到你中意的干洗店去洗。干洗店的员工会给你张发票，告诉你什么时候你的衣服会洗好(这就是一个Future事件)。衣服干洗的同时，你可以去做其他的事情。 同步API 与 异步API 同步API其实只是对传统方法调用的另一种称呼:你调用了某个方法，调用方在被调用方运行的过程中会等待，被调用方运行结束返回，调用方取得被调用方的返回值并继续运行。即使调用方和被调用方在不同的线程中运行，调用方还是需要等待被调用方结束运行，这就是阻塞式调用这个名词的由来。 与此相反，异步API会直接返回，或者至少在被调用方计算完成之前，将它剩余的计算任务给另一个线程去做，该线程和调用方是异步的——这就是非阻塞调用的由来。执行剩余计算任务的线程会将它的计算结果返回给调用方。返回的方式要么是通过过回调函数，要么是由调用方再次执行一个\"等待，直到计算完成\"的方法调用。这种方式的计算在I/O系统程序设计中非常常见:你发起了一次磁盘访问，这次访问和你的其它计算操作是异步的，你完成其它的任务时，磁盘块的数据可能还没载入到内存，你只需要等待数据的载入完成。 实际例子 class Shop { /** * 模拟1秒中延迟的方法 */ public static void delay() { try { Thread.sleep(1000L); } catch (InterruptedException e) { throw new RuntimeException(e); } } private double calculatePrice(String product) { delay(); Random random = new Random(); return random.nextDouble() * product.charAt(0) + product.charAt(1); } /** * 同步API * @param product * @return */ public double getPrice(String product) { return calculatePrice(product); } /** * 异步API * @param product * @return */ public Future getPriceAsync(String product) { CompletableFuture futurePrice = new CompletableFuture<>(); new Thread( () -> { double price = calculatePrice(product); futurePrice.complete(price); }).start(); return futurePrice; } public void doSomethingElse(){ } } public class MainTest { public static void main(String[] args) { Shop shop = new Shop(); long start = System.nanoTime(); double price = shop.getPrice(\"apple\"); System.out.printf(\"Price is %.2f%n\", price); long duration = (System.nanoTime() - start) / 1_000_000; System.out.println(duration + \" msecs\"); System.out.println(\"======================\"); start = System.nanoTime(); // 查询商店,试图取&#x10FDC4;得商品的价格 Future futurePrice = shop.getPriceAsync(\"apple\"); long invocationTime = ((System.nanoTime() - start) / 1_000_000); System.out.println(\"Invocation returned after \" + invocationTime + \" msecs\"); // 执行更多任务，比如查询其他商店 shop.doSomethingElse(); // 在计算商品价格的同时 try { // 通过该对象可以在将来的某个时刻取得的价格 // 执行了这个操作后，要么获得Future中封装的值(如果异步任务已经完成)， // 要么发生阻塞，直到该异步任务完成，期望的值能够访问。 price = futurePrice.get(); System.out.printf(\"Price is %.2f%n\", price); } catch (Exception e) { throw new RuntimeException(e); } long retrievalTime = ((System.nanoTime() - start) / 1_000_000); System.out.println(\"Price returned after \" + retrievalTime + \" msecs\"); } } output Price is 126.26 1024 msecs ====================== Invocation returned after 64 msecs Price is 190.31 Price returned after 1065 msecs 错误处理 如果价格计算过程中产生了错误会怎样呢？ 用于提示错误的异常会被限制在试图计算商品价格的当前线程的范围内，最终会杀死该线程，而这会导致等待get方法返回结果的客户端永久地被阻塞。 使用工厂方法supplyAsync创建CompletableFuture class Shop { /** * 模拟1秒中延迟的方法 */ public static void delay() { try { Thread.sleep(1000L); } catch (InterruptedException e) { throw new RuntimeException(e); } } private double calculatePrice(String product) { delay(); throw new RuntimeException(product + \" not available\"); // Random random = new Random(); // return random.nextDouble() * product.charAt(0) + product.charAt(1); } /** * 同步API * @param product * @return */ public double getPrice(String product) { return calculatePrice(product); } /** * 异步API * @param product * @return */ public Future getPriceAsync(String product) { CompletableFuture futurePrice = new CompletableFuture<>(); new Thread( () -> { try { double price = calculatePrice(product); futurePrice.complete(price); }catch (Exception ex){ futurePrice.completeExceptionally(ex); } }).start(); return futurePrice; // return CompletableFuture.supplyAsync(() -> calculatePrice(product)); } public void doSomethingElse(){ System.out.println(\"查询其他商店...\"); } } public class MainTest { public static void main(String[] args) { Shop shop = new Shop(); long start = System.nanoTime(); double price = 0.0f; // double price = shop.getPrice(\"apple\"); // System.out.printf(\"Price is %.2f%n\", price); // long duration = (System.nanoTime() - start) / 1_000_000; // System.out.println(duration + \" msecs\"); System.out.println(\"======================\"); start = System.nanoTime(); System.out.println(\"查询商店,试图取得商品的价格\"); Future futurePrice = shop.getPriceAsync(\"apple\"); long invocationTime = ((System.nanoTime() - start) / 1_000_000); System.out.println(\"Invocation returned after \" + invocationTime + \" msecs\"); // 执行更多任务，比如查询其他商店 shop.doSomethingElse(); // 在计算商品价格的同时 try { // 通过该对象&#x10FCEC;&#x10FC06;可以在将来的某个时刻取得&#x10FD51;&#x10FECC;的价格 // 执行了这个操作后，&#x10FCEC;&#x10FC06;要么获得Future中封装的值(如果异步任务已经完成)， // 要么发生阻塞，直到该异步任务完成，期望&#x10FC10;&#x10FCDD;的值能够访问。 price = futurePrice.get(); System.out.printf(\"Price is %.2f%n\", price); } catch (Exception e) { throw new RuntimeException(e); } long retrievalTime = ((System.nanoTime() - start) / 1_000_000); System.out.println(\"Price returned after \" + retrievalTime + \" msecs\"); } } 以异步的方式查询多个商店，避免被单一的请求所阻塞，并由此提升你的\"最佳价格查询器\"的性能和吞吐量。 让代码免受阻塞之苦 顺序查询各个商店的某个商品的价格 class Shop { private String name; public Shop(String name) { this.name = name; } public String getName() { return name; } /** * 模拟1秒中延迟的方法 */ public static void delay() { try { Thread.sleep(1000L); } catch (InterruptedException e) { throw new RuntimeException(e); } } private double calculatePrice(String product) { delay(); Random random = new Random(); return random.nextDouble() * product.charAt(0) + product.charAt(1); } /** * 同步API * @param product * @return */ public double getPrice(String product) { return calculatePrice(product); } } public class MainTest { List shops = Arrays.asList(new Shop(\"BestPrice\"), new Shop(\"LetsSaveBig\"), new Shop(\"MyFavoriteShop\"), new Shop(\"BuyItAll\")); public List findPrices(String product) { return shops.stream() .map(shop -> String.format(\"%s price is %.2f\", shop.getName(), shop.getPrice(product))) .collect(Collectors.toList()); } public static void main(String[] args) { MainTest mainTest = new MainTest(); long start = System.nanoTime(); List shopPriceList = mainTest.findPrices(\"apple\"); shopPriceList.forEach( shopPrice -> System.out.println(shopPrice) ); long duration = ((System.nanoTime() - start) / 1_000_000); System.out.println(\"Done in \" + duration + \" msecs\"); } } 如预期一样，findPrices方法的执行时间仅比4秒多了那么些毫秒，因为对4个商店对查询是顺序进行对，并且一个查询操作会阻塞另一个，每一饿操作都要话费大约1秒左右都时间 BestPrice price is 168.62 LetsSaveBig price is 159.47 MyFavoriteShop price is 187.64 BuyItAll price is 196.31 Done in 4109 msecs 并行流操作 class Shop { private String name; public Shop(String name) { this.name = name; } public String getName() { return name; } /** * 模拟1秒中延迟的方法 */ public static void delay() { try { Thread.sleep(1000L); } catch (InterruptedException e) { throw new RuntimeException(e); } } private double calculatePrice(String product) { delay(); Random random = new Random(); return random.nextDouble() * product.charAt(0) + product.charAt(1); } /** * 同步API * @param product * @return */ public double getPrice(String product) { return calculatePrice(product); } /** * 异步API * @param product * @return */ public Future getPriceAsync(String product) { CompletableFuture futurePrice = new CompletableFuture<>(); new Thread( () -> { try { double price = calculatePrice(product); futurePrice.complete(price); }catch (Exception ex){ futurePrice.completeExceptionally(ex); } }).start(); return futurePrice; // return CompletableFuture.supplyAsync(() -> calculatePrice(product)); } } public class MainTest { List shops = Arrays.asList(new Shop(\"BestPrice\"), new Shop(\"LetsSaveBig\"), new Shop(\"MyFavoriteShop\"), new Shop(\"BuyItAll\")); public List findPrices(String product) { return shops.stream() .map(shop -> String.format(\"%s price is %.2f\", shop.getName(), shop.getPrice(product))) .collect(Collectors.toList()); } public List parallelFindPrices(String product) { return shops.parallelStream() .map(shop -> String.format(\"%s price is %.2f\", shop.getName(), shop.getPrice(product))) .collect(Collectors.toList()); } public static void main(String[] args) { MainTest mainTest = new MainTest(); long start = System.nanoTime(); List shopPriceList = mainTest.parallelFindPrices(\"apple\"); shopPriceList.forEach( shopPrice -> System.out.println(shopPrice) ); long duration = ((System.nanoTime() - start) / 1_000_000); System.out.println(\"Done in \" + duration + \" msecs\"); } } 运行结果如下： BestPrice price is 179.70 LetsSaveBig price is 177.18 MyFavoriteShop price is 196.27 BuyItAll price is 114.68 Done in 1120 msecs 现在对四个不同商店的查询实现了并行，所以完成所有操作的总耗时只有1秒多一点儿？能做得更好吗? 使用CompletableFuture: 组合式异步编程 public List> parallelFindPricesAnyc(String product) { return shops.stream() .map(shop -> CompletableFuture.supplyAsync( () -> String.format(\"%s price is %.2f\", shop.getName(), shop.getPrice(product)))) .collect(Collectors.toList()); } public List bestFindPrices(String product) { // 异步方式计算么个商店商品价格 List> priceFutures = parallelFindPricesAnyc(product); // 等待所有异步操作结束 return priceFutures.stream() .map(CompletableFuture::join) .collect(Collectors.toList()); } public static void main(String[] args) { MainTest mainTest = new MainTest(); long start = System.nanoTime(); List shopPriceList = mainTest.bestFindPrices(\"apple\"); shopPriceList.forEach( shopPrice -> System.out.println(shopPrice) ); long duration = ((System.nanoTime() - start) / 1_000_000); System.out.println(\"Done in \" + duration + \" msecs\"); } 结果如下, 不尽人意 BestPrice price is 158.86 LetsSaveBig price is 127.60 MyFavoriteShop price is 119.70 BuyItAll price is 128.21 Done in 2110 msecs 并行流版本执行的很好，因为它几乎能为4个任务都分配一个线程，并行执行任务 当把shops增加到5个,9个 并行流运行结果如下 BestPrice price is 114.81 LetsSaveBig price is 159.87 MyFavoriteShop price is 193.59 BuyItAll price is 123.66 five price is 139.15 Done in 2118 msecs CompletableFuture版本 BestPrice price is 173.66 LetsSaveBig price is 186.67 MyFavoriteShop price is 207.36 BuyItAll price is 137.48 five price is 120.48 Done in 2009 msecs CompletableFuture版本的程序似乎比并行流版本的程序还快那么一点儿。但是最后这个版本也不太令人满意。比如，如果你试图让你的代码处理9个商店，并行流版本耗时3143毫秒， 而CompletableFuture版本&#x10FE71;时3009毫秒。它们看起来不相伯仲，究其原因都一样: 它们内部采用的是同样的通用线程池，默认都使用固定数目的线程，具体线程数取决于Runtime. getRuntime().availableProcessors()的返回值(即CPU核心数)。然而，CompletableFuture具有一定的优势，因为它允许你对执行器(Executor)进行配置，尤其是线程池的大小，让它以更适合应用需求的方式进行配置，满足程序的要求，而这是并行流API无法提供的。让我们看看你怎样利用这种配置上的灵活性带来实际应用程序性能上的提升。 使用定制的执行器 创建一个配有线程池的执行器，线程池中线程的数目取决于你预计你的应用需要处理的负荷，但是你该如何选择合适的线程数目呢？ 《Java 并发编程实战》： 如果线程池中的数量过多，最终它们会竞争稀缺的处理器和内存资源，浪费大量的时间在上下文切换上。反之，如果线程的数目过少，正如你的应用所面临的情况，处理器的一些核可能就无法充分利用。Brian Goetz建议，线程池大小与处理器的利用率之比可以使用下面的公式进行估算： 线程池数目 = CPU核心数 * 期望的CPU利用率(介于0和1之间) *（1 + 等待时间和计算时间的比率） List shops = Arrays.asList(new Shop(\"BestPrice\"), new Shop(\"LetsSaveBig\"), new Shop(\"MyFavoriteShop\"), new Shop(\"BuyItAll\"), new Shop(\"five\"), new Shop(\"six\"), new Shop(\"seven\"), new Shop(\"eight\"), new Shop(\"nine\") ); /** * 创建了一个由`守护线程`构成的线程池 */ private final Executor executor = Executors.newFixedThreadPool(Math.min(shops.size(), 100) , new ThreadFactory() { @Override public Thread newThread(Runnable r) { Thread t = new Thread(r); t.setDaemon(true); return t; } }); public List> parallelFindPricesAsync(String product) { // supplyAsync工&#x10FC63;方法 指定线程池 return shops.stream() .map(shop -> CompletableFuture.supplyAsync( () -> String.format(\"%s price is %.2f\", shop.getName(), shop.getPrice(product)), executor)) .collect(Collectors.toList()); } public static void testCompletableFuture(){ MainTest mainTest = new MainTest(); long start = System.nanoTime(); List shopPriceList = mainTest.bestFindPrices(\"apple\"); shopPriceList.forEach( shopPrice -> System.out.println(shopPrice) ); long duration = ((System.nanoTime() - start) / 1_000_000); System.out.println(\"Done in \" + duration + \" msecs\"); } 改进之后，使CompletableFuture方案的程序处理5个商店仅需要1021毫秒，处理9个商店耗时1022毫秒。一般而言，这种状态态会一直持续，直到商店的数目达到我们之前计算的阈值400。这个例子说明了要创建更适合你的应用特性的执行器，利用CompletableFutures向其提交任务执行是个不错的主意。处理需大量使用异步操作的情况时，这几乎是最有效的策略。 并行 -- 使用流还是CompletableFutures ? 目前为止，你已经集合对集合进行并行计算有两种方式:要么将其转化为并行流，利用map这样的操作展开工作，要么枚举出集合中的每一个元素，创建新的线程，在CompletableFuture内对其进行操作。后者提供了更多的灵活性，你可以调整线程池的大小，而这能帮助你确保整体的计算不会因为线程都在等待I/O而发生阻塞。 建议： 对于计算密集型操作，并且没有I/O，那么推荐使用Stream接口，因为实现简单，同时效率也是最高的(如果所有的线程都是计算密集型的)，那就没有必要创建比处理器和数更多的线程。 如果并行的工作单元还涉及等待I/O的操作(包括网络连接等待)，那么使用CompletableFuture的灵活性更好。不使用并行流另一个原因是：处理流的流水线中如果发生I/O等待，流的延迟特效会让我们很难判断到底什么时候触发了等待。 对多个异步任务进行流水线操作 Discount /** * 折扣服务api */ public class Discount { public enum Code { NONE(0), SILVER(0), GOLD(10), PLATINUM(15), DIAMOND(20); private final int percentage; Code(int percentage) { this.percentage = percentage; } } public static String applyDiscount(Quote quote) { return quote.getShopName() + \" price is \" + Discount.apply(quote.getPrice(), quote.getDiscountCode()); } private static double apply(double price, Code code) { delay(); return price * (100 - code.percentage) / 100; } /** * 模拟计算,查询数据库等耗时 */ public static void delay() { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } } Quote /** * 商店返回消息实体,不可变对象模式 线程安全 */ public final class Quote { private final String shopName; private final double price; private final Discount.Code discountCode; public Quote(String shopName, double price, Discount.Code discountCode) { this.shopName = shopName; this.price = price; this.discountCode = discountCode; } public static Quote parse(String s) { String[] split = s.split(\":\"); String shopName = split[0]; double price = Double.parseDouble(split[1]); Discount.Code discountCode = Discount.Code.valueOf(split[2]); return new Quote(shopName, price, discountCode); } public String getShopName() { return shopName; } public double getPrice() { return price; } public Discount.Code getDiscountCode() { return discountCode; } } Shop public class Shop { private String name; public Shop(String name) { this.name = name; } public String getName() { return name; } /** * 模拟1秒中延迟的方法 */ public static void delay() { try { Thread.sleep(1000L); } catch (InterruptedException e) { throw new RuntimeException(e); } } private double calculatePrice(String product) { delay(); Random random = new Random(); return random.nextDouble() * product.charAt(0) + product.charAt(1); } public String getPrice(String product) { Random random = new Random(); double price = calculatePrice(product); Discount.Code code = Discount.Code.values()[ random.nextInt(Discount.Code.values().length)]; return String.format(\"%s:%.2f:%s\", name, price, code); } } MainTest public class MainTest { List shops = Arrays.asList(new Shop(\"BestPrice\"), new Shop(\"LetsSaveBig\"), new Shop(\"MyFavoriteShop\"), new Shop(\"BuyItAll\"), new Shop(\"five\") // new Shop(\"six\"), // new Shop(\"seven\"), // new Shop(\"eight\"), // new Shop(\"nine\") ); public List findprices(String product) { // 1. 取出商品的原始价格 -- 耗时1秒多 // 2. 在Quote对象中对shop返回对字符串进行转换 // 3. 联系Discount服务，为每个Quote申请折扣 -- 耗时1秒多 return shops.stream() .map(shop -> shop.getPrice(product)) .map(Quote::parse) .map(Discount::applyDiscount) .collect(Collectors.toList()); } public static void testCompletableFuture(){ MainTest mainTest = new MainTest(); long start = System.nanoTime(); List shopPriceList = mainTest.findprices(\"apple\"); System.out.println(shopPriceList); // shopPriceList.forEach( shopPrice -> System.out.println(shopPrice) ); long duration = ((System.nanoTime() - start) / 1_000_000); System.out.println(\"Done in \" + duration + \" msecs\"); } public static void main(String[] args) { // 5个商店，耗时大概10秒多 testCompletableFuture(); } } 构造同步和异步操作 /** * 创建了一个由`守护线程`构成的线程池 */ private final Executor executor = Executors.newFixedThreadPool(Math.min(shops.size(), 100) , new ThreadFactory() { @Override public Thread newThread(Runnable r) { Thread t = new Thread(r); t.setDaemon(true); return t; } }); public List findPricesCompletableFuture(String product) { // supplyAsync工方法 指定线程池 List> priceFutureList = shops .stream() // 异步方式取得每个shop中指定产品的原始价格 .map(shop -> CompletableFuture.supplyAsync( () -> shop.getPrice(product), executor)) // 在Quote对象中对shop返回对字符串进行转换 .map(future -> future.thenApply(Quote::parse)) // 另一个异步任务构建期望的Future,申请折扣 thenCompose 将多个future组合 一个一个执行 .map(future -> future.thenCompose(quote -> CompletableFuture.supplyAsync( () -> Discount.applyDiscount(quote), executor))) .collect(Collectors.toList()); return priceFutureList.stream() // 等待流中所有的future执行完毕,并提取各自的返回值 .map(CompletableFuture::join) .collect(Collectors.toList()); } public static void testCompletableFuture(){ MainTest mainTest = new MainTest(); long start = System.nanoTime(); List shopPriceList = mainTest.findPricesCompletableFuture(\"apple\"); System.out.println(shopPriceList); // shopPriceList.forEach( shopPrice -> System.out.println(shopPrice) ); long duration = ((System.nanoTime() - start) / 1_000_000); System.out.println(\"Done in \" + duration + \" msecs\"); } public static void main(String[] args) { // 异步方式只用了 2117 msecs testCompletableFuture(); } 执行流程图 合并两个独立的CompletableFuture对象 响应CompletableFuture的completion事件 public Stream> findPricesStream(String product) { return shops.stream() // 异步方式取得每个shop中指定产品的原始价格 .map(shop -> CompletableFuture.supplyAsync( () -> shop.getPrice(product), executor)) // 在Quote对象中对shop返回对字符串进行转换 .map(future -> future.thenApply(Quote::parse)) // 另一个异步任务构建期望的Future,申请折扣 thenCompose 将多个future组合 一个一个执行 .map(future -> future.thenCompose(quote -> CompletableFuture.supplyAsync( () -> Discount.applyDiscount(quote), executor))); } public static void testCompletableFuture(){ MainTest mainTest = new MainTest(); /** * thenAccept方法也提供 了一个异步版本，名为thenAcceptAsync。 * 异步版本的方法会对处理结果的消费者进行调度，从线程池中选择一个新的线程继续执行， * 不再由同一个线程完成CompletableFuture的所有任务。 * 因为你想要避免不必要的上下文切换，更重要的是你希望避免在等待线程上浪费时间， * 尽快响应CompletableFuture的completion事件，所以这里没有采用异步版本。 */ long start = System.nanoTime(); CompletableFuture[] futures = mainTest.findPricesStream(\"myPhone27S\") .map(f -> f.thenAccept( s -> System.out.println(s + \" (done in \" + ((System.nanoTime() - start) / 1_000_000) + \" msecs)\"))) .toArray(size -> new CompletableFuture[size]); CompletableFuture.allOf(futures).join(); System.out.println(\"All shops have now responded in \" + ((System.nanoTime() - start) / 1_000_000) + \" msecs\"); } 总结 执行比较耗时的操作时，尤其是那些依赖一个或多个远程服务的操作，使用异步任务可以改善程序的性能，加快程序的响应速度。 你应该尽可能地为客户提供异步API。使用CompletableFuture类提供的特性，你能够轻松地实现这一目标。 CompletableFuture类还提供了异常管理的机制，让你有机会抛出/管理异步任务执行 中发生的异常。 将同步API的调用封装到一个CompletableFuture中，你能够以异步的方式使用其结果。 如果异步任务之间相互独立，或者它们之间某一些的结果是另一些的输入，你可以将这些异步任务构造或者合并成一个。 你可以为CompletableFuture注册一个回调函数，在Future执行完毕或者它们计算的结果可用时，针对性地执行一些程序。 你可以决定在什么时候结束程序的运行，是等待由CompletableFuture对象构成的列表中所有的对象都执行完毕，还是只要其中任何一个首先完成就中止程序的运行。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-31 10:28:08 "},"content/java8/java8_future.html":{"url":"content/java8/java8_future.html","title":"Future","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Future在规定时间内获取结果 超时获取输出 Future规定时间未获取到,中断处理 Callable、Future、FutureTask [TOC] Future在规定时间内获取结果 import java.text.SimpleDateFormat; import java.util.Date; import java.util.Scanner; import java.util.concurrent.*; public class Main { public static Scanner sc = new Scanner(System.in); public static SimpleDateFormat simpleFormatter = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); /** * 模拟sec秒延迟 */ public static void delay(int sec) { try { TimeUnit.SECONDS.sleep(sec); } catch (InterruptedException e) { throw new RuntimeException(e); } } public static Future getPrice(double df){ ExecutorService executor = Executors.newSingleThreadExecutor(); Future future = executor.submit(new Callable() { @Override public Double call() throws Exception { delay(5); return df * 10; } }); executor.shutdown(); return future; } public static void priceTest(){ Future futurePrice = getPrice(10.0f); Double price = null; try{ price = futurePrice.get(1,TimeUnit.SECONDS); }catch (Exception e){ System.out.println(\"cannot get within 1 sec\"); futurePrice.cancel(false); throw new RuntimeException(e); } System.out.println(price); } public static void main(String[] args) { System.out.println(simpleFormatter.format(new Date())); priceTest(); System.out.println(simpleFormatter.format(new Date())); } } 超时获取输出 2019-11-02 15:14:47 cannot get within 1 sec Exception in thread \"main\" java.lang.RuntimeException: java.util.concurrent.TimeoutException at Main.priceTest(Main.java:48) at Main.main(Main.java:55) Caused by: java.util.concurrent.TimeoutException at java.util.concurrent.FutureTask.get(FutureTask.java:205) at Main.priceTest(Main.java:44) ... 1 more Process finished with exit code 1 Future规定时间未获取到,中断处理 import com.google.common.util.concurrent.MoreExecutors; import java.text.SimpleDateFormat; import java.util.Date; import java.util.Scanner; import java.util.concurrent.*; public class Main { public static Scanner sc = new Scanner(System.in); public static SimpleDateFormat simpleFormatter = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); /** * 模拟sec秒延迟 */ public static void delay(int sec) { try { TimeUnit.SECONDS.sleep(sec); } catch (InterruptedException e) { throw new RuntimeException(e); } } public static Future getPrice(double df){ // ExecutorService executor = MoreExecutors.newDirectExecutorService(); ExecutorService executor = Executors.newSingleThreadExecutor(); System.out.println(simpleFormatter.format(new Date())); Future future = executor.submit(new Callable() { @Override public Double call() throws Exception { delay(5); return df * 10; } }); System.out.println(simpleFormatter.format(new Date())); // executor.shutdown(); return future; } public static void priceTest(){ Future futurePrice = getPrice(10.0f); Double price = null; try { price = futurePrice.get(1, TimeUnit.SECONDS); }catch (TimeoutException e){ System.out.println(\"cannot get within 1 sec\"); // throw new RuntimeException(e); // 取消执行 // futurePrice.cancel(true); }catch (Exception e){ futurePrice.cancel(false); // throw new RuntimeException(e); } System.out.println(price); try { price = futurePrice.get(); }catch (Exception e){ } System.out.println(price); } public static void main(String[] args) { System.out.println(simpleFormatter.format(new Date())); priceTest(); System.out.println(simpleFormatter.format(new Date())); } } Callable、Future、FutureTask Runnable @FunctionalInterface public interface Runnable { /** * When an object implementing interface Runnable is used * to create a thread, starting the thread causes the object's * run method to be called in that separately executing * thread. * * The general contract of the method run is that it may * take any action whatsoever. * * @see java.lang.Thread#run() */ public abstract void run(); } Callable @FunctionalInterface public interface Callable { /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception; } Future /** * A {@code Future} represents the result of an asynchronous * computation. Methods are provided to check if the computation is * complete, to wait for its completion, and to retrieve the result of * the computation. The result can only be retrieved using method * {@code get} when the computation has completed, blocking if * necessary until it is ready. Cancellation is performed by the * {@code cancel} method. Additional methods are provided to * determine if the task completed normally or was cancelled. Once a * computation has completed, the computation cannot be cancelled. * If you would like to use a {@code Future} for the sake * of cancellability but not provide a usable result, you can * declare types of the form {@code Future} and * return {@code null} as a result of the underlying task. * * * Sample Usage (Note that the following classes are all * made-up.) * {@code * interface ArchiveSearcher { String search(String target); } * class App { * ExecutorService executor = ... * ArchiveSearcher searcher = ... * void showSearch(final String target) * throws InterruptedException { * Future future * = executor.submit(new Callable() { * public String call() { * return searcher.search(target); * }}); * displayOtherThings(); // do other things while searching * try { * displayText(future.get()); // use future * } catch (ExecutionException ex) { cleanup(); return; } * } * }} * * The {@link FutureTask} class is an implementation of {@code Future} that * implements {@code Runnable}, and so may be executed by an {@code Executor}. * For example, the above construction with {@code submit} could be replaced by: * {@code * FutureTask future = * new FutureTask(new Callable() { * public String call() { * return searcher.search(target); * }}); * executor.execute(future);} * * Memory consistency effects: Actions taken by the asynchronous computation * happen-before * actions following the corresponding {@code Future.get()} in another thread. * * @see FutureTask * @see Executor * @since 1.5 * @author Doug Lea * @param The result type returned by this Future's {@code get} method */ public interface Future { /** * Attempts to cancel execution of this task. This attempt will * fail if the task has already completed, has already been cancelled, * or could not be cancelled for some other reason. If successful, * and this task has not started when {@code cancel} is called, * this task should never run. If the task has already started, * then the {@code mayInterruptIfRunning} parameter determines * whether the thread executing this task should be interrupted in * an attempt to stop the task. * * After this method returns, subsequent calls to {@link #isDone} will * always return {@code true}. Subsequent calls to {@link #isCancelled} * will always return {@code true} if this method returned {@code true}. * * @param mayInterruptIfRunning {@code true} if the thread executing this * task should be interrupted; otherwise, in-progress tasks are allowed * to complete * @return {@code false} if the task could not be cancelled, * typically because it has already completed normally; * {@code true} otherwise */ boolean cancel(boolean mayInterruptIfRunning); /** * Returns {@code true} if this task was cancelled before it completed * normally. * * @return {@code true} if this task was cancelled before it completed */ boolean isCancelled(); /** * Returns {@code true} if this task completed. * * Completion may be due to normal termination, an exception, or * cancellation -- in all of these cases, this method will return * {@code true}. * * @return {@code true} if this task completed */ boolean isDone(); /** * Waits if necessary for the computation to complete, and then * retrieves its result. * * @return the computed result * @throws CancellationException if the computation was cancelled * @throws ExecutionException if the computation threw an * exception * @throws InterruptedException if the current thread was interrupted * while waiting */ V get() throws InterruptedException, ExecutionException; /** * Waits if necessary for at most the given time for the computation * to complete, and then retrieves its result, if available. * * @param timeout the maximum time to wait * @param unit the time unit of the timeout argument * @return the computed result * @throws CancellationException if the computation was cancelled * @throws ExecutionException if the computation threw an * exception * @throws InterruptedException if the current thread was interrupted * while waiting * @throws TimeoutException if the wait timed out */ V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; } cancel方法: 用来取消任务，如果取消任务成功则返回true，如果取消任务失败则返回false。参数mayInterruptIfRunning表示是否允许取消正在执行却没有执行完毕的任务，如果设置true，则表示可以取消正在执行过程中的任务。如果任务已经完成，则无论mayInterruptIfRunning为true还是false，此方法肯定返回false，即如果取消已经完成的任务会返回false；如果任务正在执行，若mayInterruptIfRunning设置为true，则返回true，若mayInterruptIfRunning设置为false，则返回false；如果任务还没有执行，则无论mayInterruptIfRunning为true还是false，肯定返回true。 isCancelled方法: 表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回true。 isDone方法:表示任务是否已经完成，若任务完成，则返回true； get()方法: 用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回； get(long timeout, TimeUnit unit):用来获取执行结果，如果在指定时间内，还没获取到结果，就直接返回null。 FutureTask Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-31 10:37:20 "},"content/java8/interface_default.html":{"url":"content/java8/interface_default.html","title":"interface defalt static","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Java8 interface default & static 实例1 实例2 interface的default方法 与 继承 interface继承interface [TOC] Java8 interface default & static Java8中为接口新增了一项功能：定义一个或者更多个静态方法。用法和普通的static方法一样。 实例1 interface Animal package com.mb; /** * @Author mubi * @Date 2019/3/21 12:41 PM */ public interface Animal { void play(); /** * 静态方法 */ static void sleep() { System.out.println(\"static sleep\"); } /** * 默认方法 */ default void eat() { System.out.println(\"default eat\"); } } Cat package com.mb; /** * @Author mubi * @Date 2019/3/21 12:45 PM */ public class Cat implements Animal{ @Override public void play() { System.out.println(\"cat play\"); } } Dog package com.mb; /** * @Author mubi * @Date 2019/3/21 12:45 PM */ public class Dog implements Animal{ @Override public void play() { System.out.println(\"dog play\"); } @Override public void eat() { System.out.println(\"dog eat\"); } } main package com.mb; /** * @Author mubi * @Date 2019/3/17 7:56 PM */ public class Main { public static void main(String[] args) throws Exception { Dog dog = new Dog(); Cat cat = new Cat(); dog.eat(); dog.play(); cat.play(); cat.eat(); Animal.sleep(); } } /*output dog eat dog play cat play default eat static sleep */ 实例2 package com.mb; interface A { String what(); default void say() { System.out.println(\"before:\" + System.currentTimeMillis()); System.out.println(what()); System.out.println(\"after:\" + System.currentTimeMillis()); } } class C implements A{ @Override public String what() { return \"I'm C\"; } } class D implements A{ @Override public String what() { return \"I'm D\"; } @Override public void say() { System.out.println(\"D:\" + what()); } } public class Main { public static void main(String[] args) throws Exception { new C().say(); new D().say(); } } /*output before:1553145296092 I'm C after:1553145296093 D:I'm D */ interface的default方法 与 继承 package com.mb; interface A { default void say() { System.out.println(\"A\"); } } class B { public void say() { System.out.println(\"B\"); } } class C implements A{ } class D extends B{ } class E extends B implements A{ } public class Main { public static void main(String[] args) throws Exception { new C().say(); // A new D().say(); // B new E().say(); // B } } 子类优先继承父类的方法，如果父类没有相同签名的方法，才继承接口的default方法。 interface继承interface package com.mb; interface A { String what(); default void say() { System.out.println(\"A:\" + what()); } } /** * interface 的继承 可以重写 default 方法 */ interface B extends A{ String how(); @Override default void say() { System.out.println(\"B:\" + what()); } } class C implements A{ @Override public String what() { return \"I'm C\"; } @Override public void say() { System.out.println(\"C:\" + what()); } } class D implements B{ @Override public String what() { return \"I'm D\"; } @Override public String how() { return \"how I' m D\"; } } class E implements A{ @Override public String what() { return \"I'm E\"; } } public class Main { public static void main(String[] args) throws Exception { new C().say(); new D().say(); new E().say(); } } /*output A:I'm C B:I'm D A:I'm E */ Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-31 10:25:16 "},"content/java8/java8_mem.html":{"url":"content/java8/java8_mem.html","title":"Java8 jvm内存结构","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Java8内存变化 Java8: 没有了永久代的概念 Java8 新增了 Metaspace（元空间） Klass Metaspace NoKlass Metaspace 替换理由 //TODO [TOC] Java8内存变化 ^Cmubi@mubideMacBook-Pro Home $ pwd /Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home mubi@mubideMacBook-Pro Home $ bin/jstat -gcutil 62850 1000 10 Warning: Unresolved Symbol: sun.gc.generation.2.space.0.capacity substituted NaN Warning: Unresolved Symbol: sun.gc.generation.2.space.0.used substituted NaN Warning: Unresolved Symbol: sun.gc.generation.2.space.0.capacity substituted NaN S0 S1 E O P YGC YGCT FGC FGCT GCT 0.00 85.81 76.97 56.33 � 161 1.624 14 0.603 2.227 0.00 85.81 77.08 56.33 � 161 1.624 14 0.603 2.227 0.00 85.81 77.22 56.33 � 161 1.624 14 0.603 2.227 0.00 85.81 77.33 56.33 � 161 1.624 14 0.603 2.227 ^Cmubi@mubideMacBook-Pro Home $ jstat -gcutil 62850 1000 10 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 85.81 78.86 56.33 93.46 89.80 161 1.624 14 0.603 2.227 0.00 85.81 78.93 56.33 93.46 89.80 161 1.624 14 0.603 2.227 0.00 85.81 79.04 56.33 93.46 89.80 161 1.624 14 0.603 2.227 0.00 85.81 79.17 56.33 93.46 89.80 161 1.624 14 0.603 2.227 0.00 85.81 79.29 56.33 93.46 89.80 161 1.624 14 0.603 2.227 ^Cmubi@mubideMacBook-Pro Home $ java7: S0 — Heap上的 Survivor space 0 区已使用空间的百分比 S1 — Heap上的 Survivor space 1 区已使用空间的百分比 E — Heap上的 Eden space 区已使用空间的百分比 O — Heap上的 Old space 区已使用空间的百分比 P — Perm space 区已使用空间的百分比 YGC — 从应用程序启动到采样时发生 Young GC 的次数 YGCT– 从应用程序启动到采样时 Young GC 所用的时间(单位秒) FGC — 从应用程序启动到采样时发生 Full GC 的次数 FGCT– 从应用程序启动到采样时 Full GC 所用的时间(单位秒) GCT — 从应用程序启动到采样时用于垃圾回收的总时间(单位秒) Java8: 没有了永久代的概念 少了一个 Perm space（永久代） Java7中方法区（Method Area）,与Javad堆一样，是各个线程共享的内存区域，主要用于存储已经被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。在HotSpot虚拟机上，通常把方法区称为\"永久代\"(Permanent Generation), 本质上两者并不等价，仅仅是因为HotSpot虚拟机的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已。这样HotSpot的垃圾收集器可以像管理Java堆一样管理这部分内存，能够省去专门为方法区编写内存管理代码的工作。 java7中，符号引用(Symbols)转移到了native heap；字面量(interned strings)转移到了java heap；类的静态变量(class statics)转移到了java heap。 Java7的Perm space在堆中，设置小了，容易OutOfMemory；设置大了比较浪费堆内存 Java8 新增了 Metaspace（元空间） M - 元空间（Metaspace）： Klass Metaspace, NoKlass Metaspace CCS - 表示的是NoKlass Metaspace的使用率 元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制，但可以通过参数来指定元空间的大小。 Klass Metaspace 存放klass的，klass是我们熟知的class文件在jvm里的运行时数据结构，这个空间的默认大小是1G NoKlass Metaspace 专门来存klass相关的其他的内容，比如method，constantPool（常量池）等，这块内存是由多块内存组合起来的，所以可以认为是不连续的内存块组成的。这块内存是必须的 -XX:MetaspaceSize，初始空间大小，达到该值就会触发垃圾收集进行类型卸载，同时GC会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过MaxMetaspaceSize时，适当提高该值。 -XX:MaxMetaspaceSize，最大空间，默认是没有限制的。 -XX:MinMetaspaceFreeRatio，在GC之后，最小的Metaspace剩余空间容量的百分比，减少为分配空间所导致的垃圾收集 -XX:MaxMetaspaceFreeRatio，在GC之后，最大的Metaspace剩余空间容量的百分比，减少为释放空间所导致的垃圾收集 替换理由 //TODO http://openjdk.java.net/jeps/122 Java8中的metaspace Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-06 16:20:29 "},"content/java8/lambda.html":{"url":"content/java8/lambda.html","title":"Java8 lambda表达式","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 lambda 需求不断变化的找苹果 java8 与 java7 内存空间的区别 @FunctionalInterface 接口使用条件 lambda的使用 基本语法 java8源码使用lambda的场景 复合式lambda表达式 《java8 in action》 lambda总结 lambda表达式 与 JVM字节码 匿名内部类 jvm字节码 lambda 字节码 invokedynamic 指令 函数式编程 [TOC] lambda 需求不断变化的找苹果 函数式编程，方法和Lambda作为一等公民 public class Apple { private String color; private long weight; public Apple() { } public Apple(String color, long weight) { this.color = color; this.weight = weight; } public String getColor() { return color; } public void setColor(String color) { this.color = color; } public long getWeight() { return weight; } public void setWeight(long weight) { this.weight = weight; } @Override public String toString() { return \"Apple{\" + \"color='\" + color + '\\'' + \", weight=\" + weight + '}'; } } @FunctionalInterface public interface AppleFilter { /** * 过滤器接口 * @param apple * @return */ boolean filter(Apple apple); } public static List findApple(List apples, AppleFilter appleFilter) { List list = new ArrayList<>(); for (Apple apple : apples) { if (appleFilter.filter(apple)) { list.add(apple); } } return list; } // lambda表达式，找到绿色的苹果 List lambdaResult = findApple(list, apple -> apple.getColor().equals(\"green\")); java8 与 java7 内存空间的区别 ^Cmubi@mubideMacBook-Pro Home $ pwd /Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home mubi@mubideMacBook-Pro Home $ bin/jstat -gcutil 62850 1000 10 Warning: Unresolved Symbol: sun.gc.generation.2.space.0.capacity substituted NaN Warning: Unresolved Symbol: sun.gc.generation.2.space.0.used substituted NaN Warning: Unresolved Symbol: sun.gc.generation.2.space.0.capacity substituted NaN S0 S1 E O P YGC YGCT FGC FGCT GCT 0.00 85.81 76.97 56.33 � 161 1.624 14 0.603 2.227 0.00 85.81 77.08 56.33 � 161 1.624 14 0.603 2.227 0.00 85.81 77.22 56.33 � 161 1.624 14 0.603 2.227 0.00 85.81 77.33 56.33 � 161 1.624 14 0.603 2.227 ^Cmubi@mubideMacBook-Pro Home $ jstat -gcutil 62850 1000 10 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 85.81 78.86 56.33 93.46 89.80 161 1.624 14 0.603 2.227 0.00 85.81 78.93 56.33 93.46 89.80 161 1.624 14 0.603 2.227 0.00 85.81 79.04 56.33 93.46 89.80 161 1.624 14 0.603 2.227 0.00 85.81 79.17 56.33 93.46 89.80 161 1.624 14 0.603 2.227 0.00 85.81 79.29 56.33 93.46 89.80 161 1.624 14 0.603 2.227 ^Cmubi@mubideMacBook-Pro Home $ java7: S0 — Heap上的 Survivor space 0 区已使用空间的百分比 S1 — Heap上的 Survivor space 1 区已使用空间的百分比 E — Heap上的 Eden space 区已使用空间的百分比 O — Heap上的 Old space 区已使用空间的百分比 P — Perm space 区已使用空间的百分比 YGC — 从应用程序启动到采样时发生 Young GC 的次数 YGCT– 从应用程序启动到采样时 Young GC 所用的时间(单位秒) FGC — 从应用程序启动到采样时发生 Full GC 的次数 FGCT– 从应用程序启动到采样时 Full GC 所用的时间(单位秒) GCT — 从应用程序启动到采样时用于垃圾回收的总时间(单位秒) java8: 少了一个 Perm space 新增了 M - 元空间（Metaspace）： Klass Metaspace, NoKlass Metaspace CCS - 表示的是NoKlass Metaspace的使用率 @FunctionalInterface 接口使用条件 只能定义了唯一的抽象方法的接口 如下的默认方法不是，不是抽象方法 如下正确: 函数式接口里允许定义默认方法和静态方法,也可以包含Object里的public方法 @FunctionalInterface public interface AppleFilter2 { boolean filter(Apple apple); default boolean filter2(){ return true; } static boolean filter3(){ return true; } @Override boolean equals(Object obj); @Override String toString(); } lambda的使用 基本语法 (parameters) -> expression (parameters) -> { statements; } (1) () -> {} (2) () -> \"Raoul\" (3) () -> {return \"Mario\";} (4) (Integer i) -> return \"Alan\" + i; (5) (String s) -> {\"IronMan\";} (4),(5) 无效 (4) 需要加上`{}` (5) 需要去掉`{}`和`;` java8源码使用lambda的场景 @FunctionalInterface public interface Comparator { @FunctionalInterface public interface Runnable { @FunctionalInterface public interface Function { 复合式lambda表达式 比较器复合 逆序 比较器链 谓词复合 negate,and,or 函数复合 Funtion接口 《java8 in action》 lambda总结 Lambda表达式可以理解为一种匿名函数:它没有名称，但有参数列表、函数主体、返回类型，可能还有一个可以抛出的异常的列表。 Lambda表达式让你可以简洁地传递代码。 函数式接口就是仅仅声明了一个抽象方法的接口。 只有在接受函数式接口的地方才可以使用Lambda表达式。 Lambda表达式允许你直接内联，为函数式接口的抽象方法提供实现，并且将整个表达式作为函数式接口的一个实例。 Java 8自带一些常用的函数式接口，放在java.util.function包里，包括Predicate、Function、Supplier、Consumer和BinaryOperator 为了避免装箱操作，对Predicate和Function等通用函数式接口的原始类型 特化:IntPredicate、IntToLongFunction等。 环绕执行模式(即在方法所必需的代码中间，你需要执行点儿什么操作，比如资源分配 和清理)可以配合Lambda提高灵活性和可重用性。 Lambda表达式所需要代表的类型称为目标类型。 方法引用让你重复使用现有的方法实现并直接传递它们。 Comparator、Predicate和Function等函数式接口都有几个可以用来结合Lambda表达式的默认方法。 lambda表达式 与 JVM字节码 匿名内部类 jvm字节码 InnerClass.java import java.util.function.Function; public class InnerClass { Function f = new Function() { @Override public String apply(Object obj) { return obj.toString(); } }; } javac InnerClass.java 生成 InnerClass$1.class InnerClass.class javap -c -v InnerClass 查看字节码和常量池 public com.other.InnerClass(); descriptor: ()V flags: ACC_PUBLIC Code: stack=4, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"\":()V 4: aload_0 5: new #2 // class com/other/InnerClass$1 8: dup 9: aload_0 10: invokespecial #3 // Method com/other/InnerClass$1.\"\":(Lcom/other/InnerClass;)V 13: putfield #4 // Field f:Ljava/util/function/Function; 16: return LineNumberTable: line 4: 0 line 5: 4 } 通过字节码操作new，一个InnerClass$1类型的对象被实例化了。与此同时，一个指向新创建对象的引用会被压入栈。 dup操作会复制栈上的引用。 接着，这个值会被invokespecial指令处理，该指令会初始化对象。 栈顶现在包含了指向对象的引用，该值通过putfield指令保存到了LambdaBytecode类的f1字段 lambda 字节码 import java.util.function.Function; public class Lambda { Function f = obj -> obj.toString(); } public com.other.Lambda(); descriptor: ()V flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"\":()V 4: aload_0 5: invokedynamic #2, 0 // InvokeDynamic #0:apply:()Ljava/util/function/Function; 10: putfield #3 // Field f:Ljava/util/function/Function; 13: return LineNumberTable: line 5: 0 line 6: 4 } 创建额外的类现在被invokedynamic指令替代了 invokedynamic 指令 字节码指令invokedynamic最初被JDK7引入，用于支持运行于JVM上的动态类型语言。执行方法调用时，invokedynamic添加了更高层的抽象，使得一部分逻辑可以依据动态语言的特征来决定调用目标。这一指令的典型使用场景如下: def add(a, b) { a + b } 这里a和b的类型在编译时都未知，有可能随着运行时发生变化。由于这个原因，JVM首次执行invokedynamic调用时，它会查询一个bootstrap方法，该方法实现了依赖语言的逻辑，可以决定选择哪一个方法进行调用。bootstrap方法返回一个链接调用点(linked call site)。很多情况下，如果add方法使用两个int类型的变量，紧接下来的调用也会使用两个int类型的值。所以，每次调用也没有必要都重新选择调用的方法。调用点自身就包含了一定的逻辑，可以判断在什么情况下需要进行重新链接。 invokedynamic指令将实现Lambda表达式的这部分代码的字节码生成推迟到运行时 Lambda表达式的代码块到字节码的转换由高层的策略变成了存粹的实现细节。它现在可以动态地改变，或者在未来版本中得到优化、修改，并且保持了字节码的后向兼容性 没有带来额外的开销，没有额外的字段，也不需要进行静态初始化，而这些如果不使用 Lambda，就不会实现。 对无状态非捕获型Lambda，我们可以创建一个Lambda对象的实例，对其进行缓存，之后 对同一对象的访问都返回同样的内容。这是一种常见的用例，也是人们在Java 8之前就惯用的方式;比如，以static final变量的方式声明某个比较器实例。 没有额外的性能开销，因为这些转换都是必须的，并且结果也进行了链接，仅在Lambda 首次被调用时需要转换。其后所有的调用都能直接跳过这一步，直接调用之前链接的实现 将Lambda表达式的代码体填入到运行时动态创建的静态方法, 类似如下 public class Lambda { Function f = [dynamic invocation of lambda$1] static String lambda$1(Object obj) { return obj.toString(); } } 函数式编程 ？ Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-28 15:19:25 "},"content/java8/java8_optional.html":{"url":"content/java8/java8_optional.html","title":"Java8 Optional","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 用optional取代null 经典的java.lang.NullPointerException问题 采用防御式检查减少NullPointerException null 带来的种种问题 Optional Optional 对象如何创建 Optional 使用实际例子 [TOC] 用optional取代null 经典的java.lang.NullPointerException问题 class Insurance { private String name; public void setName(String name) { this.name = name; } public String getName() { return name; } } class Car { private Insurance insurance; public void setInsurance(Insurance insurance) { this.insurance = insurance; } public Insurance getInsurance() { return insurance; } } class Person { private Car car; public void setCar(Car car){ this.car = car; } public Car getCar() { return car; } } public class MainTest { public static String getCarInsuranceName(Person person) { return person.getCar().getInsurance().getName(); } public static void main(String[] args) { Person person = new Person(); String carInsuranceName = getCarInsuranceName(person); System.out.print(carInsuranceName); } } 采用防御式检查减少NullPointerException 深层质疑 public static String getCarInsuranceName(Person person) { if(person != null) { if(person.getCar() != null) { if(person.getCar().getInsurance() != null) { return person.getCar().getInsurance().getName(); } } } return \"Unknown\"; } 过多的退出语句 public static String getCarInsuranceName(Person person) { if(person != null) { return \"Unknown\"; } if(person.getCar() != null) { return \"Unknown\"; } if(person.getCar().getInsurance() != null) { return \"Unknown\"; } return person.getCar().getInsurance().getName(); } null 带来的种种问题 它是错误之源 NullPointerException是目前Java程序开发中最典型的异常 它会使你的代码膨胀 它让你的代码充斥着深度嵌套的null检查，代码的可读性糟糕透顶 它自身是毫无意义的 null自身没有任何的语义，尤其是，它代表的是在静态类型语言中以一种错误的方式对缺少变量值的建模 它破坏了Java的哲学 Java一直试图避免让程序员意识到指针的存在，唯一的例外是null指针。 它在Java的类型系统上开了个口子 null并不属于任何类型，这意味着它可以被赋值给任意引用类型的变量。这会导致问题，原因是当这个变量被传递到系统中的另一个部分后，你将无法获知这个null变量最初的赋值到底是什么类型 Optional public final class Optional { 变量存在时，Optional类只是对类简单封装。变量不存在时，缺失的值会被建模成一个\"空\"的Optional对象，由方法Optional.empty()返回。Optional.empty()方法是一个静态工厂方法，它返回Optional类的特定单一实例。 使用Optional而不是null的一个非常重要而又实际的语义区别是，我们在声明变量时使用的是Optional类型，而不是Car类型，这句声明非常清楚地表明了这里发生变量缺失是允许的。与此相反，使用Car这样的类型，可能将变量赋值为null，这意味着你需要独立面对这些，你只能依赖你对业务模型的理解，判断一个null是否属于该变量的有效范畴。 Optional 对象如何创建 几种创建方式 // 依据一个非空值创建 Optional Person person = new Person(); Optional optPerson = Optional.of(person); // 声明一个空的 Optional Optional optionalEmptyPerson = Optional.empty(); // 可接受 null 的 Optional Person personNull = null; Optional optionalNullPerson = Optional.ofNullable(personNull); 在域模型中使用Optional，以及为什么它们无法序列化 建议你像下面这个例子那样，提供一个能访问声明为Optional、变量值可能缺失的接口， public class Person { private Car car; public Optional getCarAsOptional() { return Optional.ofNullable(car); } } Optional 使用实际例子 如果你对一个空的Optional对象调用flatMap，实际情况又会如何呢?结果不会发生任何改变，返回值也是个空的Optional对象(Optional.empty)。对null进行flatmap会抛出NullPointerException Optional personOptional = Optional.empty(); // 对 Optional.empty 进行 flatMap 会返回 Optional.empty System.out.println( personOptional.flatMap(Person::getCar)); // 对 null 进行 flatMap 会抛出 java.lang.NullPointerException personOptional = null; personOptional.flatMap(Person::getCar); class Insurance { /** * 保险公司必须要有名字，此处非Optional */ private String name; public void setName(String name) { this.name = name; } public String getName() { return name; } } class Car { /** * 车可能有保险，也可能没有保险，因此将这个字段声明为Optional */ private Optional insurance; public void setInsurance(Optional insurance) { this.insurance = insurance; } public Optional getInsurance() { return insurance; } } class Person { /** * 人可能有车，也可能没有车，因此将这个字段声明为Optional */ private Optional car; public void setCar(Optional car){ this.car = car; } public Optional getCar() { return car; } } public class MainTest { public static String getCarInsuranceName(Optional person) { /** * flatMap 链接 Optional 对象 */ return person.flatMap(Person::getCar) .flatMap(Car::getInsurance) .map(Insurance::getName) .orElse(\"Unknown\"); } public static void main(String[] args) { /** * 1. Person 为空 */ Optional optionalEmptyPerson = Optional.empty(); String carInsuranceName = getCarInsuranceName(optionalEmptyPerson); // Unknown System.out.println(carInsuranceName); /** * 2. Person非空，但 Car 为空 */ // 构造 Optional Person person = new Person(); // person 非空，必须设置 Car person.setCar(Optional.empty()); Optional optPerson = Optional.ofNullable(person); carInsuranceName = getCarInsuranceName(optPerson); // Unknown System.out.println(carInsuranceName); /** * 3. Person非空，Car 非空， 但 Insurance 为空 */ // 声明 Optional Car car = new Car(); // car 非空，必须设置 Insurance car.setInsurance(Optional.empty()); Optional optionalOfNullCar = Optional.ofNullable(car); // 构造 Optional person.setCar(optionalOfNullCar); optPerson = Optional.ofNullable(person); carInsuranceName = getCarInsuranceName(optPerson); // Unknown System.out.println(carInsuranceName); } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-10 10:30:08 "},"content/java8/streams.html":{"url":"content/java8/streams.html","title":"Java8 Streams","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Streams 流是什么,流的简单使用 流 特点 流操作 流与集合 流操作 规约(reduce) max, min 流操作: 无状态和有状态 [TOC] Streams 流是什么,流的简单使用 List menu = Arrays.asList( new Dish(\"pork\", false, 800, Dish.Type.MEAT), new Dish(\"beef\", false, 700, Dish.Type.MEAT), new Dish(\"chicken\", false, 400, Dish.Type.MEAT), new Dish(\"french fries\", true, 530, Dish.Type.OTHER), new Dish(\"rice\", true, 350, Dish.Type.OTHER), new Dish(\"season fruit\", true, 120, Dish.Type.OTHER), new Dish(\"pizza\", true, 550, Dish.Type.OTHER), new Dish(\"prawns\", false, 300, Dish.Type.FISH), new Dish(\"salmon\", false, 450, Dish.Type.FISH)); Java7 写法 List lowCaloricDishes = new ArrayList<>(); // 用累加器筛选卡路里() { @Override public int compare(Dish d1, Dish d2) { return Integer.compare(d1.getCalories(), d2.getCalories()); } }); // 获取最后的菜肴列表 List lowCaloricDishesName = new ArrayList<>(); for(Dish d: lowCaloricDishes){ lowCaloricDishesName.add(d.getName()); } 在这段代码中，你用了一个\"垃圾变量\"lowCaloricDishes。它唯一的作用就是作为一次性的中间容器。在Java8中，实现的细节被放在它本该归属的类里了 java8 List lowCaloricDishesName = menu.stream() .filter(d -> d.getCalories() 为了利用多核架构并行处理，需把stream()换成parallelStream() List lowCaloricDishesName = menu.parallelStream() .filter(d -> d.getCalories() 优势： 代码是以声明性方式写的:说明想要完成什么(筛选热量低的菜肴)而不是说明如何实现一个操作(利用循环和if条件等控制流语句)。 你可以把几个基础操作链接起来，来表达复杂等流水线(在filter后面接上 sorted、map和collect操作),同时保持代码清晰可读 所以通过Java8的Stream API可以写出如下的代码： 声明性 —— 更简洁，更易读 可复合 —— 更灵活 可并行 —— 性能更好 流 特点 流操作 \"A sequence of elements supporting sequential and parallel aggregate operations.\" 从支持数据处理操作的源生成的元素序列 Stream是元素的集合，这点让Stream看起来用些类似Iterator 可以支持顺序和并行的对原Stream进行汇聚的操作 流与集合 只能遍历一次 和迭代器类似，流只能遍历一次。遍历完之后，我们就说这个流已经被消费掉了。 外部迭代与内部迭代 使用Collection接口需要用户去做迭代(比如用for-each)，这称为外部迭代。相反，Streams库使用内部迭代——它帮你把迭代做了 流操作 filter、map和limit可以连成一条流水线; collect触发流水线执行并关闭它。 可以连接起来的流操作称为中间操作，关闭流的操作称为终端操作 流的使用一般包括三件事: 一个数据源(如集合)来执行一个查询 一个中间操作链，形成一条流的流水线 一个终端操作，执行流水线，并能生成结果 规约(reduce) List numberList = Arrays.asList(1,2,5,6,7); int numberSum = 0; for(int num: numberList){ numberSum += num; } System.out.println(\"sum:\"+ numberSum); int numberSum2 = numberList.stream() .reduce(0, (a, b) -> a + b); System.out.println(\"sum2:\"+ numberSum2); reduce接受两个参数 总和变量初始值，设为了0 将列表中所有原始结合在一起的操作，设为了+ （BinaryOperator操作用lambda表达式表示） 如下返回Optional对象，因为Stream中可能一个元素都没有 Optional numberSum3 = numberList.stream() .reduce( (a, b) -> a + b); System.out.println(\"sum3:\"+ numberSum3); max, min List numberList = Arrays.asList(1,2,10,6,7); int numberMax = numberList.stream() .reduce(0, (a, b) -> a > b ? a : b); System.out.println(\"max:\"+ numberMax); Optional numberMax2 = numberList.stream() .reduce(Integer::max); System.out.println(\"max2:\"+ numberMax2); 流操作: 无状态和有状态 诸如map或filter等操作会从输入流中获取每一个元素，并在输出流中输出0个或1个结果，这些操作是无状态的:它们没有内部状态（假设用户提高的lambda或方法引用没有内部可变状态） 诸如reduce,sum，max等操作需要内部状态来累计结果，要求流是有界的 诸如sort或distince等操作，开始与map,filter相同，但是需要有个缓冲区存放所有元素，这个存储要求是无界的 注：如果能避开 有状态，选用无状态操作，就能获得更好的并行性能。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 11:34:32 "},"content/java8/streams_parallel.html":{"url":"content/java8/streams_parallel.html","title":"Java8 并行数据处理与性能","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 并行数据处理与性能 数值流，装箱和拆箱 并行流 测量流性能 正确使用并行流 错误并行的例子 高效使用并行流 Fork/Join框架 RecursiveTask的使用 工作窃取算法（work stealing） Spliterator ParallelStream 使用问题 [TOC] 并行数据处理与性能 数值流，装箱和拆箱 将原始类型转换为对应的引用类型的机制，这个机制叫做装箱。 将引用类型转换为对应的原始类型，叫做拆箱。 java中装箱和拆箱是自动完成的, 但这在性能方面是要付出代价的，装箱的本质就是将原始类型包裹起来，并保存在堆里。因此装箱后的值需要更多的内存，并需要额外的内存搜索来获取被包裹的原始值。 List list = new ArrayList<>(); for(int i = 0 ; i Java8 引入了三个原始类型特化流来解决这个问题；IntStream、DoubleStream、LongStream分别将流中元素特化为int、double、long，从而避免了暗含装箱的成本。每个接口都带来了常用数值归约的新方法，例如对数值流求和的sum，找到最大元素的max。 并行流 并行流就是一个把内容分成多个数据块，并用不同的线程分别处理每个数据块的流。这样一来，你就可以自动把给定操作的工作负荷分配给多核处理器的所有内核，让它们都忙起来。 public static long parallelSum(long n) { return Stream.iterate(1L, i -> i + 1) .limit(n) .parallel() .reduce(0L, Long::sum); } 并行流用的线程是从哪来的?有多少个?怎么自定义这个过程呢? 并行流内部使用了默认的ForkJoinPool，它默认的线程数量就是你的处理器数量，这个值是由Runtime.getRuntime().availableProcessors()得到的。 但是你可以过系统性 java.util.concurrent.ForkJoinPool.common. parallelism来改变线程&#x10FE95;大小，如下所示: System.setProperty(\"java.util.concurrent.ForkJoinPool.common.parallelism\",\"12\"); 这是一个全局设置，因此它将影响代码中所有的并行流。反过来说，目前还无法专为某个并行流设定这个值。一般而言，让ForkJoinPool的大小等于处理器数量是个不错的默认值，除非你有很好的理由，否则我们强烈建议你不要修改它。 测量流性能 class ParallelStreams{ public static long parallelSum(long n) { return Stream.iterate(1L, i -> i + 1) .limit(n) .parallel() .reduce(0L, Long::sum); } public static long iterativeSum(long n) { long result = 0; for (long i = 1L; i adder, long n) { long fastest = Long.MAX_VALUE; int cnt = 10; for (int i = 0; i 求和方法的并行版本比顺序版本要慢很多, 如何解释？ iterate生成的是装箱的对象，必须拆箱成数字才能求和; 我们很难把iterate分成多个独立块来并行执行。 public static Stream iterate(final T seed, final UnaryOperator f) { Objects.requireNonNull(f); final Iterator iterator = new Iterator() { @SuppressWarnings(\"unchecked\") T t = (T) Streams.NONE; @Override public boolean hasNext() { return true; } @Override public T next() { return t = (t == Streams.NONE) ? seed : f.apply(t); } }; return StreamSupport.stream(Spliterators.spliteratorUnknownSize( iterator, Spliterator.ORDERED | Spliterator.IMMUTABLE), false); } 整张数字列表在归纳过程开始时没有准备好，因而无法有效地把流划分为小块来并行处理。把流标记为并行，其实时给顺序处理增加了开销，它还要把每次求和操作分到一个不同的线程上。 这就说明了并行编程可能很复杂，有时候甚至有点违反直觉。如果用得不对(比如采用了一个不易并行化的操作，如iterate)，它甚至可能让程序的整体性能更差，所以在调用那个看似神奇的parallel操作时，了解背后到底发生了什么是很有必要的。 正确使用并行流 LongStream.rangeClosed直接产生原始类型的long数字，没有装箱拆箱的开&#x10FEB1;。 LongStream.rangeClosed会生成数字范围，很容易拆分为独立的小块。 public static long rangedSum(long n) { return LongStream.rangeClosed(1, n) .reduce(0L, Long::sum); } public static long parallelRangedSum(long n) { return LongStream.rangeClosed(1, n) .parallel() .reduce(0L, Long::sum); } 其中运行一次的结果 // 8 msecs System.out.println(\"Sequential sum done in:\" + measureSumPerf(ParallelStreams::rangedSum, 10_000_000) + \" msecs\"); // 1 msecs System.out.println(\"Sequential sum done in:\" + measureSumPerf(ParallelStreams::parallelRangedSum, 10_000_000) + \" msecs\"); 这也表明，使用正确的数据结构，并使其并行工作能够保最佳的性能。 尽管如此，请记住，并行化并不是没有代价的。并行化过程本身需要对流做递归划分，把每个子流的归纳操作分配到不同的线程，然后把这些操作的结果合并成一个值。但在多个内核之间移动数据的代价也可能比你想的要大，所以很重要的一点是要保证在内核中并行执行工作的时间比在内核之间传输数据的时间长。总而言之，很多情况下不可能或不方便并行化。然而，在使用并行Stream加速代码之前，你必须确保用得对，如果结果错了，算得快就毫无意义了。 错误并行的例子 public class Accumulator { public long total = 0; public void add(long value) { total += value; } } public static long sideEffectSum(long n) { Accumulator accumulator = new Accumulator(); LongStream.rangeClosed(1, n).forEach(accumulator::add); return accumulator.total; } 本质上就是顺序的。每次访问total都会出现数据竞争。如果尝试用同步来修复，那就完全失去并行的意义了 System.out.println(\"Sequential sum done in:\" + measureSumPerf(ParallelStreams::sideEffectParallelSum, 10_000_000) + \" msecs\"); 结果返回离正确结果差很远, 这是由于多个线程在同时访问累加器，执行total += value，而这一句虽然看似简单，却不是一个原子操作 Result: 28164411286807 Result: 11651694778636 Result: 22043244877252 Result: 17682597464130 Result: 9609315403160 Result: 49558238667010 Result: 37620761173257 Result: 33329225372527 Result: 17778545913914 Result: 23757727257263 高效使用并行流 如果有疑问，测量。把顺序转成并行流轻而易举，但却比一定是好事。因为并行流并不总是比顺序快。 留意装箱。自动装箱和拆箱操作会大大降低性能。java8中有原始类型流(IntStream,LongStream,DoubleStream)来避免这种操作，但凡有可能都要用这些流。 有些操作本身在并行流上的性能就比顺序流查。特别是limit和findFirst等依赖于元素顺序的操作，他们在并行流上执行的代价非常大。findAny会比findFirst性能好，因为它不一定要按顺序执行。 对于较小的数据量，选择并行流几乎从来都不是一个好的决定。并行处理少数几个元素的好处还抵不上并行化造成额外的开销。 流数据源和可分解性 源 可分解性 ArrayList 极佳 LinkedList 差 IntStream.range 极佳 Stream.iterate 差 HashSet 好 TreeSet 好 流背后使用的基础架构是java7中引入的分支/合并框架。并行汇总的实例证明了要想正确使用并行流，了解它的内部原理至关重要。 Fork/Join框架 分支/合并框架的目的是以递归方式将可以并行的任务拆分成更小的任务，然后将每个子任务的结果合并起来生成整体结果。它是ExecutorService接口的一个实现，它把子任务分配给线程池(称为ForkJoinPool)中的工作线程。 伪代码如下 if (任务足够小或不可分) { 顺序计算该任务 } else { 将任务分成两个子任务 递归调用本方法，拆分每个子任务，等待所有子任务完成 合并每个子任务的结果 } RecursiveTask的使用 public class ForkJoinSumRecursiveTask extends java.util.concurrent.RecursiveTask { /** * 要求和的数组，起始和结束位置 */ private final long[] numbers; private final int start; private final int end; /** * 不再将任务分解为子任务的数组大小 */ private static final long THRESHOLD = 10_000; public ForkJoinSumRecursiveTask(long[] numbers) { this(0, numbers.length,numbers); } public ForkJoinSumRecursiveTask(int start, int end, long[] data) { this.start = start; this.end = end; this.numbers = data; } /** * 覆盖RecursiveTask抽象方法 * @return */ @Override protected Long compute() { if ((end - start) 运行情况如下 public static long forkJoinSum(long n) { long[] numbers = LongStream.rangeClosed(1, n).toArray(); ForkJoinTask task = new ForkJoinSumRecursiveTask(numbers); return new ForkJoinPool().invoke(task); } // 61 msecs System.out.println(\"Sequential sum done in:\" + measureSumPerf(ParallelStreams::forkJoinSum, 10_000_000) + \" msecs\"); 这个性能看起来比用并行流的版本要差，但这只是因为必须先要把整个数字流都放进一个long[]，之后才能在ForkJoinSumRecursiveTask任务中使用它 工作窃取算法（work stealing） 工作窃取算法（work stealing）用于在池中的工作线程之间重新分配和平衡任务. 在实际应用中，这意味着这些任务差不多被平均分配到ForkJoinPool中的所有线程上。 Spliterator Spliterator是Java8中加入的另一个新接口;这个名字代表“可分迭代器”(splitable iterator)。和Iterator一样，Spliterator也用于遍历数据源中的元素，但它是为了并行执行而设计的。 ParallelStream 使用问题 // TODO Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-31 10:25:09 "},"content/java_jvm/jvm_mem_model.html":{"url":"content/java_jvm/jvm_mem_model.html","title":"内存模型与线程","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Java 内存模型与线程 学习文档 硬件的效率 与 一致性 Java 主内存与工作内存 volatile（可见性&顺序性） 原子性，可见性，有序性 并行（parallellism） 和 并发（concurrency） [TOC] Java 内存模型与线程 学习文档 参考学习1: Java Memory Model外文文档 硬件的效率 与 一致性 每个处理器都有自己的高速缓存，而它们又共享同一内存（Main Memory）；当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致 Java 主内存与工作内存 Java内存模型(JMM), 主要目标是定义各个变量（注意是共享变量，如实例字段，静态字段，构成数组对象的元素等，不包括局部变量）的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节 Java的每个线程有自己的工作线程（Working Memory, 可类比处理器的高速缓存），线程的工作内存中保存了该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取，赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递需要通过主内存 主内存与工作内存之间的具体交互协议，虚拟机保证如下的每一种操作都是原子的，不可再分的（对于double,long类型的变量有例外，商用JVM基本优化了这个问题） lock: 作用于主内存的变量，它把一个变量标识为一个线程独占的状态 unlock：作用于主内存的变量， 解锁 load：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中 use：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作 assign: 作用于工作内存的变量，它把一个从执行引擎接收到的赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作 store: 作用于工作内存的变量，它把工作内存中的一个变量的值传送到主内存中，以便随后的write操作使用 write：作用于主内存的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中 volatile（可见性&顺序性） 当一个变量定义为volatile之后，具备两个特性 保证此变量对所有线程的可见性（指当一条线程修改了这个变量的值，新值对于其它线程来说是可以立即知晓的。普通变量需要通过工作线程，主线程传递来做到） 在各个线程的工作线程中, volatile变量也可以存在不一致的情况，但由于每次使用之前都要先刷新，执行引擎看不到不一致的情况，因为可以认为不存在一致性问题，但是Java里面的运算并非都是原子操作，这导致volatile变量的运算在并发下一样是不安全的 static int count = 20_000; volatile int num = 0; int coreSize = Runtime.getRuntime().availableProcessors(); ThreadPoolExecutor exec = new ThreadPoolExecutor(coreSize * 2, coreSize * 3, 0, TimeUnit.SECONDS, new LinkedBlockingQueue(500), new ThreadPoolExecutor.CallerRunsPolicy()); public void test() { for (int i = 0; i output count:20000 num:19763 abs(num-count):237 禁止指令重排序优化，即线程内表现为串行的语义，保证顺序性 volatile使用原则：volatile变量读操作的性能消耗与普通变量几乎没有什么差别，但是写操作可能慢一些，因为它需要在本地代码中插入许多内存屏障来保证处理器不发生乱序执行。不过即便如此，大多数场景下volatile的总开销仍然比锁低，我们在volatile与锁之中选择的唯一依据仅仅是：volatile的语义能否满足使用场景的要求 原子性，可见性，有序性 原子性 lock, unlock 对应 Java指令的monitorenter和monitorexit；synchronized关键字隐含了这两个指令，所以synchronized块之间的操作也具备了原子性 可见性 指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 当一个变量被volatile修饰是，它会保证修改的值会立即被更新到主存，当有其它线程需要读取时，他回去内存中读取新值。 synchronized 和 final 也能保证可见性 有序性 线程内串行有序 / 指令重排 / 工作内存与主内存同步延迟 synchronized 和 volotile 并行（parallellism） 和 并发（concurrency） 并发：当有多个线程在操作时,如果系统只有一个CPU,则它根本不可能真正同时进行一个以上的线程；它只能把CPU运行时间划分成若干个时间段,再将时间片分配给各个线程执行，在一个时间段的线程代码运行时，其它线程处于挂起状。这种方式我们称之为并发(Concurrent)。 并行：当系统有一个以上CPU时,则线程的操作有可能非并发。当一个CPU执行一个线程时，另一个CPU可以执行另一个线程，两个线程互不抢占CPU资源，可以同时进行，这种方式我们称之为并行(Parallel)。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-31 10:17:08 "},"content/java_jvm/jvm_class_load.html":{"url":"content/java_jvm/jvm_class_load.html","title":"类加载机制,类加载器,内存布局","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Class 文件 Class 对象 魔数与Class文件的版本 常量池 访问标志 类索引，父类索引，接口索引 字段表(field_info) 方法表 属性表 JVM运行时各内存区域 Java7 Java8 程序计数器(PC) 虚拟机栈（线程stack） 什么情况下会发生栈内存溢出（面试题） 本地方法栈(native stack) 堆(heap) 元空间(metaspace)（不属于JVM，使用堆外内存） 方法区(method area) & 永久代(Perm Space) 常量池 hotSpot对象存储 对象布局 new Object() 占用多少字节？ 对象头 & markword 锁升级过程 程序编译和代码优化 类加载过程(*) 1 加载 2-1 连接：验证（class字节流的校验） 2-2 连接：准备（分配内存，初始化默认值） 2-3 连接：解析 3 初始化 什么时候需要对类进行初始化? 附：类实例初始化过程？ 类加载器分类 1. 根加载器Bootstrap ClassLoader 2. 扩展类加载器Extension ClassLoader 3. 系统类加载器Application ClassLoader 4. 自定义类加载器Custom CLassLoader 双亲委派模型（*） 双亲委派优势 类加载题目例子（Java7环境） 结果分析 Singleton 结果分析 Singleton2 分析 静态初始化再次验证 自定义类加载器 自定义类加载器的一般步骤 MyClassLoader 实践 MyClassLoader实现热加载 如何改变 new 的类加载器？ 自定义类加载器的优缺点 // TODO com.mysql.jdbc.Driver（打破parents delegate） 例子代码 源码逻辑说明 Connection的getConnection方法 [TOC] Class 文件 Class文件是一组以8位字节为基础单位的二进制流，任何一个Class文件都对应唯一一个类或接口的定义信息 Class 对象 每一个类都有一个Class对象，每当加载一个新类就产生一个Class对象，基本类型 (boolean, byte, char, short, int, long, float, and double)有Class对象，数组有Class对象，就连关键字void也有Class对象（void.class）。Class对象对应着java.lang.Class类，如果说类是对象抽象的集合的话，那么Class类就是对类的抽象的集合。Class类没有公共的构造方法，Class对象是在类加载的时候由Java虚拟机以及通过调用类加载器中的 defineClass 方法自动构造的，因此不能显式地声明一个Class对象 魔数与Class文件的版本 常量池 主要存放两大类常量：字面量（Literal）和 符号引用（Symbolic Reference） 字面量：如文本字符串，声明为final的常量值 符号引用：类和接口的全限定名，字段的名称和描述符，方法的名称和描述符 Class文件中不会保存各个方法、字段的最终内存布局信息；因此这些字段，方法的符号引用不经过运行期转换的话，无法得到真正的内存入口地址，也就无法直接被虚拟机使用。当虚拟机运行时，需要从常量池获得对应的符号引用，再在类创建时或运行时解析，翻译到具体的内存地址之中。 访问标志 用于识别一些类或者接口层次的访问信息，包括：这个Class是类还是接口；是否定义为public类型；是否定义为abstract类型；如果是类的话，是否被声明为final等。 类索引，父类索引，接口索引 字段表(field_info) 用来描述接口或者类中声明的变量， 可以包括的信息有： 字段的作用域(public,private,protected修饰符)，是实例变量还是类变量（static修饰符），可变性（final）,并发可见性（volatile修饰符,是否强制从主内存读写），可否被序列化（transient修饰符），字段数据类型（基本类型，对象，数组），字段名称。 方法表 方法签名：方法名称，参数顺序，参数类型 属性表 上述Class文件，字段表，方法表都可以携带自己的属性表集合 JVM运行时各内存区域 Java7 Java8 程序计数器(PC) 指向下一条需要执行的字节码；记录当前线程的位置便于线程切换与恢复； 唯一 一个不会出现 OOM 的区域 虚拟机栈（线程stack） 描述了Java方法执行的内存模型，创建栈帧，保存该本地方法的局部变量表、操作数栈、动态链接、出口信息。 什么情况下会发生栈内存溢出（面试题） 如果线程请求的栈深度大于虚拟机所允许的最大深度，将抛出StackOverflowError异常，方法递归调用产生这种结果。 如果Java虚拟机栈可以动态扩展，并且扩展的动作已经尝试过，但是无法申请到足够的内存去完成扩展，或者在新建立线程的时候没有足够的内存去创建对应的虚拟机栈，那么Java虚拟机将抛出一个OutOfMemory 异常。(线程启动过多) 参数 -Xss 去调整JVM栈的大小 本地方法栈(native stack) 描述 native 的方法执行，会创建栈帧。也保存了该本地方法的局部变量表、操作数栈、动态链接、出口信息。 堆(heap) 主要用于存放对象；Java8之前有【方法区】的大部分被移到堆中了，所以，堆中还放有：运行时常量池,字符串常量池 元空间(metaspace)（不属于JVM，使用堆外内存） 类的元数据，如方法、字段、类、包的描述信息，这些信息可以用于创建文档、跟踪代码中的依赖性、执行编译时检查 Metaspace由两大部分组成：Klass Metaspace和NoKlass Metaspace。 klass Metaspace就是用来存klass的，就是class文件在jvm里的运行时数据结构，是一块连续的内存区域，紧接着Heap NoKlass Metaspace专门来存klass相关的其他的内容，比如method，constantPool等，可以由多块不连续的内存组成 方法区(method area) & 永久代(Perm Space) 在JDK1.6及之前，运行时常量池是方法区的一个部分，同时方法区里面存储了类的元数据信息、静态变量、即时编译器编译后的代码（比如spring 使用IOC或者AOP创建bean时，或者使用cglib，反射的形式动态生成class信息等）等。 在JDK1.7及以后，JVM已经将运行时常量池从方法区中移了出来，在JVM堆开辟了一块区域存放常量池。 常量池 大体可以分为：静态常量池，运行时常量池。 静态常量池 静态常量池，即*.class文件中的常量池，class文件中的常量池不仅仅包含字符串(数字)字面量，还包含类、方法的信息，占用class文件绝大部分空间。这种常量池主要用于存放两大类常量：字面量(Literal)和符号引用量(Symbolic References) 运行时常量池 运行时常量池，则是jvm虚拟机在完成类装载操作后，将class文件中的常量池载入到内存中，并保存在方法区中，我们常说的常量池，就是指方法区中的运行时常量池。 String的intern()方法会查找在常量池中是否存在一份equal相等的字符串,如果有则返回该字符串的引用,如果没有则添加自己的字符串进入常量池。 hotSpot对象存储 对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding） hotspot 相关术语表 术语 英文说明 中文解释 mark word The first word of every object header. Usually a set of bitfields including synchronization state and identity hash code. May also be a pointer (with characteristic low bit encoding) to synchronization related information. During GC, may contain GC state bits. 用于存储对象自身的运行时数据， 如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等等 klass pointer The second word of every object header. Points to another object (a metaobject) which describes the layout and behavior of the original object. For Java objects, the \"klass\" contains a C++ style \"vtable\". 是对象指向它的类的元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说查找对象的元数据信息并不一定要经过对象本身。 对象布局 // https://mvnrepository.com/artifact/org.openjdk.jol/jol-core compile group: 'org.openjdk.jol', name: 'jol-core', version: '0.10' new Object() 占用多少字节？ java -XX:+PrintCommandLineFlags -version -XX:InitialHeapSize=268435456 -XX:MaxHeapSize=4294967296 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC java version \"1.8.0_171\" Java(TM) SE Runtime Environment (build 1.8.0_171-b11) Java HotSpot(TM) 64-Bit Server VM (build 25.171-b11, mixed mode) +UseCompressedClassPointers：64bit机器，一个指针8个字节，如果使用压缩会只有4个字节 -XX:+UseCompressedOops：普通对象指针，如果压缩也是4个字节 public class Main { public static void main(String[] args) throws Exception { Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); } } /* java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 00 00 00 (00000001 00000000 00000000 00000000) (1) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external = 4 bytes total markword:8个字节 _kclass:4个字节 没有成员变量：instance data:0字节 紧接着4个字节，是对齐要使用4个字节，即凑成8个字节 即共16个字节 */ 对象头 & markword markword 8个字节，64bit 无锁例子 public class Main { public static void main(String[] args) throws Exception { Object o = new Object(); int hashCode = o.hashCode(); int b = hashCode % 2; System.out.println(hashCode + \" \" + Integer.toBinaryString(hashCode) + \" \" + b); System.out.println(ClassLayout.parseInstance(o).toPrintable()); } } /* 2007328737 1110111101001010110011111100001 1 # WARNING: Unable to attach Serviceability Agent. You can try again with escalated privileges. Two options: a) use -Djol.tryWithSudo=true to try with sudo; b) echo 0 | sudo tee /proc/sys/kernel/yama/ptrace_scope java.lang.Object object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 01 e1 67 a5 (00000001 11100001 01100111 10100101) (-1519918847) 4 4 (object header) 77 00 00 00 (01110111 00000000 00000000 00000000) (119) 8 4 (object header) e5 01 00 f8 (11100101 00000001 00000000 11111000) (-134217243) 12 4 (loss due to the next object alignment) Instance size: 16 bytes Space losses: 0 bytes internal + 4 bytes external = 4 bytes total markword 64bit，如下 00000000 000000 00000000 01110111 10100101 01100111 11100001 00000001 根据无锁(new)，64bit 具体如下 unused:25bit ｜ identity hashcode:31bit ｜unused | age | biased_lock | lock 00000000 000000 00000000 0 ｜ 1110111 10100101 01100111 11100001 ｜ 0 | 0000 | 0 | 01 ｜ ｜ | | | */ 锁升级过程 无锁态(new) ； 偏向锁 ； 轻量级锁，自旋锁，无锁 ；重量级锁 程序编译和代码优化 词法，语法分析 词法分析将源代码的字符流转变为标记(Token)集合 语法分析根据Token序列构造抽象语法树（Abstract Syntax Tree） Annotation，编译期间读取，修改，添加抽象语法树中的任意符号 语义分析与字节码生成 类加载过程(*) 加载（即加载class文件） =>连接( 验证 =》 准备 =》 解析) => 初始化 => 使用 => 卸载 1 加载 这是由类加载器（ClassLoader）执行的。通过一个类的全限定名来获取其定义的二进制字节流（Class字节码），将这个字节流所代表的静态存储结构转化为运行时(Runtime data area)区域的入口，根据字节码在Java堆中生成一个代表这个类的java.lang.Class对象。 2-1 连接：验证（class字节流的校验） 验证是连接阶段的第一步，这一步主要的目的是确保class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身安全。验证阶段主要包括四个检验过程：文件格式验证、元数据验证、字节码验证和符号引用验证。 2-2 连接：准备（分配内存，初始化默认值） 准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间。 public static int value = 12; 变量value在准备阶段过后的初始值为0而不是12，因为这时候尚未开始执行任何Java方法，而把value赋值为123的putstatic指令是程序被编译后，存放于类构造器()方法之中，所以把value赋值为12的动作将在初始化阶段才会被执行。 相对于一些特殊的情况，如果类字段的字段属性表中存在ConstantValue属性，那在准备阶段变量value就会被初始化为ConstantValue属性所指定的值，例如上面类变量value定义为： public static final int value = 123; 编译时javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value设置为123。 2-3 连接：解析 解析阶段是虚拟机常量池内的符号引用替换为直接引用的过程。 直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在。 3 初始化 初始化阶段是类加载最后一个阶段，前面的类加载阶段之后，除了在加载阶段可以自定义类加载器以外，其它操作都由JVM主导。到了初始阶段，才开始真正执行类中定义的Java程序代码。 初始化阶段是执行类构造器方法的过程。 `clinit`方法是由编译器自动收集类中的**类静态变量的赋值操作和静态语句块**中的语句合并而成的。JVM会保证`clinit`方法执行之前，父类的`clinit`方法已经执行完毕。 什么时候需要对类进行初始化? 使用new该类实例化对象的时候 读取或设置类静态字段的时候（但被final修饰的字段，在编译时就被放入常量池；连接-准备阶段会赋予变量常量值；所以(static final)的静态字段除外） 调用类的静态方法的时候 使用反射Class.forName(\"xxx\")对类进行反射调用的时候，该类需要初始化； 初始化一个类的时候，有父类，先初始化父类（注：1. 接口除外，父接口在调用的时候才会被初始化；2.子类引用父类静态字段，只会引发父类初始化）； 被标明为启动类的类（即包含main()方法的类）要初始化； 当使用JDK1.7的动态语言支持时，如果一个java.invoke.MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则需要先触发其初始化。 以上情况称为对一个类进行主动引用，且有且只要以上几种情况是需要对类进行初始化： 所有类变量静态初始化语句和静态代码块都会在编译时被前端编译器放在收集器里头，存放到一个特殊的方法中，这个方法就是方法，即类/接口初始化方法，该方法只能在类加载的过程中由JVM调用； 编译器收集的顺序是由语句在源文件中出现的顺序所决定的，静态语句块中只能访问到定义在静态语句块之前的变量； 如果超类还没有被初始化，那么优先对超类初始化，但在方法内部不会显示调用超类的方法，由JVM负责保证一个类的方法执行之前，它的超类方法已经被执行。 JVM必须确保一个类在初始化的过程中，如果是多线程需要同时初始化它，仅仅只能允许其中一个线程对其执行初始化操作，其余线程必须等待，只有在活动线程执行完对类的初始化操作之后，才会通知正在等待的其它线程。(所以可以利用静态内部类实现线程安全的单例模式) 如果一个类没有声明任何的类变量，也没有静态代码块，那么可以没有类方法； 附：类实例初始化过程？ 实例初始化就是执行()方法 ()方法可能重载有多个，有几个构造器就有几个()方法 ()方法由非静态实例变量显示赋值代码、非静态代码块、对应构造器代码组成 非静态实例变量显示赋值代码和非静态代码块代码从上到下顺序执行，而对应构造器代码最后执行 每次创建实例对象，调用对应构造器，执行的就是对应的方法 方法的首行是super()或super(实参)，对应父类的方法，即先执行父类实例初始化 实例创建了几次，初始化就执行了几次 类加载器分类 加载动作放到JVM外部实现，以便让应用程序决定如何获取所需的类, 类加载器大致可以分为以下3部分： 1. 根加载器Bootstrap ClassLoader 最顶层的加载器，其没有任何父加载器，由C++编写，主要负责虚拟机核心类库的加载，例如java.lang包 将存放于\\lib目录中的，或者被-Xbootclasspath参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如 rt.jar 名字不符合的类库即使放在lib目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被Java程序直接引用。 2. 扩展类加载器Extension ClassLoader 扩展类加载器的父加载器是根加载器，纯Java语言实现，将\\lib\\ext目录下的，或者被java.ext.dirs系统变量所指定的路径中的所有类库加载。开发者可以直接使用扩展类加载器。 3. 系统类加载器Application ClassLoader 负责加载用户类路径(ClassPath)上所指定的类库,开发者可直接使用。 4. 自定义类加载器Custom CLassLoader 所有自定义类加载器都是CLassLoader的直接子类或者间接子类（java.lang.ClassLoader是一个抽象类） 双亲委派模型（*） 工作过程为：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的加载器都是如此，因此所有的类加载请求都会传给顶层的启动类加载器，只有当父加载器反馈自己无法完成该加载请求（该加载器的搜索范围中没有找到对应的类）时，子加载器才会尝试自己去加载 protected synchronized Class loadClass(String name, boolean resolve) throws ClassNotFoundException { // 首先检查该name指定的class是否有被加载 Class c = findLoadedClass(name); if (c == null) { try { if (parent != null) { // 如果parent不为null，则调用parent的loadClass进行加载 c = parent.loadClass(name, false); } else { // parent为null，则调用BootstrapClassLoader进行加载 c = findBootstrapClass0(name); } } catch (ClassNotFoundException e) { // 如果仍然无法加载成功，则调用自身的findClass进行加载 c = findClass(name); } } if (resolve) { resolveClass(c); } return c; } 双亲委派优势 采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系，通过这种层级关可以避免类的重复加载，当父亲已经加载了该类时，就没有必要子ClassLoader再加载一次 Java核心Api中定义类型不会被随意替换，假设通过网络传递一个名为java.lang.Integer的类，通过双亲委托模式传递到启动类加载器，而启动类加载器在核心Java API发现这个名字的类，发现该类已被加载，并不会重新加载网络传递的过来的java.lang.Integer，而直接返回已加载过的Integer.class，这样便可以防止核心API库被随意篡改 类加载题目例子（Java7环境） class Singleton{ private static Singleton singleton = new Singleton(); static { System.out.println(\"static block\"); } public static int value1; public static int value2 = 0; public static int value3 = 10; private Singleton(){ System.out.println(String.format(\"before Singleton constructor: value1:%d, value2:%d, value3:%d\", value1,value2,value3)); value1++; value2++; value3++; System.out.println(String.format(\"after Singleton constructor: value1:%d, value2:%d, value3:%d\", value1,value2,value3)); } public static Singleton getInstance(){ return singleton; } } class Singleton2{ static{ System.out.println(String.format(\"after Singleton2 constructor: v1:%d, v2:%d, v3:%d\", v1,v2,v3)); } public static int v1; public static int v2 = 0; public static int v3 = 10; static { System.out.println(\"static block\"); } private static Singleton2 singleton2 = new Singleton2(); private Singleton2(){ System.out.println(String.format(\"before Singleton2 constructor: v1:%d, v2:%d, v3:%d\", v1,v2,v3)); v1++; v2++; v3++; System.out.println(String.format(\"after Singleton2 constructor: v1:%d, v2:%d, v3:%d\", v1,v2,v3)); } public static Singleton2 getInstance2(){ return singleton2; } } public class MainTest { public static final int _1MB = 1024 * 1024; public static void main(String[] args) throws Exception{ // idea 提示 不应该通过类的实例访问静态成员，不过程序本身无任何问题，结果如下： Singleton singleton = Singleton.getInstance(); // 1 System.out.println(\"Singleton1 value1:\" + singleton.value1); // 0 System.out.println(\"Singleton1 value2:\" + singleton.value2); // 10 System.out.println(\"Singleton1 value3:\" + singleton.value3); Singleton2 singleton2 = Singleton2.getInstance2(); // 1 System.out.println(\"Singleton2 v1:\" + singleton2.v1); // 1 System.out.println(\"Singleton2 v2:\" + singleton2.v2); // 11 System.out.println(\"Singleton2 v3:\" + singleton2.v3); } } 结果分析 before Singleton constructor: value1:0, value2:0, value3:0 after Singleton constructor: value1:1, value2:1, value3:1 static block Singleton1 value1:1 Singleton1 value2:0 Singleton1 value3:10 static block before Singleton2 constructor: v1:0, v2:0, v3:10 after Singleton2 constructor: v1:1, v2:1, v3:11 Singleton2 v1:1 Singleton2 v2:1 Singleton2 v3:11 《Java编程思想》第5章：调用构造函数是编译器的责任，必须要让编译器知道调用的是哪个方法；分配内存空间后，就会调用构造函数，确保使用对象前，对象已经被初始化了。 对象创建的过程：（类初始化 和 类实例化） 首次创建对象时，类中的静态方法/静态字段首次被访问时，java解释器必须先查找类路径，以定位.class文件 然后载入.class(这将创建一个class对象)，有关静态初始化的所有动作都会执行，按顺序执行。因此，静态初始化只在Class对象首次加载的时候进行一次 当用new XXX()创建对象时，首先在堆上为对象分配足够的存储空间 这块存储空间会被清零，这就自动地将对象中的所有基本类型数据都设置成了缺省值（对数字来说就是0，对布尔型和字符型也相同），而引用则被设置成了null。 执行所有出现于字段定义处的初始化动作（非静态对象的初始化） 执行构造器。 Singleton 结果分析 首先执行main中的Singleton singleton = Singleton.getInstance(), 访问了静态方法访问静态方法, 开始加载类Singleton 随后：类的连接( 验证 =》 准备 =》 解析) 这里会将为singleton(引用类型)设置为null,value1,value2,value3（基本数据类型）设置默认值0 ） 类的初始化（按照赋值语句进行修改） private static Singleton singleton = new Singleton(); public static int value1; public static int value2 = 0; public static int value3 = 10; new Singleton() 不在进行类加载过程(上面已经类加载过了)，直接对象初始化, 如下 before Singleton constructor: value1:0, value2:0, value3:0 after Singleton constructor: value1:1, value2:1, value3:1 然后是如下的初始化语句，（注意如下的静态操作只会进行一次） static { System.out.println(\"static block\"); } public static int value1; // 没有赋值，取在对象实例的构造函数执行后的值 public static int value2 = 0; // 类初次赋值 public static int value3 = 10; // 类初次赋值 所以最后main函数中打印 Singleton1 value1:1 Singleton1 value2:0 Singleton1 value3:10 Singleton2 分析 与Singleton的初始化语句顺序不一样,new对象，是在类初始变量之后 public static int v1; public static int v2 = 0; public static int v3 = 10; static { System.out.println(\"static block\"); } private static Singleton2 singleton2 = new Singleton2(); output，注意到构造函数执行之前是：v1:0, v2:0, v3:10 static block before Singleton2 constructor: v1:0, v2:0, v3:10 after Singleton2 constructor: v1:1, v2:1, v3:11 Singleton2 v1:1 Singleton2 v2:1 Singleton2 v3:11 静态初始化再次验证 类中静态初始化语句，只会在类加载的时候执行一次 code1 Singleton2 singleton2 = Singleton2.getInstance2(); System.out.println(\"Singleton2 v1:\" + singleton2.v1); System.out.println(\"Singleton2 v2:\" + singleton2.v2); System.out.println(\"Singleton2 v3:\" + singleton2.v3); Singleton2 singleton22 = Singleton2.getInstance2(); System.out.println(\"Singleton2 v1:\" + singleton22.v1); System.out.println(\"Singleton2 v2:\" + singleton22.v2); System.out.println(\"Singleton2 v3:\" + singleton22.v3); output1 static block before Singleton2 constructor: v1:0, v2:0, v3:10 before Singleton2 constructor: v1:1, v2:1, v3:11 Singleton2 v1:1 Singleton2 v2:1 Singleton2 v3:11 Singleton2 v1:1 Singleton2 v2:1 Singleton2 v3:11 code2 Singleton singleton = Singleton.getInstance(); System.out.println(\"Singleton1 value1:\" + singleton.value1); System.out.println(\"Singleton1 value2:\" + singleton.value2); System.out.println(\"Singleton1 value3:\" + singleton.value3); Singleton singleton2 = new Singleton(); System.out.println(\"Singleton1 value1:\" + singleton2.value1); System.out.println(\"Singleton1 value2:\" + singleton2.value2); System.out.println(\"Singleton1 value3:\" + singleton2.value3); output2 before Singleton constructor: value1:0, value2:0, value3:0 after Singleton constructor: value1:1, value2:1, value3:1 static block Singleton1 value1:1 Singleton1 value2:0 Singleton1 value3:10 before Singleton constructor: value1:1, value2:0, value3:10 after Singleton constructor: value1:2, value2:1, value3:11 Singleton1 value1:2 Singleton1 value2:1 Singleton1 value3:11 自定义类加载器 自定义类加载器的一般步骤 继承ClassLoader 重写loadClass()方法 重写findClass()方法 class文件路径判断和获取 将class文件载入内存 对载入内存的字节码数据，调用defineClass()方法将字节码转化为类 MyClassLoader 实践 Hello.java编译成Hello.class package com.other; public class Hello { public void test() { System.out.println(\"Loader Class is:\" + getClass().getClassLoader().getClass()); } } MyComOtherClassLoader package com.mb; import java.io.ByteArrayOutputStream; import java.io.File; import java.io.FileInputStream; import java.io.IOException; import java.lang.reflect.Method; /** * @Author mubi * @Date 2019/3/20 10:54 PM */ public class MyComOtherClassLoader extends ClassLoader{ public String path; public String packageName; public String className; public MyComOtherClassLoader() { super(ClassLoader.getSystemClassLoader()); } private String classNameToPath() { // 得到类文件的URL return path + \"/\" + packageName.replace('.', '/') + \"/\" + className + \".class\"; } @Override public Class loadClass(String name) throws ClassNotFoundException { // 非 com.test package下面的类，都用默认的加载， 否则用自定义的加载方法 if (!name.contains(\"com.other\")) { // 是否已经被加载 Class loadedClass = findLoadedClass(name); if (loadedClass == null) { // 用父类去加载该类 loadedClass = getParent().loadClass(name); return loadedClass; } else { return loadedClass; } } int i = name.lastIndexOf('.'); packageName = \"\"; if (i != -1) { packageName = name.substring(0, i); // System.out.println(\"package: \" + packageName); className = name.substring(i + 1); // System.out.println(\"class name: \" + name); SecurityManager sm = System.getSecurityManager(); if (sm != null) { sm.checkPackageAccess(packageName); } } //依然调用父类的方法 // return super.loadClass(name); return this.findClass(name); } @Override public Class findClass(String name) throws ClassNotFoundException { int i = name.lastIndexOf('.'); packageName = \"\"; if (i != -1) { packageName = name.substring(0, i); // System.out.println(\"package: \" + packageName); className = name.substring(i + 1); // System.out.println(\"class name: \" + name); SecurityManager sm = System.getSecurityManager(); if (sm != null) { sm.checkPackageAccess(packageName); } } Class clazz = this.findLoadedClass(name); // 父类已加载 if(null != clazz){ return clazz; } // System.out.println(\"findClass param name: \" + name); byte [] b = this.getClassBytes(); // System.out.println(\"b len:\" + b.length); clazz=defineClass(null, b, 0, b.length); return clazz; } public byte[] getClassBytes() { String classPath = classNameToPath(); // System.out.println(\"classPath:\" + classPath); File file=new File(classPath); try(FileInputStream fis = new FileInputStream(file);ByteArrayOutputStream bos=new ByteArrayOutputStream();) { byte[] b=new byte[1024*2]; int n; while((n=fis.read(b))!=-1){ bos.write(b, 0, n); } return bos.toByteArray(); } catch (IOException e) { e.printStackTrace(); } return null; } static void testMyClassLoaderHello() throws Exception{ String path = \"/Users/mubi/IdeaProjects/untitled/out/production/untitled\"; MyComOtherClassLoader myClassLoader = new MyComOtherClassLoader(); myClassLoader.path = path; Class clazz = myClassLoader.loadClass(\"com.other.Hello\"); Object obj = clazz.newInstance(); System.out.println(\"===\" + obj.getClass()); Method method = clazz.getDeclaredMethod(\"test\", null); Object c = method.invoke(obj, null); if(c != null){ System.out.println(\"method return: \" + c.getClass()); }else { System.out.println(\"method return:\" + c); } } static void testMyClassLoaderString() throws Exception{ MyComOtherClassLoader myClassLoader = new MyComOtherClassLoader(); Class clazz = myClassLoader.loadClass(\"java.lang.String\"); Object obj = clazz.newInstance(); System.out.println(\"===\" + obj.getClass()); Method method = clazz.getDeclaredMethod(\"length\", null); Object c = method.invoke(obj, null); if(c != null){ System.out.println(\"method return: \" + c.getClass()); }else { System.out.println(\"method return:\" + c); } } public static void main(String[] args) throws Exception { testMyClassLoaderHello(); testMyClassLoaderString(); } } /* ===class com.other.Hello Loader Class is:class com.thread.MyClassLoader2 method return:null ===class java.lang.String method return: class java.lang.Integer */ MyClassLoader实现热加载 public static void testHotDeploy() throws Exception{ while (true){ String rootPath = \"/Users/mubi/git_workspace/java8/java8-api/src/main/java\"; MyComOtherClassLoader myClassLoader = new MyComOtherClassLoader(); myClassLoader.path = rootPath; Class clazz = myClassLoader.loadClass(\"com.hotload.Test\"); Object obj = clazz.newInstance(); String helloRs = (String)clazz.getMethod(\"hello\").invoke(obj); System.out.println(\"Test:hello() return:\" + helloRs); TimeUnit.SECONDS.sleep(2); } } 只需要修改Test.class文件，即可自动加载，而不需要重新部署项目 mubi@mubideMacBook-Pro hotload $ ll total 32 -rw-r--r-- 1 mubi staff 1.6K 7 27 09:13 LoadTestMain.java -rw-r--r-- 1 mubi staff 3.2K 7 27 08:58 MyComOtherClassLoader.java -rw-r--r-- 1 mubi staff 300B 7 27 09:01 Test.class -rw-r--r-- 1 mubi staff 198B 7 27 08:58 Test.java mubi@mubideMacBook-Pro hotload $ vim Test.java mubi@mubideMacBook-Pro hotload $ javac Test.java mubi@mubideMacBook-Pro hotload $ 如何改变 new 的类加载器？ 双亲委派 保证被加载类只会加载一次；自定义类加载器可打破双亲委派 全盘委托 当一个classloader加载一个Class的时候，这个Class所依赖的和引用的其它Class通常也由这个classloader负责载入。 类加载还采用了cache机制 如果cache中保存了这个Class就直接返回它，如果没有才从文件中读取和转换成Class，并存入cache，这就是为什么修改了Class但是必须重新启动JVM才能生效，并且类只加载一次的原因 自定义类加载器的优缺点 // TODO 加密 从非标准的来源加载代码 部署在同一个服务器上的两个Web应用程序所使用的Java类库可以实现相互隔离。 部署在同一个服务器上的两个Web应用程序所使用的Java类库可以相互共享 支持热替换(特殊的动态加载机制) com.mysql.jdbc.Driver（打破parents delegate） 例子代码 public static void main(String[] args) { Connection conn = null; Statement stmt = null; try{ //STEP 1: Register JDBC driver Class.forName(\"com.mysql.jdbc.Driver\"); //STEP 2: Open a connection conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/test\", \"root\", \"\"); //STEP 3: Execute a query stmt = conn.createStatement(); ResultSet rs = stmt.executeQuery(\"select * from tb_user limit 5\"); //STEP 4: Get results while(rs.next()){ System.out.println(rs.getString(\"id\") + \" \" + rs.getString(\"name\")); } rs.close(); }catch(Exception e){ }//end try } 源码逻辑说明 public class Driver extends NonRegisteringDriver implements java.sql.Driver { public Driver() throws SQLException { } static { try { // 静态方法将Driver实例注册到DriverManager中 DriverManager.registerDriver(new Driver()); } catch (SQLException var1) { throw new RuntimeException(\"Can't register driver!\"); } } } /** * Registers the given driver with the {@code DriverManager}. * A newly-loaded driver class should call * the method {@code registerDriver} to make itself * known to the {@code DriverManager}. If the driver is currently * registered, no action is taken. * * @param driver the new JDBC Driver that is to be registered with the * {@code DriverManager} * @exception SQLException if a database access error occurs * @exception NullPointerException if {@code driver} is null */ public static synchronized void registerDriver(java.sql.Driver driver) throws SQLException { registerDriver(driver, null); } Connection的getConnection方法 // Worker method called by the public getConnection() methods. private static Connection getConnection( String url, java.util.Properties info, Class caller) throws SQLException { /* * When callerCl is null, we should check the application's * (which is invoking this class indirectly) * classloader, so that the JDBC driver class outside rt.jar * can be loaded from here. */ // 得到线程上下文类加载器 ClassLoader callerCL = caller != null ? caller.getClassLoader() : null; synchronized(DriverManager.class) { // synchronize loading of the correct classloader. if (callerCL == null) { callerCL = Thread.currentThread().getContextClassLoader(); } } if(url == null) { throw new SQLException(\"The url cannot be null\", \"08001\"); } println(\"DriverManager.getConnection(\\\"\" + url + \"\\\")\"); // Walk through the loaded registeredDrivers attempting to make a connection. // Remember the first exception that gets raised so we can reraise it. SQLException reason = null; // 递归DruidManager中已经注册的驱动类，然后验证数据库驱动是否可以被制定的类加载器加载 // 如果验证通过则返回Connection,此刻返回的Connection则属数据库厂商提供的实例 for(DriverInfo aDriver : registeredDrivers) { // If the caller does not have permission to load the driver then // skip it. if(isDriverAllowed(aDriver.driver, callerCL)) { try { println(\" trying \" + aDriver.driver.getClass().getName()); Connection con = aDriver.driver.connect(url, info); if (con != null) { // Success! println(\"getConnection returning \" + aDriver.driver.getClass().getName()); return (con); } } catch (SQLException ex) { if (reason == null) { reason = ex; } } } else { println(\" skipping: \" + aDriver.getClass().getName()); } } // if we got here nobody could connect. if (reason != null) { println(\"getConnection failed: \" + reason); throw reason; } println(\"getConnection: no suitable driver found for \"+ url); throw new SQLException(\"No suitable driver found for \"+ url, \"08001\"); } private static boolean isDriverAllowed(Driver driver, ClassLoader classLoader) { boolean result = false; if(driver != null) { Class aClass = null; try { // 使用线程上下文类加载器进行数据库驱动的加载和初始化 aClass = Class.forName(driver.getClass().getName(), true, classLoader); } catch (Exception ex) { result = false; } result = ( aClass == driver.getClass() ) ? true : false; } return result; } 数据库驱动加载接口被作为JDK核心标准类库的一部分，由于JVM类加载的双亲委托(parents delegate)机制的限制，启动类加载器不可能加载得到第三方厂商提供的具体实现。如何解决？ 线程上下文类加载器：有了线程上下文类加载器，启动类加载器(根加载器)反倒需要委托子类加载器去加载厂商提供的对JDK定义的SPI(Service Provider Interface)的实现 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-31 10:37:51 "},"content/java_jvm/jvm_mem_gc.html":{"url":"content/java_jvm/jvm_mem_gc.html","title":"堆栈 & 各种GC","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 堆内存 Java7堆内存划分 堆区域与分代 Java7 堆的各区域 Java7永久代(Perm space) Java8 内存区域 Java8元空间(元数据区) 垃圾收集器 三个问题 通过可达性分析来判定对象是否存活(什么是垃圾?) Java中可作为GC Roots的对象包括 4种引用Reference 强引用 软引用(SoftReference) 弱引用(WeakReference) 虚引用(PhantomReference) 对象是生存还是死亡的？ 两次标记&F-Queue&Finalizer线程 finalize()自救代码演示 最后，不推荐使用finalize() Java7方法区(永久代)的回收 HotSpot 算法实现可达性分析 Stop The World 常见的垃圾回收算法 垃圾收集器发展和介绍 GC收集器及其发展 (一) Serial （STW,单线程收集器） ParNew (Serial的多线程版本) (二) Parallel Scavenge（STW,多线程收集器） Parallel old (三) CMS收集器 (四) G1 Java垃圾回收的依据/假设 分代GC,查看默认的GC配置 new object的gc生命周期 CMS(Concurrent Mark Sweep)垃圾回收器 CMS处理的4个步骤 缺点 三色标记 三色标记问题 CMS解决方案和remark 扩展：G1解决方法(写屏障 + Snapshot At the begining) G1(Garbage First)垃圾回收器 参考学习文档 G1设计理念 G1 内存区域分布图和概念介绍 G1 常用参数 Remember Set & Collection Set SATB（Snapshot-At-The-Beginning） G1的GC young gc(对年轻代的GC) mixed gc(对老年代的GC) Initial Marking Phase(初始标记，STW) Concurrent Marking Phase（并发标记：三色标记，与用户线程并发执行） 三色标记(补充) Remark Phase（最终标记，STW, CPU停顿处理垃圾） Copying/Cleanup Phase（筛选部分region回收，而非全部回收；STW：根据用户期望的GC停顿时间回收） 对年轻代和老年代GC的总结 G1的优势（为什么能够设置一个停留时间） G1 和 CMS G1 和 CMS 堆空间分配方式不同（分代 & region） G1 和 CMS GC的区别 内存分配与回收策略(理论基础) 对象优先在Eden分配 minor gc(yong gc) major gc/ full gc Java 分代GC测试程序 和 初始堆情况(Java7 CMS) 对应的GC日志 参考 大对象直接进入老年代 长期存活的(Age15)对象将进入老年代 动态对象的年龄判定 空间分配担保 触发gc的条件 Minor GC触发条件 Full GC触发条件 JVM参数与GC Java8 默认GC 堆外内存 问题 概念 堆外内存溢出 堆外内存更适合存储的对象 Java 内存区域和内存溢出异常演练测试 OutOfMemoryError 虚拟机栈和本地方法栈溢出 方法区和运行时常量池溢出 Java7 常量池 仍是java.lang.OutOfMemoryError: Java heap space 直接内存溢出 [TOC] 堆内存 Java7堆内存划分 参考图书《深入理解java虚拟机》堆的描述 Java堆（Java Heap）是java虚拟机所管理的内存中最大的一块 Java堆被所有线程共享的一块内存区域 虚拟机启动时创建java堆 Java堆的唯一目的就是存放对象实例。 Java堆是垃圾收集器管理的主要区域。 从内存回收的角度来看， 由于现在收集器基本都采用分代收集算法， 所以Java堆可以细分为：新生代（Young）和老年代（Old）。 新生代又被划分为三个区域Eden、From Survivor， To Survivor等。无论怎么划分，最终存储的都是实例对象， 进一步划分的目的是为了更好的回收内存， 或者更快的分配内存。 Java堆的大小是可扩展的， 通过-Xms和-Xmx控制。 如果堆内存不够分配实例对象， 并且对也无法在扩展时， 将会抛出outOfMemoryError异常。 堆区域与分代 堆大小 = 新生代 + 老年代（默认：新生代:老年代=1:2，即1/3的新生代，2/3的老年代）。堆大小设置参数：–Xms（堆的初始容量）、-Xmx（堆的最大容量） 其中，新生代 (Young) 被细分为Eden和两个Survivor区域，这两个Survivor区域分别被命名为from和to，以示区分。默认的，Edem : from : to = 8 : 1 : 1。(可以通过参数–XX:SurvivorRatio来设定 。即： Eden = 8/10 的新生代空间大小，from = to = 1/10 的新生代空间大小。 JVM 每次只会使用Eden和其中的一块Survivor区域来为对象服务，所以无论什么时候，总是有一块Survivor区域是空闲着的。 新生代实际可用的内存空间为 9/10 ( 即90% )的新生代空间。 jstat查看gc相关的堆信息 Java7 堆的各区域 ^Cmubi@mubideMacBook-Pro Home $ pwd /Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home mubi@mubideMacBook-Pro Home $ bin/jstat -gcutil 62850 1000 10 Warning: Unresolved Symbol: sun.gc.generation.2.space.0.capacity substituted NaN Warning: Unresolved Symbol: sun.gc.generation.2.space.0.used substituted NaN Warning: Unresolved Symbol: sun.gc.generation.2.space.0.capacity substituted NaN S0 S1 E O P YGC YGCT FGC FGCT GCT 0.00 85.81 76.97 56.33 � 161 1.624 14 0.603 2.227 0.00 85.81 77.08 56.33 � 161 1.624 14 0.603 2.227 0.00 85.81 77.22 56.33 � 161 1.624 14 0.603 2.227 0.00 85.81 77.33 56.33 � 161 1.624 14 0.603 2.227 E — Heap上的 Eden space 区已使用空间的百分比(Eden) S0 — Heap上的 Survivor space 0 区已使用空间的百分比(From) S1 — Heap上的 Survivor space 1 区已使用空间的百分比(To) O — Heap上的 Old space 区已使用空间的百分比(Old) P — Perm space 区已使用空间的百分比（Java7中的Perm Generation） YGC — 从应用程序启动到采样时发生 Young GC 的次数 YGCT – 从应用程序启动到采样时 Young GC 所用的时间(单位秒) FGC — 从应用程序启动到采样时发生 Full GC 的次数 FGCT – 从应用程序启动到采样时 Full GC 所用的时间(单位秒) GCT — 从应用程序启动到采样时用于垃圾回收的总时间(单位秒) Java7永久代(Perm space) 是HotSpot的一种具体实现，实际指的就是方法区 类包含其对应的元数据，字符串常量池等被存储在永久代（默认大小是4m）中，容易导致性能问题和OOM 这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载 Java8 内存区域 // java7 mubi@mubideMacBook-Pro Home $ pwd /Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home mubi@mubideMacBook-Pro Home $ bin/jstat -gcutil 62850 1000 10 Warning: Unresolved Symbol: sun.gc.generation.2.space.0.capacity substituted NaN Warning: Unresolved Symbol: sun.gc.generation.2.space.0.used substituted NaN Warning: Unresolved Symbol: sun.gc.generation.2.space.0.capacity substituted NaN S0 S1 E O P YGC YGCT FGC FGCT GCT 0.00 85.81 76.97 56.33 � 161 1.624 14 0.603 2.227 0.00 85.81 77.08 56.33 � 161 1.624 14 0.603 2.227 0.00 85.81 77.22 56.33 � 161 1.624 14 0.603 2.227 0.00 85.81 77.33 56.33 � 161 1.624 14 0.603 2.227 // java 8 ^Cmubi@mubideMacBook-Pro Home $ jstat -gcutil 62850 1000 10 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 85.81 78.86 56.33 93.46 89.80 161 1.624 14 0.603 2.227 0.00 85.81 78.93 56.33 93.46 89.80 161 1.624 14 0.603 2.227 0.00 85.81 79.04 56.33 93.46 89.80 161 1.624 14 0.603 2.227 0.00 85.81 79.17 56.33 93.46 89.80 161 1.624 14 0.603 2.227 0.00 85.81 79.29 56.33 93.46 89.80 161 1.624 14 0.603 2.227 ^Cmubi@mubideMacBook-Pro Home $ S0 — Heap上的 Survivor space 0 区已使用空间的百分比(From) S1 — Heap上的 Survivor space 1 区已使用空间的百分比(To) E — Heap上的 Eden space 区已使用空间的百分比(Eden) O — Heap上的 Old space 区已使用空间的百分比(Old) M - 元空间（Metaspace）： Klass Metaspace, NoKlass Metaspace CCS - 表示的是NoKlass Metaspace的使用率 YGC — 从应用程序启动到采样时发生 Young GC 的次数 YGCT – 从应用程序启动到采样时 Young GC 所用的时间(单位秒) FGC — 从应用程序启动到采样时发生 Full GC 的次数 FGCT – 从应用程序启动到采样时 Full GC 所用的时间(单位秒) GCT — 从应用程序启动到采样时用于垃圾回收的总时间(单位秒) Java8元空间(元数据区) 参考学习1: openjdk相关文档 Class metadata, interned Strings and class static variables will be moved from the permanent generation to either the Java heap or native memory. (原来的永久代(class元信息、字面常量、静态变量等)转移到heap或者native memory中) Metaspace由两大部分组成：Klass Metaspace和NoKlass Metaspace。 klass Metaspace就是用来存klass的，就是class文件在jvm里的运行时数据结构，是一块连续的内存区域，紧接着Heap NoKlass Metaspace专门来存klass相关的其他的内容，比如method，ConstantPool等，可以由多块不连续的内存组成 垃圾收集器 三个问题 哪些内存需要回收 什么时候进行回收 如何回收 通过可达性分析来判定对象是否存活(什么是垃圾?) 算法的基本思路就是通过一系列的称为GC Roots的对象作为起始点，从这些节点向下搜索，搜索所走过的路径称为引用链(Reference Chain),当一个对象到GC Roots没有任何引用链相连(用图论的话来说，就是GC Roots到这个对象不可达)时，则证明此对象是不可用的。 Java中可作为GC Roots的对象包括 虚拟机栈（栈帧中的本地变量表）中引用的对象 本地方法栈中JNI(即一般说的Native方法)引用的对象 运行方法区中常量池引用的对象 方法区中中的类静态属性引用的对象 load的Clazz which instances are roots?(JVM规范中) JVM stack, native method stack, run-time constant pool, static references in method area, Clazz 参考学习文章链接 ## 4种引用`Reference` 参考：https://www.geeksforgeeks.org/types-references-java/ ![](../../content/java_jvm/imgs/reference.png) ### 强引用 使用最普遍的引用。如果一个对象具有强引用，那垃圾回收器绝不会回收它。如 ```java //Strong Reference - by default Gfg g = new Gfg(); //Now, object to which 'g' was pointing earlier is //eligible for garbage collection. g = null; ``` * 强引用与GC ```java static class M{ @Override protected void finalize() { System.out.println(\"finalize\"); } } /** * 强引用，强制gc * 输出如下 * Main$M@736e9adb * null * finalize */ static void testM(){ M m = new M(); System.out.println(m); m = null; System.gc(); System.out.println(m); } ``` ### 软引用(`SoftReference`) In Soft reference, even if the object is free for garbage collection then also its not garbage collected, until JVM is in need of memory badly.The objects gets cleared from the memory when JVM runs out of memory.To create such references java.lang.ref.SoftReference class is used.(JVM 内存紧张的时候会回收软引用对象) 用来描述一些还有用但并非必需的对象，对于软引用关联者的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。 ```java //Code to illustrate Soft reference import java.lang.ref.SoftReference; class Gfg { //code.. public void x() { System.out.println(\"GeeksforGeeks\"); } } public class Example { public static void main(String[] args) { // Strong Reference Gfg g = new Gfg(); g.x(); // Creating Soft Reference to Gfg-type object to which 'g' // is also pointing. SoftReference softref = new SoftReference(g); // Now, Gfg-type object to which 'g' was pointing // earlier is available for garbage collection. g = null; // You can retrieve back the object which // has been weakly referenced. // It successfully calls the method. g = softref.get(); g.x(); } } ``` * 软引用与GC ```java /** * 内存不够用了，软引用才被回收 * 输出如下 * [B@736e9adb * [B@736e9adb * [B@6d21714c * null */ static void testSoftReference() throws Exception{ SoftReference mSoft = new SoftReference<>(new byte[10 * 1024 * 1024]); System.out.println(mSoft.get()); System.gc(); TimeUnit.SECONDS.sleep(1); // gc没有回收软引用 System.out.println(mSoft.get()); byte[] b = new byte[11 * 1024 * 1024]; System.out.println(b); // 由于强引用申请空间不够，必须要清除软引用了 System.out.println(mSoft.get()); } ``` ### 弱引用(`WeakReference`) ```java // Strong Reference Gfg g = new Gfg(); g.x(); // Creating Weak Reference to Gfg-type object to which 'g' // is also pointing. WeakReference weakref = new WeakReference(g); //Now, Gfg-type object to which 'g' was pointing earlier //is available for garbage collection. //But, it will be garbage collected only when JVM needs memory. g = null; // You can retrieve back the object which // has been weakly referenced. // It successfully calls the method. g = weakref.get(); g.x(); ``` * This type of reference is used in WeakHashMap to reference the entry objects . * If JVM detects an object with only weak references (i.e. no strong or soft references linked to any object object), this object will be marked for garbage collection. * To create such references java.lang.ref.WeakReference class is used. * These references are used in real time applications while establishing a DBConnection which might be cleaned up by Garbage Collector when the application using the database gets closed. * 弱引用与GC ```java /** * 只要有垃圾回收线程执行，弱引用直接会被回收 * 输出如下： * Main$M@736e9adb * null * finalize */ static void testWeakReference(){ WeakReference m = new WeakReference<>(new M()); System.out.println(m.get()); System.gc(); System.out.println(m.get()); } ``` ### 虚引用(`PhantomReference`) The objects which are being referenced by phantom references are eligible for garbage collection. But, before removing them from the memory, JVM puts them in a queue called ‘reference queue’ . They are put in a reference queue after calling finalize() method on them.To create such references java.lang.ref.PhantomReference class is used. 也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能够在这个对象被收集器回收时收到一个系统通知。 它的get()方法写死了，返回null（也就是跟前面不一样，不能通过get()方法获取被包装的对象） Java中虚幻引用作用：管理直接内存(不属于堆) 虚引用与GC 虚引用get不到,因为get方法是直接返回的null 虚引用放到队列(java.lang.ref.ReferenceQueue)中，不断的从队列中取出来看是否被回收了 static final List LIST = new LinkedList<>(); static final ReferenceQueue QUEUE = new ReferenceQueue<>(); public static void main(String[] args) throws Exception{ PhantomReference phantomReference = new PhantomReference<>(new M(), QUEUE); new Thread(()->{ while (true){ LIST.add(new byte[3 * 1024 * 1024]); try{ TimeUnit.SECONDS.sleep(1); }catch (Exception e){ } System.out.println(phantomReference.get()); } }).start(); new Thread(()->{ while (true){ Reference poll = QUEUE.poll(); if(poll != null) { System.out.println(\"PhantomReference 被 jvm 回收了:\" + poll.get()); } } }).start(); TimeUnit.SECONDS.sleep(2); } 管理堆外内存： jvm对象用虚引用，指向堆外内存 jvm 堆 里面把引用回收掉，然后堆外也回收掉 对象是生存还是死亡的？ 两次标记&F-Queue&Finalizer线程 =》没有GC Roots的引用链 =》 判断对象是否有必要执行`finalize()`方法 第一次：通过GC roots遍历，找到不在引用链内的对象。并检查是否需要执行finalize()方法。（如果没重写finalize()则只需要标记一次，然后就可以进行gc掉） 在第一次标记中有finalize()需要被执行的对象，会被丢到一个优先级较低的队列(F-Queue:java.lang.ref.Finalizer.ReferenceQueue)中执行，但不保证能被执行(因为是由低优先级的Finalizer线程去处理的，试想低优先级线程不被执行到，那么重写了finalize()的对象就永久在堆中不能被gc掉，即java.lang.ref.Finalizer对象会占用很大的堆空间，甚至溢出) 第二次：对队列(F-Queue)中的对象再遍历一次，看是否有自救，没有则进行GC 对象没有覆盖finalize()方法，或者finalize()方法已经被虚拟机调用过,虚拟机将这两种情况都视为\"没有必要执行\" 如果这个对象被判定为有必要执行finalize()方法,则这个对象会放置在一个叫做F-Queue的队列之中，并在稍后由一个虚拟机自动建立的，低优先级的Finalizer线程去执行它。 如果对象要在finalize()中成功拯救自己，则只需要重新与引用链上的任何一个对象建立关联即可，GC对F-Queue中对对象进行第二次标记时，会将它移出\"即将回收\"的集合；否则就会被回收 finalize()自救代码演示 /** * 此代码说明如下两点： * 1. 对象可以在GC时自我拯救 * 2. 这种自救的机会只有一次，因为一个对象的`finalize()`方法最多只会被系统自动调用一次 */ public class FinalizeEscapeGC { public static FinalizeEscapeGC SAVE_HOOK = null; public String name; public FinalizeEscapeGC(String name) { this.name = name; } public void isAlive() { System.out.println(\"yes, i am still alive\"); } @Override protected void finalize() throws Throwable { super.finalize(); System.out.println(\"finalize method executed!\"); System.out.println(this.name); FinalizeEscapeGC.SAVE_HOOK = this; } public static void main(String[] args) throws Throwable { SAVE_HOOK = new FinalizeEscapeGC(\"abc\"); // 对象第一次成功拯救自己 SAVE_HOOK = null; System.gc(); // 执行finalize方法的线程优先级很低，暂停0.5秒等待它执行 Thread.sleep(500); if(SAVE_HOOK != null) { SAVE_HOOK.isAlive(); } else { System.out.println(\"no, i am dead\"); } // 下面这段代码与上面完全相同，但是这次自救却失败了 SAVE_HOOK = null; System.gc(); Thread.sleep(500); if(SAVE_HOOK != null) { SAVE_HOOK.isAlive(); } else { System.out.println(\"no, i am dead\"); } } } output finalize method executed! abc yes, i am still alive no, i am dead 最后，不推荐使用finalize() Java7方法区(永久代)的回收 堆中，新生代进行一次垃圾收集一般可以回收70%-95%的空间，而永久代的垃圾收集效率远低于此。 永久代主要回收两部分内容：废弃常量和无用的类， 判断\"无用的类\"： 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例 加载该类的ClassLoader已经被回收 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法 是否对类进行回收，HotSpot虚拟机提供了-Xnoclassgc参数进行控制，还可以使用-verbose:class以及-XX:+TraceClassLoading,-XX:+TraceClassUnLoading查看类加载和卸载信息，其中-verbose:class和-XX:+TraceClassLoading可以在Product版的虚拟机中使用，-XX:+TraceClassUnLoading参数需要FastDebug版的虚拟机支持 在大量使用反射，动态代理，CGLib等ByteCode框架，动态生成JSP以及OSGi这类频繁自定义ClassLoader的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出 HotSpot 算法实现可达性分析 可达性分析的\"一致性\"分析，GC进行时必须停顿所有Java执行线程(Sun将这件事情称为Stop The World) 虚拟机有办法直接得知哪些地方存放着对象的引用，HotSpot中使用一组称为OopMap的数据结构来达到这个目的：在类加载完成的时候，HotPot就把对象内什么偏移量是什么类型的数据计算出来，在JIT编译过程中，也会在特定的位置记录下栈和寄存器中哪些位置是引用。这样，GC在扫描时就可以直接得知这些信息了。 借助OopMap，HotSpot可以快速且准确地完成GC Roots枚举，问题： 可能导致引用关系变化，或者说OopMap内容变化的指令特别多，如果为每一条指令都生成对应的OopMap，那将会需要大量的额外空间，这样GC的空间成本将会变得很高 实际上，HotSpot没有为每条指令都生成oopMap, 安全点(Sagepoint) GC， 选举以\"是否具有让程序长时间执行的特征\"为标准进行选定，如方法调用，循环跳转，异常跳转等，这些功能的指令会产生安全点 Stop The World 参考文章 There is a term that you should know before learning about GC. The term is \"stop-the-world.\" Stop-the-world will occur no matter which GC algorithm you choose. Stop-the-world means that the JVM is stopping the application from running to execute a GC. When stop-the-world occurs, every thread except for the threads needed for the GC will stop their tasks. The interrupted tasks will resume only after the GC task has completed. GC tuning often means reducing this stop-the-world time. 只有GC线程工作，其它线程都停止；当GC线程工作完成，其它线程恢复 常见的垃圾回收算法 参考学习：几种垃圾回收算法 垃圾回收算法 优缺点 引用计数法(Referenc Counting) 无法处理循环引用 标记-清除算法(Mark-Sweep)算法 扫描并标记垃圾，然后将垃圾清理掉；能解决循环引用，会产生内存碎片 标记-缩并（Mark-Compact)算法 类似mark-sweep,不过最后是：1.压缩使用的内存，规整下到一起，2.清除剩下全部空间；可解决内存碎片；存活对象越多，耗时就越大 拷贝(Copying)算法 堆空间分两半，有用的拷贝到另一半，把当前这一半直接全部清除，解决内部碎片，但浪费空间 垃圾收集器发展和介绍 垃圾收集器，并发&并行 并行(Parallel)：指多条垃圾收集线程并行工作，但此时用户线程仍是被阻塞的等待状态 并发(Concurrent): 只用户线程与垃圾收集线程同时执行（但不一定是并行的，可能会交替执行），用户程序在继续运行，而垃圾收集程序运行于另一个CPU上 GC收集器及其发展 (一) Serial （STW,单线程收集器） a stop-the-world,coping collector which uses a single GC thread 使用Coping算法的单线程的收集器，但是它的\"单线程\"的意义并不仅仅说明它只会使用一个CPU或者一条收集线程去完成垃圾收集工作，更重要的是它进行垃圾收集时，必须暂停其他所有的工作线程，直到收集结束即Stop The World ParNew (Serial的多线程版本) ParNew收集器除了多线程收集之外，其他与Serial收集器相比并没有太多创新之处，但它却是许多运行在Server模式下的虚拟机中首选的新生代收集器，其中有一个与性能无关但很重要的原因是，除了Serial收集器外，目前只有它能与CMS收集器配合工作。 (二) Parallel Scavenge（STW,多线程收集器） a stop-the-world,coping collector which uses multi GC threads 使用Coping算法的并行多线程收集器。Parallel Scavenge是Java1.8默认的收集器，特点是并行的多线程回收，以吞吐量（CPU用于运行用户代码的时间与CPU总消耗时间的比值，吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间)）优先 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验，而高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务 Parallel old a compacting collector that uses multi GC threads (三) CMS收集器 concurret mark sweep a mostly concurrent, low-pause collector 4 phases: initial mark(stw) concurrent mark remark(stw) concurrent sweep CMS收集器在Minor GC时会暂停所有的应用线程，并以多线程的方式进行垃圾回收。在Full GC时不再暂停应用线程，而是使用若干个后台线程定期的对老年代空间进行扫描，及时回收其中不再使用的对象 (四) G1 G1收集器（或者垃圾优先收集器）的设计初衷是为了尽量缩短处理超大堆（大于4GB）时产生的停顿。相对于CMS的优势而言是内存碎片的产生率大大降低；目标是用在多核，大内存的机器上，它在大多数情况下可以实现指定的GC暂停时间，同时还能保持较高的吞吐量 Java HotSpot(TM) 64-Bit Server VM (25.171-b11) for bsd-amd64 JRE (1.8.0_171-b11), built on Mar 28 2018 12:50:57 by \"java_re\" with gcc 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00) Memory: 4k page, physical 16777216k(1978920k free) /proc/meminfo: CommandLine flags: -XX:InitialHeapSize=20971520 -XX:MaxHeapSize=20971520 -XX:MaxNewSize=10485760 -XX:NewSize=10485760 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:SurvivorRatio=8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseG1GC 0.196: [GC pause (G1 Humongous Allocation) (young) (initial-mark), 0.0022978 secs] [Parallel Time: 2.0 ms, GC Workers: 4] [GC Worker Start (ms): Min: 196.2, Avg: 196.2, Max: 196.3, Diff: 0.0] [Ext Root Scanning (ms): Min: 0.6, Avg: 0.6, Max: 0.6, Diff: 0.0, Sum: 2.4] [Update RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Processed Buffers: Min: 0, Avg: 0.0, Max: 0, Diff: 0, Sum: 0] [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Object Copy (ms): Min: 0.8, Avg: 1.1, Max: 1.3, Diff: 0.5, Sum: 4.3] [Termination (ms): Min: 0.0, Avg: 0.3, Max: 0.5, Diff: 0.5, Sum: 1.1] [Termination Attempts: Min: 1, Avg: 1.2, Max: 2, Diff: 1, Sum: 5] [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [GC Worker Total (ms): Min: 1.9, Avg: 2.0, Max: 2.0, Diff: 0.0, Sum: 7.8] [GC Worker End (ms): Min: 198.2, Avg: 198.2, Max: 198.2, Diff: 0.0] [Code Root Fixup: 0.0 ms] [Code Root Purge: 0.0 ms] [Clear CT: 0.0 ms] [Other: 0.2 ms] [Choose CSet: 0.0 ms] [Ref Proc: 0.1 ms] [Ref Enq: 0.0 ms] [Redirty Cards: 0.0 ms] [Humongous Register: 0.0 ms] [Humongous Reclaim: 0.0 ms] [Free CSet: 0.0 ms] [Eden: 3072.0K(10.0M)->0.0B(9216.0K) Survivors: 0.0B->1024.0K Heap: 8629.0K(20.0M)->6823.5K(20.0M)] [Times: user=0.00 sys=0.00, real=0.01 secs] 0.199: [GC concurrent-root-region-scan-start] 0.199: [GC concurrent-root-region-scan-end, 0.0005314 secs] 0.199: [GC concurrent-mark-start] 0.199: [GC concurrent-mark-end, 0.0000251 secs] 0.202: [GC remark 0.202: [Finalize Marking, 0.0000621 secs] 0.202: [GC ref-proc, 0.0000215 secs] 0.202: [Unloading, 0.0003779 secs], 0.0005651 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 0.203: [GC cleanup 13M->13M(20M), 0.0001664 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap garbage-first heap total 20480K, used 12967K [0x00000007bec00000, 0x00000007bed000a0, 0x00000007c0000000) region size 1024K, 2 young (2048K), 1 survivors (1024K) Metaspace used 3342K, capacity 4500K, committed 4864K, reserved 1056768K class space used 371K, capacity 388K, committed 512K, reserved 1048576K Java垃圾回收的依据/假设 Most objects soon become unreachable. References from old objects to young objects only exist in small numbers. 分代GC,查看默认的GC配置 mubi@mubideMacBook-Pro ~ $ java -XX:+PrintCommandLineFlags -version -XX:InitialHeapSize=268435456 -XX:MaxHeapSize=4294967296 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC java version \"1.8.0_171\" Java(TM) SE Runtime Environment (build 1.8.0_171-b11) Java HotSpot(TM) 64-Bit Server VM (build 25.171-b11, mixed mode) mubi@mubideMacBook-Pro ~ $ - 年轻代(别名) 老年代 JVM 参数 组合一 Serial (DefNew) Serial Old(PSOldGen) -XX:+UseSerialGC 组合二 Parallel Scavenge (PSYoungGen) Serial Old(PSOldGen) -XX:+UseParallelGC 组合三(*) Parallel Scavenge (PSYoungGen) Parallel Old (ParOldGen) -XX:+UseParallelOldGC 组合四 ParNew (ParNew) Serial Old(PSOldGen) -XX:-UseParNewGC 组合五(*) ParNew (ParNew) CMS+Serial Old(PSOldGen) -XX:+UseConcMarkSweepGC 组合六(*) G1 G1 -XX:+UseG1GC new object的gc生命周期 线程TLAB局部缓存区域（Thread Local Allocation Buffer）：Sun Hotspot JVM为了提升对象内存分配的效率，对于所创建的线程都会分配一块独立的空间TLAB（Thread Local Allocation Buffer），其大小由JVM根据运行的情况计算而得，在TLAB上分配对象时不需要加锁，因此JVM在给线程的对象分配内存时会尽量的在TLAB上分配，在这种情况下JVM中分配对象内存的性能和C基本是一样高效的，但如果对象过大的话则仍然是直接使用堆空间分配（堆是JVM中所有线程共享的，因此在其上进行对象内存的分配均需要进行加锁，这也导致了new对象的开销是比较大的） CMS(Concurrent Mark Sweep)垃圾回收器 参考文档地址 The Concurrent Mark Sweep (CMS) collector is designed for applications that prefer shorter garbage collection pauses and that can afford to share processor resources with the garbage collector while the application is running. 一种以获取最短回收停顿时间为目标的收集器(以牺牲了吞吐量为代价)：希望系统停顿时间最短，给用户带来较好但体验。基础算法是Mark-Sweep算法；不会整理、压缩堆空间，会产生内存碎片 要求多CPU；为了让应用程序不停顿，CMS线程和应用程序线程并发执行，这样就需要有更多的CPU，单纯靠线程切换效率太低。并且，重新标记阶段，为保证Stop The World快速完成，也要用到更多的甚至所有的CPU资源。 CMS处理的4个步骤 初始标记（CMS initial mark)，需要:Stop The World 这个过程从垃圾回收的\"根对象\"开始，只扫描到能够和\"根对象\"直接关联的对象，并作标记。所以这个过程虽然暂停了整个JVM，但是很快就完成了。 并发标记（CMS concurrent mark） 这个阶段紧随初始标记阶段，在初始标记的基础上继续向下追溯标记。并发标记阶段，应用程序的线程和并发标记的线程并发执行，所以用户不会感受到停顿。 重新标记（CMS remark）正确标记，需要Stop The World 这个阶段会暂停虚拟机，收集器线程扫描在CMS堆中剩余的对象。扫描从\"根对象\"开始向下追溯，并处理对象关联。 并发清除（CMS concurrent sweep） 清理垃圾对象，这个阶段收集器线程和应用程序线程并发执行；会产生浮动垃圾 缺点 CMS收集器对CPU资源非常敏感。在并发阶段，虽然不会导致用户线程停顿，但是会因为占用了一部分线程，使应用程序变慢，总吞吐量会降低，为了解决这种情况，虚拟机提供了一种\"增量式并发收集器\"(Incremental Concurrent Mark Sweep/i-CMS)的CMS收集器变种，所做的事情就是在并发标记和并发清除的时候让GC线程和用户线程交替运行，尽量减少GC线程独占资源的时间，这样整个垃圾收集的过程会变长，但是对用户程序的影响会减少。（效果不明显，已经不推荐） CMS处理器无法处理浮动垃圾（Floating Garbage）。由于CMS在并发清除阶段有用户线程还在运行着，伴随着程序的运行自然也会产生新的垃圾，这一部分垃圾产生在标记过程之后，CMS无法在当次收集中处理掉它们，所以只有等到下次gc时候再清理掉，这一部分垃圾就称作\"浮动垃圾\"；因此CMS收集器不能像其它收集器那样等到老年代几乎完全被填满了再进行收集，而是需要预留一部分空间提高并发收集时的程序运作使用。 CMS是基于(mark-sweep)\"标记-清除\"算法实现的，所以在收集结束的时候会有大量的空间碎片产生。空间碎片太多的时候，将会给大对象的分配带来很大的麻烦，往往会出现老年代还有很大的空间剩余，但是无法找到足够大的连续空间来分配当前对象的，只能提前触发full gc。 为了解决这个问题，CMS提供了一个开关参数（-XX: UseCMSCompactAtFullCollection），用于在CMS顶不住要进行full gc的时候开启内存碎片的合并整理过程，内存整理的过程是无法并发的，空间碎片没有了，但是停顿的时间变长了。另外一个参数(-XX: CMSFullGCsBeforeCompaction)用于设置执行多少次不压缩的full gc后，跟着来一次带压缩的（默认值为0，表示每次进入full gc时都进行碎片整理） 三色标记 把遍历对象图过程中遇到的对象，按“是否访问过”这个条件标记成以下三种颜色 白色：尚未访问过 灰色：正在搜索的对象：自己标记完成，其Fields还没有标记完成 黑色：搜索完成的对象,自己和其Fields都标记完成（不会当成垃圾对象，不会被GC） 遍历标记过程： 初始时，所有对象都在【白色集合】中； 将GC Roots 直接引用到的对象 挪到 【灰色集合】中； 从灰色集合中获取对象： 将本对象 引用到的 其他对象 全部挪到 【灰色集合】中； 将本对象 挪到 【黑色集合】里面。 重复步骤3，直至【灰色集合】为空时结束。 最后仍在【白色集合】的对象即为GC Roots 不可达，可以进行回收。 三色标记问题 浮动垃圾：浮动垃圾并不会影响垃圾回收的正确性，只是需要等到下一轮垃圾回收中才被清除。 多标和漏标问题 假设GC线程已经遍历到E（变为灰色了），此时应用线程先执行了： var G = objE.fieldG; objE.fieldG = null; // 灰色E 断开引用 白色G objD.fieldG = G; // 黑色D 引用 白色G 此时切回GC线程继续跑，因为E已经没有对G的引用了，所以不会将G放到灰色集合；尽管因为D重新引用了G，但因为D已经是黑色了，是不会再重新做遍历处理。最终结局就是：G会一直停留在白色集合中，最后被当作垃圾进行清除。但是G显然是不能被回收的，这种情况影响到了应用程序的正确性，是不可接受的。 CMS解决方案和remark 写屏障(读写前后，将对象G给记录下来) + 增量更新 var G = objE.fieldG; // 1.读，读屏障 objE.fieldG = null; // 2.写，写屏障 objD.fieldG = G; // 3.写，写屏障 CMS有`remark`，从头到尾扫描一遍 扩展：G1解决方法(写屏障 + Snapshot At the begining) 块(RSet) 配合 SATB 解决（将引用关系中转到GC的堆栈中） G1(Garbage First)垃圾回收器 参考学习文档 参考学习1: 美团技术文章 参考学习2: oracle g1 document 参考学习3: g1 log G1设计理念 Can operate concurrently with applications threads like the CMS collector. （能够像CMS收集器一样跟应用线程并发的去执行。【CMS本身就是一个并发的收集器，也就是GC线程与应用线程可以同时间执行】） Compact free space without lengthy GC induced pause times. （可以压缩可用的空间，而不会让GC引起暂停时间过长。） Need more predictable GC pause durations. （需要更多的可预测的GC暂停的间隔。【也就是说GC暂停的时间会尽量往我们设置的暂时时间来靠】） Do not want to sacrifice a lot of throughput performance. （不想牺牲大量吞吐性能。） Do not require a much larger Java heap. （不想需要大量Java的堆空间。） G1 内存区域分布图和概念介绍 整个堆被分为一个大小相等的region集合，每个reagion是逻辑上连续的虚拟内存区域； 这些region有eden,survivor,old的概念；G1的各代存储地址是不连续的，每一代都使用了n个不连续的大小相同的Region;年轻代（eden + survivor）,年老代（old + humongous） Humongous区域：如果一个对象占用的空间超过了region容量(region size)50%以上，G1收集器就认为这是一个巨型对象。这些巨型对象，默认直接会被分配在oldregion，为了能找到连续的region来分配巨型对象，有时候不得不启动Full GC。 H-obj直接分配到了old gen，防止了反复拷贝移动 H-obj在global concurrent marking阶段的cleanup 和 full GC阶段回收 在分配H-obj之前先检查是否超过 initiating heap occupancy percent和the marking threshold, 如果超过的话，就启动global concurrent marking，为的是提早回收，防止 evacuation failures 和 full GC。 When performing garbage collections, G1 operates in a manner similar to the CMS collector. G1 performs a concurrent global marking phase to determine the liveness of objects throughout the heap. After the mark phase completes, G1 knows which regions are mostly empty. It collects in these regions first, which usually yields a large amount of free space. This is why this method of garbage collection is called Garbage-First.As the name suggests, G1 concentrates its collection and compaction activity on the areas of the heap that are likely to be full of reclaimable objects, that is, garbage. G1 uses a pause prediction model to meet a user-defined pause time target and selects the number of regions to collect based on the specified pause time target. （概括起来：仍然类似CMS采用并发标记，不过垃圾回收时不是回收全部，而是对那些垃圾较多的region区域进行回收；根据此次回收可以对下次回收进行一个预测） G1 常用参数 参数 含义 -XX:G1HeapRegionSize=n 设置Region大小，并非最终值 -XX:MaxGCPauseMillis 设置G1收集过程目标时间，默认值200ms，不是硬性条件 -XX:G1NewSizePercent 新生代最小值，默认值5% -XX:G1MaxNewSizePercent 新生代最大值，默认值60% -XX:ParallelGCThreads STW期间，并行GC线程数 -XX:ConcGCThreads=n 并发标记阶段，并行执行的线程数 -XX:InitiatingHeapOccupancyPercent 设置触发标记周期的 Java 堆占用率阈值。默认值是45%。这里的Java堆占比指的是non_young_capacity_bytes，包括old+humongous 如下一个线上配置(机器2C4G)例子： -Xms2700M -Xmx2700M -Xss512K -XX:MaxDirectMemorySize=512M -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=4 -XX:ConcGCThreads=2 -XX:InitiatingHeapOccupancyPercent=70 -XX:MaxMetaspaceSize=500m -XX:+PrintGCDetails Remember Set & Collection Set headpRegion.cpp 部分实现 // Minimum region size; we won't go lower than that. // We might want to decrease this in the future, to deal with small // heaps a bit more efficiently. #define MIN_REGION_SIZE ( 1024 * 1024 ) // Maximum region size; we don't go higher than that. There's a good // reason for having an upper bound. We don't want regions to get too // large, otherwise cleanup's effectiveness would decrease as there // will be fewer opportunities to find totally empty regions after // marking. #define MAX_REGION_SIZE ( 32 * 1024 * 1024 ) // The automatic region size calculation will try to have around this // many regions in the heap (based on the min heap size). #define TARGET_REGION_NUMBER 2048 size_t HeapRegion::max_region_size() { return (size_t)MAX_REGION_SIZE; } // 这个方法是计算region的核心实现 void HeapRegion::setup_heap_region_size(size_t initial_heap_size, size_t max_heap_size) { uintx region_size = G1HeapRegionSize; // 是否设置了G1HeapRegionSize参数，如果没有配置，那么按照下面的方法计算；如果设置了G1HeapRegionSize就按照设置的值计算 if (FLAG_IS_DEFAULT(G1HeapRegionSize)) { // average_heap_size即平均堆的大小，(初始化堆的大小即Xms+最大堆的大小即Xmx)/2 size_t average_heap_size = (initial_heap_size + max_heap_size) / 2; // average_heap_size除以期望的REGION数量得到每个REGION的SIZE，与MIN_REGION_SIZE取两者中的更大值就是实际的REGION_SIZE；从这个计算公式可知，默认情况下如果JVM堆在2G（TARGET_REGION_NUMBER*MIN_REGION_SIZE）以下，那么每个REGION_SIZE都是1M； region_size = MAX2(average_heap_size / TARGET_REGION_NUMBER, (uintx) MIN_REGION_SIZE); } // region_size的对数值 int region_size_log = log2_long((jlong) region_size); // 重新计算region_size，确保它是最大的小于或等于region_size的2的N次方的数值，例如重新计算前region_size=33，那么重新计算后region_size=32；重新计算前region_size=16，那么重新计算后region_size=16； // Recalculate the region size to make sure it's a power of // 2. This means that region_size is the largest power of 2 that's // MAX_REGION_SIZE) { region_size = MAX_REGION_SIZE; } // 与MIN_REGION_SIZE和MAX_REGION_SIZE比较后，再次重新计算region_size // And recalculate the log. region_size_log = log2_long((jlong) region_size); ... ... } region size: 1M-32M,通过-XX:G1HeapRegionSize可指定 G1的每个region都有一个Remember Set(RSet)，用来保存别的region的对象对该region的对象的引用，通过Remember Set我们可以找到哪些对象引用了当前region的对象 This allows the GC to avoid collecting the entire heap at once, and instead approach the problem incrementally: only a subset of the regions, called the collection set will be considered at a time.（避免一次对整个堆的垃圾进行回收，而是一次回收称为collection set的部分，collection set就是垃圾比较多的那些region） 被回收的region可以复制到空的region,或者复制到survivor区域，同时可以进行压缩（复制效率高，并且减少了碎片） SATB（Snapshot-At-The-Beginning） 是GC开始时活着的对象的一个快照。它是通过Root Tracing得到的，作用是维持并发GC的正确性。结合三色标记 G1的GC Note: G1 has both concurrent (runs along with application threads, e.g., refinement, marking, cleanup) and parallel (multi-threaded, e.g., stop the world) phases. Full garbage collections are still single threaded, but if tuned properly your applications should avoid full GCs. young gc(对年轻代的GC) Live objects are evacuated to one or more survivor regions. If the aging threshold is met, some of the objects are promoted to old generation regions. (young gc的处理效果就是：存活在Eden的对象会进入survivor区域，如果达到aging阈值则进入到old区域） This is a stop the world (STW) pause. Eden size and survivor size is calculated for the next young GC. Accounting information is kept to help calculate the size. Things like the pause time goal are taken into consideration. This approach makes it very easy to resize regions, making them bigger or smaller as needed. （这是一个stop the world的停顿,eden和survivor区域会重新计算分配，停顿时间是要考虑到的） mixed gc(对老年代的GC) Phase Description (1) Initial Mark (Stop the World Event) This is a stop the world event. With G1, it is piggybacked on a normal young GC. Mark survivor regions (root regions) which may have references to objects in old generation. (2) Root Region Scanning Scan survivor regions for references into the old generation. This happens while the application continues to run. The phase must be completed before a young GC can occur. (3) Concurrent Marking Find live objects over the entire heap. This happens while the application is running. This phase can be interrupted by young generation garbage collections. (4) Remark(Stop the World Event) Completes the marking of live object in the heap. Uses an algorithm called snapshot-at-the-beginning (SATB) which is much faster than what was used in the CMS collector. (5) Cleanup(Stop the World Event and Concurrent) Performs accounting on live objects and completely free regions. (Stop the world); Scrubs the Remembered Sets. (Stop the world); * Reset the empty regions and return them to the free list. (Concurrent) (*) Copying (Stop the World Event) These are the stop the world pauses to evacuate or copy live objects to new unused regions. This can be done with young generation regions which are logged as [GC pause (young)]. Or both young and old generation regions which are logged as [GC Pause (mixed)]. Initial Marking Phase(初始标记，STW) Initial marking of live object is piggybacked on a young generation garbage collection.(标记存活对象) gc log: (young) (initial-mark) Concurrent Marking Phase（并发标记：三色标记，与用户线程并发执行） If empty regions are found (as denoted by the \"X\"), they are removed immediately in the Remark phase. Also, \"accounting\" information that determines liveness is calculated. （空区域会立刻被标记，这个阶段会计算存活对象） 三色标记(补充) 困难点：在标记对象的过程中，引用关系也正发生着变化 白色： 没有被标记的对象 灰色： 自身被标记，成员未被标记 黑色： 自身被和成员都被标记完成了 从左边变成右边的状态,两个变化 B->D 引用消失 A->D 引用新增 这样下次扫描的时候，由于A是黑色，则A的引用不会理会；B,C发现没有任何引用了；这样导致D漏标了，即D被当成垃圾了 G1 snapshot at the begining,关注引用的删除：当B->D消失时，要把这种引用保存到GC栈，保证下次D要被扫描到(配合Remember Set) Remark Phase（最终标记，STW, CPU停顿处理垃圾） Empty regions are removed and reclaimed. Region liveness is now calculated for all regions. （空区域会被删除可以让重新分配，所有区域的liveness会计算） Copying/Cleanup Phase（筛选部分region回收，而非全部回收；STW：根据用户期望的GC停顿时间回收） G1 selects the regions with the lowest \"liveness\", those regions which can be collected the fastest. Then those regions are collected at the same time as a young GC. This is denoted in the logs as [GC pause (mixed)]. So both young and old generations are collected at the same time. （the lowest \"liveness\"的region会被清理掉） （yong gc和mixed gc会同时进行） gc log: GC pause (mixed) 对年轻代和老年代GC的总结 对年轻代的GC young gc需要stop the world young gc是多线程并行处理的 eden会到达survivor或者old generation regions 对老年代的GC Concurrent Marking Phase Liveness information is calculated concurrently while the application is running. This liveness information identifies which regions will be best to reclaim during an evacuation pause. There is no sweeping phase like in CMS. Remark Phase Uses the Snapshot-at-the-Beginning (SATB) algorithm which is much faster then what was used with CMS. Completely empty regions are reclaimed.(完全空的regions会立刻被会收掉) Copying/Cleanup Phase Young generation and old generation are reclaimed at the same time.（年轻代和老年代会同时被回收） Old generation regions are selected based on their liveness. G1的优势（为什么能够设置一个停留时间） G1的另一个显著特点他能够让用户设置应用的暂停时间，为什么G1能做到这一点呢？也许你已经注意到了，G1是选择一些内存块，而不是整个代的内存来回收，这是G1跟其它GC非常不同的一点，其它GC每次回收都会回收整个Generation的内存(Eden, Old), 而回收内存所需的时间就取决于内存的大小，以及实际垃圾的多少，所以垃圾回收时间是不可控的；而G1每次并不会回收整代内存，到底回收多少内存就看用户配置的暂停时间，配置的时间短就少回收点，配置的时间长就多回收点，伸缩自如。 由于内存被分成了很多小块，又带来了另外好处，由于内存块比较小，进行内存压缩整理的代价都比较小，相比其它GC算法，可以有效的规避内存碎片的问题。 G1的思想：将一个大的分成若干个Region，然后再处理；即【分而治之】的思想 G1 和 CMS G1 和 CMS 堆空间分配方式不同（分代 & region） CMS将堆逻辑上分成Eden,Survivor(S0,S1),Old；并且他们是固定大小JVM启动的时候就已经设定不能改变,并且是连续的内存块 G1将堆分成多个大小相同的Region(区域),默认2048个：在1Mb到32Mb之间大小,逻辑上分成Eden,Survivor,Old,Humongous(巨型),空闲；他们不是固定大小,会根据每次GC的信息做出调整 G1 和 CMS GC的区别 CMS的Young GC就是依赖并行GC(ParNew)去完成的，只有老年代中使用CMS GC(也就是Old GC) CMS 使用分代回收,堆被分成了年轻代和老年代,其中年轻代回收依赖ParNew去回收,需要STW(Stop The World) G1中提供了三种模式垃圾回收模式，young gc、mixed gc 和 full gc，在不同的条件下被触发。 young gc 发生在年轻代的GC算法，一般对象（除了巨型对象）都是在eden region中分配内存，当所有eden region被耗尽无法申请内存时，就会触发一次young gc，这种触发机制和之前的young gc差不多，执行完一次young gc，活跃对象会被拷贝到survivor region或者晋升到old region中，空闲的region会被放入空闲列表中，等待下次被使用。 mixed gc 当越来越多的对象晋升到老年代old region时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即mixed gc，该算法并不是一个old gc，除了回收整个young region，还会回收一部分的old region，这里需要注意：是一部分老年代，而不是全部老年代，G1可以选择哪些old region进行收集，从而可以对垃圾回收的耗时时间进行控制 full gc 如果对象内存分配速度过快，mixed gc来不及回收，导致老年代被填满，就会触发一次full gc，G1的full gc算法就是单线程执行的serial old gc，会导致异常长时间的暂停时间；所以这需要进行不断的调优，尽可能的避免full gc的产生 g1 yong gc log [GC pause (G1 Evacuation Pause) (young), 0.0707344 secs] [Parallel Time: 68.6 ms, GC Workers: 2] [GC Worker Start (ms): Min: 4044130.9, Avg: 4044130.9, Max: 4044131.0, Diff: 0.0] [Ext Root Scanning (ms): Min: 3.1, Avg: 3.3, Max: 3.5, Diff: 0.5, Sum: 6.6] [Update RS (ms): Min: 2.2, Avg: 2.2, Max: 2.2, Diff: 0.0, Sum: 4.4] [Processed Buffers: Min: 77, Avg: 111.5, Max: 146, Diff: 69, Sum: 223] [Scan RS (ms): Min: 0.4, Avg: 0.4, Max: 0.4, Diff: 0.0, Sum: 0.7] [Code Root Scanning (ms): Min: 0.0, Avg: 0.5, Max: 1.0, Diff: 1.0, Sum: 1.0] [Object Copy (ms): Min: 61.4, Avg: 62.1, Max: 62.8, Diff: 1.4, Sum: 124.1] [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Termination Attempts: Min: 1, Avg: 1.0, Max: 1, Diff: 0, Sum: 2] [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1] [GC Worker Total (ms): Min: 68.5, Avg: 68.5, Max: 68.5, Diff: 0.0, Sum: 137.0] [GC Worker End (ms): Min: 4044199.4, Avg: 4044199.4, Max: 4044199.4, Diff: 0.0] [Code Root Fixup: 0.0 ms] [Code Root Purge: 0.0 ms] [Clear CT: 0.4 ms] [Other: 1.7 ms] [Choose CSet: 0.0 ms] [Ref Proc: 0.1 ms] [Ref Enq: 0.0 ms] [Redirty Cards: 0.1 ms] [Humongous Register: 0.1 ms] [Humongous Reclaim: 0.0 ms] [Free CSet: 0.7 ms] [Eden: 1160.0M(1160.0M)->0.0B(1153.0M) Survivors: 68.0M->75.0M Heap: 1551.2M(2048.0M)->398.7M(2048.0M)] [Times: user=0.14 sys=0.00, real=0.07 secs] 内存分配与回收策略(理论基础) 对象优先在Eden分配 大多数情况下，对象在新生代Eden区中分配。当Eden区没有足够空间进行分配是，虚拟机将发起一次Minor GC。（-XX:+PrintGCDetails） minor gc(yong gc) 新生代GC(Minor GC): 指发生在新生代的垃圾收集动作，因为Java对象大多数都具备朝生夕灭的性质，所以Minor GC非常频繁，一般回收速度也比较快 新创建的对象都是用新生代分配内存，Eden空间不足时，触发Minor GC，这时会把存活的对象转移进Survivor区。 新生代通常存活时间较短基于Copying算法进行回收，所谓Copying算法就是扫描出存活的对象，并复制到一块新的完全未使用的空间中，对应于新生代，就是在Eden和From Space或To Space之间copy。新生代采用空闲指针的方式来控制GC触发，指针保持最后一个分配的对象在新生代区间的位置，当有新的对象要分配内存时，用于检查空间是否足够，不够就触发GC。当连续分配对象时，对象会逐渐从Eden到Survivor，最后到老年代。 major gc/ full gc 老年代GC(Major GC/Full GC): 指发生在老年代的GC,出现了Major GC, 经常会伴随至少一次的Minor GC(但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程)。Major GC的速度一般会比Minor GC慢10倍以上 老年代用于存放经过多次Minor GC之后依然存活的对象。 老年代与新生代不同，老年代对象存活的时间比较长、比较稳定，因此采用标记(Mark)算法来进行回收，所谓标记就是扫描出存活的对象，然后再进行回收未被标记的对象，回收后对用空出的空间要么进行合并、要么标记出来便于下次进行分配，总之目的就是要减少内存碎片带来的效率损耗。 -Xms 默认情况下堆内存的64分之一 -Xmx 默认情况下堆内存的4分之一 -Xmn 默认情况下堆内存的64分之一， 新生代大小，该配置优先于-XX:NewRatio，即如果配置了-Xmn，-XX:NewRatio会失效。 -XXNewRatio 默认为2 -XX:SurvivorRatio 默认为8，表示Suvivor:eden=2:8,即一个Survivor占年轻代的1/10 Java 分代GC测试程序 和 初始堆情况(Java7 CMS) jdk1.7.0_80 /* * -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 */ public class MainTest { public static final int _1MB = 1024 * 1024; public static void main(String[] args) throws Exception{ byte[] alloc1, alloc2, alloc3, alloc4; alloc1 = new byte[2 * _1MB]; alloc2 = new byte[2 * _1MB]; alloc3 = new byte[2 * _1MB]; // 出现 GC alloc4 = new byte[3 * _1MB]; } } -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:SurvivorRatio=8 eden from survivor to survivor old 8192K 1024K 1024K 10240K 对应的GC日志 [GC [PSYoungGen: 7534K->416K(9216K)] 7534K->6560K(19456K), 0.0049590 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] [Full GC [PSYoungGen: 416K->0K(9216K)] [ParOldGen: 6144K->6466K(10240K)] 6560K->6466K(19456K) [PSPermGen: 3121K->3120K(21504K)], 0.0103590 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] Heap PSYoungGen total 9216K, used 3403K [0x00000007ff600000, 0x0000000800000000, 0x0000000800000000) eden space 8192K, 41% used [0x00000007ff600000,0x00000007ff952de0,0x00000007ffe00000) from space 1024K, 0% used [0x00000007ffe00000,0x00000007ffe00000,0x00000007fff00000) to space 1024K, 0% used [0x00000007fff00000,0x00000007fff00000,0x0000000800000000) ParOldGen total 10240K, used 6466K [0x00000007fec00000, 0x00000007ff600000, 0x00000007ff600000) object space 10240K, 63% used [0x00000007fec00000,0x00000007ff250b48,0x00000007ff600000) PSPermGen total 21504K, used 3142K [0x00000007f9a00000, 0x00000007faf00000, 0x00000007fec00000) object space 21504K, 14% used [0x00000007f9a00000,0x00000007f9d118a0,0x00000007faf00000) gc过程 状态 eden from survivor to survivor old 初始状态总大小 8192K 1024K 1024K 10240K 分配了alloc1,2,3 使用了6144K 接着需要分配alloc4，需要3M,不够用，GC 内存重新分配 3M存alloc4 - - old使用了6M用来存alloc1,2,3 最后使用占比 37%多 0% 0% 60%多 参考 JVM GC log文件的查看参考博文链接 [PSYoungGen: 7698K->448K(9216K)] PSYoungGen 新生代/ GC前该内存区域已使用容量 -> GC后该内存区域已使用容量(该内存区域的总容量)。 7698K->6592K(19456K) GC前Java堆已使用容量 -> GC后Java堆已使用容量（Java堆总容量）。 大对象直接进入老年代 这里所谓的大对象是指，需要大量连续内存空间的Java对象，最典型的大对象就是那种很长的字符串以及数组。大对象对虚拟机的内存分配来说就是一个坏消息。（更坏的是：一群\"朝生夕灭\"的\"短命大对象\"），经常出现大对象容易导致内存还有不少空间时就提前触发垃圾收集以获取足够的连续空间来\"安置\"它们 -XX:PretenureSizeThreshold参数，另大于这个设置值的对象直接在老年代分配。这样做的目的是避免在Eden区以及两个Survivor区之间发生大量的内存复制(复习一下：新生代采用复制算法收集内存) 长期存活的(Age>15)对象将进入老年代 内存回收时，必须识别哪些对象应该在新生代，哪些对象应放到老年代。 虚拟机给每个对象定义了一个对象年龄(Age)计数器。如果对象在Eden出生并经历过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间,并且对象的年龄为1.对象在Survivor区中每\"熬过\"一次Minor GC，年龄就增加1岁，当他的年龄增加到一定程度（默认15岁），就将会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数-XX:MaxTenuringThreshold设置 动态对象的年龄判定 为了更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄对象就可以直接进入老年代，无须等到MaxTenuringThreshold要求的年龄。 空间分配担保 老年代最大可用的连续空间 > 新生代所有对象总空间, 这样能确保Minor GC是安全的。 如果不成立，虚拟机会查看HandlerPromotionFailure设置值是否允许担保失败。如果允许，那么会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小 如果大于，将尝试着进行一次Minor GC,尽管这次的Minor GC是有风险的 如果小于，或者HandlerPromotionFailure设置值不允许担保失败，这时改为进行一次Full GC 触发gc的条件 GC触发的条件有两种。（1）程序调用System.gc时可以触发；（2）系统自身来决定GC触发的时机。 Minor GC触发条件 当Eden区满时，触发Minor GC Full GC触发条件 （1）调用System.gc时，系统建议执行Full GC，但是不必然执行 （2）老年代空间不足 （3）方法区空间不足 （4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存 （5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 JVM参数与GC 年轻代 老年代 jvm 参数 Serial (DefNew) Serial Old(PSOldGen) -XX:+UseSerialGC Parallel Scavenge (PSYoungGen) Serial Old(PSOldGen) -XX:+UseParallelGC Parallel Scavenge (PSYoungGen) Parallel Old (ParOldGen) -XX:+UseParallelOldGC ParNew (ParNew) Serial Old(PSOldGen) -XX:-UseParNewGC ParNew (ParNew) CMS+Serial Old(PSOldGen) -XX:+UseConcMarkSweepGC G1 G1 -XX:+UseG1GC Java8 默认GC jvm 配置 -Xloggc:/Users/mubi/git_workspace/java8/gc.log -verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8 -XX:+PrintGCDetails gc 类型 方式 yong gc Parallel Scavenge（PSYoungGen） full gc Parallel Old（ParOldGen） Java 程序 public static void testAllocation() throws InterruptedException{ byte[] a1, a2, a3, a4; System.out.println(\"free:\" + Runtime.getRuntime().freeMemory() / 1024 / 1024); System.out.println(\"total:\" + Runtime.getRuntime().totalMemory() / 1024 / 1024); System.out.println(\"max:\" + Runtime.getRuntime().maxMemory() / 1024 / 1024); System.out.println(\"used:\" + ( Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory()) / 1024 / 1024); a1 = new byte[2 * _1MB]; a2 = new byte[2 * _1MB]; System.out.println(\"free:\" + Runtime.getRuntime().freeMemory() / 1024 / 1024); System.out.println(\"total:\" + Runtime.getRuntime().totalMemory() / 1024 / 1024); System.out.println(\"max:\" + Runtime.getRuntime().maxMemory() / 1024 / 1024); System.out.println(\"used:\" + ( Runtime.getRuntime().totalMemory() - Runtime.getRuntime().freeMemory()) / 1024 / 1024); a3 = new byte[2 * _1MB]; a4 = new byte[6 * _1MB]; } public static void main(String[] args) throws InterruptedException { testAllocation(); TimeUnit.SECONDS.sleep(30); } gc.log 文件 Java HotSpot(TM) 64-Bit Server VM (25.171-b11) for bsd-amd64 JRE (1.8.0_171-b11), built on Mar 28 2018 12:50:57 by \"java_re\" with gcc 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00) Memory: 4k page, physical 16777216k(3251600k free) /proc/meminfo: CommandLine flags: -XX:InitialHeapSize=20971520 -XX:MaxHeapSize=20971520 -XX:MaxNewSize=10485760 -XX:NewSize=10485760 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:SurvivorRatio=8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseParallelGC 0.240: [GC (Allocation Failure) [PSYoungGen: 6524K->706K(9216K)] 6524K->4810K(19456K), 0.0127210 secs] [Times: user=0.01 sys=0.00, real=0.02 secs] 0.256: [GC (Allocation Failure) [PSYoungGen: 2754K->690K(9216K)] 6858K->6850K(19456K), 0.0114299 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 0.267: [Full GC (Ergonomics) [PSYoungGen: 690K->0K(9216K)] [ParOldGen: 6160K->6699K(10240K)] 6850K->6699K(19456K), [Metaspace: 3305K->3305K(1056768K)], 0.0128112 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] Heap PSYoungGen total 9216K, used 6547K [0x00000007bf600000, 0x00000007c0000000, 0x00000007c0000000) eden space 8192K, 79% used [0x00000007bf600000,0x00000007bfc64d10,0x00000007bfe00000) from space 1024K, 0% used [0x00000007bff00000,0x00000007bff00000,0x00000007c0000000) to space 1024K, 0% used [0x00000007bfe00000,0x00000007bfe00000,0x00000007bff00000) ParOldGen total 10240K, used 6699K [0x00000007bec00000, 0x00000007bf600000, 0x00000007bf600000) object space 10240K, 65% used [0x00000007bec00000,0x00000007bf28afe8,0x00000007bf600000) Metaspace used 3339K, capacity 4500K, committed 4864K, reserved 1056768K class space used 371K, capacity 388K, committed 512K, reserved 1048576K 堆外内存 问题 metaspace没有限制，堆内存使用正常(没有full gc)而没有释放，最终会遇到OOMKilled(程序因为内存使用超过限额被 kill -9 杀掉),即机器实例的OOM 概念 除了堆内存，Java 还可以使用堆外内存，也称直接内存（Direct Memory）。 例如：在通信中，将存在于堆内存中的数据 flush 到远程时，需要首先将堆内存中的数据拷贝到堆外内存中，然后再写入 Socket 中；如果直接将数据存到堆外内存中就可以避免上述拷贝操作，提升性能。类似的例子还有读写文件。 很多 NIO 框架 （如 netty，rpc） 会采用 Java 的 DirectByteBuffer 类来操作堆外内存，DirectByteBuffer 类对象本身位于 Java 内存模型的堆中，由 JVM 直接管控、操纵。DirectByteBuffer 中用于分配堆外内存的方法 unsafe.allocateMemory(size) 是个 native 方法，本质上是用 C 的 malloc 来进行分配的。 堆外内存并不直接控制于JVM，因此只能等到full GC的时候才能垃圾回收！（direct buffer归属的的JAVA对象是在堆上且能够被GC回收的，一旦它被回收，JVM将释放direct buffer的堆外空间。前提是没有关闭DisableExplicitGC）。堆外内存包含线程栈，应用程序代码，NIO缓存，JNI调用等.例如ByteBuffer bb = ByteBuffer.allocateDirect(1024)，这段代码的执行会在堆外占用1k的内存，Java堆内只会占用一个对象的指针引用的大小，堆外的这1k的空间只有当bb对象被回收时，才会被回收，这里会发现一个明显的不对称现象，就是堆外可能占用了很多，而堆内没占用多少，导致还没触发GC，那就很容易出现Direct Memory造成物理内存耗光 堆外内存溢出 最大的堆外内存设置的太小了 没有full gc，堆外内存没有及时被清理掉 元空间溢出 堆外内存更适合存储的对象 存储生命周期长的对象 可以在进程间可以共享，减少 JVM 间的对象复制，使得 JVM 的分割部署更容易实现 本地缓存，减少磁盘缓存或者分布式缓存的响应时间 Java 内存区域和内存溢出异常演练测试 OutOfMemoryError java vm参数 -Xms20M 表示设置堆容量的最小值为20M，必须以M为单位 -Xmx20M 表示设置堆容量的最大值为20M，必须以M为单位。将-Xmx和-Xms设置为一样可以避免堆自动扩展。 package java7; import java.util.ArrayList; import java.util.List; /** * 参数设置：-verbose:gc -Xms20M -Xmx20M -XX:+HeapDumpOnOutOfMemoryError * @Author mubi * @Date 2019/2/20 11:05 PM */ public class HeapOOM { static class OOMObject{ } public static void main(String[] args) { List list = new ArrayList<>(16); while (true){ list.add(new OOMObject()); } } } output [GC 5499K->3757K(20480K), 0.0069130 secs] [GC 9901K->8805K(20480K), 0.0089900 secs] [Full GC 18460K->13805K(20480K), 0.1417260 secs] [Full GC 17849K->17803K(20480K), 0.1140610 secs] [Full GC 17803K->17791K(20480K), 0.0981060 secs] java.lang.OutOfMemoryError: Java heap space Dumping heap to java_pid42185.hprof ... Heap dump file created [30470683 bytes in 0.161 secs] Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:2245) at java.util.Arrays.copyOf(Arrays.java:2219) at java.util.ArrayList.grow(ArrayList.java:242) at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:216) at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:208) at java.util.ArrayList.add(ArrayList.java:440) at java7.HeapOOM.main(HeapOOM.java:17) Shallow heap是一个对象消费的内存数量。每个对象的引用需要32（或者64 bits，基于CPU架构）。 Retained Heap显示的是那些当垃圾回收时候会清理的所有对象的Shallow Heap的总和。 参考 《Java 虚拟机》（第二版） 参考1 参考2 虚拟机栈和本地方法栈溢出 Java程序中，每个线程都有自己的Stack Space(堆栈)。 -Xss128k： 设置每个线程的堆栈大小。JDK5.0以后每个线程堆 栈大小为1M，以前每个线程堆栈大小为256K。根据应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右 Stack Space用来做方法的递归调用时压入Stack Frame(栈帧)。所以当递归调用太深的时候，就有可能耗尽Stack Space，爆出StackOverflow的错误。 code package java7; /** * 参数设置：-Xss160k * @Author mubi * @Date 2019/2/20 11:05 PM */ public class JavaVMStackSOF { private int stackLength = 1; public void stackLeak(){ stackLength ++; stackLeak(); } public static void main(String[] args) { JavaVMStackSOF javaVMStackSOF = new JavaVMStackSOF(); try{ javaVMStackSOF.stackLeak(); }catch (Throwable e){ System.out.println(\"stackLength:\" + javaVMStackSOF.stackLength); throw e; } } } output stackLength:774 Exception in thread \"main\" java.lang.StackOverflowError at java7.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:10) at java7.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11) at java7.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11) at java7.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11) at java7.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11) at java7.JavaVMStackSOF.stackLeak(JavaVMStackSOF.java:11) 参考： 参考blog 方法区和运行时常量池溢出 方法区用于存放Class的相关信息，如：类名，访问修饰符，常量池，字符描述，方法描述等。对于这个区域的测试，基本思路是运行时产生大量的类去填满方法区，直到溢出。 Java7中 Java7 永久代仍存在；对比java6，其中：符号引用(Symbols)转移到了native heap；字面量(interned strings)转移到了java heap；类的静态变量(class statics)转移到了java heap。 Java7 常量池 仍是java.lang.OutOfMemoryError: Java heap space package java7; import java.util.ArrayList; import java.util.List; /** * VM args: -XX:PermSize=10M -XX:MaxPermSize=10M * */ public class JavaMethodAreaOOM { /** * 在JDK1.6中，intern()方法会把首次遇到的字符串复制到永久代中， * 返回的也是永久代中这个字符串的引用， * 而由StringBuilder创建的字符串实例在Java堆中，所以必然不是同一个引用，将返回false。 * * 而JDK1.7(以及部分其他虚拟机，例如JRockit)的intern()实现不会再复制实例，而是在常量池中记录首次出现的实例引用， * 因此intern()返回的引用和由StringBuilder创建的那个字符串是同一个。 */ static void testStringIntern() { String str1 = new StringBuilder(\"计算机\").append(\"软件\").toString(); System.out.println(str1.intern() == str1); // true String str2 = new StringBuilder(\"ja\").append(\"va\").toString(); System.out.println(str2.intern() == str2); // false } static String base = \"string\"; public static void main(String[] args) { List list = new ArrayList(); // 不断生成字符串常量 for (int i=0;i output Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:2367) at java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:130) at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:114) at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:415) at java.lang.StringBuilder.append(StringBuilder.java:132) at java7.JavaMethodAreaOOM.main(JavaMethodAreaOOM.java:31 参考： 参考blog 直接内存溢出 NIO的Buffer提供了一个可以不经过JVM内存直接访问系统物理内存的类——DirectBuffer。DirectBuffer类继承自ByteBuffer，但和普通的ByteBuffer不同，普通的ByteBuffer仍在JVM堆上分配内存，其最大内存受到最大堆内存的限制；而DirectBuffer直接分配在物理内存中，并不占用堆空间，其可申请的最大内存受操作系统限制。 直接内存的读写操作比普通Buffer快，但它的创建、销毁比普通Buffer慢。 因此直接内存使用于需要大内存空间且频繁访问的场合，不适用于频繁申请释放内存的场合。 -XX:MaxDirectMemorySize，该值是有上限的，默认是64M，最大为sun.misc.VM.maxDirectMemory()，此参数的含义是当Direct ByteBuffer分配的堆外内存到达指定大小后，即触发Full GC package java7; import java.nio.ByteBuffer; /** * 参数设置：-verbose:-Xmx20M -XX:MaxDirectMemorySize=10M * @Author mubi * @Date 2019/2/20 11:05 PM */ public class DirectMemoryOOM { public static final int _1MB = 1024 * 1024; public static void main(String[] args) throws Exception{ ByteBuffer.allocateDirect(11 * _1MB); } } output Exception in thread \"main\" java.lang.OutOfMemoryError: Direct buffer memory at java.nio.Bits.reserveMemory(Bits.java:658) at java.nio.DirectByteBuffer.(DirectByteBuffer.java:123) at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:306) at java7.DirectMemoryOOM.main(DirectMemoryOOM.java:14) Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-02 23:20:09 "},"content/java_jvm/jvm_params.html":{"url":"content/java_jvm/jvm_params.html","title":"JVM参数","keywords":"","body":"[TOC] VM 参数 http://jvmmemory.com/ oracle g1 vm 参数 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-31 10:17:11 "},"content/java_jvm/jvm_tools.html":{"url":"content/java_jvm/jvm_tools.html","title":"JVM命令工具(jstack,jmap,jcmd...)","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Java自带的各类型命令工具 JVM 内存溢出&内存泄漏 JVM调优 jps jstat 例1（jstat -gc）查看gc信息 例2（jstat -gccapacity） 例3 (jstat -gcutil)查看gc情况 jmap dump jvm堆内存信息 jmap -histo pid 查看加载的对象实例 jstack 查看java stack和native stack的线程信息 jcmd Native Memory Tracking(简称:NMT) 分析 举例heap内存分布 linux pmap 命令(查看进程的内存映像信息) linux strace 命令(追踪进程执行时的系统调用和所接收的信号) [TOC] Java自带的各类型命令工具 名称 主要作用 jps JVM Process Status Tool, 显示指定系统内所有的HotSpot虚拟机进程 jstat JVM Statistics Monitoring Tool, 用于收集HotSpot虚拟机各方面的运行数据 jinfo Configuration Info for Java, 显示虚拟机配置信息 jmap Memory Map for Java, 生成虚拟机的内存转储快照(heapdump文件) jhat JVM Heap Dump Brower, 用于分析heapdump文件，它会建立一个HTTP/HTML服务器, 让用户可以在浏览器上查看分析结果 jstack Stack Trace for Java, 显示虚拟机的线程快照 jcmd 可以用它来查看Java进程，导出堆、线程信息、执行GC，还可以进行采样分析的一个多功能工具 JVM 内存溢出&内存泄漏 内存溢出：（out of memory）通俗理解就是内存不够，通常在运行大型软件或游戏时，软件或游戏所需要的内存远远超出了你主机内安装的内存所承受大小，就叫内存溢出。 内存泄漏：（Memory Leak）是指程序中己动态分配的堆内存由于某种原因程序未释放或无法释放，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果 泄漏越来越多，会导致内存溢出 JVM调优 根据需求进行JVM规划和预调优 优化JVM运行环境（慢，卡顿） 解决JVM运行过程中的各种问题（full gc, oom等） jps mubi@mubideMacBook-Pro webapps $ jps --help illegal argument: --help usage: jps [-help] jps [-q] [-mlvV] [] Definitions: : [:] 参数 -q：只输出进程 ID -m：输出传入 main 方法的参数 -l：输出完全的包名，应用主类名，jar的完全路径名 -v：输出jvm参数 -V：输出通过flag文件传递到JVM中的参数 这些进程的本地虚拟机唯一ID(Local VIrtual Machine Identifier, LVMID), 对于本地虚拟机进程来说，LVMID与操作系统的进程ID(Process Identifier, PID)是一致的 jstat mubi@mubideMacBook-Pro webapps $ jstat --help invalid argument count Usage: jstat -help|-options jstat - [-t] [-h] [ []] Definitions: An option reported by the -options option Virtual Machine Identifier. A vmid takes the following form: [@[:]] Where is the local vm identifier for the target Java virtual machine, typically a process id; is the name of the host running the target Java virtual machine; and is the port number for the rmiregistry on the target host. See the jvmstat documentation for a more complete description of the Virtual Machine Identifier. Number of samples between header lines. Sampling interval. The following forms are allowed: [\"ms\"|\"s\"] Where is an integer and the suffix specifies the units as milliseconds(\"ms\") or seconds(\"s\"). The default units are \"ms\". Number of samples to take before terminating. -J Pass directly to the runtime system. options -class 显示ClassLoad的相关信息； -compiler 显示JIT编译的相关信息； -gc 显示和gc相关的堆信息； -gccapacity 　　 显示各个代的容量以及使用情况； -gcmetacapacity 显示metaspace的大小 -gcnew 显示新生代信息； -gcnewcapacity 显示新生代大小和使用情况； -gcold 显示老年代和永久代的信息； -gcoldcapacity 显示老年代的大小； -gcutil　　 显示垃圾收集信息； -gccause 显示垃圾回收的相关信息（通-gcutil）,同时显示最后一次或当前正在发生的垃圾回收的诱因； -printcompilation 输出JIT编译的方法信息； 例1（jstat -gc）查看gc信息 mubi@mubideMacBook-Pro webapps $ jps 4402 Jps 2611 Launcher 1812 3800 82874 44363 MacLauncher 28461 ApacheJMeter.jar mubi@mubideMacBook-Pro webapps $ jstat -gc 28461 S0C S1C S0U S1U EC EU OC OU MC MU CCSC CCSU YGC YGCT FGC FGCT GCT 0.0 1024.0 0.0 1024.0 659456.0 158720.0 388096.0 29131.9 51324.0 49395.6 7344.0 6748.7 27 0.919 5 0.921 1.840 mubi@mubideMacBook-Pro webapps $ S0C：第一个幸存区的大小 S1C：第二个幸存区的大小 S0U：第一个幸存区的使用大小 S1U：第二个幸存区的使用大小 EC：伊甸园区的大小 EU：伊甸园区的使用大小 OC：老年代大小 OU：老年代使用大小 MC：方法区大小 MU：方法区使用大小 CCSC:压缩类空间大小 CCSU:压缩类空间使用大小 YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT：垃圾回收消耗总时间 例2（jstat -gccapacity） jstat -gccapacity 8207 NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC MCMN MCMX MC CCSMN CCSMX CCSC YGC FGC 0.0 1048576.0 82944.0 0.0 7168.0 75776.0 0.0 1048576.0 965632.0 965632.0 0.0 1083392.0 40572.0 0.0 1048576.0 6320.0 6 0 NGCMN：年轻代(young)中初始化(最小)的大小(字节) NGCMX：年轻代(young)的最大容量 (字节) NGC：年轻代(young)中当前的容量 (字节) S0C：年轻代中第一个survivor（幸存区）的容量 (字节) S1C：年轻代中第二个survivor（幸存区）的容量 (字节) EC：年轻代中Eden（伊甸园）的容量 (字节) OGCMN：old代中初始化(最小)的大小 (字节) OGCMX：old代的最大容量(字节) OGC：old代当前新生成的容量 (字节) OC：Old代的容量 (字节) MCMN：metaspace(元空间)中初始化(最小)的大小 (字节) MCMX：metaspace(元空间)的最大容量 (字节) MC：metaspace(元空间)当前新生成的容量 (字节) CCSMN：最小压缩类空间大小 CCSMX：最大压缩类空间大小 CCSC：当前压缩类空间大小 YGC：从应用程序启动到采样时年轻代中gc次数 FGC：从应用程序启动到采样时old代(全gc)gc次数 例3 (jstat -gcutil)查看gc情况 jstat -gcutil 8207 1000 5 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 100.00 43.24 3.73 97.04 92.86 6 0.058 0 0.000 0.058 0.00 100.00 43.24 3.73 97.04 92.86 6 0.058 0 0.000 0.058 0.00 100.00 43.24 3.73 97.04 92.86 6 0.058 0 0.000 0.058 0.00 100.00 43.24 3.73 97.04 92.86 6 0.058 0 0.000 0.058 0.00 100.00 43.24 3.73 97.04 92.86 6 0.058 0 0.000 0.058 jmap dump jvm堆内存信息 jmap -dump:format=b,file=xx.hprof jmap -histo 查看加载的对象实例 所有对象：jmap -histo |more 活跃对象：jmap -histo:live |more eg: jmap -histo 23387 num #instances #bytes class name ---------------------------------------------- 1: 79631 39402720 [B 2: 7755 8347472 [I 3: 57423 8173936 [C 4: 34560 1658880 java.nio.HeapByteBuffer 5: 18982 1366704 org.apache.zookeeper.server.Request 6: 51326 1231824 java.lang.String 7: 34971 1119072 java.util.HashMap$Node 8: 19887 954576 java.util.HashMap 9: 21705 847632 [Ljava.lang.Object; 10: 13935 668880 org.apache.zookeeper.txn.TxnHeader jstack 查看java stack和native stack的线程信息 jstack jstack -F 参数选项 -F to force a thread dump. Use when jstack does not respond (process is hung) -m to print both java and native frames (mixed mode) -l long listing. Prints additional information about locks -h or -help to print this help message jcmd 查看当前机器上所有的jvm进程信息 jcmd -l 列出某个jvm进程可以执行的操作 mubi@mubideMacBook-Pro Downloads $ jcmd 22553 help 22553: The following commands are available: JFR.stop JFR.start JFR.dump JFR.check VM.native_memory VM.check_commercial_features VM.unlock_commercial_features ManagementAgent.stop ManagementAgent.start_local ManagementAgent.start GC.rotate_log Thread.print GC.class_stats GC.class_histogram GC.heap_dump GC.run_finalization GC.run VM.uptime VM.flags VM.system_properties VM.command_line VM.version help For more information about a specific command use 'help '. mubi@mubideMacBook-Pro Downloads $ 查看进程内存区域的详情(jvm加上-XX:NativeMemoryTracking=detail) mubi@mubideMacBook-Pro Downloads $ jcmd 22553 VM.native_memory detail > 22553.native_detail mubi@mubideMacBook-Pro Downloads $ head 22553.native_detail 22553: Native Memory Tracking: Total: reserved=6033952KB, committed=2097428KB - Java Heap (reserved=4194304KB, committed=1537024KB) (mmap: reserved=4194304KB, committed=1537024KB) - Class (reserved=1125078KB, committed=85206KB) (classes #14483) mubi@mubideMacBook-Pro Downloads $ Native Memory Tracking(简称:NMT) 分析 参考文档见：NMT 22553: Native Memory Tracking: Total: reserved=6033952KB, committed=2097428KB - Java Heap (reserved=4194304KB, committed=1537024KB) (mmap: reserved=4194304KB, committed=1537024KB) - Class (reserved=1125078KB, committed=85206KB) (classes #14483) (malloc=6870KB #17632) (mmap: reserved=1118208KB, committed=78336KB) - Thread (reserved=130665KB, committed=130665KB) (thread #128) (stack: reserved=130048KB, committed=130048KB) (malloc=404KB #641) (arena=214KB #255) - Code (reserved=254310KB, committed=25318KB) (malloc=4710KB #11332) (mmap: reserved=249600KB, committed=20608KB) - GC (reserved=159021KB, committed=148641KB) (malloc=5777KB #297) (mmap: reserved=153244KB, committed=142864KB) - Compiler (reserved=177KB, committed=177KB) (malloc=46KB #844) (arena=131KB #3) - Internal (reserved=143983KB, committed=143983KB) (malloc=143951KB #18708) (mmap: reserved=32KB, committed=32KB) - Symbol (reserved=21199KB, committed=21199KB) (malloc=17164KB #176970) (arena=4036KB #1) - Native Memory Tracking (reserved=3693KB, committed=3693KB) (malloc=120KB #1832) (tracking overhead=3573KB) - Arena Chunk (reserved=1521KB, committed=1521KB) (malloc=1521KB) Virtual memory map: [0x00000001025e7000 - 0x00000001025ef000] reserved and committed 32KB for Internal from [0x00000001032b4ae8] PerfMemory::create_memory_region(unsigned long)+0x728 [0x00000001032b41ef] PerfMemory::initialize()+0x39 [0x0000000103370c79] Threads::create_vm(JavaVMInitArgs*, bool*)+0x13b [0x000000010312586e] JNI_CreateJavaVM+0x76 reserved表示应用可用的内存大小, committed 为真正使用的内存 From the sample output below, you will see reserved and committed memory. Note that only committed memory is actually used. For example, if you run with -Xms100m -Xmx1000m, the JVM will reserve 1000 MB for the Java Heap. Since the initial heap size is only 100 MB, only 100MB will be committed to begin with. For a 64-bit machine where address space is almost unlimited, there is no problem if a JVM reserves a lot of memory. The problem arises if more and more memory gets committed, which may lead to swapping or native OOM situations. 举例heap内存分布 堆可用内存总大小:4194304KB,映射地址[0x00000006c0000000 - 0x00000007c0000000] committed的映射地址范围为已经使用的内存 58880KB + 80384KB + 1310720KB + 87040KB = 1537024KB(与Native Memory Tracking中的Java Heap一致) [0x00000006c0000000 - 0x00000007c0000000] reserved 4194304KB for Java Heap from [0x00000001033b1e8a] ReservedSpace::initialize(unsigned long, unsigned long, bool, char*, unsigned long, bool)+0x14a [0x00000001033b211e] ReservedHeapSpace::ReservedHeapSpace(unsigned long, unsigned long, bool, char*)+0x78 [0x0000000103380b80] Universe::reserve_heap(unsigned long, unsigned long)+0x84 [0x000000010329fe27] ParallelScavengeHeap::initialize()+0x89 [0x00000006c4e80000 - 0x00000006c8800000] committed 58880KB from [0x00000001032ce10b] PSVirtualSpace::expand_by(unsigned long)+0x3d [0x00000001032c35fa] PSOldGen::expand_by(unsigned long)+0x1c [0x00000001032c3724] PSOldGen::expand(unsigned long)+0xa8 [0x00000001032c380a] PSOldGen::resize(unsigned long)+0xb4 [0x00000006c0000000 - 0x00000006c4e80000] committed 80384KB from [0x00000001032ce10b] PSVirtualSpace::expand_by(unsigned long)+0x3d [0x00000001032c3d14] PSOldGen::initialize_virtual_space(ReservedSpace, unsigned long)+0x72 [0x00000001032c3d85] PSOldGen::initialize(ReservedSpace, unsigned long, char const*, int)+0x49 [0x0000000102ea09b2] AdjoiningGenerations::AdjoiningGenerations(ReservedSpace, GenerationSizer*, unsigned long)+0x36c [0x0000000770000000 - 0x00000007c0000000] committed 1310720KB from [0x00000001032ce10b] PSVirtualSpace::expand_by(unsigned long)+0x3d [0x00000001032ce7f9] PSYoungGen::resize_generation(unsigned long, unsigned long)+0x57 [0x00000001032cf032] PSYoungGen::resize(unsigned long, unsigned long)+0x24 [0x00000001032cc81c] PSScavenge::invoke_no_policy()+0xfb2 [0x000000076ab00000 - 0x0000000770000000] committed 87040KB from [0x00000001032ce10b] PSVirtualSpace::expand_by(unsigned long)+0x3d [0x00000001032cee37] PSYoungGen::initialize_virtual_space(ReservedSpace, unsigned long)+0x6f [0x00000001032cedb9] PSYoungGen::initialize(ReservedSpace, unsigned long)+0x41 [0x0000000102ea0962] AdjoiningGenerations::AdjoiningGenerations(ReservedSpace, GenerationSizer*, unsigned long)+0x31c linux pmap 命令(查看进程的内存映像信息) 参考文档见：linux pmap 帮助文档 The pmap command reports the memory map of a process or processes. 参数 -x extended Show the extended format.(显示扩展格式) -d device Show the device format.(显示设备格式) -q quiet Do not display some header/footer lines.(不显示头尾行) -V show version Displays version of program.(显示版本) 字段说明 Address: start address of map Kbytes: size of map in kilobytes RSS: resident set size in kilobytes Dirty: dirty pages (both shared and private) in kilobytes Mode: permissions on map: read, write, execute, shared, private (copy on write) Mapping: file backing the map, or '[ anon ]' for allocated memory, or '[ stack ]' for the program stack Offset: offset into the file Device: device name (major:minor) linux strace 命令(追踪进程执行时的系统调用和所接收的信号) 参考文档见：linux strace 帮助文档 -p pid Attach to the process with the process ID pid and begin tracing. The trace may be terminated at any time by a keyboard interrupt signal ( CTRL -C). strace will respond by detaching itself from the traced process(es) leaving it (them) to continue running. Multiple -p options can be used to attach to up to 32 processes in addition to command (which is optional if at least one -p option is given). Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-30 18:12:24 "},"content/db_cache/LFU.html":{"url":"content/db_cache/LFU.html","title":"LFU","keywords":"","body":"[TOC] LFU Least Frequently Used ,最近最少使用算法 这个缓存算法使用一个计数器来记录条目被访问的频率。通过使用LFU缓存算法，最低访问数的条目首先被移除。这个方法并不经常使用，因为它无法对一个拥有最初高访问率之后长时间没有被访问的条目缓存负责。 leetcode java (460题) 注意capacity=0的特殊情况，以及get,put 频率改变的情况 // 普通双向链表,有一个初始的dummyNode class DoubleList { private DoubleNode head, tail; // 头尾虚节点 private int size; // 链表当前size public DoubleList() { head = new DoubleNode(0, 0); tail = new DoubleNode(0, 0); head.next = tail; tail.prev = head; size = 0; } // O(1) // 头插 public void addFirst(DoubleNode x) { x.next = head.next; x.prev = head; head.next.prev = x; head.next = x; size++; } // O(1) // 删除链表中的 x 节点（x 一定存在） public void remove(DoubleNode x) { x.prev.next = x.next; x.next.prev = x.prev; size--; } // O(1) // 删除链表中最后一个节点，并返回该节点 public DoubleNode removeLast() { if (tail.prev == head) { return null; } DoubleNode last = tail.prev; remove(last); return last; } public DoubleNode getFirst() { if (tail.prev == head) { return null; } return head.next; } public DoubleNode putFirst(DoubleNode node) { remove(node); addFirst(node); return head.next; } // 返回链表长度 public int size() { return size; } public boolean isEmpty() { return size == 0; } // 双向链表的节点 class DoubleNode { public int key, val; public DoubleNode next, prev; public DoubleNode(int k, int v) { this.key = k; this.val = v; } } } class LFUCache { // 频率对应的双向链表 Map freDoubleListMap; // key 对应的 频率 Map keyFreMap; // key 对应 在链表中的位置 Map keyNodeMap; int cap; int minFre; public LFUCache(int capacity) { cap = capacity; freDoubleListMap = new HashMap<>(); keyFreMap = new HashMap<>(); keyNodeMap = new HashMap<>(); minFre = 0; } public int get(int key) { if(cap == 0){ return -1; } if (keyFreMap.containsKey(key)) { // 频率加1, 删除老的，添加新的 DoubleList.DoubleNode node = keyNodeMap.get(key); int oldFre = keyFreMap.get(key); freDoubleListMap.get(oldFre).remove(node); // 最小频率不会骤然增加, 如下情况最小频率要加1，否则还保持最小频率 if(minFre == oldFre && freDoubleListMap.get(oldFre).isEmpty()) { minFre ++; } int newFre = oldFre + 1; if (freDoubleListMap.containsKey(newFre)) { freDoubleListMap.get(newFre).addFirst(node); } else { // 新的双向链表 DoubleList doubleList = new DoubleList(); doubleList.addFirst(node); freDoubleListMap.put(newFre, doubleList); } keyNodeMap.put(key, freDoubleListMap.get(newFre).getFirst()); keyFreMap.put(key, newFre); return node.val; } else { return -1; } } public void put(int key, int value) { if(cap == 0){ return; } if (keyFreMap.containsKey(key)) { // 频率加1, 删除老的，添加新的 DoubleList.DoubleNode node = keyNodeMap.get(key); int oldFre = keyFreMap.get(key); freDoubleListMap.get(oldFre).remove(node); // 最小频率不会骤然增加, 如下情况最小频率要加1，否则还保持最小频率 if(minFre == oldFre && freDoubleListMap.get(oldFre).isEmpty()) { minFre ++; } node.val = value; int newFre = oldFre + 1; if (freDoubleListMap.containsKey(newFre)) { freDoubleListMap.get(newFre).addFirst(node); } else { // 新的双向链表 DoubleList doubleList = new DoubleList(); doubleList.addFirst(node); freDoubleListMap.put(newFre, doubleList); } keyNodeMap.put(key, freDoubleListMap.get(newFre).getFirst()); keyFreMap.put(key, newFre); } else { // 容量满了，删除最小频率，最后访问的那个节点 if (keyFreMap.size() == cap) { DoubleList.DoubleNode rmNode = freDoubleListMap.get(minFre).removeLast(); keyNodeMap.remove(rmNode.key); keyFreMap.remove(rmNode.key); if(freDoubleListMap.get(minFre).isEmpty()){ minFre ++; } } DoubleList doubleList; if (freDoubleListMap.containsKey(1)) { doubleList = freDoubleListMap.get(1); } else { // new doubleList doubleList = new DoubleList(); } // new node DoubleList.DoubleNode newNode = doubleList.new DoubleNode(key, value); doubleList.addFirst(newNode); freDoubleListMap.put(1, doubleList); keyNodeMap.put(key, freDoubleListMap.get(1).getFirst()); keyFreMap.put(key, 1); minFre = 1; } } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-16 08:40:23 "},"content/db_cache/LRU.html":{"url":"content/db_cache/LRU.html","title":"LRU","keywords":"","body":"[TOC] LRU(Least Recently Used) 选择最近最久未使用的页面予以淘汰 leetcode 146题，eg LRUCache cache = new LRUCache( 2 /* 缓存容量 */ ); cache.put(1, 1); cache.put(2, 2); cache.get(1); // 返回 1 cache.put(3, 3); // 该操作会使得关键字 2 作废 cache.get(2); // 返回 -1 (未找到) cache.put(4, 4); // 该操作会使得关键字 1 作废 cache.get(1); // 返回 -1 (未找到) cache.get(3); // 返回 3 cache.get(4); // 返回 4 来源：力扣（LeetCode） 链接：https://leetcode-cn.com/problems/lru-cache 著作权归领扣网络所有。商业转载请联系官方授权，非商业转载请注明出处。 Java的一个求解如下 双向链表(带头节点) + Map // 普通双向链表,有一个初始的dummyNode class DoubleList { private DoubleNode head, tail; // 头尾虚节点 private int size; // 链表当前size public DoubleList() { head = new DoubleNode(0, 0); tail = new DoubleNode(0, 0); head.next = tail; tail.prev = head; size = 0; } // O(1) // 头插 public void addFirst(DoubleNode x) { x.next = head.next; x.prev = head; head.next.prev = x; head.next = x; size++; } // O(1) // 删除链表中的 x 节点（x 一定存在） public void remove(DoubleNode x) { x.prev.next = x.next; x.next.prev = x.prev; size--; } // O(1) // 删除链表中最后一个节点，并返回该节点 public DoubleNode removeLast() { if (tail.prev == head) { return null; } DoubleNode last = tail.prev; remove(last); return last; } public DoubleNode getFirst() { if (tail.prev == head) { return null; } return head.next; } public DoubleNode putFirst(DoubleNode node) { remove(node); addFirst(node); return head.next; } // 返回链表长度 public int size() { return size; } // 双向链表的节点 class DoubleNode { public int key, val; public DoubleNode next, prev; public DoubleNode(int k, int v) { this.key = k; this.val = v; } } } class LRUCache { DoubleList doubleList; Map mp; int cap; public LRUCache(int capacity) { cap = capacity; mp = new HashMap<>(); doubleList = new DoubleList(); } public int get(int key) { if (mp.containsKey(key)) { // 已存在，位置要重置 DoubleList.DoubleNode node = mp.get(key); DoubleList.DoubleNode node1 = doubleList.putFirst(node); mp.put(key, node1); return node1.val; } else { // 不存在返回-1 return -1; } } public void put(int key, int value) { if ( mp.containsKey(key) ) { // 已存在，位置要重置，且要修改value DoubleList.DoubleNode node = mp.get(key); doubleList.remove(node); node.val = value; doubleList.addFirst(node); mp.put(key, doubleList.getFirst()); } else { if( doubleList.size() == cap) { DoubleList.DoubleNode lastNode = doubleList.removeLast(); mp.remove(lastNode.key); } // 添加新节点 DoubleList.DoubleNode newNode = doubleList.new DoubleNode(key,value); doubleList.addFirst(newNode); mp.put(key, doubleList.getFirst()); } } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-27 13:50:23 "},"content/db_cache/consistent_hash.html":{"url":"content/db_cache/consistent_hash.html","title":"一致性Hash","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 一致性Hash 问题引入 一致性Hash算法 节点少，数据倾斜问题 [TOC] 一致性Hash 问题引入 在解决分布式系统中负载均衡的问题时候可以使用Hash算法让固定的一部分请求落到同一台服务器上，这样每台服务器固定处理一部分请求（并维护这些请求的信息），起到负载均衡的作用。 但是普通的除留余数法（hash(比如用户id)%服务器机器数）算法伸缩性很差，当新增或者下线服务器机器时候，用户id与服务器的映射关系会大量失效。一致性hash则利用hash环对其进行了改进。 一致性Hash算法 将整个哈希值空间映射成一个虚拟的圆环，整个哈希空间的取值范围为0~2^32-1（即是一个32位无符号整型） 将各个服务器使用Hash进行一个哈希，具体可以选择服务器的ip或主机名作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置 数据如何定位到服务器？ 将数据key使用相同的函数Hash计算出哈希值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。 现假设Node C不幸宕机，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node D。一般的，在一致性哈希算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它不会受到影响。 现假设新增了服务器X，可以看到此时对象A、B、D不会受到影响，只有C对象被重定位到Node X，则受影响的数据仅仅是新服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器）之间数据，其它数据也不会受到影响。 节点少，数据倾斜问题 引入虚拟节点 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-26 21:02:14 "},"content/db_cache/bloom.html":{"url":"content/db_cache/bloom.html","title":"布隆过滤器","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 布隆过滤器 算法过程 [TOC] 布隆过滤器 /wiki/Bloom_filter 本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 “某样东西一定不存在或者可能存在”。 讲述布隆过滤器的原理之前，我们先思考一下，通常你判断某个元素是否存在用的是什么？应该蛮多人回答 HashMap 吧，确实可以将值映射到 HashMap 的 Key，然后可以在 O(1) 的时间复杂度内返回结果，效率奇高。但是 HashMap 的实现也有缺点，例如存储容量占比高，考虑到负载因子的存在，通常空间是不能被用满的，而一旦你的值很多例如上亿的时候，那 HashMap 占据的内存大小就变得很可观了。 算法过程 首先需要k个hash函数，每个函数可以把key散列成为1个整数 初始化时，需要一个长度为n比特的数组，每个比特位初始化为0 某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位置为1 判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，认为在集合中。 优点： 不需要存储key，节省空间 缺点： 算法判断key在集合中时，有一定的概率key其实不在集合中 无法删除 随着数据的增加，误判率随之增加；只能判断数据是否一定不存在，而无法判断数据是否一定存在。 主要命令 bf.add 添加元素 bf.exists 查询元素是否存在 bf.madd 一次添加多个元素 bf.mexists 一次查询多个元素是否存在 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-26 21:03:52 "},"content/db_cache/cache.html":{"url":"content/db_cache/cache.html","title":"缓存","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 缓存 缓存的使用 缓存穿透 什么是缓存穿透（cache penetration） Why does cache penetration occur?（如何产生？） The hazard of cache penetration(缓存穿透的危害) 如何解决缓存穿透 解决1:缓存空对象(Cache empty data)（缺点） 解决2:BloomFilter BloomFilter的缺点 缓存雪崩（cache avalanche） 缓存雪崩的概念 如何解决 Using a Cache Cluster to Ensure High Availability of Caches Using Hystrix（限流） 事后恢复缓存 Hotspot data set is invalid (热点数据集失效) What is the hotspot data set failure? 解决方法 Facebook's Memcached Multiget Hole: More Machines != More Capacity(无底洞问题) 产生原因 危害（更多的机器不代表更多的性能） hash的两种方式 针对性的优化 如何保证缓存与数据库双写时一致的问题 Cache Aside Pattern 缓存/数据库更新 先更新数据库，再更新缓存 先删除缓存，再更新数据库，下一次读操作会更新缓存(删除缓存方案1) 先更新数据库，再删除缓存，下一次读操作会更新缓存(删除缓存方案2) [TOC] 缓存 单词短语 解释 penetration n. 穿透; 渗透; 进入; 插入 avalanche n. 雪崩; 山崩; 3 major problems and solutions in the cache world 缓存的使用 In most Internet applications: When the business system initiates a certain query request, it first determines whether the data exists in the cache; If there is a cache, return the data directly; If the cache does not exist, query the database again and return the data. 业务查询 =》 判断缓存命中 =》 直接返回数据结果 否则： 查询数据库并更新缓存，然后返回数据结果 缓存分担部分请求压力 但缓存不可能把所有的数据都缓存起来(需要有过期时间和删除策略） 缓存穿透 什么是缓存穿透（cache penetration） 缓存穿透是说：收到一个请求，但是该请求在缓存中不存在，只能去数据库中查询，然后再放进缓存。但当有好多请求同时访问同一个数据时，业务系统把这些请求全发到了数据库；或者恶意构造一个逻辑上不存在的数据，然后大量发送这个请求，这样每次都会被发送到数据库去处理，最终导致数据库挂掉。 即：请求的数据在缓存大量不命中，导致请求都走数据库。缓存穿透如果发生了，也可能把我们的数据库搞垮，导致整个服务瘫痪！ Why does cache penetration occur?（如何产生？） There are many reasons for cache penetration, which are generally as follows: Malicious attacks deliberately create a large amount of non-existent data to request our services. Since these data do not exist in the cache, massive requests fall into the database, which may cause the database to crash. Code logic error. This is the programmer’s pot, nothing to say, must be avoided in development! 单词短语 解释 malicious adj.恶意的，有敌意的； 蓄意的； 预谋的； 存心不良的 attack vt.& vi.攻击，进攻，抨击；n.攻击； 抨击；（队员等的）进攻；（疾病）侵袭；vt.抨击； 非难； 侵袭； 损害 deliberate adj.故意的； 蓄意的； 深思熟虑的； 慎重的；vt.权衡；vi.熟虑； 商讨； pot n.罐； 一罐； （某种用途的）容器； 陶盆 锅；vt.把…栽入盆中； 种盆栽； 台球、普尔和斯诺克击（球）入袋； 射杀; vi.随手射击； The hazard of cache penetration(缓存穿透的危害) If there are massive data that does not exist in the query request, then these massive requests will fall into the database, and the database pressure will increase dramatically, which may lead to system crash. (You have to know that the most vulnerable in the current business system is IO, a little bit It will collapse under pressure, so we have to think of ways to protect it). 单词短语 解释 hazard vt.冒险； 使遭受危险；n.危险； 冒险的事； 机会； 双骰子游戏 massive adj.大的，重的； 大块的，大量的； 魁伟的，结实的； 大规模的 fall into 分成； 掉进，陷入； 堕入； 陷于 dramatically adv.戏剧性地，引人注目地； 显著地，剧烈地； vulnerable adj.（地方）易受攻击的； 易受伤的； 易受批评的； [桥牌]已成局的 collapse vi.折叠； 倒塌； 崩溃； （尤指工作劳累后）坐下; vt.使倒塌； 使坍塌； 使瓦解；n.垮台； （身体的）衰弱； 如何解决缓存穿透 当我们从数据库找不到的时候，我们也将这个空对象设置到缓存里边去。下次再请求的时候，就可以从缓存里边获取了。一般会将空对象设置一个较短的过期时间。 由于请求的参数是不合法的(每次都请求不存在的参数)，于是我们可以使用布隆过滤器(BloomFilter)或者压缩filter提前拦截，不合法就不让这个请求到数据库层！ 解决1:缓存空对象(Cache empty data)（缺点） 指标不治本(空数据对象本身缓存也是有过期时间的) 大量空值会占用缓存内存 解决2:BloomFilter It needs to add a barrier（n.障碍； 屏障； 栅栏； 分界线vt.把…关入栅栏； 用栅栏围住；） before the cache, which ；stores all the keys that exist in the current database. 将数据库中所有的查询条件，放入布隆过滤器中；当一个查询请求过来时，先经过布隆过滤器进行查，如果判断请求查询值存在，则继续查；如果判断请求查询不存在，则直接丢弃。 springboot demo项目 低并发,定时任务去每天更新bloomFilter,维护每天的一个bloomFilter 初始预热，动态新增 BloomFilter的缺点 存在误判(当一个布隆过滤器判断一个数据在集合中存在时，有一定的可能性误判;不存在的则100%正确)。如果bloom filter中存储的是黑名单，那么可以通过建立一个白名单来存储可能会误判的元素 删除困难。一个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断。可以采用Counting Bloom Filter Counting Bloom Filter:将标准Bloom Filter位数组的每一位扩展为一个小的计数器（Counter），在插入元素时给对应的k（k为哈希函数个数）个Counter的值分别加1，删除元素时给对应的k个Counter的值分别减1。Counting Bloom Filter通过多占用几倍的存储空间的代价，给Bloom Filter增加了删除操作 缓存雪崩（cache avalanche） 缓存雪崩的概念 If the cache goes down for some reason, the massive query request that was originally blocked by the cache will flock to the database like a mad dog. At this point, if the database can’t withstand this huge pressure, it will collapse. This is the cache avalanche. 单词短语 解释 go down 停止； 被接受； 沉下； 被打败 flock to 成群结队地走向…； mad adj.疯狂的； 猛烈的； 着迷的； 〔口语〕愤怒的，生气的；vt.使疯狂； withstand vt.经受，承受，禁得起； 反抗；vi.反抗； 耐得住，禁得起； Redis挂掉了，请求全部都走数据库了 对缓存数据设置相同的过期时间，导致某段时间内缓存全部都失效，请求全部走数据库了 缓存雪崩如果发生了，很可能就把我们的数据库搞垮，导致整个服务瘫痪！ 如何解决 对于“对缓存数据设置相同的过期时间，导致某段时间内缓存失效，请求全部走数据库。”这种情况，非常好解决： 解决方法：在缓存的时候给过期时间加上一个随机值，这样就会大幅度的减少缓存在同一时间过期。 对于“Redis挂掉了，请求全部走数据库”这种情况，我们可以有以下的思路： Using a Cache Cluster to Ensure High Availability of Caches 事发前：实现Redis的高可用(主从架构+Sentinel 或者Redis Cluster)，尽量避免Redis挂掉这种情况发生。 Using Hystrix（限流） Hystrix is ​​an open source “anti-avalanche tool” that reduces losses after avalanches by blowing, degrading, and limiting currents. 单词短语 解释 anti n.& adj.反对者，反对论者反对的；抵抗 losses n.损失( loss的名词复数 )； 损耗； 失败； 降低 degrade vt.降低，贬低； 使降级； 降低…身份； 使丢脸；vt.& vi.（使）退化，降解，分解； 降解； 撤职，免职； 降低品格[身价，价值（等）] 事发中：万一Redis真的挂了，我们可以设置本地缓存(ehcache)+限流(hystrix)，尽量避免我们的数据库被干掉(起码能保证我们的服务还是能正常工作的) 事后恢复缓存 事发后：redis持久化，重启后自动从磁盘上加载数据，快速恢复缓存数据。 Hotspot data set is invalid (热点数据集失效) What is the hotspot data set failure? We usually set an expiration time for the cache. After the expiration time, the database will be deleted directly by the cache, thus ensuring the real-time performance of the data to a certain extent. However, for some hot data with very high requests, once the valid time has passed, there will be a large number of requests falling on the database at this moment, which may cause the database to crash. The process is as follows: If a hotspot data fails, then when there is a query request [req-1] for the data again, it will go to the database query. However, from the time the request is sent to the database to the time the data is updated into the cache, since the data is still not in the cache, the query request arriving during this time will fall on the database, which will cause the database Enormous pressure. In addition, when these request queries are completed, the cache is updated repeatedly. 解决方法 设置热点数据永远不过期；设置不同的过期时间 使用互斥锁 业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候，不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。 public String get(key) { String value = redis.get(key); if (value == null) { //代表缓存值过期 //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db if (redis.setnx(key_mutex, 1, 3 * 60) == 1) { //代表设置成功 value = db.get(key); redis.set(key, value, expire_secs); redis.del(key_mutex); } else { //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可 sleep(50); get(key); //重试 } } return value; } We can use the lock mechanism that comes with the cache. When the first database query request is initiated, the data in the cache will be locked; at this time, other query requests that arrive at the cache will not be able to query the field, and thus will be blocked waiting; After a request completes the database query and caches the data update value, the lock is released; at this time, other blocked query requests can be directly retrieved from the cache. When a hotspot data fails, only the first database query request is sent to the database, and all other query requests are blocked, thus protecting the database. However, due to the use of a mutex, other requests will block waiting and the throughput of the system will drop. This needs to be combined with actual business considerations to allow this. （当出现热点数据失效时，只有第一个请求会发送到数据库，其它的请求都会被阻塞，这样能保护数据库；当然，由于使用了mutex，其它的请求会被阻塞而进行等待，这会降低系统的吞吐率。这需要与实际的业务考虑相结合。） 第一个获取到锁，当更新或者从数据库获取完成后再释放锁，其它的请求只需要牺牲一定的等待时间，即可直接从缓存中继续获取数据。 Mutex locks can avoid the problem of database corruption caused by the failure of ahotspot data. In actual business, there are often scenes where a batch of hotspot data fails at the same time. So how do you prevent database overload for this scenario? 单词短语 解释 corruption n.腐败； 贪污； 贿赂； 变体 scenario n.设想； 可能发生的情况； 剧情梗概； Facebook's Memcached Multiget Hole: More Machines != More Capacity(无底洞问题) Facebook’s Memcached Multiget Hole: More machines != More Capacity 用一句通俗的话总结：更多的机器不代表更多的性能，所谓“无底洞”就是说投入越多不一定产出越多。 产生原因 键值数据库或者缓存系统，由于通常采用hash函数将key映射到对应的实例，造成key的分布与业务无关，但是由于数据量、访问量的需求，需要使用分布式后（无论是客户端一致性哈性、redis-cluster、codis），批量操作比如批量获取多个key(例如redis的mget操作)，通常需要从不同实例获取key值，相比于单机批量操作只涉及到一次网络操作，分布式批量操作会涉及到多次网络io。 eg:一次mget操作，需要从多个缓存实例去获取数据，这包含了多次网络；如果mget的key都在一个实例中，那么就只要一次网络操作 危害（更多的机器不代表更多的性能） 客户端一次批量操作会涉及多次网络操作，也就意味着批量操作会随着实例的增多，耗时会不断增大。 服务端网络连接次数变多，对实例的性能也有一定影响。 hash的两种方式 分布方式 特点 典型产品 哈希分布 1.数据分散度高,2.键值分布与业务无关,3.无法顺序访问,4.支持批量操作 一致性哈希memcacheredisCluster其他缓存产品 顺序分布 1.数据分散度易倾斜,2.键值分布与业务相关,3.可以顺序访问,4.支持批量操作 BigTableHbase 针对性的优化 命令本身的效率：例如sql优化，命令优化 网络次数：减少通信次数 降低接入成本:长连/连接池,NIO等。 IO访问合并:O(n)到O(1)过程:批量接口(mget) 批量操作的一些方案 方案 优点 缺点 网络IO 串行mget 1.编程简单2.少量keys，性能满足要求 大量keys请求延迟严重 O(keys) 串行IO 1.编程简单2.少量节点，性能满足要求 大量node延迟严重 O(nodes) 并行IO 1.利用并行特性2.延迟取决于最慢的节点 1.编程复杂2.超时定位较难 O(max_slow(node)) hash tags 性能最高 1.tag-key业务维护成本较高2.tag分布容易出现数据倾斜 O(1) 如何保证缓存与数据库双写时一致的问题 Cache Aside Pattern cache-aside Load data on demand into a cache from a data store. This can improve performance and also helps to maintain consistency between data held in the cache and data in the underlying data store. Applications should implement a strategy that helps to ensure that the data in the cache is as up-to-date as possible, but can also detect and handle situations that arise when the data in the cache has become stale. stale 英[steɪl] 美[steɪl] adj. 不新鲜的; (空气) 污浊的; (烟味) 难闻的; 陈腐的; 没有新意的; 老掉牙的; n. （牛马、骆驼的） 尿; 缓存/数据库更新 给缓存设置过期时间，是保证最终一致性的解决方案; 理解如下 对存入缓存的数据设置过期时间，所有的写操作以数据库为准，对缓存操作只是尽最大努力即可。也就是说如果数据库写成功，缓存更新失败，那么只要到达过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存 先更新数据库，再更新缓存 --------------------------------------->时间线 线程A更新了数据库 线程A更新了缓存 线程B更新了数据库 线程B更新了缓存 请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存了，导致脏数据 先删除缓存，再更新数据库，下一次读操作会更新缓存(删除缓存方案1) --------------------------------------->时间线 先删除缓存 再更新数据库 下一次读操作会更新缓存 读操作 设置缓存 读脏 读脏 先更新数据库，再删除缓存，下一次读操作会更新缓存(删除缓存方案2) --------------------------------------->时间线 先更新数据库 再删除缓存 下一次读操作会更新缓存 读操作(且缓存失效） 读老数据库 更新缓存（更新的是旧的数据库数据） 这个条件需要发生在读缓存时缓存失效，而且有一个并发的写操作。实际上数据库的写操作会比读操作慢得多，而且还要加锁，而读操作必需在写操作前进入数据库操作，又要晚于写操作更新缓存，所有这些条件都具备的概率并不大。但是为了避免这种极端情况造成脏数据所产生的影响，我们还是要为缓存设置过期时间。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-26 21:16:25 "},"content/distributed_design/flow_limit.html":{"url":"content/distributed_design/flow_limit.html","title":"限流","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 限流 常见限流算法 通过限制单位时间段内的调用量来限流（控制访问速率） 通过限制系统的并发调用程度来限流（控制并发数量） [TOC] 限流 常见限流算法 计数器（固定窗口）算法 滑动窗口算法 漏桶算法 令牌桶算法 通过限制单位时间段内的调用量来限流（控制访问速率） 通过限制系统的并发调用程度来限流（控制并发数量） Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-07 22:39:25 "},"content/java_thread_concurrent/cpu_cache.html":{"url":"content/java_thread_concurrent/cpu_cache.html","title":"CPU,缓存","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 缓存一致性 CPU提速优化 指令乱序例子程序 三级缓存 MESI协议 总线锁和缓存锁 缓存行 cache line 两个变量在一个缓存行中 消除伪共享 原因 [TOC] 缓存一致性 计算机体系架构 CPU提速优化 CPU优化的两点 指令乱序执行（CPU执行更多的指令） CPU高速缓存（匹配速度慢的主存，也是能执行更多的指令） cpu中为了能够让指令的执行尽可能地并行起来，从而发明了流水线技术。但是如果两条指令的前后存在依赖关系，比如数据依赖，控制依赖等，此时后一条语句就必需等到前一条指令完成后，才能开始。cpu为了提高流水线的运行效率，会做出比如： 对无依赖的前后指令做适当的乱序和调度； 对控制依赖的指令做分支预测； 对读取内存等的耗时操作，做提前预读； 等等。 这些都可能会导致指令乱序 指令乱序例子程序 public class Main { static int x, y, a, b; public static void main(String[] args) throws Exception{ int i = 0; while (true) { x = 0; y = 0; b = 0; a = 0; Thread A = new Thread(new Runnable() { @Override public void run() { a = 1; x = b; } }); Thread B = new Thread(new Runnable() { @Override public void run() { b = 1; y = a; } }); A.start(); B.start(); A.join(); B.join(); i++; if(x == 0 && y == 0){ System.err.println(i + \" \" + x + \" \" + y); break; } } System.out.println(\"main end\"); } } 三级缓存 L1高速缓存：也叫一级缓存。一般内置在内核旁边，是与CPU结合最为紧密的CPU缓存。一次访问只需要2~4个时钟周期 L2高速缓存：也叫二级缓存。空间比L1缓存大，速度比L1缓存略慢。一次访问约需要10多个时钟周期 L3高速缓存：也叫三级缓存。部分单CPU多核心的才会有的缓存，介于多核和内存之间。存储空间已达Mb级别，一次访问约需要数十个时钟周期。 当CPU要读取一个数据时，首先从L1缓存查找，命中则返回；若未命中，再从L2缓存中查找，如果还没有则从L3缓存查找（如果有L3缓存的话）。如果还是没有，则从内存中查找，并将读取到的数据逐级放入缓存。 eg: MESI协议 多个处理器都涉及同一块主内存区域的更改时，将导致各自的缓存数据不一致？如何解决？ 当某个cpu修改缓存行数据时，其它的cpu通过监听机制获悉共享缓存行的数据被修改，会使其共享缓存行失效。本cpu会将修改后的缓存行写回到主内存中。此时其它的cpu如果需要此缓存行共享数据，则从主内存中重新加载，并放入缓存，以此完成了缓存一致性。 mesi wiki 总线锁和缓存锁 总线锁是把CPU和内存的通信给锁住了；使得在锁定期间，其它处理器不能操作内存的其它数据，这样开销较大 缓存锁不需锁定总线，只需要“锁定”被缓存的共享对象（实际为：缓存行）即可；接受到lock指令，通过缓存一致性协议，维护本处理器内部缓存和其它处理器缓存的一致性。相比总线锁，会提高cpu利用率。 缓存行 cache line 程序局部性原理（这里解释为：访问内存或缓存但某个位置，顺带但把紧邻的位置一起读取出来） 缓存行越大，局部性空间效率越高，但读取时间慢 缓存行越小，局部性空间效率越低，但读取时间快 折中取：64字节 消除伪共享 两个变量在一个缓存行中 import java.util.concurrent.CountDownLatch; public class Main { private static class T { public volatile long x; } public static T[] arr = new T[2]; static { arr[0] = new T(); arr[1] = new T(); } // 一亿次 static int FOR_COUNT = 100_000_000; public static void main(String[] args) throws Exception{ CountDownLatch latch = new CountDownLatch(2); Thread t1 = new Thread(()->{ for (int i = 0; i { for (int i = 0; i 程序输出：2990 ms,2952 ms,2490 ms，大概3秒左右 消除伪共享 import java.util.concurrent.CountDownLatch; public class Main { private static class T { public volatile long p1, p2, p3, p4, p5, p6, p7; public volatile long x; public volatile long p8, p9, p10, p11, p12, p13, p14; } public static T[] arr = new T[2]; static { arr[0] = new T(); arr[1] = new T(); } // 一亿次 static int FOR_COUNT = 100_000_000; public static void main(String[] args) throws Exception{ CountDownLatch latch = new CountDownLatch(2); Thread t1 = new Thread(()->{ for (int i = 0; i { for (int i = 0; i 程序输出：900 ms,894 ms,1189 ms，1秒多 原因 private static class T { public volatile long p1, p2, p3, p4, p5, p6, p7; public volatile long x; public volatile long p8, p9, p10, p11, p12, p13, p14; } 数组如下，arr[0].x 与 arr[1].x 不会在一个缓存行中；这样修改用的各自的缓存行，互不影响 56字节 x(8字节) 56字节 56字节 x(8字节) 56字节 配合import sun.misc.Contended;的@Contended注解(注意加上-XX:-RestrictContended参数) Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-17 20:00:03 "},"content/db_cache/io.html":{"url":"content/db_cache/io.html","title":"局部性原理&磁盘IO","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 局部性原理 几种常见的局部性 硬盘读写基础 硬盘构成 磁盘读写的动作 IOPS(每秒的IO次数) 硬盘吞吐量 磁盘预读 页 SSD 随机/顺序访问 [TOC] 局部性原理 当一个数据被用到时，其附近的数据也通常会马上被使用。程序运行期间所需要的数据通常比较集中。由于磁盘顺序读取的效率很高(不需要寻道时间，只需很少的旋转时间) ，因此对于具有局部性的程序来说，磁盘预读可以提高1/0效率。预读的长度一般为页(page)的整倍数。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页(在许多操作系统中，页得大小通常为4k) ，主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。 几种常见的局部性 时间局部性（Temporal Locality）：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。 程序循环、堆栈等是产生时间局部性的原因。 空间局部性（Spatial Locality）：在最近的将来将用到的信息很可能与正在使用的信息在空间地址上是临近的。 顺序局部性（Order Locality）：在典型程序中，除转移类指令外，大部分指令是顺序进行的。顺序执行和非顺序执行的比例大致是5:1。此外，对大型数组访问也是顺序的。 指令的顺序执行、数组的连续存放等是产生顺序局部性的原因。 硬盘读写基础 硬盘构成 盘面：盘面类似于光盘的数据存储面，由许多同心圆的磁道组成的盘面。一块硬盘有多个盘面 柱面：垂直方向由多个盘面组成，读取或者写入数据都是垂直方向的从第一个盘面同一磁道一直写入到最后一个盘面，然后数据还没写完的话在切换磁道 磁道：盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道;同一磁道再被划分成多个扇区 扇区：存储数据，每个扇区包括512个字节的数据和一些其他信息（每个扇区是磁盘的最小存储单元） 磁盘读写的动作 一次访盘请求（读/写）完成过程由三个动作组成： 寻道（时间）：磁头移动定位到指定磁道 旋转延迟（时间）：等待指定扇区从磁头下旋转经过 数据传输（时间）：数据在磁盘与内存之间的实际传输 因此在磁盘上读取扇区数据（一块数据）所需时间： Ti/o=tseek +tla + n *twm tseek 为寻道时间 tla为旋转时间 twm 为传输时间 IOPS(每秒的IO次数) 1000ms / (平均寻道时间+平均旋转延迟时间+平均数据读取的时间）ms 硬盘吞吐量 每秒IO吞吐量 = IOPS * 平均每次IO的数据大小 磁盘预读 磁盘读取的一系列动作，导致其读写很慢；要提高效率，显然要尽量减少磁盘IO，为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会磁盘预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存，这通常是一页的整倍数 页 页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行 SSD 固态驱动器（Solid State Disk或Solid State Drive，简称SSD），俗称固态硬盘，固态硬盘是用固态电子存储芯片阵列而制成的硬盘，因为台湾英语里把固体电容称之为Solid而得名。SSD由控制单元和存储单元（FLASH芯片、DRAM芯片）组成。固态硬盘在接口的规范和定义、功能及使用方法上与普通硬盘的完全相同，在产品外形和尺寸上也完全与普通硬盘一致。被广泛应用于军事、车载、工控、视频监控、网络监控、网络终端、电力、医疗、航空、导航设备等诸多领域。 优点(来自百度百科)： 读写速度快：采用闪存作为存储介质，读取速度相对机械硬盘更快。固态硬盘不用磁头，寻道时间几乎为0。持续写入的速度非常惊人，固态硬盘厂商大多会宣称自家的固态硬盘持续读写速度超过了500MB/s！固态硬盘的快绝不仅仅体现在持续读写上，随机读写速度快才是固态硬盘的终极奥义，这最直接体现在绝大部分的日常操作中。与之相关的还有极低的存取时间，最常见的7200转机械硬盘的寻道时间一般为12-14毫秒，而固态硬盘可以轻易达到0.1毫秒甚至更低。 防震抗摔性：传统硬盘都是磁碟型的，数据储存在磁碟扇区里。而固态硬盘是使用闪存颗粒（即mp3、U盘等存储介质）制作而成，所以SSD固态硬盘内部不存在任何机械部件，这样即使在高速移动甚至伴随翻转倾斜的情况下也不会影响到正常使用，而且在发生碰撞和震荡时能够将数据丢失的可能性降到最小。相较传统硬盘，固态硬盘占有绝对优势。 低功耗：固态硬盘的功耗上要低于传统硬盘。 无噪音：固态硬盘没有机械马达和风扇，工作时噪音值为0分贝。基于闪存的固态硬盘在工作状态下能耗和发热量较低（但高端或大容量产品能耗会较高）。内部不存在任何机械活动部件，不会发生机械故障，也不怕碰撞、冲击、振动。由于固态硬盘采用无机械部件的闪存芯片，所以具有了发热量小、散热快等特点。 工作温度范围大：典型的硬盘驱动器只能在5到55摄氏度范围内工作。而大多数固态硬盘可在-10~70摄氏度工作。固态硬盘比同容量机械硬盘体积小、重量轻。固态硬盘的接口规范和定义、功能及使用方法上与普通硬盘的相同，在产品外形和尺寸上也与普通硬盘一致。其芯片的工作温度范围很宽（-40~85摄氏度）。 轻便：固态硬盘在重量方面更轻，与常规1.8英寸硬盘相比，重量轻20-30克 随机/顺序访问 随机访问(Random Access) 指的是本次IO所给出的扇区地址和上次IO给出扇区地址相差比较大，这样的话磁头在两次IO操作之间需要作比较大的移动动作才能重新开始读/写数据 顺序访问(Sequential Access) 如果当次IO给出的扇区地址与上次IO结束的扇区地址一致或者是接近的话，那磁头就能很快的开始这次IO操作，这样的多个IO操作称为顺序访问 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-03 21:45:04 "},"content/db_cache/mysql.html":{"url":"content/db_cache/mysql.html","title":"MySQL","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 MySQL 数据库引擎有哪些？ 数据库范式 第一范式 第二范式 第三范式 BCNF范式 数据表join操作 多表连接的三种方式详解 hash join、merge join、nested loop nested loop（嵌套循环） Hash Join merge join InnoDb 页（Page）是 Innodb 存储引擎用于管理数据的最小磁盘单位 记录在页中的存储 innodb ibd文件 innodb 页类型 实践分析ibd文件 查看数据表的行格式 查看ibd文件 分析第4个页：B-tree Node类型 先分析File Header(38字节-描述页信息) 再分析Page Header（56字节-记录页的状态信息） 分析Infimum + Supremum Record (26字节-两个虚拟行记录) User Record(表中的数据记录) COMPACT行记录格式 File Tailer(最后8字节) 附：二进制文件查看小工具 页分裂/页合并 innodb数据的存储(.frm & .ibd) 页合并 页分裂 索引 MySql 5.6默认索引（InnoDB） 为什么要用B+ Tree而不是B Tree? MySql中B+树索引可以分为聚集索引和非聚集索引 聚集索引（clustered index） 非聚集索引 对比和注意点 为什么InnoDB要有主键？并且推荐使用整型自增主键？ 索引类型 联合索引 联合索引为什么是最左前缀匹配？ MySql有哪些锁？ 慢查询优化？ [TOC] MySQL 官方文档 mysql 5.6 我的博客专题 数据库引擎有哪些？ InnoDB Myisam Memory 说明： InnoDB,Myisam的默认索引是B+Tree，Memory的默认索引是hash InnoDB支持事务，支持外键，支持行锁，写入数据时操作快，MySQL5.6版本以上才支持全文索引 Myisam不支持事务。不支持外键，支持表锁，支持全文索引，读取数据快 Memory所有的数据都保留在内存中,不需要进行磁盘的IO所以读取的速度很快, 但是一旦关机,表的结构会保留但是数据就会丢失,表支持Hash索引，因此查找速度很快 数据库范式 第一范式 每个属性都不可再分 第二范式 每一名学生的学号、姓名、系名、系主任这些数据重复多次。每个系与对应的系主任的数据也重复多次——数据冗余过大 假如学校新建了一个系，但是暂时还没有招收任何学生（比如3月份就新建了，但要等到8月份才招生），那么是无法将系名与系主任的数据单独地添加到数据表中去的 （注１）——插入异常 注１：根据三种关系完整性约束中实体完整性的要求，关系中的码（注２）所包含的任意一个属性都不能为空，所有属性的组合也不能重复。为了满足此要求，图中的表，只能将学号与课名的组合作为码，否则就无法唯一地区分每一条记录 码：关系中的某个属性或者某几个属性的组合，用于区分每个元组（可以把“元组”理解为一张表中的每条记录，也就是每一行）。 假如将某个系中所有学生相关的记录都删除，那么所有系与系主任的数据也就随之消失了（一个系所有学生都没有了，并不表示这个系就没有了）。——删除异常 假如李小明转系到法律系，那么为了保证数据库中数据的一致性，需要修改三条记录中系与系主任的数据。——修改异常 “若在一张表中，在属性（或属性组）X的值确定的情况下，必定能确定属性Y的值，那么就可以说Y函数依赖于X，写作X → Y” 第二范式：在1NF的基础上，非码属性必须完全依赖于候选码（在1NF基础上消除非主属性对主码的部分函数依赖） 选课（学号，课名，分数） 学生（学号，姓名，系名，系主任） 对于选课表，其码是（学号，课名），主属性是学号和课名，非主属性是分数，学号确定，并不能唯一确定分数，课名确定，也不能唯一确定分数，所以不存在非主属性分数对于码 （学号，课名）的部分函数依赖，所以此表符合2NF的要求。 对于学生表，其码是学号，主属性是学号，非主属性是姓名、系名和系主任，因为码只有一个属性，所以不可能存在非主属性对于码 的部分函数依赖，所以此表符合2NF的要求。 第三范式 在2NF基础上，任何非主属性不依赖于其它非主属性（在2NF基础上消除传递依赖） 学生（学号，姓名，系名，系主任） 对于学生表，主码为学号，主属性为学号，非主属性为姓名、系名和系主任。因为 学号 → 系名，同时 系名 → 系主任，所以存在非主属性系主任对于码学号的传递函数依赖，所以学生表的设计，不符合3NF的要求。 选课（学号，课名，分数） 学生（学号，姓名，系名） 系（系名，系主任） BCNF范式 巴斯-科德范式（BCNF）是第三范式（3NF）的一个子集，即满足巴斯-科德范式（BCNF）必须满足第三范式（3NF）。通常情况下，巴斯-科德范式被认为没有新的设计规范加入，只是对第二范式与第三范式中设计规范要求更强，因而被认为是修正第三范式，也就是说，它事实上是对第三范式的修正，使数据库冗余度更小。这也是BCNF不被称为第四范式的原因 数据表join操作 INNER JOIN: 内连接是最常见的一种连接，只连接匹配的行 LEFT JOIN: 返回左表的全部行和右表满足ON条件的行，如果左表的行在右表中没有匹配，那么这一行右表中对应数据用NULL代替 RIGHT JOIN: 返回右表的全部行和左表满足ON条件的行，如果右表的行在左表中没有匹配，那么这一行左表中对应数据用NULL代替 FULL OUTER JOIN: 会从左表 和右表 那里返回所有的行。如果其中一个表的数据行在另一个表中没有匹配的行，那么对面的数据用NULL代替 CROSS JOIN: 把表A和表B的数据进行一个N*M的组合，即笛卡尔积 多表连接的三种方式详解 hash join、merge join、nested loop nested loop（嵌套循环） 驱动表(也叫外表)和被驱动表(也叫非驱动表，还可以叫匹配表，亦可叫内表)，简单来说，驱动表就是主表，left join 中的左表就是驱动表，right join 中的右表是驱动表。一个是驱动表，那另一个就只能是非驱动表了 在 join 的过程中，其实就是从驱动表里面依次(注意理解这里面的依次)取出每一个值，然后去非驱动表里面进行匹配，那具体是怎么匹配的呢？这就是我们接下来讲的这三种连接方式： (Simple Nested-Loop Join )暴力匹配的方式；如果 table A 有10行，table B 有10行，总共需要执行10 x 10 = 100次查询 (Index Nested-Loop Join)这个 Index 是要求非驱动表上要有索引，有了索引以后可以减少匹配次数，匹配次数减少了就可以提高查询的效率了,eg:左边就是普通列的存储方式，右边是树结构索引, 能减少查询次数 (Block Nested-Loop Join) 理想情况下，用索引匹配是最高效的一种方式，但是在现实工作中，并不是所有的列都是索引列，这个时候就需要用到 Block Nested-Loop Join 方法了，这种方法与第一种方法比较类似，唯一的区别就是:会把驱动表中 left join 涉及到的所有列(不止是用来on的列，还有select部分的列)先取出来放到一个缓存区域，然后再去和非驱动表进行匹配，这种方法和第一种方法相比所需要的匹配次数是一样的，差别就在于驱动表的列数不同，也就是数据量的多少不同。所以虽然匹配次数没有减少，但是总体的查询性能还是有提升的。 适用于小表与小表的连接 Hash Join hash join仅仅在join的字段上没有索引时才起作用，在此之前，我们不建议在没有索引的字段上做join操作，因为通常中这种操作会执行得很慢，但是有了hash join，它能够创建一个内存中的hash表，代替之前的nested loop，使得没有索引的等值join性能提升很多。 配置hash join功能是否开启： optimizer_switch 中的 hash_join=on/off，默认为on sql语句中指定HASH_JOIN或者NO_HASH_JOIN 限制： hash join只能在没有索引的字段上有效 hash join只在等值join条件中有效 hash join不能用于left join和right join 适用于小表与大表的连接 merge join merge join第一个步骤是确保两个关联表都是按照关联的字段进行排序。如果关联字段有可用的索引，并且排序一致，则可以直接进行merge join操作； 两个表都按照关联字段排序好之后，merge join操作从每个表取一条记录开始匹配，如果符合关联条件，则放入结果集中；否则，将关联字段值较小的记录抛弃，从这条记录对应的表中取下一条记录继续进行匹配，直到整个循环结束。 function sortMerge(relation left, relation right, attribute a) var relation output var list left_sorted := sort(left, a) // Relation left sorted on attribute a var list right_sorted := sort(right, a) var attribute left_key, right_key var set left_subset, right_subset // These sets discarded except where join predicate is satisfied advance(left_subset, left_sorted, left_key, a) advance(right_subset, right_sorted, right_key, a) while not empty(left_subset) and not empty(right_subset) if left_key = right_key // Join predicate satisfied add cartesian product of left_subset and right_subset to output advance(left_subset, left_sorted, left_key, a) advance(right_subset, right_sorted, right_key, a) else if left_key right_key advance(right_subset, right_sorted, right_key, a) return output // Remove tuples from sorted to subset until the sorted[1].a value changes function advance(subset out, sorted inout, key out, a in) key := sorted[1].a subset := emptySet while not empty(sorted) and sorted[1].a = key insert sorted[1] into subset remove sorted[1] merge join操作本身是非常快的，但是merge join前进行的排序可能会相当耗时 它首先根据R和S的join key分别对两张表进行排序，然后同时遍历排序后的R和S 其I/O复杂度可以表示为O[p(R) + p(S) + p(R) · logp(R) + p(S) · logp(S)] 附：归并排序是稳定排序，最好，最坏，平均时间复杂度均为O(nlogn)。 InnoDb Mysql innodb refman 页（Page）是 Innodb 存储引擎用于管理数据的最小磁盘单位 File Header: 文件头部，页的一些通用信息（38字节） page Header: 页面头部,数据页专有的一些信息（56字节） infimum+supremum: 行记录最小值和最大值，两个虚拟的行记录（26字节） user recorders: 实际存储的行记录内容（不确定） free space: 页中尚未使用的空间（不确定） Page Directory: 页中的某些记录的相对位置（不确定） File Tailer: 校验页是否完整（8字节） 记录在页中的存储 1.当一个记录需要插入页的时候，会从free space划分空间到user recorders 2.Free Space部分的空间全部被User Records部分替代掉之后，也就意味着这个页使用完了，如果还有新的记录插入的话，就需要去申请新的页了。 innodb ibd文件 ibd文件是以页为单位进行管理的，页通常是以16k为单位，所以ibd文件通常是16k的整数倍 innodb 页类型 名称 十六进制 解释 FIL_PAGE_INDEX 0x45BF B+树叶节点 FIL_PAGE_UNDO_LOGO 0x0002 UNDO LOG页 FIL_PAGE_INODE 0x0003 索引节点 FIL_PAGE_IBUF_FREE_LIST 0x0004 InsertBuffer空闲列表 FIL_PAGE_TYPE_ALLOCATED 0x0000 该页的最新分配 FIL_PAGE_IBUF_BITMAP 0x0005 InsertBuffer位图 FIL_PAGE_TYPE_SYS 0x0006 系统页 FIL_PAGE_TYPE_TRX_SYS 0x0007 事务系统数据 FIL_PAGE_TYPE_FSP_HDR 0x0008 FILE SPACE HEADER FIL_PAGE_TYPE_XDES 0x0009 扩展描述页 FIL_PAGE_TYPE_BLOB 0x000A BLOB页 实践分析ibd文件 mubi@mubideMacBook-Pro bin $ mysql -uroot -p123456 mysql: [Warning] Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 109 Server version: 5.6.40 MySQL Community Server (GPL) Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql> use test; Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed mysql> select * from tb_user; +------------+--------+----------+-------+-------------+----------+ | id | userID | password | name | phone | address | +------------+--------+----------+-------+-------------+----------+ | 1 | 00001 | 123456 | zhang | 15133339999 | Shanghai | | 2 | 00002 | 123456 | wang | 15133339999 | Beijing | | 4 | 0003 | NULL | abc | NULL | NULL | | 6 | 0003 | NULL | abc | NULL | NULL | | 7 | 0004 | 123456 | tom | 110 | beijing | | 10 | 0004 | 123456 | tom | 110 | beijing | | 2147483647 | 0004 | 123456 | tom | 110 | beijing | +------------+--------+----------+-------+-------------+----------+ 7 rows in set (0.00 sec) mysql> 查看数据表的行格式 mysql> show table status like 'tb_user'\\G; *************************** 1. row *************************** Name: tb_user Engine: InnoDB Version: 10 Row_format: Compact Rows: 6 Avg_row_length: 2730 Data_length: 16384 Max_data_length: 0 Index_length: 16384 Data_free: 0 Auto_increment: 2147483647 Create_time: 2020-03-21 16:10:06 Update_time: NULL Check_time: NULL Collation: utf8_general_ci Checksum: NULL Create_options: Comment: 1 row in set (0.00 sec) ERROR: No query specified mysql> 查看ibd文件 使用py_innodb_page_info工具（https://github.com/happieme/py_innodb_page_info） 注意到文件大小114688字节（114688 = 16 1024 7）即有7个页（要分析哪个页直接定位到二进制文件到开始，然后分析即可） 分析第4个页：B-tree Node类型 page offset 00000003, page type , page level >>> hex(3 * 16 * 1024) '0xc000' >>> hex(4 * 16 * 1024) '0x10000' >>> 先分析File Header(38字节-描述页信息) 2D A1 2D 57 -> 数据页的checksum值 00 00 00 03 -> 页号（偏移量）,当前是第3页 FF FF FF FF -> 目前只有一个数据页，无上一页 FF FF FF FF -> 目前只有一个数据页，无下一页 00 00 00 04 6F 65 24 CF -> 该页最后被修改的LSN 45 BF -> 页的类型，0x45BF代表数据页，刚好这页是数据页 00 00 00 00 00 00 00 00 -> 独立表空间，该值为0 00 00 00 06 -> 表空间的SPACE ID 再分析Page Header（56字节-记录页的状态信息） 参见：innodb-page-header 标识 字节数 解释 本次值:说明 PAGE_N_DIR_SLOTS 2 number of directory slots in the Page Directory part; initial value = 2 00 02,2个槽位 PAGE_HEAP_TOP 2 record pointer to first record in heap 01 ED，堆第一个开始位置的偏移量，也即空闲偏移量 PAGE_N_HEAP 2 number of heap records; initial value = 2 80 0A PAGE_FREE 2 record pointer to first free record 01 1C PAGE_GARBAGE 2 \"number of bytes in deleted records\" 00 20，删除的记录字节 PAGE_LAST_INSERT 2 record pointer to the last inserted record 01 C5，最后插入记录的位置偏移 PAGE_DIRECTION 2 either PAGE_LEFT, PAGE_RIGHT, or PAGE_NO_DIRECTION 00 02，自增长的方式进行行记录的插入，方向向右 PAGE_N_DIRECTION 2 number of consecutive inserts in the same direction, for example, \"last 5 were all to the left\" 00 02 PAGE_N_RECS 2 number of up[ser records 00 07，共7条有效记录数 PAGE_MAX_TRX_ID 8 the highest ID of a transaction which might have changed a record on the page (only set for secondary indexes) 00 00 00 00 00 00 00 00 PAGE_LEVEL 2 level within the index (0 for a leaf page) 00 00 PAGE_INDEX_ID 8 identifier of the index the page belongs to 00 00 00 00 00 00 00 16 PAGE_BTR 10 \"file segment header for the leaf pages in a B-tree\" (this is irrelevant here) 00 00 00 06 00 00 00 02 00 F2 PAGE_LEVEL 10 \"file segment header for the non-leaf pages in a B-tree\" (this is irrelevant here) 00 00 00 06 00 00 00 02 00 32 0xc000 + 01 ED = 0xC1ED地址后面的都是空闲的 0xc000 + 01 C5 = 0xC1C5最后一条记录 分析Infimum + Supremum Record (26字节-两个虚拟行记录) infimum: n. 下确界; supremum: n. 上确界; Infimum和Suprenum Record用来限定记录的边界，Infimum是比页中任何主键值都要小的值，Suprenum 是指比任何可能大值还要大的值，这两个值在页创建时被建立，并且在任何情况下都不会被删除。Infimum和Suprenum与行记录组成单链表结构，查询记录时，从Infimum开始查找，如果找不到结果会直到查到最后的suprenum为止，然后通过Page Header中的FIL_PAGE_NEXT指针跳转到下一个page继续从Infimum开始逐个查找 #Infimum伪行记录 01 00 02 00 20/*recorder header*/ 69 6E 66 69 6D 75 6D 00/*只有一个列的伪行记录，记录内容就是Infimum（多了一个0x00字节） */ #Supremum伪行记录 08 00 0B 00 00/*recorder header*/ 73 75 70 72 65 6D 75 6D/*只有一个列的伪行记录，记录内容就是Supremum*/ infimum行记录的recorder header部分，最后2个字节位00 20表示下一个记录的位置的偏移量 User Record(表中的数据记录) 用户所有插入的记录都存放在这里，默认情况下记录跟记录之间没有间隙，但是如果重用了已删除记录的空间，就会导致空间碎片。每个记录都有指向下一个记录的指针，但是没有指向上一个记录的指针。记录按照主键顺序排序。即，用户可以从数据页最小记录开始遍历，直到最大的记录，这包括了所有正常的记录和所有被delete-marked记录，但是不会访问到被删除的记录(PAGE_FREE) COMPACT行记录格式 行格式的首部是一个非NULL变长字段长度列表，而且是按照列的顺序逆序放置的。当列的长度小于255字节，用1字节表示，若大于255个字节，用2个字节表示，变长字段的长度最大不可以超过2个字节（这也很好地解释了为什么MySQL中varchar的最大长度为65535，因为2个字节为16位，即pow(2,16)-1=65536）。第二个部分是NULL标志位，该位指示了该行数据中是否有NULL值，1个字节表示。该部分所占的字节应该为bytes。接下去的部分是为记录头信息（record header），固定占用5个字节（40位），每位的含义如下 预留位1 1（bit位） 没有使用 预留位2 1 没有使用 delete_mask 1 标记该记录是否被删除 min_rec_mask 1 标记该记录是否为B+树的非叶子节点中的最小记录 n_owned 4 表示当前槽管理的记录数 heap_no 13 表示当前记录在记录堆的位置信息 record_type 3 表示当前记录的类型，0表示普通记录，1表示B+树非叶节点记录，2表示最小记录，3表示最大记录 next_record 16 表示下一条记录的相对位置 0000c070: 73 75 70 72 65 6D 75 6D 08 0B 05 06 05 00 00 00 supremum........ 0000c080: 10 00 3F 80 00 00 01 00 00 00 00 27 06 86 00 00 ..?........'.... 0000c090: 01 39 01 10 30 30 30 30 31 31 32 33 34 35 36 7A .9..00001123456z 0000c0a0: 68 61 6E 67 31 35 31 33 33 33 33 39 39 39 39 53 hang15133339999S 0000c0b0: 68 61 6E 67 68 61 69 07 0B 04 06 05 00 00 00 18 hanghai......... 08 0B 05 06 05: 8(address字段) 11(phone字段) 5(name字段) 6(password字段) 5(userID字段)，一个逆序的方式表示可变长字段列表 00 : Null值列表 00 00 10 00 3F：记录头信息 5个字节，40bit 0000 0000 0000 0000 00001 0000 0000 0000 0011 1111 80 00 00 01：自增主键（有符号的int类型），1 00 00 00 00 27 06：隐藏列DB_TRX_ID 86 00 00 01 39 01 10：隐藏列DB_ROLL_PTR 30 30 30 30 31 ： 00001 31 32 33 34 35 36 ： 123456 7A 68 61 6E 67 : zhang 31 35 31 33 33 33 33 39 39 39 39 : 15133339999 53 68 61 6E 67 68 61 69 : beijing File Tailer(最后8字节) 7E 75 29 30 6F 65 24 CF 注意到File Header该页最后被修改的LSN：00 00 00 04 6F 65 24 CF，可以看到后4个字节和File Tailer的后4个字节相同 附：二进制文件查看小工具 使用python可以方便的进行二进制相关的转换 hex(16) # 10进制转16进制 oct(8) # 10进制转8进制 bin(8) # 10进制转2进制 >>> hex(6 * 16 * 1024) '0x18000' >>> hex(3 * 16 * 1024) '0xc000' >>> vscode可以安装hexdump for VSCode插件 页分裂/页合并 innodb-page-merging-and-page-splitting InnoDB不是按行的来操作的，它可操作的最小粒度是页，页加载进内存后才会通过扫描页来获取行/记录。 innodb数据的存储(.frm & .ibd) 在 InnoDB 存储引擎中，所有的数据都被逻辑地存放在表空间中，表空间（tablespace）是存储引擎中最高的存储逻辑单位，在表空间的下面又包括段（segment）、区（extent）、页（page）, 页中存放实际的数据记录行 MySQL 使用 InnoDB 存储表时，会将表的定义和数据索引等信息分开存储，其中前者存储在.frm文件中，后者存储在.ibd文件中(ibd文件既存储了数据也存储了索引) 在创建表时，会在磁盘上的 datadir 文件夹中生成一个 .frm 的文件，这个文件中包含了表结构相关的信息 页合并 删除记录时会设置record的flaged标记为删除，当一页中删除记录超过MERGE_THRESHOLD（默认页体积的50%）时，InnoDB会开始寻找最靠近的页（前或后）看看是否可以将两个页合并以优化空间使用。例如：合并操作使得页#5保留它之前的数据，并且容纳来自页#6的数据。页#6变成一个空页，可以接纳新数据。 页分裂 页可能填充至100%，在页填满了之后，下一页会继续接管新的记录。但如果下一页页没有足够空间去容纳新（或更新）的记录，那么 创建新页 判断当前页（页#10）可以从哪里进行分裂（记录行层面） 移动记录行 重新定义页之间的关系 例如：页#10没有足够空间去容纳新记录，页#11也同样满了, #10要分列为两列, 且页的前后指针关系要发生改变 #9 #10 #11 #12 #13 ... #8 #10 #14 #11 #12 #13 ... 索引 MySql 5.6默认索引（InnoDB） mysql> show variables like '%storage_engine%'; ERROR 2006 (HY000): MySQL server has gone away No connection. Trying to reconnect... Connection id: 112 Current database: test +----------------------------+--------+ | Variable_name | Value | +----------------------------+--------+ | default_storage_engine | InnoDB | | default_tmp_storage_engine | InnoDB | | storage_engine | InnoDB | +----------------------------+--------+ 3 rows in set (0.06 sec) mysql> 为什么要用B+ Tree而不是B Tree? 1行记录假如有1KB；如果B Tree（其非叶子节点是要存储数据的，显然存储有限）；B-Tree为了存储大量数据，不得不提高树的高度，这就会导致IO次数增多。所以有B+ Tree MySql中B+树索引可以分为聚集索引和非聚集索引 聚集索引（clustered index） 索引中键值的逻辑顺序决定了表中相应行的物理顺序（索引中的数据物理存放地址和索引的顺序是一致的），可以这么理解：只要是索引是连续的，那么数据在存储介质上的存储位置也是连续的。 聚集索引就像我们根据拼音的顺序查字典一样，可以大大的提高效率。在经常搜索一定范围的值时，通过索引找到第一条数据，根据物理地址连续存储的特点，然后检索相邻的数据，直到到达条件截至项。 聚集索引：叶子节点包含了完整的数据记录 Cluster index is a type of index which sorts the data rows in the table on their key values. In the Database, there is only one clustered index per table. A clustered index defines the order in which data is stored in the table which can be sorted in only one way. So, there can be an only a single clustered index for every table. In an RDBMS, usually, the primary key allows you to create a clustered index based on that specific column. 非聚集索引 索引的逻辑顺序与磁盘上的物理存储顺序不同。非聚集索引的键值在逻辑上也是连续的，但是表中的数据在存储介质上的物理顺序是不一致的，即记录的逻辑顺序和实际存储的物理顺序没有任何联系。索引的记录节点有一个数据指针指向真正的数据存储位置。 A Non-clustered index stores the data at one location and indices at another location. The index contains pointers to the location of that data. A single table can have many non-clustered indexes as an index in the non-clustered index is stored in different places. For example, a book can have more than one index, one at the beginning which displays the contents of a book unit wise while the second index shows the index of terms in alphabetical order. A non-clustering index is defined in the non-ordering field of the table. This type of indexing method helps you to improve the performance of queries that use keys which are not assigned as a primary key. A non-clustered index allows you to add a unique key for a table. 对比和注意点 innodb-index-types 如果一个主键被定义了，那么这个主键就是作为聚集索引 如果没有主键被定义，那么该表的第一个唯一非空索引会被作为聚集索引 如果没有主键也没有合适的唯一索引，那么innodb内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键是一个6个字节的列，该列的值会随着数据的插入进行自增 聚集索引的特点 聚集索引表记录的排列顺序和索引的排列顺序保持一致，所以查询效率相当快。只要找到第一个索引记录的值，其余的连续性的记录也一定是连续存放的。 聚集索引的缺点就是修改起来比较慢，因为它需要保持表中记录和索引的顺序一致，在插入新记录的时候就会对数据也重新做一次排序。 InnoDB表数据本身就是一个按B+Tree组织的一个索引结构文件，叶节点包含了完整的数据记录（.ibd文件）;MyIsam数据和索引文件是分开的（.MYD文件，.MYI文件） myisam innodb 为什么InnoDB要有主键？并且推荐使用整型自增主键？ 为什么InnoDB要有主键？（InnoDB设计如此） 如果一个主键被定义了，那么这个主键就是作为聚集索引 如果没有主键被定义，那么该表的第一个唯一非空索引会被作为聚集索引 如果没有主键也没有合适的唯一索引，那么innodb内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键是一个6个字节的列，该列的值会随着数据的插入进行自增 推荐使用整型？ B+Tree搜索比对，显然整型比字符串比较快（原因1），整型占用空间小（原因2） 推荐使用自增？ 补充：hash索引，直接定位到记录的磁盘地址（等值查找）区间查找用hash行不同，所以hash索引用的少 自增是页不断的创建新增，后面加，调整小；如果非自增，涉及到页分裂/创建，B+Tree调整大 B+Tree 可视化操作 索引类型 联合索引 仍然是B+Tree, 索引中包含多个字段，按照联合索引的先后顺序 联合索引为什么是最左前缀匹配？ 数据结构底层决定（严格的按照第一个，第二个，第三个字段一个一个匹配），不符合最左匹配则需要全局扫描了 MySql有哪些锁？ 慢查询优化？ Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-06 08:39:34 "},"content/java_io_net/io_interrupte.html":{"url":"content/java_io_net/io_interrupte.html","title":"IO和中断","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 中断 中断分类 中断号(中断种类是有限的) 中断隐指令 I/O控制方式 程序控制IO（轮询） 中断驱动IO DMA（Direct Memory Access） I/O zero copy 传统I/O,用户进程读写的几次拷贝 mmap 内存映射文件(memory-mapped file，用户内存到文件系统页的映射) [TOC] 中断 一台典型的个人PC中，中断结构如下图： 设备完成工作，产生一个中断，他是通过在分配给它的一条总线信号线上置起信号而产生中断的。该信号主板上的中断控制器芯片检测到，由中断控制器芯片决定做什么。 在总线上置起中断信号，中断信号导致CPU停止当前正在做的工作并且开始做其它的事情。地址线上的数字被用做指向一个成为中断向量(interrupt vector)的表格的所用，以便读取一个新的程序计数器。这个程序计数器指向相应的中断服务过程的开始。 中断分类 中断源 中断是指由于某种事件的发生（硬件或者软件的），计算机暂停执行当前的程序，转而执行另一程序，以处理发生的事件，处理完毕后又返回原程序继续作业的过程。中断是处理器一种工作状态的描述。我们把引起中断的原因，或者能够发出中断请求信号的来源统称为中断源。 中断分类:外部中断/内部中断 外部设备请求中断。一般的外部设备（如键盘、打印机和A / D转换器等）在完成自身的操作后，向CPU发出中断请求，要求CPU为他服务。 故障强迫中断。计算机在一些关键部位都设有故障自动检测装置。如运算溢出、存储器读出出错、外部设备故障、电源掉电以及其他报警信号等，这些装置的报警信号都能使CPU中断，进行相应的中断处理。由计算机硬件异常或故障引起的中断，也称为内部异常中断。 实时时钟请求中断。在控制中遇到定时检测和控制，为此常采用一个外部时钟电路（可编程）控制其时间间隔。需要定时时，CPU发出命令使时钟电路开始工作，一旦到达规定时间，时钟电路发出中断请求，由CPU转去完成检测和控制工作。 数据通道中断。数据通道中断也称直接存储器存取（DMA）操作中断，如磁盘、磁带机或CRT等直接与存储器交换数据所要求的中断。 程序自愿中断。CPU执行了特殊指令（自陷指令）或由硬件电路引起的中断是程序自愿中断，是指当用户调试程序时，程序自愿中断检查中间结果或寻找错误所在而采用的检查手段，如断点中断和单步中断等。 中断分类:可屏蔽中断和非屏蔽中断 不可屏蔽中断源一旦提出请求，cpu必须无条件响应，而对于可屏蔽中断源的请求，cpu可以响应，也可以不响应。 cup一般设置两根中断请求输入线：可屏蔽中断请求INTR(Interrupt Require)和不可屏蔽中断请求NMI(Nonmaskable Interrupt)。对于可屏蔽中断，除了受本身的屏蔽位的控制外，还都要受一个总的控制，即CPU标志寄存器中的中断允许标志位IF(Interrupt Flag)的控制，IF位为1，可以得到CPU的响应，否则，得不到响应。IF位可以有用户控制，指令STI或Turbo c的Enable()函数，将IF位置1(开中断)，指令CLI或Turbo_c 的Disable()函数，将IF位清0(关中断)。 可屏蔽中断：CPU关中断，则CU不响应中断；中断屏蔽字，CPU响应优先级高的中断 中断号(中断种类是有限的) 寻找中断服务程序的入口地址？ 中断向量表（硬件向量法）(存储在内存中的某个位置) 中断识别程序 (软件查询法) 中断处理过程 问题1: 中断向量表用于保存：服务程序的入口地址 问题2: 中断响应是在：一条执行执行之末；（缺页中断：是在一条指令执行中间，执行执行不下去了；在执行中，不得不去响应中断） 问题3: 主存故障引起的中断是：机器校验中断（bootstrap会对主存，磁盘进行自检） 中断隐指令 中断隐指令引导CPU在响应中断信号时随机做出的一系列动作，这些动作是在检测到中断信号后便随即发生的，因而不能由软件来完成，而是由硬件来处理。中断隐指令并不是指令系统中的一条真正的指令，它没有操作码，所以中断隐指令是一种不允许、也不可能为用户使用的特殊指令。其所完成的操作主要有： 保存现场 为了保证在中断服务程序执行完毕能正确返回原来的程序，必须将原来程序的断点（即程序计数器(PC)的内容）保存起来。断点可以压入堆栈，也可以存入主存的特定单元中。 暂不允许中断(关中断) 暂不允许中断即关中断。在中断服务程序中，为了保护中断现场（即CPU主要寄存器的内容）期间不被新的中断所打断，必须要关中断，从而保证被中断的程序在中断服务程序执行完毕之后能接着正确地执行下去。并不是所有的计算机都在中断隐指令中由硬件自动地关中断，也有些计算机的这一操作是由软件（中断服务程序）来实现的。但是大部分计算机还是靠硬件来进行相关动作，因为硬件具有更好的可靠性和实时性。 引出中断服务程序 引出中断服务程序的实质就是取出中断服务程序的入口地址送程序计数器（PC）。对于向量中断和非向量中断，引出中断服务程序的方法是不相同的。 中断分发 硬件中断处理。在Windows所支持的硬件平台上，外部I/O中断进入到中断控制器的一根线上。该控制器接着在某一根线上中断处理器。处理器一旦被中断，就会询问控制器以获得此中断请求（IRQ）。中断控制器将该IRQ转译成一个中断号，利用该编号作为索引，在一个称为中断分发表（IDT）的结构中找到一个IDT项，并且将控制权传递给恰当的中断分发例程。每个处理器都有单独的IDT，所以，如果合适，不同的处理器可以运行不同的ISR。 I/O控制方式 cpu与外设 程序控制IO（轮询） CPU要不断地查询外围设备的工作状态，一旦外围设备“准备好”或“不忙”，即可进行数据的传送；主机与外设只能串行工作，主机一个时间段只能与一个外设进行通讯，CPU效率低。 CPU：轮询，忙等待 中断驱动IO 首先每次的IO中断，都带来CPU的上下文切换 优点：CPU没有轮询检测I/O，只是根据I/O操作去向相应的设备控制器发出一条I/O命令，理论上可以去做其它的事情； 但是有大量数据传输时，CPU基本全程都在等待中断结束：在等待I/O数据的传输处理（CPU要等待中断返回，并没有去做别的事情） DMA（Direct Memory Access） 用来提供在外设和存储器之间或者存储器和存储器之间的高速数据传输。不需要依赖于CPU的大量中断负载。DMA控制器接管了数据读写请求，减少CPU的负担。 DMA向CPU申请权限，让DMA进行I/O操作；CPU不需要在负责大量的I/O操作而无法处理其它事情了，此处有DMA总线 传统I/O流即类似DMA方式 如果大量I/O请求，DMA申请多，DMA总线冲突，一样有问题？ I/O zero copy 传统I/O,用户进程读写的几次拷贝 写：用户态->内核态->DMA CPU copy, DMA copy 读：DMA->内核态->用户态 DMA copy, CPU copy mmap mmap将一个文件或者其它对象映射进内存。文件被映射到多个页上，如果文件的大小不是所有页的大小之和，最后一个页不被使用的空间将会清零 内存映射文件(memory-mapped file，用户内存到文件系统页的映射) 由一个文件到一块内存的映射；文件的数据就是这块区域内存中对应的数据，读写文件中的数据，即直接对这块内存区域的地址操作，减少了内存复制的环节。 使用内存映射文件处理存储于磁盘上的文件时，将不必再对文件执行I/O操作，这意味着在对文件进行处理时将不必再为文件申请并分配缓存，所有的文件缓存操作均由系统直接管理，由于取消了将文件数据加载到内存、数据从内存到文件的回写以及释放内存块等步骤，使得内存映射文件在处理大数据量的文件时能起到相当重要的作用。 好处： 用户进程把文件数据当作内存，所以无需发起read()或 write()系统调用。 当用户进程碰触到映射内存空间，页错误会自动产生，从而将文件数据从磁盘读进内存。如果用户修改了映射内存空间，相关页会自动标记为脏，随后刷新到磁盘，文件得到更新。 操作系统的虚拟内存子系统会对页进行智能高速缓存，自动根据系统负载进行内存管理。 数据总是按页对齐的，无需执行缓冲区拷贝。 大型文件使用映射，无需耗费大量内存，即可进行数据拷贝。 映射文件区域的能力取决于于内存寻址的大小。在32位机器中，你不能访问超过4GB或2 ^ 32（以上的文件）。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-01 15:51:05 "},"content/java_io_net/io_basic.html":{"url":"content/java_io_net/io_basic.html","title":"IO基础","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Java IO 基础 How Java I/O Works Internally at Lower Level? 缓冲区 缓冲流 用户空间,内核空间,磁盘 文件IO 系统调用和文件读写 用户I/O缓冲区的类型 用户空间 & 内核空间 为什么不直接 让磁盘控制器把数据送到用户空间的缓冲区呢? vfs(虚拟文件系统) I/O模型：同步/阻塞概念 阻塞与非阻塞(等待I/O时的状态) 同步与异步（用户线程与内核的消息交互方式） 用水壶烧水的例子说明[同步/阻塞] 网络IO模型演进 传统的BIO(Blocking I/O 阻塞IO) selector(NIO Single Thread 模型) NIO reactor模式（多线程轮询） AIO（异步IO） IO复用 select poll epoll [TOC] Java IO 基础 流是一组有顺序的，有起点和终点的字节集合，是对数据传输的总称或抽象。即数据在两设备间的传输称为流，流的本质是数据传输，根据数据传输特性将流抽象为各种类，方便更直观的进行数据操作。 字节流 InputStream/OutStream 字节流能处理所有类型的数据（如图片、avi等），而字符流只能处理字符类型的数据。 字符流 Reader/Writer How Java I/O Works Internally at Lower Level? 缓冲区 计算机访问外部设备或文件，要比直接访问内存慢的多。如果我们每次调用read()方法或者write()方法访问外部的设备或文件，CPU就要花上最多的时间是在等外部设备响应，而不是数据处理。为此，我们开辟一个内存缓冲区的内存区域，程序每次调用read()方法或write()方法都是读写在这个缓冲区中。当这个缓冲区被装满后，系统才将这个缓冲区的内容一次集中写到外部设备或读取进来给CPU。使用缓冲区可以有效的提高CPU的使用率，能提高整个计算机系统的效率。在字符流操作中，所有的字符都是在内存中形成的，在字符流输出前都将保存在内存中的缓冲区内。 缓冲流 在读写数据时，让数据在缓冲区能减少系统实际对原始数据来源的存取次数，因为一次能做多个数据单位的操作，相较而言，对于从文件读取数据或将数据写入文件，比起缓冲区的读写要慢多了。所以使用有缓冲区的流，一般都会比没有缓冲区的流效率更高，拥有缓冲区的流别称为缓冲流，包括BufferedInputStream、BufferedOutputStream类和BufferedReader、BufferedWriter类。缓冲流把数据从原始流成块读入或把数据积累到一个大数据块后再成批写出，通过减少通过资源的读写次数来加快程序的执行 用户空间,内核空间,磁盘 在磁盘空间和用户空间中加一个内核空间的缓存区的原因有两个： 一个是用户空间的程序不能直接去磁盘空间中读取数据，必须由经由内核空间通过DMA来获取; 另一个原因是一般用户空间的内存分页与磁盘空间不会对齐，因此需要由内核空间在中间做一层处理。 目前的操作系统，用户空间和内核空间的区分一般采用虚拟内存来实现，因此用户空间和内存空间都是在虚拟内存中。使用虚拟内存无非是因为其两大优势：一是它可以使多个虚拟内存地址指向同一个物理内存;二是虚拟内存的空间可以大于物理内存的空间。 当用户空间所需要的数据在内核空间中已经存在，那么内核无需再次向磁盘控制硬件发起系统调用，直接对内核缓冲区进行复制，这些数据成为高速缓存，当然内核也可以预读取用户空间需要的数据。 用户空间通常是常规进程所在区域，即非特权区域，不能直接访问磁盘硬件设备； 使用虚拟内存省去了用户空间和内存空间的数据往来拷贝，但缓冲区的大小必须是磁盘数据块的倍数，用户空间和内核空间也必须使用相同的页对其方式。 文件IO 文件系统是安排、解释磁盘数据的一种独特方式，文件系统定义了文件名、路径、文件、文件属性等一系列抽象概念。 当用户进程请求文件数据时，文件系统需要确定数据在磁盘什么位置，然后将相关磁盘分区读进内存。 系统调用和文件读写 应用程序代码运行在用户模式下，当应用程序需要实现内核模式下的指令时，先向操作系统发送调用请求。操作系统收到请求后，执行系统调用接口，使处理器进入内核模式。当处理器处理完系统调用操作后，操作系统会让处理器返回用户模式，继续执行用户代码。 用户态 -> (系统调用) -> 内核态 \\ 磁盘 / 用户态IO缓冲区 用户I/O缓冲区的类型 全缓冲 此种类型的缓冲只有在缓冲区满的时候才会调用实际的文件 IO 进入内核态操作。除了涉及到终端设备文件的流，其它文件流默认基本都是全缓冲。 行缓冲 此种类型的缓冲在缓冲区满或者遇到 \\n 的时候才会调用实际的文件 IO 进入内核态操作。当流涉及到终端设备的时候就是行缓冲，比如标准输入流和标准输出流。如果对标准输入流或者输出流进行重定向到某个文件的时候，该流就是全缓冲的。 无缓冲 没有缓冲区。直接调用文件 IO 进入内核态操作。标准错误流默认就是无缓冲的。 用户空间 & 内核空间 用户空间是常规进程所在区域。JVM就是常规进程，驻守于用户空间。用户空间是非特权区域:比如，在该区域执行的代码就不能直接访问硬件设备。内核空间是操作系统所在区域。内核代码有特别的权力:它能与设备控制器通讯，控制着用户区域 进程的运行状态，等等。最重要的是，所有I/O都直接或间接通过内核空间。 当进程请求I/O操作的时候，它执行一个系统调用(有时称为陷阱)将控制权移交给内核。C/C++程序员所熟知的底层函数open()、read()、write()和close()要做的无非就是建立和执行适当的系统调用。当内核以这种方式被调用，它随即采取任何必要步骤，找到进程所需数据，并把数据 传送到用户空间内的指定缓冲区。内核试图对数据进行高速缓存或预读取，因此进程所需数据可能 已经在内核空间里了。如果是这样，该数据只需简单地拷贝出来即可。如果数据不在内核空间，则 进程被挂起，内核要把数据读进内存。 内核缓冲区的主要思想就是：一次读入大量的数据放在缓冲区，需要的时候从缓冲区取得数据。 为什么不直接 让磁盘控制器把数据送到用户空间的缓冲区呢? 硬件通常不能直接访问 用户空间；硬件设备通常不能直接使用虚拟内存地址 像磁盘这样基于块存储的硬件设备操作的是固定大小的数据块，而用户进程请 求的可能是任意大小的或非对齐的数据块。在数据往来于用户空间与存储设备的过程中，内核负责 数据的分解、再组合工作，因此充当着中间人的角色 vfs(虚拟文件系统) 虚拟文件系统(VFS)是由Sun microsystems公司在定义网络文件系统(NFS)时创造的。它是一种用于网络环境的分布式文件系统，是允许和操作系统使用不同的文件系统实现的接口。虚拟文件系统（VFS）是物理文件系统与服务之间的一个接口层，它对Linux的每个文件系统的所有细节进行抽象，使得不同的文件系统在Linux核心以及系统中运行的其他进程看来，都是相同的。严格说来，VFS并不是一种实际的文件系统。它只存在于内存中，不存在于任何外存空间。VFS在系统启动时建立，在系统关闭时消亡。 I/O模型：同步/阻塞概念 阻塞与非阻塞(等待I/O时的状态) 函数或方法（用户线程调用内核I/O操作）的实现方式： 阻塞是指I/O操作需要彻底完成后才返回到用户空间 非阻塞是指I/O操作被调用后立即返回给用户一个状态值，无需等到I/O操作彻底完成。 同步与异步（用户线程与内核的消息交互方式） 同步指用户线程发起I/O请求后需要等待或者轮询内核I/O操作完成后才能继续执行；同步有阻塞，非阻塞之分 异步是指用户线程发起I/O请求后仍然可以继续执行，当内核I/O操作完成后会通知用户线程，或者调用用户线程注册的回调函数。异步一定是非阻塞的（内核会通过函数回调或者信号机制通知用户进程；类似观察者模式） 用水壶烧水的例子说明[同步/阻塞] 同步阻塞 点火(发消息) 搬个小板凳盯着水壶(傻等，眼睛不动)，不等到水壶烧开水，坚决不去做别的事情（阻塞） 用户线程的IO处理过程需要等待，中间不能做任何事情，对CPU利用率很低 同步非阻塞 点火(发消息) 去看会儿电视，时不时过来(轮询)看水壶烧开水没有（非阻塞)；水开后接着处理 用户线程每次IO请求都能立刻返回，但需要通过轮询去判断数据是否返回，会无谓地消耗大量的CPU 异步阻塞（很少发生） 点火(发消息) 水壶有个响铃，自动绑定了开水之后的处理程序，这样响铃之后自动处理(异步) 但是还是可以轮询去看水壶开了没有 异步非阻塞 点火(发消息), 写好水壶烧开水之后的处理程序 水壶有个响铃，自动绑定了开水之后的处理程序，这样响铃之后自动处理 人该干嘛干嘛去，不用管了（不用傻等，不用轮询） 网络IO模型演进 传统的BIO(Blocking I/O 阻塞IO) BIO server public class Server { public static void main(String[] args) throws IOException { ServerSocket ss = new ServerSocket(); ss.bind(new InetSocketAddress(\"127.0.0.1\", 8888)); while(true) { Socket s = ss.accept(); //阻塞方法 new Thread(() -> { handle(s); }).start(); } } static void handle(Socket s) { try { byte[] bytes = new byte[1024]; int len = s.getInputStream().read(bytes); System.out.println(new String(bytes, 0, len)); s.getOutputStream().write(bytes, 0, len); s.getOutputStream().flush(); } catch (IOException e) { e.printStackTrace(); } } } client public class Client { public static void main(String[] args) throws IOException { Socket s = new Socket(\"127.0.0.1\", 8888); s.getOutputStream().write(\"HelloServer\".getBytes()); s.getOutputStream().flush(); //s.getOutputStream().close(); System.out.println(\"write over, waiting for msg back...\"); byte[] bytes = new byte[1024]; int len = s.getInputStream().read(bytes); System.out.println(new String(bytes, 0, len)); s.close(); } } Server端的accept方法是阻塞的，等待客户端来连接 用一个线程建立连接后，输入/输出流的读写过程是阻塞的（内核操作阻塞） 效率低，并发不高，线程开销大 selector(NIO Single Thread 模型) 不同的事情(有客户端来连接，有输入/输出的读写事件)进行轮训监听，该线程负责所有的这些工作 NIO Server import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.SelectionKey; import java.nio.channels.Selector; import java.nio.channels.ServerSocketChannel; import java.nio.channels.SocketChannel; import java.util.Iterator; import java.util.Set; public class Server { public static void main(String[] args) throws IOException { ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.socket().bind(new InetSocketAddress(\"127.0.0.1\", 8888)); ssc.configureBlocking(false); System.out.println(\"server started, listening on :\" + ssc.getLocalAddress()); Selector selector = Selector.open(); // selector 注册感兴趣的事情：连接时间 ssc.register(selector, SelectionKey.OP_ACCEPT); while(true) { // 阻塞 selector.select(); Set keys = selector.selectedKeys(); Iterator it = keys.iterator(); while(it.hasNext()) { SelectionKey key = it.next(); it.remove(); // 处理这个事件 handle(key); } } } private static void handle(SelectionKey key) { if(key.isAcceptable()) { try { ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel sc = ssc.accept(); sc.configureBlocking(false); //new Client // //String hostIP = ((InetSocketAddress)sc.getRemoteAddress()).getHostString(); /* log.info(\"client \" + hostIP + \" trying to connect\"); for(int i=0; i NIO reactor模式（多线程轮询） The reactor design pattern is an event handling pattern for handling service requests delivered concurrently to a service handler by one or more inputs. The service handler then demultiplexes the incoming requests and dispatches them synchronously to the associated request handlers. (基于事件驱动，有一个Service Handler，处理一个或多个并发输入源，同步的分发给不同的Request Handlers) 基于事件驱动-> selector（支持对多个socketChannel的监听） 统一的事件分派中心-> dispatch 事件处理服务-> read & write AIO（异步IO） NIO是同步的非阻塞,AIO是异步非阻塞的； 事件通知，而不是轮询 但是AIO,NIO在linux下都是基于epoll（轮询）的, 所以netty对nio封装，但是API更像是AIO IO复用 等待数据准备好（waiting for data to be ready）。对于一个套接口上的操作，这一步骤关系到数据从网络到达，并将其复制到内核的某个缓冲区。 将数据从内核缓冲区复制到进程缓冲区（copying the data from the kernel to the process） IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。I select Select是通过将需要监听的文件描述符加入相应的文件描述符集合(readset、writeset，exceptset)，由内核负责监视相应的文件描述符是否就绪。 目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点，但select有如下的一些局限 select监控的文件描述符有上限 每次调用都需要手动的设置文件描述符集合，使用非常不便 每次调用都要把文件描述符从用户态拷贝到内核态，开销比较大 当就绪的文件描述符好后，需要循环遍历来进行判断，效率不高 linux select服务端例子代码 int main() { int server_sockfd, client_sockfd; int server_len, client_len; struct sockaddr_in server_address; struct sockaddr_in client_address; int result; fd_set readfds, testfds; server_sockfd = socket(AF_INET, SOCK_STREAM, 0);//建立服务器端socket server_address.sin_family = AF_INET; server_address.sin_addr.s_addr = htonl(INADDR_ANY); server_address.sin_port = htons(8888); server_len = sizeof(server_address); bind(server_sockfd, (struct sockaddr *)&server_address, server_len); listen(server_sockfd, 5); //监听队列最多容纳5个 FD_ZERO(&readfds); FD_SET(server_sockfd, &readfds);//将服务器端socket加入到集合中 while(1) { char ch; int fd; int nread; testfds = readfds;//将需要监视的描述符集copy到select查询队列中，select会对其修改，所以一定要分开使用变量 printf(\"server waiting\\n\"); /*无限期阻塞，并测试文件描述符变动 */ result = select(FD_SETSIZE, &testfds, (fd_set *)0,(fd_set *)0, (struct timeval *) 0); //FD_SETSIZE：系统默认的最大文件描述符 if(result poll poll() 的机制与 select() 类似，与 select() 在本质上没有多大差别，管理多个描述符也是进行轮询，根据描述符的状态进行处理。 优点 poll() 不要求开发者计算最大文件描述符加一的大小 poll() 在应付大数目的文件描述符的时候速度更快，相比于select 它没有最大连接数的限制，原因是它是基于链表来存储的 在调用函数时，只需要对参数进行一次设置就好了 缺点 大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义 与select一样，poll返回后，需要轮询pollfd来获取就绪的描述符，这样会使性能下降 同时连接的大量客户端在一时刻可能只有很少的就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降 epoll epoll linux例子程序 epoll是一个I/O管理组件 select 和 poll 的升级版本 怎么用，用在什么地方 linux epoll 服务端例子 int main(int argc, char *argv[]) { //服务器IP + port struct sockaddr_in serverAddr; serverAddr.sin_family = PF_INET; serverAddr.sin_port = htons(SERVER_PORT); serverAddr.sin_addr.s_addr = inet_addr(SERVER_IP); //创建监听socket int listener = socket(PF_INET, SOCK_STREAM, 0); if(listener Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-01 15:02:28 "},"content/java_io_net/server_socket_channel.html":{"url":"content/java_io_net/server_socket_channel.html","title":"ServerSocketChannel","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 ServerSocketChannel 阻塞方式的ServerSocketChannel 阻塞方式register selector会报错 附：linux socket accept方法 非阻塞方式 Selector处理事件 [TOC] ServerSocketChannel 阻塞方式的ServerSocketChannel public static void main(String[] args) throws IOException { ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.socket().bind(new InetSocketAddress(\"127.0.0.1\", 8889)); ssc.configureBlocking(true); System.out.println(\"server started, listening on :\" + ssc.getLocalAddress()); while(true) { // ssc.configureBlocking(true);则 accept会一直阻塞直到接收到连接 SocketChannel sc = ssc.accept(); System.out.println(\"accept SocketChannel:\" + sc.getRemoteAddress()); try { ByteBuffer buffer = ByteBuffer.allocate(1024); buffer.clear(); int len = sc.read(buffer); if(len != -1) { System.out.println(\"receive client data:\" + new String(buffer.array(), 0, len)); } ByteBuffer bufferToWrite = ByteBuffer.wrap(\"I am Server\".getBytes()); sc.write(bufferToWrite); } catch (IOException e) { e.printStackTrace(); } finally { if(sc != null) { try { sc.close(); } catch (IOException e) { e.printStackTrace(); } } } } } accept方法一直阻塞等待连接的到来 阻塞方式register selector会报错 Selector selector = Selector.open(); // selector 注册感兴趣的事情：连接事件 ssc.register(selector, SelectionKey.OP_ACCEPT); 报错如下 Exception in thread \"main\" java.nio.channels.IllegalBlockingModeException at java.nio.channels.spi.AbstractSelectableChannel.register(AbstractSelectableChannel.java:201) at java.nio.channels.SelectableChannel.register(SelectableChannel.java:280) at io.Server.main(Server.java:28) 源码 /** * Registers this channel with the given selector, returning a selection key. * * This method first verifies that this channel is open and that the * given initial interest set is valid. * * If this channel is already registered with the given selector then * the selection key representing that registration is returned after * setting its interest set to the given value. * * Otherwise this channel has not yet been registered with the given * selector, so the {@link AbstractSelector#register register} method of * the selector is invoked while holding the appropriate locks. The * resulting key is added to this channel's key set before being returned. * * * @throws ClosedSelectorException {@inheritDoc} * * @throws IllegalBlockingModeException {@inheritDoc} * * @throws IllegalSelectorException {@inheritDoc} * * @throws CancelledKeyException {@inheritDoc} * * @throws IllegalArgumentException {@inheritDoc} */ public final SelectionKey register(Selector sel, int ops, Object att) throws ClosedChannelException { synchronized (regLock) { if (!isOpen()) throw new ClosedChannelException(); if ((ops & ~validOps()) != 0) throw new IllegalArgumentException(); if (blocking) throw new IllegalBlockingModeException(); SelectionKey k = findKey(sel); if (k != null) { k.interestOps(ops); k.attach(att); } if (k == null) { // New registration synchronized (keyLock) { if (!isOpen()) throw new ClosedChannelException(); k = ((AbstractSelector)sel).register(this, ops, att); addKey(k); } } return k; } } 附：linux socket accept方法 #include #include int accept(int sockfd,struct sockaddr *addr,socklen_t *addrlen); accept()系统调用主要用在基于连接的套接字类型，比如SOCK_STREAM和SOCK_SEQPACKET。它提取出所监听套接字的等待连接队列中第一个连接请求，创建一个新的套接字，并返回指向该套接字的文件描述符。 一般accept()为阻塞函数，当监听socket调用accept()时，它先到自己的receive_buf中查看是否有连接数据包；若有，把数据拷贝出来，删掉接收到的数据包，创建新的socket与客户发来的地址建立连接；若没有，就阻塞等待； 非阻塞方式 public static void main(String[] args) throws IOException { ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.socket().bind(new InetSocketAddress(\"127.0.0.1\", 8889)); ssc.configureBlocking(false); System.out.println(\"server started, listening on :\" + ssc.getLocalAddress()); while(true) { // 非阻塞的accept: 如果没有连接，则返回null SocketChannel sc = ssc.accept(); if(sc != null) { System.out.println(\"accept SocketChannel:\" + sc.getRemoteAddress()); try { ByteBuffer buffer = ByteBuffer.allocate(1024); buffer.clear(); int len = sc.read(buffer); if (len != -1) { System.out.println(\"receive client data:\" + new String(buffer.array(), 0, len)); } ByteBuffer bufferToWrite = ByteBuffer.wrap(\"I am Server\".getBytes()); sc.write(bufferToWrite); } catch (IOException e) { e.printStackTrace(); } finally { if (sc != null) { try { sc.close(); } catch (IOException e) { e.printStackTrace(); } } } } } } Selector处理事件 public static void main(String[] args) throws IOException { ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.socket().bind(new InetSocketAddress(\"127.0.0.1\", 8889)); ssc.configureBlocking(false); System.out.println(\"server started, listening on :\" + ssc.getLocalAddress()); // Select 轮询监听channel事件（这里是注册连接事件） Selector selector = Selector.open(); ssc.register(selector, SelectionKey.OP_ACCEPT); while (true) { // selector.select(); 阻塞等待连接事件 selector.select(); Set keys = selector.selectedKeys(); Iterator it = keys.iterator(); while (it.hasNext()) { SelectionKey key = it.next(); it.remove(); // 处理连接事件 handleConnect(key); } } } private static void handleConnect(SelectionKey key) { if(key.isAcceptable()) { try { ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel sc = ssc.accept(); System.out.println(\"accept a client:\" + sc.getRemoteAddress()); // 继续注册socket的读事件 sc.configureBlocking(false); sc.register(key.selector(), SelectionKey.OP_READ ); } catch (IOException e) { e.printStackTrace(); } finally { } } else if (key.isReadable()) { SocketChannel sc = null; try { sc = (SocketChannel)key.channel(); ByteBuffer buffer = ByteBuffer.allocate(1024); buffer.clear(); int len = sc.read(buffer); if(len != -1) { System.out.println(new String(buffer.array(), 0, len)); } ByteBuffer bufferToWrite = ByteBuffer.wrap(\"I am Server\".getBytes()); sc.write(bufferToWrite); } catch (IOException e) { e.printStackTrace(); } finally { if(sc != null) { try { sc.close(); } catch (IOException e) { e.printStackTrace(); } } } } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-01 20:49:32 "},"content/java_io_net/nio_basic.html":{"url":"content/java_io_net/nio_basic.html","title":"NIO & BIO问题","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 NIO(非阻塞IO) BIO问题 what defines an active thread ？ NIO与IO的区别 NIO API 的抽象 缓冲区(Buffer) 属性信息 非线程安全 两个缓冲区被认为相等的充要条件 （*）直接缓冲区 & 非直接缓冲区 缓冲区的一些操作类 字符集及其相关解码器 和编码器 通道 Channel Channel的一些类 获取通道 选择器 Selector Scatter/Gather(缓冲区操作) [TOC] NIO(非阻塞IO) BIO问题 一个线程负责多个文件的读写，如果按照阻塞的方式，那么必须是按照文件1， 文件2， 文件3...... 顺序的读取这么多文件； 如果是非阻塞方式， 你可以同时发起成百上千个读操作，然后在那个循环中检查， 看看谁的数据准备好了，就读取谁的， 效率就高了。 socket编程：一个socket连接来了， 就创建一个新的线程或者从线程池分配一个线程去处理这个连接，显然线程数不能太多，线程的切换也是个开销；所以让一个线程管理成百上千个sockcet连接，就像管理多个文件一样，这样就不用做线程切换了。 美团《Java NIO浅析》 使用多线程的本质： 1. 利用多核。 2. 当I/O阻塞系统，但CPU空闲的时候，可以利用多线程使用CPU资源。(现在的多线程一般都使用线程池,现在的多线程一般都使用线程池，可以让线程的创建和回收成本相对较低。在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的) 线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数 线程本身占用较大内存，像Java的线程栈，一般至少分配512K～1M的空间，如果系统中的线程数过千，恐怕整个JVM的内存都会被吃掉一半 线程的切换成本是很高的。操作系统发生线程切换的时候，需要保留线程的上下文，然后执行系统调用。如果线程数过高，可能执行线程切换的时间甚至会大于线程执行的时间，这时候带来的表现往往是系统load偏高、CPU sy使用率特别高（超过20%以上)，导致系统几乎陷入不可用的状态。 容易造成锯齿状的系统负载。因为系统负载是用活动线程数或CPU核心数，一旦线程数量高但外部网络环境不是很稳定，就很容易造成大量请求的结果同时返回，激活大量阻塞线程从而使系统负载压力过大。 结论：当面对十万甚至百万级连接的时候，传统的BIO模型是无能为力的。 what defines an active thread ？ In this context I take \"active\" to mean that they are executing code. Inactive threads--those that are blocked on I/O calls or awaiting locks--consume only memory resources without affecting the CPU (or only marginally). However, it really depends on what your threads are doing. If each thread is iterating over numbers to calculate primes, they are fully CPU-bound, and you should really only have one per core to maximize throughput. If they are making HTTP requests or performing file I/O, you can afford to have quite a few per core. In the end, a blanket statement covering all threads in general without regard for what they are doing is pretty worthless. I highly recommend the book Java Concurrency in Practice for a high-quality treatment of the topic of concurrent Java programming. NIO与IO的区别 Java NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取。而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此，一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。 线程通常将非阻塞IO的空闲时间用于在其它通道上执行IO操作，所以一个单独的线程现在可以管理多个输入和输出通道（channel）。 参考: java-nio-tutorials NIO是以块的方式处理数据，但是IO是以最基础的字节流的形式去写入和读出的。所以在效率上，肯定是NIO效率比IO效率会高出很多。 NIO不在是和IO一样用OutputStream和InputStream输入流的形式来进行处理数据的，但是又是基于这种流的形式，而是采用了通道和缓冲区的形式来进行处理数据的。还有一点就是NIO的通道是可以双向的，但是IO中的流只能是单向的。 NIO的缓冲区（其实也就是一个字节数组）还可以进行分片，可以建立只读缓冲区、直接缓冲区和间接缓冲区，只读缓冲区很明显就是字面意思，直接缓冲区是为加快I/O速度，而以一种特殊的方式分配其内存的缓冲区。 NIO API 的抽象 缓冲区(Buffer) 进程执行I/O操作，即是向操作系统发出请求，让它要么把缓冲区里的数据排干(写)，要么用数据把缓冲区填满（读）。进程使用这一机制处理所有数据进出操作。\"输入/输出\"也就是把数据移入或移出缓冲区。 属性信息 容量(Capacity): 缓冲区能够容纳的数据元素的最大数量。这一容量在缓冲区创建时被设定，并且永远不能被改变。 位置(Position): 下一个要被读或写的元素的索引。位置会自动由相应的get()和put()函数更新。 界限(Limit): 缓冲区的第一个不能被读或写的元素。或者说，缓冲区中现存元素的计数。 标记(Mark): 一个备忘位置。调用mark()来设定mark=postion。调用reset()设定position=mark。标记在设定前是未定义的(undefined) 0 非线程安全 缓冲区并不是线程安全的。如果您想以多线程同时存取特定的缓冲区，您需要在存取缓冲区之前进行同步(例如对缓冲区对象进行跟踪) 两个缓冲区被认为相等的充要条件 两个对象类型相同。包含不同数据类型的buffer永远不会相等，而且buffer 绝不会等于非 buffer 对象。 两个对象都剩余同样数量的元素。Buffer 的容量不需要相同，而且缓冲区中剩 余数据的索引也不必相同。但每个缓冲区中剩余元素的数目(从位置到上界)必须相同。 在每个缓冲区中应被Get()函数返回的剩余数据元素序列必须一致。 （*）直接缓冲区 & 非直接缓冲区 直接缓冲区：通过allocateDirect()方法分配直接缓冲区，将缓冲区建立在物理内存中(内存映射文件，减少内核与用户空间的拷贝) 直接字节缓冲区通过调用allocateDirect()工厂方法来创建，此方法返回的缓冲区进行分配和取消分配所需成本通常高于非直接缓冲区；直接缓冲区的内容可以驻留在常规的垃圾回收堆之外，因此，它们对应用程序的内存需求量造成的影响可能并不明显。所以，建议将直接缓冲区主要分配给那些易受基础系统的本机 I/O 操作影响的大型、持久的缓冲区。一般情况下，最好仅在直接缓冲区能在程序性能方面带来明显好处时分配它们。 直接字节缓冲区还可以通过FileChannel的map()方法,将文件区域直接映射到内存中来创建。该方法返回MappedByteBuffer。Java 平台的实现有助于通过JNI从本机代码创建直接字节缓冲区。如果以上这些缓冲区中的某个缓冲区实例指的是不可访问的内存区域，则试图访问该区域不会更改该缓冲区的内容，并且将会在访问期间或稍后的某个时间导致抛出不确定的异常。 非直接缓冲区： 通过allocate()方法分配缓冲区，将缓冲区建立在JVM的内存中 缓冲区的一些操作类 ByteBuffer MappedByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer ByteOrder 它们是数据容器 字符集及其相关解码器 和编码器 它们在字节和Unicode字符之间进行转换 通道 Channel 通道：专门处理I/O（跟DMA处理差不多）,是完全独立的处理器(不像DMA还要向CPU申请)，附属于CPU，提高CPU利用率 Channel是一个对象，可以通过它读取和写入数据，本身不存储数据，配合缓冲区使用。拿 NIO 与原来的 I/O 做个比较，通道就像是流，而且它们面向缓冲区的。 通道与流的不同之处在于：通道是双向的。而流只是在一个方向上移动(一个流必须是 InputStream 或者 OutputStream 的子类)， 而 通道 可以用于读、写或者同时用于读写。 通道可以以阻塞(blocking)或非阻塞(nonblocking)模式运行。非阻塞模式的通道永远不会让调用的线程休眠。请求的操作要么立即完成,要么返回一个结果表明未进行任何操作。只有面向流的(stream-oriented)的通道,如 sockets 和 pipes 才能使用非阻塞模式。 Channel的一些类 FileChannel: 文件通道，用于文件的数据读写 SocketChannel: 套接字通道，用于socket套接字tcp连接的数据读写 ServerSocketChannel: 服务端套接字通道，允许我们监听TCP连接请求，为每个监听到的请求，创建一个SocketChannel套接字通道 DatagramChannel: 数据包通道，用于UDP协议的数据读写 获取通道 Java针对支持通道的类提供了getChannel()方法 a. 本地IO: FileInputStream/FileOutputStream RandomAccessFile b. 网络IO: Socket ServerSocket DatagramSocket 在JDK1.7中的NIO2针对各个通道提供了静态方法open() 在JDK1.7中的NIO2的Files工具类的newByteChannel() 选择器 Selector Selector能够检测多个注册的通道上是否有事件发生，如果有事件发生，便获取事件然后针对每个事件进行相应的响应处理。 这样一来，只是用一个单线程就可以管理多个通道，也就是管理多个连接。这样使得只有在连接真正有读写事件发生时，才会调用函数来进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程，并且避免了多线程之间的上下文切换导致的开销。 Scatter/Gather(缓冲区操作) scatter/gather指的在多个缓冲区上实现一个简单的I/O操作，比如从通道中读取数据到多个缓冲区，或从多个缓冲区中写入数据到通道； scatter（分散）：指的是从通道中读取数据分散到多个缓冲区Buffer的过程，该过程会将每个缓存区填满，直至通道中无数据或缓冲区没有空间； gather（聚集）：指的是将多个缓冲区Buffer聚集起来写入到通道的过程，该过程类似于将多个缓冲区的内容连接起来写入通道； Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-01 14:55:15 "},"content/java_io_net/from_io_to_epoll.html":{"url":"content/java_io_net/from_io_to_epoll.html","title":"从BIO到epoll","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 从nio到epoll BIO实践 BIO Server & 系统调用 nc命令去连接服务端 strace 追踪系统调用 ServerSocket启动过程 netstat查看tcp相关 文件描述符的查看 BIO的问题? select select的问题? epoll epoll 三个函数 epoll_create epoll_ctl epoll_wait I/O存储金字塔 附：Linux相关操作 man命令的使用 nc命令 strace命令 linux 相关文件描述符 ulimit -n 输入/输出/错误描述符 [TOC] 从nio到epoll BIO实践 BIO Server & 系统调用 服务端监听8090端口，每一个客户端用一个线程处理，不断的获取客户端的输入数据并打印 import java.io.BufferedReader; import java.io.InputStream; import java.io.InputStreamReader; import java.net.ServerSocket; import java.net.Socket; /** * @Author mubi * @Date 2020/6/25 18:54 */ public class TestSocket { public static void main(String[] args) throws Exception{ ServerSocket serverSocket = new ServerSocket(8090); System.out.println(\"step1 new ServerSocket(8090)\"); while(true){ final Socket client = serverSocket.accept(); System.out.println(\"step2 client:\" + client.getPort()); new Thread(()->{ try{ InputStream in = client.getInputStream(); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(in)); while (true){ System.out.println(bufferedReader.readLine()); } }catch (Exception e){ e.printStackTrace(); } }).start(); } } } nc命令去连接服务端 nc localhost 8090 ` strace 追踪系统调用 javac TestSocket.java strace -ff -o ./stracefile java TestSocket ServerSocket启动过程 socket 系统调用, 得到文件描述符,如 fd5 bind端口 listen，文件描述符 accept(阻塞状态), 有客户端连接得到新的socket, 产生文件描述符 如 fd6，fd7 小知识：通过进程ID号能知道有多少个线程(/proc//task) 补充：linux创建线程，走的clone系统调用，eg： clone(child_stack=0x7fd8d8508ff0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_ PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fd8d85099d0, tls=0x7fd8d8509700, child_tidptr=0x7fd8d85099d0) = 4787 netstat查看tcp相关 有Listen,ESTABLISHED状态的TCP 文件描述符的查看 在工作目录会看到很多stracefile,以.线程id结尾；56544端口客户端连接，vim stracefile.4772(4772是服务端开启的线程)，可以找到如下一句 accept(5, {sa_family=AF_INET6, sin6_port=htons(56544), inet_pton(AF_INET6, \"::ffff:127.0.0.1\", &sin6_addr), sin6_flowinfo=0, sin6_scope_id=0}, [28]) = 6 fcntl(6, F_GETFL) = 0x2 (flags O_RDWR) fcntl(6, F_SETFL, O_RDWR) = 0 lseek(3, 62493071, SEEK_SET) = 62493071 read(3, \"PK\\3\\4\\n\\0\\0\\10\\0\\0000\\211|L9\\267\\215\\270R\\6\\0\\0R\\6\\0\\0;\\0\\0\\0\", 30) = 30 lseek(3, 62493160, SEEK_SET) = 62493160 read(3, \"\\312\\376\\272\\276\\0\\0\\0004\\0:\\7\\0!\\n\\0\\v\\0\\\"\\t\\0\\10\\0#\\n\\0\\1\\0$\\t\\0\\v\\0\"..., 1618) = 1618 write(1, \"step2 client:56544\", 18) = 18 man 2 accept了解到 accept 的返回：系统会产生一个文件描述符，关联接收到的socket文件 RETURN VALUE On success, these system calls return a nonnegative integer that is a descriptor for the accepted socket. On error, -1 is returned, and errno is set appropriately. 从上可以看出是文件描述符6的一个文件,即代表了连接上的socket： strace给客户端起的线程，会阻塞在recvfrom接收数据上 set_robust_list(0x7fd8d85099e0, 24) = 0 gettid() = 4787 rt_sigprocmask(SIG_BLOCK, NULL, [QUIT], 8) = 0 rt_sigprocmask(SIG_UNBLOCK, [HUP INT ILL BUS FPE SEGV USR2 TERM], NULL, 8) = 0 rt_sigprocmask(SIG_BLOCK, [QUIT], NULL, 8) = 0 futex(0x7fd8f000b354, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x7fd8f000b350, {FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1}) = 1 futex(0x7fd8f000b328, FUTEX_WAKE_PRIVATE, 1) = 1 sched_getaffinity(4787, 32, [1, 0, 0, 0, 0, 145, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) = 32 sched_getaffinity(4787, 32, [1, 0, 0, 0, 0, 145, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) = 32 mmap(0x7fd8d8409000, 12288, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7fd8d8409000 mprotect(0x7fd8d8409000, 12288, PROT_NONE) = 0 lseek(3, 30054856, SEEK_SET) = 30054856 read(3, \"PK\\3\\4\\n\\0\\0\\10\\0\\0006\\211|L\\24w\\0067E\\3\\0\\0E\\3\\0\\0\\27\\0\\0\\0\", 30) = 30 lseek(3, 30054909, SEEK_SET) = 30054909 read(3, \"\\312\\376\\272\\276\\0\\0\\0004\\0-\\t\\0\\6\\0\\34\\n\\0\\7\\0\\35\\t\\0\\32\\0\\36\\n\\0\\37\\0\\33\\n\\0\"..., 837) = 837 lseek(3, 30056639, SEEK_SET) = 30056639 read(3, \"PK\\3\\4\\n\\0\\0\\10\\0\\0B\\211|L\\305SF\\t\\265\\r\\0\\0\\265\\r\\0\\0 \\0\\0\\0\", 30) = 30 lseek(3, 30056701, SEEK_SET) = 30056701 read(3, \"\\312\\376\\272\\276\\0\\0\\0004\\0\\242\\n\\0Y\\0Z\\n\\0-\\0[\\t\\0,\\0\\\\\\t\\0,\\0]\\t\\0\"..., 3509) = 3509 recvfrom(6, \"helloABC\\n\", 8192, 0, NULL, NULL) = 9 ioctl(6, FIONREAD, [0]) = 0 write(1, \"helloABC\", 8) = 8 write(1, \"\\n\", 1) = 1 recvfrom(6, BIO的问题? 线程开销大（线程多，单核需要切换线程） 资源开销大，线程栈消耗内存；系统调用多 C10K问题: 需要每次遍历n个fd()，去进行系统调用检查，但实际上可能只有m(m fd拷贝到内核复杂度是O(n) 内核检查fd是否准备好的复杂度是O(n) select BIO的问题解决,可以把所有fd放到一个集合(select)中，一次性的拷贝到内核处理，那么复杂度： fd拷贝到内核复杂度是O(1) 内核检查fd是否准备好的复杂度是O(n) select的问题? 虽然每次只进行一次fd集合拷贝到内核，但注意到每次传递都差不多是同样的fd集合 内核仍然是需要遍历所有fd去检查其是否准备好数据的，但实际上可能只有m(m epoll select的问题解决，在内核区域开辟一块共享区域，有一个fd就加入进去，不用拷贝了；随着fd的增多，这个集合也增多了；不像select那样，每次传递重复的fd集合 不需要遍历所有fd，基于事件驱动（中断），哪个df准备好了，就发出通知事件，这些事件放到一个事件区域中，用户态自己去等待其中的事件 无需fd拷贝到内核 内核检查fd是否准备好,采用事件通知方式 epoll 三个函数 epoll_create int epoll_create(int size) 创建一个epoll句柄，参数size用来告诉内核监听的数目，size为epoll所支持的最大句柄数 epoll_ctl int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event) 函数功能：用于控制某个文件描述符上的事件，可以注册事件，修改事件，删除事件。 参数epfd为epoll的句柄，即 epoll_create 函数返回值 参数op表示动作，用3个宏来表示： EPOLL_CTL_ADD(注册新的fd到epfd)， EPOLL_CTL_MOD(修改已经注册的fd的监听事件)， EPOLL_CTL_DEL(从epfd删除一个fd)； 其中参数fd为需要监听的标示符； 参数event告诉内核需要监听的事件 epoll_wait int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout) 该函数用于轮询I/O事件的发生； epfd:由epoll_create 生成的epoll专用的文件描述符； epoll_event:用于回传代处理事件的数组； maxevents:每次能处理的事件数； timeout:等待I/O事件发生的超时值（ms）；-1永不超时，直到有事件产生才触发，0立即返回。 该函数返回发生事件数。-1有错误。 I/O存储金字塔 附：Linux相关操作 man命令的使用 是普通的命令 是系统调用,如open,write之类的(通过这个，至少可以很方便的查到调用这个函数，需要加什么头文件) 是库函数,如printf,fread 是特殊文件,也就是/dev下的各种设备文件 是指文件的格式,比如passwd, 就会说明这个文件中各个字段的含义 是给游戏留的,由各个游戏自己定义 是附件还有一些变量,比如向environ这种全局变量在这里就有说明 是系统管理用的命令, eg: man 2 accept man 2 socket nc命令 nc命令的作用 实现任意TCP或UDP端口的侦听，nc可以作为server以TCP或UDP方式侦听指定端口 端口的扫描，nc可以作为client发起TCP或UDP连接 机器之间传输文件 机器之间的网络测速 nc [-hlnruz][-g][-G][-i][-o][-p][-s][-v...][-w][主机名称][通信端口...] strace命令 trace system calls and signals(可用于诊断、调试和教学的Linux用户空间跟踪器。我们用它来监控用户空间进程和内核的交互，比如系统调用、信号传递、进程状态变更等。) man strace linux 相关文件描述符 ulimit -n 查看用户级文件描述符的限制，一般：1024 查看系统级别限制 sysctl -a | grep file-max sysctl: fs.file-max = 100262 cat /proc/sys/fs/file-max 100262 输入/输出/错误描述符 0：标准输入（stdin），通常对应终端的键盘 1：标准输出（stdout），通常对应终端的屏幕 2： 标准错误（stderr），通常对应终端的屏幕 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-28 10:11:21 "},"content/distributed_design/design.html":{"url":"content/distributed_design/design.html","title":"网络设计模式","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 线程上下文设计模式 Reactor 模式 传统做法回顾 服务器一个while，单线程处理客户端所有的请求 多线程/线程池，每个请求分配一个线程处理 事件驱动 Reactor Future Callable 接口 Future 接口 RunnableFuture 接口 FutureTask 类 get 方法获取返回结果 run 方法执行任务 FutureTask & Thread 简单使用 [TOC] 线程上下文设计模式 上下文是贯穿整个系统或阶段生命周期的对象，其中包含了系统全局的一些信息，比如登录后的用户信息、账号信息，以及在程序每一个阶段运行时的数据。设计时要考虑到全局唯一性，还要考虑有些成员只能被初始化一次，比如配置信息加载，以及在多线程环境下，上下文成员的线程安全性。 Reactor 模式 reactor: n. 核反应堆; 基于事件驱动，主程序将事件以及对应事件处理的方法在Reactor上进行注册, 如果相应的事件发生（比如轮询判断），Reactor将会主动调用事件注册的接口，即 回调函数. 最简单的Reactor模式：注册所有感兴趣的事件处理器，单线程轮询选择就绪事件，执行事件处理器。 interface ChannelHandler{ void channelReadable(Channel channel); void channelWritable(Channel channel); } class Channel{ Socket socket; Event event;//读，写或者连接 } //IO线程主循环: class IoThread extends Thread{ public void run(){ Channel channel; while(channel=Selector.select()){//选择就绪的事件和对应的连接 if(channel.event==accept){ registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器 } if(channel.event==write){ getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件 } if(channel.event==read){ getChannelHandler(channel).channelReadable(channel);//如果可以读，则执行读事件 } } } Map handlerMap;//所有channel的对应事件处理器 } 单线程处理I/O的效率确实非常高，没有线程切换，只是拼命的读、写、选择事件。但现在的服务器，一般都是多核处理器，如果能够利用多核心进行I/O，无疑对效率会有更大的提高。 传统做法回顾 服务器一个while，单线程处理客户端所有的请求 while(true){ socket = accept(); handle(socket) } 多线程/线程池，每个请求分配一个线程处理 while(true){ socket = accept(); new thread(socket); } 线程同步的粒度太大了，限制了吞吐量。应该把一次连接的操作分为更细的粒度或者过程，这些更细的粒度是更小的线程。整个线程池的数目会翻倍，但是线程更简单，任务更加单一 事件驱动 事件驱动程序的基本结构是由一个事件收集器、一个事件发送器和一个事件处理器组成。 事件收集器专门负责收集所有事件 事件发送器负责将收集器收集到的事件分发到目标对象中 事件处理器做具体的事件响应工作 Reactor 在Reactor中，这些被拆分的小线程或者子过程对应的是handler，每一种handler会出处理一种event。 这里会有一个全局的管理者selector，我们需要把channel注册感兴趣的事件，那么这个selector就会不断在channel上检测是否有该类型的事件发生，如果没有，那么主线程就会被阻塞，否则就会调用相应的事件处理函数即handler来处理。 Future \"凭据\"：如果有任务执行需要比较长的时间，通常需要等待任务执行结束或者出错才能返回结果，在此期间调用者只能陷入阻塞苦苦等待，对此，Future设计模式提供了一种凭据式解决方案。可以先提交任务，立即返回一个凭据，调用者可稍后凭借凭借查询执行结果。 Callable 接口 /** * A task that returns a result and may throw an exception. * Implementors define a single method with no arguments called * {@code call}. * * The {@code Callable} interface is similar to {@link * java.lang.Runnable}, in that both are designed for classes whose * instances are potentially executed by another thread. A * {@code Runnable}, however, does not return a result and cannot * throw a checked exception. * * The {@link Executors} class contains utility methods to * convert from other common forms to {@code Callable} classes. * * @see Executor * @since 1.5 * @author Doug Lea * @param the result type of method {@code call} */ @FunctionalInterface public interface Callable { /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception; } Future 接口 Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。 主要是将一些耗时的操作交给一个线程去执行，从而达到异步的目的；在提交线程在提交任务和获得任务结果的过程中可以进行其它任务操作，而不是傻傻的等待 public interface Future { /** * Attempts to cancel execution of this task. This attempt will * fail if the task has already completed, has already been cancelled, * or could not be cancelled for some other reason. If successful, * and this task has not started when {@code cancel} is called, * this task should never run. If the task has already started, * then the {@code mayInterruptIfRunning} parameter determines * whether the thread executing this task should be interrupted in * an attempt to stop the task. * * After this method returns, subsequent calls to {@link #isDone} will * always return {@code true}. Subsequent calls to {@link #isCancelled} * will always return {@code true} if this method returned {@code true}. * * @param mayInterruptIfRunning {@code true} if the thread executing this * task should be interrupted; otherwise, in-progress tasks are allowed * to complete * @return {@code false} if the task could not be cancelled, * typically because it has already completed normally; * {@code true} otherwise */ boolean cancel(boolean mayInterruptIfRunning); /** * Returns {@code true} if this task was cancelled before it completed * normally. * * @return {@code true} if this task was cancelled before it completed */ boolean isCancelled(); /** * Returns {@code true} if this task completed. * * Completion may be due to normal termination, an exception, or * cancellation -- in all of these cases, this method will return * {@code true}. * * @return {@code true} if this task completed */ boolean isDone(); /** * Waits if necessary for the computation to complete, and then * retrieves its result. * * @return the computed result * @throws CancellationException if the computation was cancelled * @throws ExecutionException if the computation threw an * exception * @throws InterruptedException if the current thread was interrupted * while waiting */ V get() throws InterruptedException, ExecutionException; /** * Waits if necessary for at most the given time for the computation * to complete, and then retrieves its result, if available. * * @param timeout the maximum time to wait * @param unit the time unit of the timeout argument * @return the computed result * @throws CancellationException if the computation was cancelled * @throws ExecutionException if the computation threw an * exception * @throws InterruptedException if the current thread was interrupted * while waiting * @throws TimeoutException if the wait timed out */ V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; } RunnableFuture 接口 /** * A {@link Future} that is {@link Runnable}. Successful execution of * the {@code run} method causes completion of the {@code Future} * and allows access to its results. * @see FutureTask * @see Executor * @since 1.6 * @author Doug Lea * @param The result type returned by this Future's {@code get} method */ public interface RunnableFuture extends Runnable, Future { /** * Sets this Future to the result of its computation * unless it has been cancelled. */ void run(); } FutureTask 类 /** * A cancellable asynchronous computation. This class provides a base * implementation of {@link Future}, with methods to start and cancel * a computation, query to see if the computation is complete, and * retrieve the result of the computation. The result can only be * retrieved when the computation has completed; the {@code get} * methods will block if the computation has not yet completed. Once * the computation has completed, the computation cannot be restarted * or cancelled (unless the computation is invoked using * {@link #runAndReset}). * * A {@code FutureTask} can be used to wrap a {@link Callable} or * {@link Runnable} object. Because {@code FutureTask} implements * {@code Runnable}, a {@code FutureTask} can be submitted to an * {@link Executor} for execution. * * In addition to serving as a standalone class, this class provides * {@code protected} functionality that may be useful when creating * customized task classes. * * @since 1.5 * @author Doug Lea * @param The result type returned by this FutureTask's {@code get} methods */ public class FutureTask implements RunnableFuture { get 方法获取返回结果 /** * @throws CancellationException {@inheritDoc} */ public V get() throws InterruptedException, ExecutionException { int s = state; if (s /** * Awaits completion or aborts on interrupt or timeout. * * @param timed true if use timed waits * @param nanos time to wait, if timed * @return state upon completion */ private int awaitDone(boolean timed, long nanos) throws InterruptedException { final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) { if (Thread.interrupted()) { removeWaiter(q); throw new InterruptedException(); } int s = state; if (s > COMPLETING) { if (q != null) q.thread = null; return s; } else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) q = new WaitNode(); else if (!queued) queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) { nanos = deadline - System.nanoTime(); if (nanos run 方法执行任务 public void run() { //1.判断状态是否是NEW，不是NEW，说明任务已经被其他线程执行，甚至执行结束，或者被取消了，直接返回 //2.调用CAS方法，判断RUNNER为null的话，就将当前线程保存到RUNNER中，设置RUNNER失败，就直接返回 if (state != NEW || !U.compareAndSwapObject(this, RUNNER, null, Thread.currentThread())) return; try { Callable c = callable; if (c != null && state == NEW) { V result; boolean ran; try { //3.执行Callable任务，结果保存到result中 result = c.call(); ran = true; } catch (Throwable ex) { //3.1 如果执行任务过程中发生异常，将调用setException()设置异常 result = null; ran = false; setException(ex); } //3.2 任务正常执行结束调用set(result)保存结果 if (ran) set(result); } } finally { // runner must be non-null until state is settled to // prevent concurrent calls to run() //4. 任务执行结束，runner设置为null，表示当前没有线程在执行这个任务了 runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts //5. 读取状态，判断是否在执行的过程中，被中断了，如果被中断，处理中断 int s = state; if (s >= INTERRUPTING) handlePossibleCancellationInterrupt(s); } } FutureTask & Thread 简单使用 import java.util.concurrent.Callable; import java.util.concurrent.FutureTask; import java.util.concurrent.TimeUnit; public class Solution { public static void main(String[] args) throws Exception { Callable callable = ()->{ System.out.println(\"Thread [\" + Thread.currentThread().getName() + \"] is running\"); int result = 0; for(int i = 0; i futureTask = new FutureTask<>(callable); // 3. 新建Thread对象并启动 Thread thread = new Thread(futureTask); thread.setName(\"Task thread\"); thread.start(); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"Thread [\" + Thread.currentThread().getName() + \"] is running\"); // 4. 调用isDone()判断任务是否结束 if(!futureTask.isDone()) { System.out.println(\"Task is not done\"); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } } int result = 0; try { System.out.println(\"get 1:\" + System.currentTimeMillis()); // 5. 调用get()方法获取任务结果,如果任务没有执行完成则阻塞等待 result = futureTask.get(); System.out.println(\"get 2:\" + System.currentTimeMillis()); } catch (Exception e) { e.printStackTrace(); } System.out.println(\"result is \" + result); } } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-20 21:11:28 "},"content/java_io_net/http_tcp.html":{"url":"content/java_io_net/http_tcp.html","title":"http & tcp","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 网络相关 TCP 流量控制 滑动窗口 滑动机制 拥塞控制 网络抖动？ [TOC] 网络相关 TCP 面向字节流/全双工 发送和接收的速率不一样 =》 发送缓存 & 接收缓存 TCP利用发送缓存 & 接收缓存来进行流量控制和差错控制 IP层必须以分组为单位发送数据，而不是字节流，所以TCP把若干字节流组成一个分组，称为报文段，TCP给报文段加上TCP头部，然后交给IP层。报文段在接收时有可能会失序，丢失，或者受到损伤和重传 参考：tcp三次握手，Wireshark实践 流量控制 Sender won’t overflow receiver’s buffer by transmitting too much, too fast. 流量控制就是让发送方的发送速率不要太快，让接收方来得及接受。利用滑动窗口机制可以很方便的在TCP连接上实现对发送方的流量控制 滑动窗口 tcp双方都各自维护一个发送窗口和一个接收窗口 （1）接收端将自己可以接收的缓冲区大小放入TCP首部中的“窗口大小”字段，通过ACK来通知发送端 （2）窗口大小字段越大，说明网络的吞吐率越高 （3）窗口大小指的是无需等待确认应答而可以继续发送数据的最大值，即就是说不需要接收端的应答，可以一次连续的发送数据 （4）操作系统内核为了维护滑动窗口，需要开辟发送缓冲区，来记录当前还有哪些数据没有应答，只有确认应答过的数据，才能从缓冲区删掉 ps:发送缓冲区如果太大，就会有空间开销 （5）接收端一旦发现自己的缓冲区快满了，就会将窗口大小设置成一个更小的值通知给发送端，发送端收到这个值后，就会减慢自己的发送速度 （6）如果接收端发现自己的缓冲区满了，就会将窗口的大小设置为0，此时发送端将不再发送数据，但是需要定期发送一个窗口探测数据段，使接收端把窗口大小告诉发送端 ps：在TCP的首部中，有一个16为窗口字段，此字段就是用来存放窗口大小信息的 转载自：CSDN博主「dangzhangjing97」 原文链接：https://blog.csdn.net/dangzhangjing97/article/details/81008836 滑动机制 发送窗口只有收到发送窗口内字节的ACK确认，才会移动发送窗口的左边界。 接收窗口只有在前面所有的段都确认的情况下才会移动左边界。当在前面还有字节未接收但收到后面字节的情况下，窗口不会移动，并不对后续字节确认。以此确保对端会对这些数据重传。 遵循快速重传、累计确认、选择确认等规则。 发送方发的window size = 8192;就是接收端最多发送8192字节，这个8192一般就是发送方接收缓存的大小。 拥塞控制 拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制所要做的都有一个前提，就是网络能承受现有的网络负荷。拥塞问题是一个全局性的问题,涉及到所有的主机、所有的路由器、以及与降低网络传输性能有关的所有因素 流量控制往往指的是点对点通信量的控制，是个端到端的问题。流量控制所要做的就是控制发送端发送数据的速率，以便使接收端来得及接受 因特网建议标准RFC2581定义了进行拥塞控制的四种算法 慢开始（Slow-start) 拥塞避免（Congestion Avoidance) 快重传（Fast Restrangsmit) 快恢复（Fast Recovery） 网络抖动？ Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-21 12:29:37 "},"content/distributed_design/nginx.html":{"url":"content/distributed_design/nginx.html","title":"nginx基础","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 nginx reverse proxy（反向代理） What Is a Reverse Proxy Server? High-Performance Load Balancing （负载均衡） HTTP load balance Problem Solution(解决方案) 负载均衡算法 Round Robin（轮询） Weight Round Robin Least connections（最小连接数） Least time(最短响应时间负载均衡算法) Generic hash(哈希) Random IP hash URL hash TCP/UDP load balance cookie & session（http 知识复习） http无连接概念介绍 Session Cookie how to create cookie HTTP Health Checks（HTTP健康检查） Server Slow Start（服务慢开始） Passive Health Checks Active Health Checks TCP Health Checks（TCP健康检查） Passive TCP Health Checks(被动的TCP健康检查) Active TCP Health Checks(主动的TCP健康检查) Fine-Tuning TCP Health Checks Massively Scalable Content Caching [TOC] nginx reverse proxy（反向代理） nginx reverse proxy docs What Is a Reverse Proxy Server? A proxy server is a go‑between or intermediary server that forwards requests for content from multiple clients to different servers across the Internet. A reverse proxy server is a type of proxy server that typically sits behind the firewall in a private network and directs client requests to the appropriate backend server. A reverse proxy provides an additional level of abstraction and control to ensure the smooth flow of network traffic between clients and servers. 单词短语 解释 intermediary adj.中间人的； 调解的； 居间的； 媒介的; n. 中间人； 媒介； 调解人； 中间阶段 go‑between 中间人 firewall n.防火墙；vt.用作防火墙； backend server 后端服务器 smooth adj.光滑的； 流畅的； 柔软的； 温和的，安详的;vt.使平滑； 排除，消除； 安抚，平息； 使优雅;vi.变平和，变缓和；;n.平地，平面； forwards adv.向前方，继续向前；v.促进( forward的第三人称单数 )； （按新地址）转寄； 发送； 助长； Common uses for a reverse proxy server include: Load balancing – A reverse proxy server can act as a “traffic cop”, sitting in front of your backend servers and distributing client requests across a group of servers in a manner that maximizes speed and capacity utilization while ensuring no one server is overloaded, which can degrade performance. If a server goes down, the load balancer redirects traffic to the remaining online servers. Web acceleration – Reverse proxies can compress inbound and outbound data, as well as cache commonly requested content, both of which speed up the flow of traffic between clients and servers. They can also perform additional tasks such as SSL encryption to take load off of your web servers, thereby boosting their performance. Security and anonymity – By intercepting requests headed for your backend servers, a reverse proxy server protects their identities and acts as an additional defense against security attacks. It also ensures that multiple servers can be accessed from a single record locator or URL regardless of the structure of your local area network. 单词短语 解释 Load balancing 负载均衡 Web acceleration 网络加速 Security and anonymity 安全和匿名 degrade vt.降低，贬低； 使降级； 降低…身份； 使丢脸;vt.& vi.（使）退化，降解，分解； 降解； 撤职，免职； 降低品格[身价，价值（等）] traffic cop n.交通警察； inbound adj.回内地的； 归本国的； 到达的； 入境的 outbound adj.开往外地的，开往外国的； take load off 卸下包袱 boost vt.促进，提高； 增加； 吹捧； 向上推起;vi.宣扬； [美国俚语]（尤指在商店）行窃，偷窃；n.提高，增加； 帮助； 吹捧； 加速[助推]器 High-Performance Load Balancing （负载均衡） multiple copies of the same system horizontal scaling(水平扩展) HTTP load balance Problem You need to distribute load between two or more HTTP servers. (需要解决的是：将用户请求分发到 2 台以上 HTTP 服务器) Solution(解决方案) 将后端请求路由到2个服务器，并配置权重 upstream backend { server 10.10.12.45:80 weight=1; server app.example.com:80 weight=2; } server { location / { proxy_pass http://backend; } } 单词短语 解释 upstream adj.向上游的； 逆流而上的； （石油工业等）上游的；adv.向上游； 逆流地；n.上游部门； 如下，默认使用Round Robin使用两台服务器 http { upstream backend { server backend1.example.com; server backend2.example.com; server 192.0.0.1 backup; } server { location / { proxy_pass http://backend; } } } 负载均衡算法 Round Robin（轮询） This is the default load-balancing method, which distributes requests in the order of the list of servers in the upstream pool.You can also take weight into consideration for a weighted round robin, which you can use if the capacity of the upstream servers varies. The higher the integer value for the weight, the more favored the server will be in the round robin. The algorithm behind weight is simply statistical probability of a weighted average. 将请求按顺序轮流分配到后台服务器上，均衡的对待每一台服务器，而不关心服务器实际的连接数和当前的系统负载。也可以考虑假如权重。 Weight Round Robin Least connections（最小连接数） This method balances load by proxying the current request to the upstream server with the least number of open connections.Least connections, like round robin, also takes weights into account when deciding to which server to send the connection. The directive name is least_conn. 由于后台服务器的配置不尽相同，对请求的处理有快有慢，它正是根据后端服务器当前的连接情况，动态的选取其中当前积压连接数最少的一台服务器来处理当前请求，尽可能的提高后台服务器利用率，将负载合理的分流到每一台服务器。 Least time(最短响应时间负载均衡算法) Available only in NGINX Plus, least time is akin to least connections in that it proxies to the upstream server with the least number of current connections but favors the servers with the lowest average response times. This method is one of the most sophisticated load-balancing algorithms and fits the needs of highly performant web applications. This algorithm is a value\u0002add over least connections because a small number of connections does not necessarily mean the quickest response. A parameter of header or last_byte must be specified for this directive. When header is specified, the time to receive the response header is used. When last_byte is specified, the time to receive the full response is used. The directive name is least_time. 将请求 分发给平均响应时间更短的应用服务器。它是负载均衡算法最复杂的算法 之一，能够适用于需要高性能的 Web 服务器负载均衡的业务场景。该算法 是对最少连接数负载均衡算法的优化实现，因为最少的访问连接并非意味着 更快的响应。该指令的配置名称是 least_time。 Generic hash(哈希) The administrator defines a hash with the given text, variables of the request or runtime, or both. NGINX distributes the load among the servers by producing a hash for the current request and placing it against the upstream servers. This method is very useful when you need more control over where requests are sent or for determining which upstream server most likely will have the data cached. Note that when a server is added or removed from the pool, the hashed requests will be redistributed. This algorithm has an optional parameter, consistent, to minimize the effect of redistribution. The directive name is hash. 缓存使用，一致性哈希问题 Random This method is used to instruct NGINX to select a random server from the group, taking server weights into consideration. The optional two [method] parameter directs NGINX to randomly select two servers and then use the provided load\u0002balancing method to balance between those two. By default the least_conn method is used if two is passed without a method. The directive name for random load balancing is random. IP hash This method works only for HTTP. IP hash uses the client IP address as the hash. Slightly different from using the remote variable in a generic hash, this algorithm uses the first three octets of an IPv4 address or the entire IPv6 address. This method ensures that clients are proxied to the same upstream server as long as that server is available, which is extremely helpful when the session state is of concern and not handled by shared memory of the application. This method also takes the weight parameter into consideration when distributing the hash. The directive name is ip_hash. 通过客户端请求ip进行hash，再通过hash值选择后端server 当你服务端的一个特定url路径会被同一个用户连续访问时，如果负载均衡策略还是轮询的话，那该用户的多次访问会被打到各台服务器上，这显然并不高效（会建立多次http链接等问题）。甚至考虑一种极端情况，用户需要分片上传文件到服务器下，然后再由服务器将分片合并，这时如果用户的请求到达了不同的服务器，那么分片将存储于不同的服务器目录中，导致无法将分片合并。所以，此类场景可以考虑采用nginx提供的ip_hash策略。既能满足每个用户请求到同一台服务器，又能满足不同用户之间负载均衡。 URL hash 一般来讲，要用到url hash，是要配合缓存命中来使用。举一个我遇到的实例：有一个服务器集群A，需要对外提供文件下载，由于文件上传量巨大，没法存储到服务器磁盘中，所以用到了第三方云存储来做文件存储。服务器集群A收到客户端请求之后，需要从云存储中下载文件然后返回，为了省去不必要的网络带宽和下载耗时，在服务器集群A上做了一层临时缓存（缓存一个月）。由于是服务器集群，所以同一个资源多次请求，可能会到达不同的服务器上，导致不必要的多次下载，缓存命中率不高，以及一些资源时间的浪费。在此类场景下，为了使得缓存命中率提高，很适合使用url_hash策略，同一个url（也就是同一个资源请求）会到达同一台机器，一旦缓存住了资源，再此收到请求，就可以从缓存中读取，既减少了带宽，也减少的下载时间。 TCP/UDP load balance Load balancing refers to efficiently distributing network traffic across multiple backend servers. In NGINX Plus Release 5 and later, NGINX Plus can proxy and load balance Transmission Control Protocol) (TCP) traffic. TCP is the protocol for many popular applications and services, such as LDAP, MySQL, and RTMP. In NGINX Plus Release 9 and later, NGINX Plus can proxy and load balance UDP traffic. UDP (User Datagram Protocol) is the protocol for many popular non-transactional applications, such as DNS, syslog, and RADIUS. cookie & session（http 知识复习） http无连接概念介绍 HTTP的设计者有意利用这种特点将协议设计为请求时建连接、请求完释放连接，以尽快将资源释放出来服务其他客户端。随着时间的推移，网页变得越来越复杂，里面可能嵌入了很多图片，这时候每次访问图片都需要建立一次 TCP 连接就显得很低效。后来，Keep-Alive 被提出用来解决这效率低的问题。 我们知道HTTP协议采用“请求-应答”模式，当使用非KeepAlive模式时，每个请求/应答客户和服务器都要新建一个连接，完成之后立即断开连接；当使用Keep-Alive模式时，Keep-Alive功能使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，Keep-Alive功能避免了建立或者重新建立连接。 http 1.0中默认是关闭的，需要在http头加入”Connection: Keep-Alive”，才能启用Keep-Alive； http 1.1中默认启用Keep-Alive，如果加入”Connection: close“，才关闭，目前大部分浏览器都是用http1.1协议，也就是说默认都会发起Keep-Alive的连接请求了。Keep-Alive不会永久保持连接，它有一个保持时间。 Session A session creates a file in a temporary directory on the server where registered session variables and their values are stored. This data will be available to all pages on the site during that visit. A session ends when the user closes the browser or after leaving the site, the server will terminate the session after a predetermined period of time, commonly 30 minutes duration. Cookie mozilla doc of cookie An HTTP cookie (web cookie, browser cookie) is a small piece of data that a server sends to the user's web browser. The browser may store it and send it back with the next request to the same server. Typically, it's used to tell if two requests came from the same browser — keeping a user logged-in, for example. It remembers stateful information for the stateless HTTP protocol. Cookies are mainly used for three purposes: Session management Logins, shopping carts, game scores, or anything else the server should remember Personalization User preferences, themes, and other settings Tracking Recording and analyzing user behavior how to create cookie When receiving an HTTP request, a server can send a Set-Cookie header with the response. The cookie is usually stored by the browser, and then the cookie is sent with requests made to the same server inside a Cookie HTTP header. An expiration date or duration can be specified, after which the cookie is no longer sent. Additionally, restrictions to a specific domain and path can be set, limiting where the cookie is sent. HTTP Health Checks（HTTP健康检查） Server Slow Start（服务慢开始） A recently recovered server can be easily overwhelmed by connections, which may cause the server to be marked as unavailable again. Slow start allows an upstream server to gradually recover its weight from zero to its nominal value after it has been recovered or became available. This can be done with the slow_start parameter of the the upstream server directive: upstream backend { server backend1.example.com slow_start=30s; server backend2.example.com; server 192.0.0.1 backup; } Note that if there is only a single server in a group, the slow_start parameter is ignored and the server is never marked unavailable. Slow start is exclusive to NGINX Plus. Passive Health Checks For passive health checks, NGINX and NGINX Plus monitor transactions as they happen, and try to resume failed connections. If the transaction still cannot be resumed, NGINX Open Source and NGINX Plus mark the server as unavailable and temporarily stop sending requests to it until it is marked active again. Active Health Checks NGINX Plus can periodically check the health of upstream servers by sending special health‑check requests to each server and verifying the correct response. TCP Health Checks（TCP健康检查） NGINX and NGINX Plus can continually test your TCP upstream servers, avoid the servers that have failed, and gracefully add the recovered servers into the load‑balanced group. Passive TCP Health Checks(被动的TCP健康检查) If an attempt to connect to an upstream server times out or results in an error, NGINX Open Source or NGINX Plus can mark the server as unavailable and stop sending requests to it for a defined amount of time. To define the conditions under which NGINX considers an upstream server unavailable, include the following parameters to the server directive fail_timeout – The amount of time within which a specified number of connection attempts must fail for the server to be considered unavailable. Also, the amount of time that NGINX considers the server unavailable after marking it so. max_fails – The number of failed attempts that happen during the specified time for NGINX to consider the server unavailable. Active TCP Health Checks(主动的TCP健康检查) NGINX Plus sends special health check requests to each upstream server and checks for a response that satisfies certain conditions. If a connection to the server cannot be established, the health check fails, and the server is considered unhealthy. NGINX Plus does not proxy client connections to unhealthy servers. If several health checks are configured for an upstream group, the failure of any check is enough to consider the corresponding server unhealthy. Fine-Tuning TCP Health Checks 单词短语 解释 fine-tuning v.调整，使有规则( fine-tune的现在分词 )； By default, NGINX Plus tries to connect to each server in an upstream server group every 5 seconds. If the connection cannot be established, NGINX Plus considers the health check failed, marks the server as unhealthy, and stops forwarding client connections to the server. interval – How often (in seconds) NGINX Plus sends health check requests (default is 5 seconds) passes – Number of consecutive health checks the server must respond to to be considered healthy (default is 1) fails – Number of consecutive health checks the server must fail to respond to to be considered unhealthy (default is 1) Massively Scalable Content Caching 单词短语 解释 massive adj.大的，重的； 大块的，大量的； 魁伟的，结实的； 大规模的 Caching accelerates content serving by storing request responses to be served again in the future. Content caching reduces load to upstream servers, caching the full response rather than running computations and queries again for the same request. Caching increases performance and reduces load, meaning you can served faster with fewer resources. Scaling and distributing caching servers in strategic locations can have a dramatic effect on user experience. It’s optimal to host content close to the consumer for the best performance. You can also cache your content close to your users. This is the pattern of content delivery networks, or CDNs. With NGINX you’re able to cache your content wherever you can place an NGINX server, effectively enabling you to create your own CDN. With NGINX caching, you’re also able to passively cache and serve cached responses in the event of an upstream failure. 通过对请求的响应结果进行缓存，能够为后续相同请求提供加速服务。对相同请求 响应内容进行内容缓存(Content Caching)，相比每次请求都重新计算和查询被代理 服务器，能有效降低被代理服务器负载。内容缓存能提升服务性能，降低服务器负载压力，同时意味着能够使用更少的资源提供更快的服务。可伸缩的缓存服务从架构 层面来讲，能够显著提升用户体验，因为响应内容经过更少的转发就能够发送给用户，同时能提升服务器性能。 Web缓存类型 描述 数据库缓存 当web应用关系复杂，数据表蹭蹭蹭往上涨时，可以将查询后的数据放到内存中进行缓存，下次再查询时，就直接从内存缓存中获取，从而提高响应速度。 CDN缓存 当我们发送一个web请求时，CDN会帮我们计算去哪得到这些内容的路径短且快。这个是网站管理员部署的，所以他们也可以将大家经常访问的内容放在CDN里，从而加快响应。 代理服务器缓存 代理服务器缓存，跟浏览器缓存性质类似，但是代理服务器缓存面向的群体更广，规模更大。它不只为一个用户服务，一般为大量用户提供服务，同一个副本会被重用多次,因此在减少响应时间和带宽使用方面很有效。 浏览器缓存 每个浏览器都实现了 HTTP 缓存，我们通过浏览器使用HTTP协议与服务器交互的时候，浏览器就会根据一套与服务器约定的规则进行缓存工作。当我们在浏览器中点击前进和后退 按钮时，利用的便是浏览器的缓存机制。 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-06-28 23:25:23 "},"content/distributed_design/tomcat.html":{"url":"content/distributed_design/tomcat.html","title":"tomcat","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 Tomcat 几个问题 Tomcat是一个Servlet容器？ Servlet Servlet在应用中的架构位置 Servlet架构图 Servlet生命周期 如何创建 Servlet ? 应用部署(how to deploy?) War包和Jar包的区别？ Tomcat源码阅读笔记 Tomcat架构 Tomcat 如何处理请求 Connector(根据协议确定网络IO模型) org.apache.coyote.http11.Http11Protocol JIoEndpoint JIoEndpoint Acceptor BIO模型 附：限流组件LimitLatch 附：StandardThreadExecutor(Tomcat 7.0.105,基于JDKThreadPoolExecutor) org.apache.coyote.http11.Http11NioProtocol NioEndpoint NioEndpoint的初始化 NioEndpoint Acceptor 同步非阻塞NIO（None Blocking IO） 补充：如何避免同步非阻塞NIO模型中轮询等待的问题呢？ 复习阻塞/非阻塞，同步/异步的概念 [TOC] Tomcat 直接认识：一个URL访问，经过Tomcat处理请求，将请求传递给SpringBoot/SpringMvc的Controller 几个问题 为什么说Tomcat是一个Servlet容器？ Tomcat部署应用有几种方式？ War包和Jar包的区别？ Tomcat是怎么处理请求的，处理请求的流程是怎么样的？ Tcp,Http,Socket,Tomcat之间的关系是什么？ Tomcat是一个Servlet容器？ class Tomcat{ List servlets; } Servlet Servlet在应用中的架构位置 Servlet架构图 第一个到达服务器的 HTTP 请求被委派到 Servlet 容器。 Servlet 容器在调用 service() 方法之前加载 Servlet。 然后 Servlet 容器处理由多个线程产生的多个请求，每个线程执行一个单一的 Servlet 实例的 service() 方法。 Servlet生命周期 Servlet 生命周期可被定义为从创建直到毁灭的整个过程。以下是 Servlet 遵循的过程： Servlet 通过调用init()方法进行初始化。 Servlet 调用service()方法来处理客户端的请求。 Servlet 通过调用destroy()方法终止（结束）。 最后，Servlet 是由 JVM 的垃圾回收器进行垃圾回收的。 service()方法是执行实际任务的主要方法。Servlet 容器（即 Web 服务器）调用 service() 方法来处理来自客户端（浏览器）的请求，并把格式化的响应写回给客户端。每次服务器接收到一个 Servlet 请求时，服务器会产生一个新的线程并调用服务。service() 方法检查 HTTP 请求类型（GET、POST、PUT、DELETE 等），并在适当的时候调用 doGet、doPost、doPut，doDelete等方法。 doGet方法 public void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // Servlet 代码 } doPost()方法 public void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { // Servlet 代码 } 如何创建 Servlet ? 实现 Servlet 接口 继承 GenericServlet 类 GenericServlet实现了 Servlet 接口除了 service 的方法，不过这种方法我们极少用) 继承 HttpServlet 方法 HttpServlet 类，提供了 Http 相关的方法，HttpServlet 扩展了 GenericServlet 类，而 GenericServlet 类又实现了 Servlet 类和 ServletConfig 类 应用部署(how to deploy?) // todo War包和Jar包的区别？ archive n. 档案; 档案馆; 档案室; v. 把…存档; 把…归档; 将(不常用信息)存档; A JAR file is a file that contains all components to make a self-contained executable Java application. Moreover, a JAR file includes compiled Java source code, manifest file, XML based configuration data, JSON based data files, images and audio. It is an aggregation of all these files into a single, compressed file. Compressing all the files helps to reduce the size of the application. Furthermore, it makes it easier to move the JAR file over the network between different platforms. Every Java Development Kit (JDK) includes a JAR utility to support JAR files. It allows creating new JAR files with a manifest file and extracting all the content of a JAR file onto the file system. Moreover, JAR utility helps to update existing JAR files. Most JAR files are simply containers for data that another program needs to run with Java; therefore you cannot run these files and nothing will happen when you double-click them. Similarly, most executable JAR files are downloaded as installation files to install applications or programs. A WAR file contains files related to a web project. It contains servlet, JSP, XML, HTML, CSS, and JavaScript files that can be deployed on any servlet/JSP container. The jar tool of JDK helps to create a WAR file. These files are inside the WEB-INF folder of the project. A WAR file combines all the files into a single unit. Therefore, it takes a minimum amount of time to transfer a file from client to server. WAR files need to be deployed on web container like Apache Tomcat, Jetty, Wildfly etc or it will also deployed on application server. Tomcat源码阅读笔记 https://github.com/doctording/apache-tomcat-8.5.57-src Tomcat架构 回答：为什么说Tomcat是一个Servlet容器？ 4个容器：Engine, Host, Context，Wrapper 最后Servlet实例执行service方法 Tomcat 如何处理请求 Tomcat要从Socket读取网络数据，这要涉及到I/O，tomcat I/O包括: NIO BIO AIO AJP socket --> socket.getInputStream() --> parse --> Request Connector(根据协议确定网络IO模型) 见：Tomcat7 的 Connector类，配置参考：HTTP Connector config /** * Set the Coyote protocol which will be used by the connector. * * @param protocol The Coyote protocol name */ public void setProtocol(String protocol) { if (AprLifecycleListener.isAprAvailable()) { if (\"HTTP/1.1\".equals(protocol)) { setProtocolHandlerClassName (\"org.apache.coyote.http11.Http11AprProtocol\"); } else if (\"AJP/1.3\".equals(protocol)) { setProtocolHandlerClassName (\"org.apache.coyote.ajp.AjpAprProtocol\"); } else if (protocol != null) { setProtocolHandlerClassName(protocol); } else { setProtocolHandlerClassName (\"org.apache.coyote.http11.Http11AprProtocol\"); } } else { if (\"HTTP/1.1\".equals(protocol)) { setProtocolHandlerClassName (\"org.apache.coyote.http11.Http11Protocol\"); } else if (\"AJP/1.3\".equals(protocol)) { setProtocolHandlerClassName (\"org.apache.coyote.ajp.AjpProtocol\"); } else if (protocol != null) { setProtocolHandlerClassName(protocol); } } } HTTP使用的是org.apache.coyote.http11.Http11Protocol处理的 org.apache.coyote.http11.Http11Protocol tomcat7 源码中 public class Http11Protocol extends AbstractHttp11JsseProtocol public class Http11NioProtocol extends AbstractHttp11JsseProtocol JIoEndpoint JIoEndpoint的作用是处理访问的TCP连接.具体的实现是主线程启动一个Acceptor线程,它将启用一个阻塞型Socket监听Tcp连接,获得连接后对每个连接启动一个worker线程进行处理.（常规的BIO模型） JIoEndpoint Acceptor // --------------------------------------------------- Acceptor Inner Class /** * The background thread that listens for incoming TCP/IP connections and * hands them off to an appropriate processor. */ protected class Acceptor extends AbstractEndpoint.Acceptor { @Override public void run() { int errorDelay = 0; // Loop until we receive a shutdown command while (running) { // Loop if endpoint is paused while (paused && running) { state = AcceptorState.PAUSED; try { Thread.sleep(50); } catch (InterruptedException e) { // Ignore } } if (!running) { break; } state = AcceptorState.RUNNING; try { //if we have reached max connections, wait countUpOrAwaitConnection(); Socket socket = null; try { // Accept the next incoming connection from the server // socket socket = serverSocketFactory.acceptSocket(serverSocket); } catch (IOException ioe) { countDownConnection(); // Introduce delay if necessary errorDelay = handleExceptionWithDelay(errorDelay); // re-throw throw ioe; } // Successful accept, reset the error delay errorDelay = 0; // Configure the socket if (running && !paused && setSocketOptions(socket)) { // Hand this socket off to an appropriate processor if (!processSocket(socket)) { countDownConnection(); // Close socket right away closeSocket(socket); } } else { countDownConnection(); // Close socket right away closeSocket(socket); } } catch (IOException x) { if (running) { log.error(sm.getString(\"endpoint.accept.fail\"), x); } } catch (NullPointerException npe) { if (running) { log.error(sm.getString(\"endpoint.accept.fail\"), npe); } } catch (Throwable t) { ExceptionUtils.handleThrowable(t); log.error(sm.getString(\"endpoint.accept.fail\"), t); } } state = AcceptorState.ENDED; } } 阻塞接收Socket; 对Socket处理也是阻塞的 socket = serverSocketFactory.acceptSocket(serverSocket); Process socket 开启新线程处理 /** * Process a new connection from a new client. Wraps the socket so * keep-alive and other attributes can be tracked and then passes the socket * to the executor for processing. * * @param socket The socket associated with the client. * * @return true if the socket is passed to the * executor, false if something went wrong or * if the endpoint is shutting down. Returning * false is an indication to close the socket * immediately. */ protected boolean processSocket(Socket socket) { // Process the request from this socket try { SocketWrapper wrapper = new SocketWrapper(socket); wrapper.setKeepAliveLeft(getMaxKeepAliveRequests()); wrapper.setSecure(isSSLEnabled()); // During shutdown, executor may be null - avoid NPE if (!running) { return false; } getExecutor().execute(new SocketProcessor(wrapper)); } catch (RejectedExecutionException x) { log.warn(\"Socket processing request was rejected for:\"+socket,x); return false; } catch (Throwable t) { ExceptionUtils.handleThrowable(t); // This means we got an OOM or similar creating a thread, or that // the pool and its queue are full log.error(sm.getString(\"endpoint.process.fail\"), t); return false; } return true; } BIO模型 JIoEndpoint维护了Acceptor和Worker：Acceptor接收socket，然后从Worker线程池中找出空闲的线程处理socket，如果worker线程池没有空闲线程，则Acceptor将阻塞。 小于等于Coresize：创建线程执行 大于CoreSize：加入队列 队列满且小于maxSize：有空闲线程使用空闲线程执行，没有的话，创建线程执行；如果大于maxSize则执行拒绝策略 附：限流组件LimitLatch LimitLatch组件是一个流量控制组件，目的是为了不让Tomcat组件被大流量冲垮。LimitLatch通过AQS机制实现，这个组件启动时先初始化同步器的最大限制值，然后每接收一个套接字就将计数变量累加1，每关闭一个套接字将计数变量减1。当连接数达到最大值时，Acceptor线程就进入等待状态，不再accept新的socket连接。 需要额外说明的是，当到达最大连接数时（已经LimitLatch组件最大值，acceptor组件阻塞了），操作系统底层还是会继续接收客户端连接，并将请求放入一个队列中（backlog队列）。这个队列是有一个默认长度的，默认值是100。当然，这个值可以通过server.xml的Connector节点的acceptCount属性配置。假如在短时间内，有大量请求过来，连backlog队列都放满了，那么操作系统将拒绝接收后续的连接，返回“connection refused”。 在BIO模式中，LimitLatch组件支持的最大连接数是通过server.xml的Connector节点的maxConnections属性设置的，如果设置成-1，则表示不限制。 附：StandardThreadExecutor(Tomcat 7.0.105,基于JDKThreadPoolExecutor) package org.apache.catalina.core; import java.util.concurrent.RejectedExecutionException; import java.util.concurrent.TimeUnit; import org.apache.catalina.Executor; import org.apache.catalina.LifecycleException; import org.apache.catalina.LifecycleState; import org.apache.catalina.util.LifecycleMBeanBase; import org.apache.tomcat.util.threads.ResizableExecutor; import org.apache.tomcat.util.threads.TaskQueue; import org.apache.tomcat.util.threads.TaskThreadFactory; import org.apache.tomcat.util.threads.ThreadPoolExecutor; public class StandardThreadExecutor extends LifecycleMBeanBase implements Executor, ResizableExecutor { // ---------------------------------------------- Properties /** * Default thread priority */ protected int threadPriority = Thread.NORM_PRIORITY; /** * Run threads in daemon or non-daemon state */ protected boolean daemon = true; /** * Default name prefix for the thread name */ protected String namePrefix = \"tomcat-exec-\"; /** * max number of threads */ protected int maxThreads = 200; /** * min number of threads */ protected int minSpareThreads = 25; /** * idle time in milliseconds */ protected int maxIdleTime = 60000; /** * The executor we use for this component */ protected ThreadPoolExecutor executor = null; /** * the name of this thread pool */ protected String name; /** * prestart threads? */ protected boolean prestartminSpareThreads = false; /** * The maximum number of elements that can queue up before we reject them */ protected int maxQueueSize = Integer.MAX_VALUE; /** * After a context is stopped, threads in the pool are renewed. To avoid * renewing all threads at the same time, this delay is observed between 2 * threads being renewed. */ protected long threadRenewalDelay = org.apache.tomcat.util.threads.Constants.DEFAULT_THREAD_RENEWAL_DELAY; private TaskQueue taskqueue = null; // ---------------------------------------------- Constructors public StandardThreadExecutor() { //empty constructor for the digester } // ---------------------------------------------- Public Methods @Override protected void initInternal() throws LifecycleException { super.initInternal(); } /** * Start the component and implement the requirements * of {@link org.apache.catalina.util.LifecycleBase#startInternal()}. * * @exception LifecycleException if this component detects a fatal error * that prevents this component from being used */ @Override protected void startInternal() throws LifecycleException { taskqueue = new TaskQueue(maxQueueSize); TaskThreadFactory tf = new TaskThreadFactory(namePrefix,daemon,getThreadPriority()); executor = new ThreadPoolExecutor(getMinSpareThreads(), getMaxThreads(), maxIdleTime, TimeUnit.MILLISECONDS,taskqueue, tf); executor.setThreadRenewalDelay(threadRenewalDelay); if (prestartminSpareThreads) { executor.prestartAllCoreThreads(); } taskqueue.setParent(executor); setState(LifecycleState.STARTING); } /** * Stop the component and implement the requirements * of {@link org.apache.catalina.util.LifecycleBase#stopInternal()}. * * @exception LifecycleException if this component detects a fatal error * that needs to be reported */ @Override protected void stopInternal() throws LifecycleException { setState(LifecycleState.STOPPING); if ( executor != null ) executor.shutdownNow(); executor = null; taskqueue = null; } @Override protected void destroyInternal() throws LifecycleException { super.destroyInternal(); } @Override public void execute(Runnable command, long timeout, TimeUnit unit) { if ( executor != null ) { executor.execute(command,timeout,unit); } else { throw new IllegalStateException(\"StandardThreadExecutor not started.\"); } } @Override public void execute(Runnable command) { if ( executor != null ) { try { executor.execute(command); } catch (RejectedExecutionException rx) { //there could have been contention around the queue if ( !( (TaskQueue) executor.getQueue()).force(command) ) throw new RejectedExecutionException(\"Work queue full.\"); } } else throw new IllegalStateException(\"StandardThreadPool not started.\"); } public void contextStopping() { if (executor != null) { executor.contextStopping(); } } public int getThreadPriority() { return threadPriority; } public boolean isDaemon() { return daemon; } public String getNamePrefix() { return namePrefix; } public int getMaxIdleTime() { return maxIdleTime; } @Override public int getMaxThreads() { return maxThreads; } public int getMinSpareThreads() { return minSpareThreads; } @Override public String getName() { return name; } public boolean isPrestartminSpareThreads() { return prestartminSpareThreads; } public void setThreadPriority(int threadPriority) { this.threadPriority = threadPriority; } public void setDaemon(boolean daemon) { this.daemon = daemon; } public void setNamePrefix(String namePrefix) { this.namePrefix = namePrefix; } public void setMaxIdleTime(int maxIdleTime) { this.maxIdleTime = maxIdleTime; if (executor != null) { executor.setKeepAliveTime(maxIdleTime, TimeUnit.MILLISECONDS); } } public void setMaxThreads(int maxThreads) { this.maxThreads = maxThreads; if (executor != null) { executor.setMaximumPoolSize(maxThreads); } } public void setMinSpareThreads(int minSpareThreads) { this.minSpareThreads = minSpareThreads; if (executor != null) { executor.setCorePoolSize(minSpareThreads); } } public void setPrestartminSpareThreads(boolean prestartminSpareThreads) { this.prestartminSpareThreads = prestartminSpareThreads; } public void setName(String name) { this.name = name; } public void setMaxQueueSize(int size) { this.maxQueueSize = size; } public int getMaxQueueSize() { return maxQueueSize; } public long getThreadRenewalDelay() { return threadRenewalDelay; } public void setThreadRenewalDelay(long threadRenewalDelay) { this.threadRenewalDelay = threadRenewalDelay; if (executor != null) { executor.setThreadRenewalDelay(threadRenewalDelay); } } // Statistics from the thread pool @Override public int getActiveCount() { return (executor != null) ? executor.getActiveCount() : 0; } public long getCompletedTaskCount() { return (executor != null) ? executor.getCompletedTaskCount() : 0; } public int getCorePoolSize() { return (executor != null) ? executor.getCorePoolSize() : 0; } public int getLargestPoolSize() { return (executor != null) ? executor.getLargestPoolSize() : 0; } @Override public int getPoolSize() { return (executor != null) ? executor.getPoolSize() : 0; } public int getQueueSize() { return (executor != null) ? executor.getQueue().size() : -1; } @Override public boolean resizePool(int corePoolSize, int maximumPoolSize) { if (executor == null) return false; executor.setCorePoolSize(corePoolSize); executor.setMaximumPoolSize(maximumPoolSize); return true; } @Override public boolean resizeQueue(int capacity) { return false; } @Override protected String getDomainInternal() { // No way to navigate to Engine. Needs to have domain set. return null; } @Override protected String getObjectNameKeyProperties() { StringBuilder name = new StringBuilder(\"type=Executor,name=\"); name.append(getName()); return name.toString(); } } org.apache.coyote.http11.Http11NioProtocol NioEndpoint NioEndpoint的初始化 /** * Initialize the endpoint. */ @Override public void bind() throws Exception { // 开启一个新的ServerSocketChannel serverSock = ServerSocketChannel.open(); socketProperties.setProperties(serverSock.socket()); InetSocketAddress addr = (getAddress()!=null?new InetSocketAddress(getAddress(),getPort()):new InetSocketAddress(getPort())); // 绑定端口 serverSock.socket().bind(addr,getBacklog()); // 设置成阻塞方式 serverSock.configureBlocking(true); //mimic APR behavior if (getSocketProperties().getSoTimeout() >= 0) { serverSock.socket().setSoTimeout(getSocketProperties().getSoTimeout()); } // 初始化acceptor线程数 // Initialize thread count defaults for acceptor, poller if (acceptorThreadCount == 0) { // FIXME: Doesn't seem to work that well with multiple accept threads acceptorThreadCount = 1; } // 初始化poller线程数 if (pollerThreadCount 0) reclaimParachute(true); // 开启NioSelectorPool selectorPool.open(); } NioEndpoint Acceptor // --------------------------------------------------- Acceptor Inner Class /** * The background thread that listens for incoming TCP/IP connections and * hands them off to an appropriate processor. */ protected class Acceptor extends AbstractEndpoint.Acceptor { @Override public void run() { int errorDelay = 0; // Loop until we receive a shutdown command while (running) { // Loop if endpoint is paused while (paused && running) { state = AcceptorState.PAUSED; try { Thread.sleep(50); } catch (InterruptedException e) { // Ignore } } if (!running) { break; } state = AcceptorState.RUNNING; try { //if we have reached max connections, wait countUpOrAwaitConnection(); SocketChannel socket = null; try { // 接收请求 // Accept the next incoming connection from the server // socket socket = serverSock.accept(); } catch (IOException ioe) { //we didn't get a socket countDownConnection(); // Introduce delay if necessary errorDelay = handleExceptionWithDelay(errorDelay); // re-throw throw ioe; } // Successful accept, reset the error delay errorDelay = 0; // setSocketOptions() will add channel to the poller // if successful if (running && !paused) { // setSocketOptions() 把socket channel 加到 poller 中 if (!setSocketOptions(socket)) { countDownConnection(); closeSocket(socket); } } else { countDownConnection(); closeSocket(socket); } } catch (SocketTimeoutException sx) { // Ignore: Normal condition } catch (IOException x) { if (running) { log.error(sm.getString(\"endpoint.accept.fail\"), x); } } catch (OutOfMemoryError oom) { try { oomParachuteData = null; releaseCaches(); log.error(\"\", oom); }catch ( Throwable oomt ) { try { try { System.err.println(oomParachuteMsg); oomt.printStackTrace(); }catch (Throwable letsHopeWeDontGetHere){ ExceptionUtils.handleThrowable(letsHopeWeDontGetHere); } }catch (Throwable letsHopeWeDontGetHere){ ExceptionUtils.handleThrowable(letsHopeWeDontGetHere); } } } catch (Throwable t) { ExceptionUtils.handleThrowable(t); log.error(sm.getString(\"endpoint.accept.fail\"), t); } } state = AcceptorState.ENDED; } } 设置非阻塞 新的SocketChannel后会构建一个OP_REGISTER类型的PollerEvent事件并放到Poller.events队列中 /** * Process the specified connection. */ protected boolean setSocketOptions(SocketChannel socket) { // Process the connection try { //disable blocking, APR style, we are gonna be polling it socket.configureBlocking(false); Socket sock = socket.socket(); socketProperties.setProperties(sock); NioChannel channel = nioChannels.poll(); if ( channel == null ) { // SSL setup if (sslContext != null) { SSLEngine engine = createSSLEngine(); int appbufsize = engine.getSession().getApplicationBufferSize(); NioBufferHandler bufhandler = new NioBufferHandler(Math.max(appbufsize,socketProperties.getAppReadBufSize()), Math.max(appbufsize,socketProperties.getAppWriteBufSize()), socketProperties.getDirectBuffer()); channel = new SecureNioChannel(socket, engine, bufhandler, selectorPool); } else { // normal tcp setup NioBufferHandler bufhandler = new NioBufferHandler(socketProperties.getAppReadBufSize(), socketProperties.getAppWriteBufSize(), socketProperties.getDirectBuffer()); channel = new NioChannel(socket, bufhandler); } } else { channel.setIOChannel(socket); if ( channel instanceof SecureNioChannel ) { SSLEngine engine = createSSLEngine(); ((SecureNioChannel)channel).reset(engine); } else { channel.reset(); } } // 注册NioChannel对象 getPoller0().register(channel); } catch (Throwable t) { ExceptionUtils.handleThrowable(t); try { log.error(\"\",t); } catch (Throwable tt) { ExceptionUtils.handleThrowable(tt); } // Tell to close the socket return false; } return true; } public void register(final NioChannel socket) { socket.setPoller(this); KeyAttachment key = keyCache.poll(); final KeyAttachment ka = key!=null?key:new KeyAttachment(socket); ka.reset(this,socket,getSocketProperties().getSoTimeout()); ka.setKeepAliveLeft(NioEndpoint.this.getMaxKeepAliveRequests()); ka.setSecure(isSSLEnabled()); PollerEvent r = eventCache.poll(); ka.interestOps(SelectionKey.OP_READ);//this is what OP_REGISTER turns into. if ( r==null) r = new PollerEvent(socket,ka,OP_REGISTER); else r.reset(socket,ka,OP_REGISTER); // 添加`PollerEvent` addEvent(r); } Poller线程会从Poller.events队列中取出PollerEvent对象，并运行PollerEvent.run()方法。在PollerEvent.run()方法中发现是OP_REGISTER事件，则会在Poller.selector上注册SocketChannel对象的OP_READ就绪事件 @Override public void run() { if ( interestOps == OP_REGISTER ) { try { socket.getIOChannel().register(socket.getPoller().getSelector(), SelectionKey.OP_READ, key); } catch (Exception x) { log.error(\"\", x); } } else { final SelectionKey key = socket.getIOChannel().keyFor(socket.getPoller().getSelector()); try { if (key == null) { // The key was cancelled (e.g. due to socket closure) // and removed from the selector while it was being // processed. Count down the connections at this point // since it won't have been counted down when the socket // closed. socket.getPoller().getEndpoint().countDownConnection(); } else { final KeyAttachment att = (KeyAttachment) key.attachment(); if ( att!=null ) { //handle callback flag if (att.isComet() && (interestOps & OP_CALLBACK) == OP_CALLBACK ) { att.setCometNotify(true); } else { att.setCometNotify(false); } interestOps = (interestOps & (~OP_CALLBACK));//remove the callback flag att.access();//to prevent timeout //we are registering the key to start with, reset the fairness counter. int ops = key.interestOps() | interestOps; att.interestOps(ops); key.interestOps(ops); } else { socket.getPoller().cancelledKey(key, SocketStatus.ERROR, false); } } } catch (CancelledKeyException ckx) { try { socket.getPoller().cancelledKey(key, SocketStatus.DISCONNECT, true); } catch (Exception ignore) {} } }//end if }//run 同步非阻塞NIO（None Blocking IO） 应用程序的线程需要不断的进行 I/O 系统调用，轮询数据是否已经准备好，如果没有准备好，继续轮询，直到完成系统调用为止。 优点：每次发起的 IO 系统调用，在内核的等待数据过程中可以立即返回。用户线程不会阻塞，实时性较好 缺点：需要不断的重复发起IO系统调用，这种不断的轮询，将会不断地询问内核，这将占用大量的 CPU 时间，系统资源利用率较低。 补充：如何避免同步非阻塞NIO模型中轮询等待的问题呢？ 如何避免同步非阻塞NIO模型中轮询等待的问题呢？这就是IO多路复用模型。 IO多路复用模型，就是通过一种新的系统调用，一个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是内核缓冲区可读/可写），内核kernel能够通知程序进行相应的IO系统调用。 目前支持IO多路复用的系统调用，有 select，epoll等等。select系统调用，是目前几乎在所有的操作系统上都有支持，具有良好跨平台特性。epoll是在linux 2.6内核中提出的，是select系统调用的linux增强版本。 复习阻塞/非阻塞，同步/异步的概念 阻塞与非阻塞(等待IO时的状态) 函数或方法（用户线程调用内核IO操作）的实现方式： 阻塞是指IO操作需要彻底完成后才返回到用户空间 非阻塞是指IO操作被调用后立即返回给用户一个状态值，无需等到IO操作彻底完成。 同步与异步（用户线程与内核的消息交互方式） 同步指用户线程发起IO请求后需要等待或者轮询内核IO操作完成后才能继续执行；同步有阻塞，非阻塞之分 异步是指用户线程发起IO请求后仍然继续执行，当内核IO操作完成后会通知用户线程，或者调用用户线程注册的回调函数。异步一定是非阻塞的（内核会通过函数回调或者信号机制通知用户进程；类似观察者模式） Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-08-01 20:41:57 "},"content/distributed_design/distribute.html":{"url":"content/distributed_design/distribute.html","title":"分布式基础","keywords":"","body":"[TOC] 分布式架构 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-21 10:38:12 "},"content/distributed_design/distribute_tx.html":{"url":"content/distributed_design/distribute_tx.html","title":"分布式事务","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 分布式事务 分布式事务问题？ 分布式事务的理论标准 BASE理论 CAP理论 Two-phase Commit，2PC 系统组件 两阶段执行过程 缺点 Three-Phase Commit，3PC 三阶段执行过程 TTC(Try-Confirm-Cancel) seata how to define a Distributed Transaction? 模拟分布式事务的解决 There are 3 basic components in Seata [TOC] 分布式事务 分布式事务问题？ 如图：订单系统中的本地事务A，远程调用了库存系统中的本地事务B；如果事务A遇到了问题，事务A会回滚，但是事务B如果正常执行，不会回滚，这就产生了问题： 订单创建是失败的，订单确实没有生成，但是库存却减少了；这显然要出问题 显然我们想要实现的是：要么一起执行完，要么一起回滚掉，这样就不会产生问题。所以如何解决这个问题？ 分布式事务的理论标准 BASE理论 ACID只适合于本地事务，对于分布式系统来说，应该有全新的标准 ==> BASE BASE Transaction If we call transactions that satisfy ACID features as hard transactions, then transactions based on BASE features are called soft transactions. BASE is the abbreviation(n.略语;缩写词;缩写形式;) of basically available（基本可用）, soft state（持久化写入没必要一定要写入一致） and eventually consistent（最终一致） those there factors. Basically available feature means not all the participants（n. 参与者; 参加者;）of distributed transactions have to be online at the same time. Soft state feature permits some time delay in system renewal（n. 恢复; 更新; 重新开始; (对合同等的) 有效期延长，展期，续订; 改进; 复兴; 振兴;）, which may not be noticed by users. Eventually consistent feature of systems is usually guaranteed by message availability. 补偿 compensation：n. 补偿(或赔偿)物; (尤指) 赔偿金，补偿金; 赔偿; 使坏的情况变好的事物; (对不利局面的) 补偿; 补偿就是指的一个事务中的某个一个操作片段，就是补偿，具体说来可以是一个远程的操作，也可以是一个本地的操作，可以是一个更新操作，也可以是一个取消操作。 eg: 比如我把500元从某个银行卡账户转入到微信钱包。那么对微信这边的转入接口进行的操作便是一个补偿操作。看到这里，你可能在想，原来是调用一个远程接口啊。没错，直接去调用现有的远程接口就是一种补偿操作。 CAP理论 CAP理论指的是一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。 Two-phase Commit，2PC 两阶段提交协议（two phase commit protocol，2PC）可以保证数据的强一致性，许多分布式关系型数据管理系统采用此协议来完成分布式事务。它是协调所有分布式原子事务参与者，并决定提交或取消（回滚）的分布式算法。同时也是解决一致性问题的一致性算法。该算法能够解决很多的临时性系统故障（包括进程、网络节点、通信等故障），被广泛地使用。 系统组件 协调者coordinator，通常一个系统中只有一个 事务参与者 participants，cohorts或workers，一般包含多个 两阶段执行过程 阶段1：请求阶段（commit-request phase，或称表决阶段，voting phase） 在请求阶段，协调者将通知事务参与者准备提交或取消事务，然后进入表决过程。在表决过程中，参与者将告知协调者自己的决策：同意（事务参与者本地作业执行成功）或取消（本地作业执行故障）。 阶段2：提交阶段（commit phase） 在该阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消。当且仅当所有的参与者同意提交事务协调者才通知所有的参与者提交事务，否则协调者将通知所有的参与者取消事务。参与者在接收到协调者发来的消息后将执行响应的操作。 例子说明：A将成为该活动的协调者，B、C和D将成为该活动的参与者。 阶段1 A发邮件给B、C和D，提出下周三去爬山，问是否同意。那么此时A需要等待B、C和D的邮件。 B、C和D分别查看自己的日程安排表。B、C发现自己在当日没有活动安排，则发邮件告诉A它们同意下周三去爬长城。由于某种原因， D白天没有查看邮件。那么此时A、B和C均需要等待。到晚上的时候，D发现了A的邮件，然后查看日程安排，发现周三当天已经有别的安排，那么D回复A说活动取消吧。 阶段2 此时A收到了所有活动参与者的邮件，并且A发现D下周三不能去爬山。那么A将发邮件通知B、C和D，下周三爬长城活动取消。 此时B、C回复A“太可惜了”，D回复A“不好意思”。至此该事务终止。 缺点 同步阻塞：最大的问题即同步阻塞，即：所有参与事务的逻辑均处于阻塞状态。 单点：协调者存在单点问题，如果协调者出现故障，参与者将一直处于锁定状态。 脑裂：在阶段2中，如果只有部分参与者接收并执行了Commit请求，会导致节点数据不一致。 Three-Phase Commit，3PC 3PC，三阶段提交协议，是2PC的改进版本；协调者、参与者都引入了超时机制；三阶段 CanCommit、PreCommit（其中一个超时或者执行失败，则发起中断）和doCommit 三阶段执行过程 CanCommit阶段 3PC的CanCommit阶段其实和2PC的准备阶段很像。 协调者向参与者发送commit请求，参与者如果可以提交就返回Yes响应，否则返回No响应。 PreCommit阶段 Coordinator根据Cohort的反应情况来决定是否可以继续事务的PreCommit操作。 根据响应情况，有以下两种可能。 A.假如Coordinator从所有的Cohort获得的反馈都是Yes响应，那么就会进行事务的预执行： 发送预提交请求。Coordinator向Cohort发送PreCommit请求，并进入Prepared阶段。 事务预提交。Cohort接收到PreCommit请求后，会执行事务操作，并将undo和redo信息记录到事务日志中。 响应反馈。如果Cohort成功的执行了事务操作，则返回ACK响应，同时开始等待最终指令。 B.假如有任何一个Cohort向Coordinator发送了No响应，或者等待超时之后，Coordinator都没有接到Cohort的响应，那么就中断事务： 发送中断请求。Coordinator向所有Cohort发送abort请求。 中断事务。Cohort收到来自Coordinator的abort请求之后（或超时之后，仍未收到Cohort的请求），执行事务的中断。 DoCommit阶段 该阶段进行真正的事务提交，也可以分为以下两种情况: 执行提交 A.发送提交请求。Coordinator接收到Cohort发送的ACK响应，那么他将从预提交状态进入到提交状态。并向所有Cohort发送doCommit请求。 B.事务提交。Cohort接收到doCommit请求之后，执行正式的事务提交。并在完成事务提交之后释放所有事务资源。 C.响应反馈。事务提交完之后，向Coordinator发送ACK响应。 D.完成事务。Coordinator接收到所有Cohort的ACK响应之后，完成事务。 中断事务 Coordinator没有接收到Cohort发送的ACK响应（可能是接受者发送的不是ACK响应，也可能响应超时），那么就会执行中断事务。 TTC(Try-Confirm-Cancel) DML try : 预留业务资源 Commit confirm : 确认执行业务操作 Rollback cancel : 取消执行业务操作 例子说明: A,B,C三个账户事务(A：-30，B：-50，C：+80) Try：尝试执行业务 完成所有业务检查(一致性)：检查A、B、C的帐户状态是否正常，帐户A的余额是否不少于30元，帐户B的余额是否不少于50元。 预留必须业务资源(准隔离性)：帐户A的冻结金额增加30元，帐户B的冻结金额增加50元，这样就保证不会出现其他并发进程扣减了这两个帐户的余额而导致在后续的真正转帐操作过程中，帐户A和B的可用余额不够的情况。 Confirm：确认执行业务 真正执行业务：如果Try阶段帐户A、B、C状态正常，且帐户A、B余额够用，则执行帐户A给账户C转账30元、帐户B给账户C转账50元的转帐操作。 不做任何业务检查：这时已经不需要做业务检查，Try阶段已经完成了业务检查。 只使用Try阶段预留的业务资源：只需要使用Try阶段帐户A和帐户B冻结的金额即可。 Cancel：取消执行业务 释放Try阶段预留的业务资源：如果Try阶段部分成功，比如帐户A的余额够用，且冻结相应金额成功，帐户B的余额不够而冻结失败，则需要对帐户A做Cancel操作，将帐户A被冻结的金额解冻掉。 seata github seata how to define a Distributed Transaction? We say, a Distributed Transaction is a Global Transaction which is made up with a batch of Branch Transaction, and normally Branch Transaction is just Local Transaction. 模拟分布式事务的解决 There are 3 basic components in Seata Transaction Coordinator(TC): Maintain status of global and branch transactions, drive the global commit or rollback. Transaction Manager(TM): Define the scope of global transaction: begin a global transaction, commit or rollback a global transaction. Resource Manager(RM): Manage resources that branch transactions working on, talk to TC for registering branch transactions and reporting status of branch transactions, and drive the branch transaction commit or rollback. A typical lifecycle of Seata managed distributed transaction: TM asks TC to begin a new global transaction. TC generates an XID representing the global transaction. XID is propagated through microservices' invoke chain. RM register local transaction as a branch of the corresponding global transaction of XID to TC. TM asks TC for committing or rollbacking the corresponding global transaction of XID. TC drives all branch transactions under the corresponding global transaction of XID to finish branch committing or rollbacking. Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-24 13:59:47 "},"content/distributed_design/distribute_lock.html":{"url":"content/distributed_design/distribute_lock.html","title":"分布式锁","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 分布式锁 什么是分布式锁？ 分布式锁的实现方式 基于数据库(mysql)实现 基于缓存(redis) 多实例并发访问问题演示 项目代码(使用redis) 配置nginx.conf jmeter压测复现问题 并发是1，即不产生并发问题 并发30测试,产生并发问题(虽然单实例是synchronized) redis 分布式锁：setnx实现 Redisson 代码&测试 底层原理 redis主从架构问题？ Redlock 高并发分布式锁如何实现 基于ZooKeeper实现 zookeeper节点类型 zookeeper的watch机制 zookeeper lock 普通临时节点（羊群效应） 顺序节点（公平，避免羊群效应） Curator InterProcessMutex code&测试\b InterProcessMutex 内部原理 [TOC] 分布式锁 什么是分布式锁？ 锁：共享资源；共享资源互斥的；多任务环境 分布式锁：如果多任务是多个JVM进程，需要一个外部锁，而不是JDK提供的锁 在分布式的部署环境下，通过锁机制来让多客户端互斥的对共享资源进行访问 排它性：在同一时间只会有一个客户端能获取到锁，其它客户端无法同时获取 避免死锁：这把锁在一段有限的时间之后，一定会被释放（正常释放或异常释放） 高可用：获取或释放锁的机制必须高可用且性能佳 分布式锁的实现方式 基于数据库(mysql)实现 新建一个锁表 CREATE TABLE `methodLock` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键', `method_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的方法名', `desc` varchar(1024) NOT NULL DEFAULT '备注信息', `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '保存数据时间，自动生成', PRIMARY KEY (`id`), UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='锁定中的方法'; insert, delete(method_name有唯一约束) 缺点： * 数据库单点会导致业务不可用 * 锁没有失效时间：一旦解锁操作失败，就会导致锁记录一直在数据库中，其它线程无法再获得到锁。 * 非重入锁：同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在记录了 * 非公平锁 通过数据库的排他锁来实现 在查询语句后面增加for update(表锁，行锁)，数据库会在查询过程中给数据库表增加排它锁。当某条记录被加上排他锁之后，其它线程无法再在该行记录上增加排它锁。可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过connection.commit()操作来释放锁 public boolean lock(){ connection.setAutoCommit(false) while (true) { try { result = select * from methodLock where method_name=xxx for update; if (result == null) { return true; } } catch (Exception e) { } sleep(1000); } return false; } public void unlock(){ connection.commit(); } 基于缓存(redis) 多实例并发访问问题演示 项目代码(使用redis) 见项目pr：https://github.com/doctording/springboot_gradle_demos/pull/2 Springboot项目启动两个实例(即有两个JVM进程) curl -X POST \\ http://localhost:8088/deduct_stock_sync \\ -H 'Content-Type: application/json' curl -X POST \\ http://localhost:8089/deduct_stock_sync \\ -H 'Content-Type: application/json' 配置nginx.conf http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' # '$status $body_bytes_sent \"$http_referer\" ' # '\"$http_user_agent\" \"$http_x_forwarded_for\"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream redislock{ server localhost:8088 weight=1; server localhost:8089 weight=1; } server { listen 8080; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; proxy_pass http://redislock; } } } nginx启动和关闭命令 mubi@mubideMacBook-Pro nginx $ sudo nginx mubi@mubideMacBook-Pro nginx $ ps -ef | grep nginx 0 47802 1 0 1:18下午 ?? 0:00.00 nginx: master process nginx -2 47803 47802 0 1:18下午 ?? 0:00.00 nginx: worker process 501 47835 20264 0 1:18下午 ttys001 0:00.00 grep --color=always nginx mubi@mubideMacBook-Pro nginx $ sudo nginx -s stop 访问测试 curl -X POST \\ http://localhost:8080/deduct_stock_sync \\ -H 'Content-Type: application/json' jmeter压测复现问题 redis 设置 stock 为 100 并发是1，即不产生并发问题 redis get结果会是最终的70 并发30测试,产生并发问题(虽然单实例是synchronized) 并发30访问测试结果：并不是最后的70 redis 分布式锁：setnx实现 30的并发失败率是60%，即只有12个成功的，最后redis的stock值是88符合预期 可以看到大部分没有抢到redis锁，而返回了系统繁忙错误 问题： 超时时间是个问题：业务时常不确定 其它线程可能删除别的线程的锁 改进1 @PostMapping(value = \"/deduct_stock_lock\") public String deductStockLock() throws Exception { // setnx，redis单线程 String lockKey = \"lockKey\"; String clientId = UUID.randomUUID().toString(); // 如下两句要原子操作 // Boolean setOk = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, lockVal); // stringRedisTemplate.expire(lockKey, 10 , TimeUnit.SECONDS); // 设置过期时间 Boolean setOk = stringRedisTemplate.opsForValue().setIfAbsent(lockKey, clientId, 10, TimeUnit.SECONDS); if (!setOk) { throw new Exception(\"业务繁忙，请稍后再试\"); } String retVal; try { // 只有一个线程能执行成功,可能有业务异常抛出来，可能宕机等等；但无论如何要释放锁 retVal = stockReduce(); } finally { // 可能失败 if (clientId.equals(stringRedisTemplate.opsForValue().get(lockKey))) { stringRedisTemplate.delete(lockKey); } } return retVal; } 超时不够，不断的定时设置，给锁续命 开启线程，每隔一段时间，判断锁还在不在，然后重新设置过期时间 Redisson 代码&测试 @Bean public Redisson redisson(){ Config config = new Config(); config.useSingleServer().setAddress(\"redis://localhost:6379\").setDatabase(0); return (Redisson)Redisson.create(config); } @Autowired private Redisson redisson; @PostMapping(value = \"/deduct_stock_redisson\") public String deductStockRedisson() throws Exception { String lockKey = \"lockKey\"; RLock rLock = redisson.getLock(lockKey); String retVal; try { rLock.lock(); // 只有一个线程能执行成功,可能有业务异常抛出来，可能宕机等等；但无论如何要释放锁 retVal = stockReduce(); } finally { rLock.unlock(); } return retVal; } 底层原理 setnx的设置key与过期时间用脚本实现原子操作 key设置成功默认30s，则有后台线程每10秒(1/3的原始过期时间定时检查)检查判断，延长过期时间 未获取到锁的线程会自旋，知道获取到锁的其它线程的释放 redis主从架构问题？ 补充知识：redis单机qps支持：10w级别 redis主从架构是主同步到从，如果主设置key成功，但是同步到从还没结束，就挂了；这样从成为主，但是是没有key存在的，那么另一个线程又能够加锁成功。（redis主从架构锁失效问题？） redis无法保证强一致性？zookeeper解决，但是zk性能不如redis Redlock 加锁失败的回滚 redis加锁多，性能受影响 高并发分布式锁如何实现 分段锁思想 基于ZooKeeper实现 回顾zookeeper的一些相关知识: 文件系统+监听通知机制 zookeeper节点类型 PERSISTENT-持久节点 除非手动删除，否则节点一直存在于 Zookeeper 上; 重启Zookeeper后也会恢复 EPHEMERAL-临时节点 临时节点的生命周期与客户端会话绑定，一旦客户端会话失效（客户端与zookeeper 连接断开不一定会话失效），那么这个客户端创建的所有临时节点都会被移除。 PERSISTENT_SEQUENTIAL-持久顺序节点 基本特性同持久节点，只是增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。 EPHEMERAL_SEQUENTIAL-临时顺序节点 基本特性同临时节点，增加了顺序属性，节点名后边会追加一个由父节点维护的自增整型数字。 zookeeper的watch机制 主动推送：watch被触发时，由zookeeper主动推送给客户端，而不需要客户端轮询 一次性：数据变化时，watch只会被触发一次；如果客户端想得到后续更新的通知，必须要在watch被触发后重新注册一个watch 可见性：如果一个客户端在读请求中附带 Watch，Watch 被触发的同时再次读取数据，客户端在得到 Watch消息之前肯定不可能看到更新后的数据。换句话说，更新通知先于更新结果 顺序性：如果多个更新触发了多个 Watch ，那 Watch 被触发的顺序与更新顺序一致 zookeeper lock 普通临时节点（羊群效应） 比如1000个并发，只有1个客户端获取锁成功，其它999个客户端都处在监听并等待中；如果成功释放锁了，那么999个客户端都监听到，再次继续进行创建锁的流程。 所以每次锁有变化，几乎所有客户端节点都要监听并作出反应，这会给集群带来巨大压力，即为羊群效应 顺序节点（公平，避免羊群效应） 首先需要创建一个父节点，尽量是持久节点（PERSISTENT类型) 每个要获得锁的线程都会在这个节点下创建个临时顺序节点， 由于序号的递增性，可以规定排号最小的那个获得锁。 所以，每个线程在尝试占用锁之前，首先判断自己是排号是不是当前最小，如果是，则获取锁。 利用顺序性：每个线程都只监听前一个线程，事件通知也只通知后面都一个线程，而不是通知全部 Curator InterProcessMutex curator官方文档 code&测试\b 实践代码链接 @Component public class CuratorConfiguration { @Bean(initMethod = \"start\") public CuratorFramework curatorFramework() { RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3); CuratorFramework client = CuratorFrameworkFactory.newClient( \"127.0.0.1:2181\", retryPolicy); return client; } } @Autowired private CuratorFramework curatorFramework; @PostMapping(value = \"/deduct_stock_zk\") public String deductStockZk() throws Exception { String path = \"/stock\"; InterProcessMutex interProcessMutex = new InterProcessMutex(curatorFramework, path); String retVal; try { interProcessMutex.acquire(); retVal = stockReduce(); } catch (Exception e) { throw new Exception(\"lock error\"); } finally { interProcessMutex.release(); } return retVal; } 压测结果 InterProcessMutex 内部原理 初始化 /** * @param client client * @param path the path to lock * @param driver lock driver */ public InterProcessMutex(CuratorFramework client, String path, LockInternalsDriver driver) { this(client, path, LOCK_NAME, 1, driver); } /** * Returns a facade of the current instance that tracks * watchers created and allows a one-shot removal of all watchers * via {@link WatcherRemoveCuratorFramework#removeWatchers()} * * @return facade */ public WatcherRemoveCuratorFramework newWatcherRemoveCuratorFramework(); 加锁 private boolean internalLock(long time, TimeUnit unit) throws Exception { /* Note on concurrency: a given lockData instance can be only acted on by a single thread so locking isn't necessary */ Thread currentThread = Thread.currentThread(); // 获取当前线程锁数据，获取到的化，设置可重入 LockData lockData = threadData.get(currentThread); if ( lockData != null ) { // re-entering lockData.lockCount.incrementAndGet(); return true; } // 尝试获取锁 String lockPath = internals.attemptLock(time, unit, getLockNodeBytes()); if ( lockPath != null ) { // 获取到锁，锁数据加入`threadData`的map结构中 LockData newLockData = new LockData(currentThread, lockPath); threadData.put(currentThread, newLockData); return true; } // 没有获取到锁 return false; } String attemptLock(long time, TimeUnit unit, byte[] lockNodeBytes) throws Exception { final long startMillis = System.currentTimeMillis(); final Long millisToWait = (unit != null) ? unit.toMillis(time) : null; final byte[] localLockNodeBytes = (revocable.get() != null) ? new byte[0] : lockNodeBytes; int retryCount = 0; String ourPath = null; boolean hasTheLock = false; boolean isDone = false; while ( !isDone ) { isDone = true; try { ourPath = driver.createsTheLock(client, path, localLockNodeBytes); hasTheLock = internalLockLoop(startMillis, millisToWait, ourPath); } catch ( KeeperException.NoNodeException e ) { // gets thrown by StandardLockInternalsDriver when it can't find the lock node // this can happen when the session expires, etc. So, if the retry allows, just try it all again if ( client.getZookeeperClient().getRetryPolicy().allowRetry(retryCount++, System.currentTimeMillis() - startMillis, RetryLoop.getDefaultRetrySleeper()) ) { isDone = false; } else { throw e; } } } if ( hasTheLock ) { return ourPath; } return null; } 创建锁是创建的临时顺序节点 @Override public String createsTheLock(CuratorFramework client, String path, byte[] lockNodeBytes) throws Exception { String ourPath; if ( lockNodeBytes != null ) { ourPath = client.create().creatingParentContainersIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path, lockNodeBytes); } else { ourPath = client.create().creatingParentContainersIfNeeded().withProtection().withMode(CreateMode.EPHEMERAL_SEQUENTIAL).forPath(path); } return ourPath; } watch private boolean internalLockLoop(long startMillis, Long millisToWait, String ourPath) throws Exception { boolean haveTheLock = false; boolean doDelete = false; try { if ( revocable.get() != null ) { client.getData().usingWatcher(revocableWatcher).forPath(ourPath); } while ( (client.getState() == CuratorFrameworkState.STARTED) && !haveTheLock ) { // 获取lock下所有节点数据，并排序 List children = getSortedChildren(); String sequenceNodeName = ourPath.substring(basePath.length() + 1); // +1 to include the slash // 判断获取到锁 PredicateResults predicateResults = driver.getsTheLock(client, children, sequenceNodeName, maxLeases); if ( predicateResults.getsTheLock() ) { haveTheLock = true; } else { String previousSequencePath = basePath + \"/\" + predicateResults.getPathToWatch(); synchronized(this) { try { // use getData() instead of exists() to avoid leaving unneeded watchers which is a type of resource leak // 监听前一个节点，并等待 client.getData().usingWatcher(watcher).forPath(previousSequencePath); if ( millisToWait != null ) { millisToWait -= (System.currentTimeMillis() - startMillis); startMillis = System.currentTimeMillis(); if ( millisToWait 是不是加锁成功:是不是最小的那个节点 @Override public PredicateResults getsTheLock(CuratorFramework client, List children, String sequenceNodeName, int maxLeases) throws Exception { int ourIndex = children.indexOf(sequenceNodeName); validateOurIndex(sequenceNodeName, ourIndex); boolean getsTheLock = ourIndex 释放锁 可重入判断；删除watchers，删除节点 /** * Perform one release of the mutex if the calling thread is the same thread that acquired it. If the * thread had made multiple calls to acquire, the mutex will still be held when this method returns. * * @throws Exception ZK errors, interruptions, current thread does not own the lock */ @Override public void release() throws Exception { /* Note on concurrency: a given lockData instance can be only acted on by a single thread so locking isn't necessary */ Thread currentThread = Thread.currentThread(); LockData lockData = threadData.get(currentThread); if ( lockData == null ) { throw new IllegalMonitorStateException(\"You do not own the lock: \" + basePath); } int newLockCount = lockData.lockCount.decrementAndGet(); if ( newLockCount > 0 ) { return; } if ( newLockCount final void releaseLock(String lockPath) throws Exception { client.removeWatchers(); revocable.set(null); deleteOurPath(lockPath); } Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-28 09:51:59 "},"content/distributed_design/distribute_id.html":{"url":"content/distributed_design/distribute_id.html","title":"分布式ID","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 分布式Id 数据库自增ID AUTO_INCREMENT Handling in InnoDB 相关的MySql系统变量 innodbautoinclock_mode(refman-5.7) innodbautoinclock_mode = 1 (“consecutive” lock mode) 自增id的大小 Leaf(美团点评分布式ID生成系统) [TOC] 分布式Id 数据库自增ID The AUTO_INCREMENT attribute can be used to generate a unique identity for new rows: CREATE TABLE animals ( id MEDIUMINT NOT NULL AUTO_INCREMENT, name CHAR(30) NOT NULL, PRIMARY KEY (id) ); INSERT INTO animals (name) VALUES ('dog'),('cat'),('penguin'), ('lax'),('whale'),('ostrich'); SELECT * FROM animals; When you insert any other value into an AUTO_INCREMENT column, the column is set to that value and the sequence is reset so that the next automatically generated value follows sequentially from the largest column value. For example: INSERT INTO animals (id,name) VALUES(100,'rabbit'); INSERT INTO animals (id,name) VALUES(NULL,'mouse'); SELECT * FROM animals; +-----+-----------+ | id | name | +-----+-----------+ | 1 | dog | | 2 | cat | | 3 | penguin | | 4 | lax | | 5 | whale | | 6 | ostrich | | 7 | groundhog | | 8 | squirrel | | 100 | rabbit | | 101 | mouse | +-----+-----------+ AUTO_INCREMENT Handling in InnoDB 相关的MySql系统变量 mysql> show variables like '%auto_increment%'; +--------------------------+-------+ | Variable_name | Value | +--------------------------+-------+ | auto_increment_increment | 1 | | auto_increment_offset | 1 | +--------------------------+-------+ 2 rows in set (0.01 sec) mysql> auto_increment_increment：自增量 auto_increment_offset：自增开始值 自增锁的innodb_autoinc_lock_mode是1 mysql> show variables like '%lock%'; +-----------------------------------------+----------------------+ | Variable_name | Value | +-----------------------------------------+----------------------+ | block_encryption_mode | aes-128-ecb | | innodb_api_disable_rowlock | OFF | | innodb_autoinc_lock_mode | 1 | | innodb_lock_wait_timeout | 50 | | innodb_locks_unsafe_for_binlog | OFF | | innodb_old_blocks_pct | 37 | | innodb_old_blocks_time | 1000 | | innodb_print_all_deadlocks | OFF | | innodb_status_output_locks | OFF | | innodb_table_locks | ON | | key_cache_block_size | 1024 | | lock_wait_timeout | 31536000 | | locked_in_memory | OFF | | max_write_lock_count | 18446744073709551615 | | metadata_locks_cache_size | 1024 | | metadata_locks_hash_instances | 8 | | performance_schema_max_rwlock_classes | 40 | | performance_schema_max_rwlock_instances | 9102 | | query_alloc_block_size | 8192 | | query_cache_wlock_invalidate | OFF | | range_alloc_block_size | 4096 | | skip_external_locking | ON | | transaction_alloc_block_size | 8192 | +-----------------------------------------+----------------------+ 23 rows in set (0.00 sec) mysql> innodb_autoinc_lock_mode(refman-5.7) The lock mode to use for generating auto-increment values. Permissible values are 0, 1, or 2, for traditional, consecutive(adj.连续不断的), or interleaved, respectively. The default setting is 1 (consecutive). 几个语句概念 “INSERT-like” statements All statements that generate new rows in a table, including INSERT, INSERT ... SELECT, REPLACE, REPLACE ... SELECT, and LOAD DATA. Includes “simple-inserts”, “bulk-inserts”, and “mixed-mode” inserts. “simple-inserts” Statements for which the number of rows to be inserted can be determined in advance (when the statement is initially processed). This includes single-row and multiple-row INSERT and REPLACE statements that do not have a nested subquery, but not INSERT ... ON DUPLICATE KEY UPDATE. “bulk-inserts” Statements for which the number of rows to be inserted (and the number of required auto\u0002increment values) is not known in advance. This includes INSERT ... SELECT, REPLACE ... SELECT, and LOAD DATA statements, but not plain INSERT. InnoDB assigns new values for the AUTO_INCREMENT column one at a time as each row is processed. “Mixed-mode inserts” innodb_autoinc_lock_mode = 1 (“consecutive” lock mode) This is the default lock mode. In this mode, “bulk inserts” use the special AUTO-INC table-level lock and hold it until the end of the statement. This applies to all INSERT ... SELECT, REPLACE ... SELECT, and LOAD DATA statements. Only one statement holding the AUTO-INC lock can execute at a time. “Simple inserts” (for which the number of rows to be inserted is known in advance) avoid table-level AUTO-INC locks by obtaining the required number of auto-increment values under the control of a mutex (a light-weight lock) that is only held for the duration of the allocation process, not until the statement completes. The exception is for “mixed-mode inserts”, where the user provides explicit values for an AUTO_INCREMENT column for some, but not all, rows in a multiple-row “simple insert”. For such inserts, InnoDB allocates more auto-increment values than the number of rows to be inserted. However, all values automatically assigned are consecutively generated (and thus higher than) the auto-increment value generated by the most recently executed previous statement. “Excess” numbers are lost. “bulk inserts”仍然使用AUTO-INC表级锁,并保持到语句结束.这适用于所有INSERT ... SELECT，REPLACE ... SELECT和LOAD DATA语句。同一时刻只有一个语句可以持有AUTO-INC锁。 而“Simple inserts”（要插入的行数事先已知）通过在mutex（轻量锁）的控制下获得所需数量的自动递增值来避免表级AUTO-INC锁，它只在分配过程的持续时间内保持，而不是直到语句完成。 不使用表级AUTO-INC锁，除非AUTO-INC锁由另一个事务保持。如果另一个事务保持AUTO-INC锁，则“简单插入”等待AUTO-INC锁，如同它是一个“批量插入”。 自增id的大小 一个正常大小整数有符号的范围是-2147483648到2147483647，无符号的范围是0到4294967295 insert into tb_user(userID, password, name, phone, address) values('0004','123456','tom', '110', 'beijing'); insert into tb_user values(10, '0004','123456','tom', '110', 'beijing'); 插入超过大值会默认最大，并报错 mysql> insert into tb_user values(2147483648, '0004','123456','tom', '110', 'beijing'); Query OK, 1 row affected, 1 warning (0.00 sec) mysql> select * from tb_user; +------------+--------+----------+-------+-------------+----------+ | id | userID | password | name | phone | address | +------------+--------+----------+-------+-------------+----------+ | 1 | 00001 | 123456 | zhang | 15133339999 | Shanghai | | 2 | 00002 | 123456 | wang | 15133339999 | Beijing | | 4 | 0003 | NULL | abc | NULL | NULL | | 6 | 0003 | NULL | abc | NULL | NULL | | 7 | 0004 | 123456 | tom | 110 | beijing | | 10 | 0004 | 123456 | tom | 110 | beijing | | 2147483647 | 0004 | 123456 | tom | 110 | beijing | +------------+--------+----------+-------+-------------+----------+ 7 rows in set (0.00 sec) mysql> insert into tb_user values(2147483648, '0004','123456','tom', '110', 'beijing'); ERROR 1062 (23000): Duplicate entry '2147483647' for key 'PRIMARY' mysql> mysql> mysql> mysql> insert into tb_user(userID, password, name, phone, address) values('0004','123456','tom', '110', 'beijing'); ERROR 1062 (23000): Duplicate entry '2147483647' for key 'PRIMARY' mysql> Leaf(美团点评分布式ID生成系统) 美团Leaf Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-25 20:18:06 "},"content/distributed_design/rpc.html":{"url":"content/distributed_design/rpc.html","title":"rpc","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 rpc(Remote Procedure Call) rpc 问题引入 传统的socket编程 Stub代理类屏蔽网络细节 反射 + 动态代理 改进 任意服务的灵活支持 RPC 序列化协议 用序列化协议改写代码 RPC 网络协议 回顾RPC 为什么需要服务注册与发现 服务发现 客户端实现 服务端实现 服务注册中心（Service Registry） [TOC] rpc(Remote Procedure Call) Remote Procedure Call (RPC) is a powerful technique for constructing distributed, client-server based applications. It is based on extending the conventional local procedure calling so that the called procedure need not exist in the same address space as the calling procedure. The two processes may be on the same system, or they may be on different systems with a network connecting them. rpc 问题引入 两台不同的主机进程要进行通信？ 最易想到的最原始做法：tcp/ip通信，二进制数据传输 蛮烦点：写网络；服务动态扩展后，客户端又得对接处理了 如下一点一点的改进出来（参考：马士兵老师的RPC讲解课程），知识点 JAVA socket编程基础 JAVA反射 代理模式/动态代理 序列化 传统的socket编程 User package rpc; import java.io.Serializable; /** * @Author mubi * @Date 2020/5/18 23:10 */ public class User implements Serializable { private Integer id; private String name; public User(Integer id, String name) { this.id = id; this.name = name; } public Integer getId() { return id; } public void setId(Integer id) { this.id = id; } public String getName() { return name; } public void setName(String name) { this.name = name; } @Override public String toString() { return \"User{\" + \"id=\" + id + \", name='\" + name + '\\'' + '}'; } } IUserService package rpc; /** * @Author mubi * @Date 2020/5/18 23:10 */ public interface IUserService { User getUserById(Integer id); } UserServiceImpl package rpc; /** * @Author mubi * @Date 2020/5/18 23:10 */ public class UserServiceImpl implements IUserService { @Override public User getUserById(Integer id) { return new User(id, \"zhang\"); } } Server package rpc; import java.io.*; import java.net.ServerSocket; import java.net.Socket; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Server { public static void main(String[] args) throws Exception { // 监听指定的端口 int port = 55533; ServerSocket server = new ServerSocket(port); // server将一直等待连接的到来 System.out.println(\"server将一直等待连接的到来\"); Socket socket = server.accept(); // 建立好连接后，从socket中获取输入流，并建立缓冲区进行读取 InputStream in = socket.getInputStream(); OutputStream out = socket.getOutputStream(); DataInputStream dis = new DataInputStream(in); DataOutputStream dos = new DataOutputStream(out); int id = dis.readInt(); System.out.println(\"client send id:\" + id); IUserService userService = new UserServiceImpl(); User user = userService.getUserById(id); dos.writeInt(user.getId()); dos.writeUTF(user.getName()); dos.flush(); socket.close(); server.close(); } } client package rpc; import java.io.*; import java.net.Socket; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Client { public static void main(String args[]) throws Exception { // 要连接的服务端IP地址和端口 String host = \"127.0.0.1\"; int port = 55533; // 与服务端建立连接 Socket socket = new Socket(host, port); // 建立连接后获得输出流 ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); DataOutputStream dos = new DataOutputStream(byteArrayOutputStream); dos.writeInt(12); socket.getOutputStream().write(byteArrayOutputStream.toByteArray()); socket.getOutputStream().flush(); InputStream in = socket.getInputStream(); DataInputStream dis = new DataInputStream(in); int id = dis.readInt(); String name = dis.readUTF(); User user = new User(id, name); System.out.println(user); socket.close(); } } Stub代理类屏蔽网络细节 client 访问太复杂，且网络这部分非得了解不可 一个代理Stub类，把网络这部分给封装下，客户端轻松点 client package rpc; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Client { public static void main(String args[]) throws Exception { // 代理 Stub stub = new Stub(); System.out.println(stub.getUserById(12)); } } Stub package rpc; import java.io.ByteArrayOutputStream; import java.io.DataInputStream; import java.io.DataOutputStream; import java.io.InputStream; import java.net.Socket; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Stub { public User getUserById(Integer id) throws Exception{ // 要连接的服务端IP地址和端口 String host = \"127.0.0.1\"; int port = 55533; // 与服务端建立连接 Socket socket = new Socket(host, port); // 建立连接后获得输出流 ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); DataOutputStream dos = new DataOutputStream(byteArrayOutputStream); dos.writeInt(id); socket.getOutputStream().write(byteArrayOutputStream.toByteArray()); socket.getOutputStream().flush(); InputStream in = socket.getInputStream(); DataInputStream dis = new DataInputStream(in); int userId = dis.readInt(); String userName = dis.readUTF(); User user = new User(userId, userName); socket.close(); return user; } } 反射 + 动态代理 既然服务端 和 客户端都知道约定的方法，那么Stub直接把调用传递的方法，参数什么的直接给服务端；服务端通过反射执行，把结果返回给 Stub 就行了; Stub 把 服务端执行的 service类 代理给客户端； 这样：客户端的调用，就很简单：得到service对象，直接调用service的方法就好了；service增加方法，客户端也是直接调用 Client package rpc; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Client { public static void main(String args[]) throws Exception { IUserService iUserService = Stub.getStub(); System.out.println(iUserService.getUserById(12)); } } Server package rpc; import java.io.*; import java.lang.reflect.Method; import java.net.ServerSocket; import java.net.Socket; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Server { public static void main(String[] args) throws Exception { // 监听指定的端口 int port = 55533; ServerSocket server = new ServerSocket(port); // server将一直等待连接的到来 System.out.println(\"server将一直等待连接的到来\"); Socket socket = server.accept(); // 建立好连接后，从socket中获取输入流，并建立缓冲区进行读取 InputStream in = socket.getInputStream(); OutputStream out = socket.getOutputStream(); ObjectInputStream objectInputStream = new ObjectInputStream(in); DataOutputStream dos = new DataOutputStream(out); // int id = dis.readInt(); // System.out.println(\"client send id:\" + id); // // IUserService userService = new UserServiceImpl(); // User user = userService.getUserById(id); String methodName = objectInputStream.readUTF(); Class[] parameterTypes = (Class[])objectInputStream.readObject(); Object[] methodArgs = (Object[])objectInputStream.readObject(); // 方法实现在 UserServiceImpl 对象上 IUserService service = new UserServiceImpl(); Method method = service.getClass().getMethod(methodName, parameterTypes); User user = (User)method.invoke(service, methodArgs); dos.writeInt(user.getId()); dos.writeUTF(user.getName()); dos.flush(); socket.close(); server.close(); } } Stub package rpc; import java.io.*; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.net.Socket; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Stub { public static IUserService getStub(){ // 调用方法处理器 InvocationHandler h = new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 要连接的服务端IP地址和端口 String host = \"127.0.0.1\"; int port = 55533; // 与服务端建立连接 Socket socket = new Socket(host, port); // 建立连接后获得输出流 ObjectOutputStream oos = new ObjectOutputStream(socket.getOutputStream()); // 方法名，参数类型和列表（把方法传递给服务端） String methodName = method.getName(); Class[] paramTypes = method.getParameterTypes(); oos.writeUTF(methodName); oos.writeObject(paramTypes); oos.writeObject(args); oos.flush(); InputStream in = socket.getInputStream(); DataInputStream dis = new DataInputStream(in); int userId = dis.readInt(); String userName = dis.readUTF(); User user = new User(userId, userName); socket.close(); return user; } }; Object o = Proxy.newProxyInstance(IUserService.class.getClassLoader(), new Class[]{IUserService.class}, h); System.out.println(o.getClass().getInterfaces()[0]); return (IUserService)o; } @Deprecated public User getUserById(Integer id) throws Exception{ // 要连接的服务端IP地址和端口 String host = \"127.0.0.1\"; int port = 55533; // 与服务端建立连接 Socket socket = new Socket(host, port); // 建立连接后获得输出流 ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); DataOutputStream dos = new DataOutputStream(byteArrayOutputStream); dos.writeInt(id); socket.getOutputStream().write(byteArrayOutputStream.toByteArray()); socket.getOutputStream().flush(); InputStream in = socket.getInputStream(); DataInputStream dis = new DataInputStream(in); int userId = dis.readInt(); String userName = dis.readUTF(); User user = new User(userId, userName); socket.close(); return user; } } 改进 Stub package rpc; import java.io.*; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.net.Socket; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Stub { public static IUserService getStub(){ // 调用方法处理器 InvocationHandler h = new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 要连接的服务端IP地址和端口 String host = \"127.0.0.1\"; int port = 55533; // 与服务端建立连接 Socket socket = new Socket(host, port); // 建立连接后获得输出流 ObjectOutputStream oos = new ObjectOutputStream(socket.getOutputStream()); // 方法名，参数类型和列表（把方法传递给服务端） String methodName = method.getName(); Class[] paramTypes = method.getParameterTypes(); oos.writeUTF(methodName); oos.writeObject(paramTypes); oos.writeObject(args); oos.flush(); // InputStream in = socket.getInputStream(); // DataInputStream dis = new DataInputStream(in); // int userId = dis.readInt(); // String userName = dis.readUTF(); // User user = new User(userId, userName); // 直接读取服务端返回的对象 ObjectInputStream objectInputStream = new ObjectInputStream(socket.getInputStream()); User user = (User) objectInputStream.readObject(); socket.close(); return user; } }; Object o = Proxy.newProxyInstance(IUserService.class.getClassLoader(), new Class[]{IUserService.class}, h); System.out.println(o.getClass().getInterfaces()[0]); return (IUserService)o; } @Deprecated public User getUserById(Integer id) throws Exception{ // 要连接的服务端IP地址和端口 String host = \"127.0.0.1\"; int port = 55533; // 与服务端建立连接 Socket socket = new Socket(host, port); // 建立连接后获得输出流 ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); DataOutputStream dos = new DataOutputStream(byteArrayOutputStream); dos.writeInt(id); socket.getOutputStream().write(byteArrayOutputStream.toByteArray()); socket.getOutputStream().flush(); InputStream in = socket.getInputStream(); DataInputStream dis = new DataInputStream(in); int userId = dis.readInt(); String userName = dis.readUTF(); User user = new User(userId, userName); socket.close(); return user; } } Server package rpc; import java.io.*; import java.lang.reflect.Method; import java.net.ServerSocket; import java.net.Socket; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Server { public static void main(String[] args) throws Exception { // 监听指定的端口 int port = 55533; ServerSocket server = new ServerSocket(port); // server将一直等待连接的到来 System.out.println(\"server将一直等待连接的到来\"); Socket socket = server.accept(); // 建立好连接后，从socket中获取输入流，并建立缓冲区进行读取 InputStream in = socket.getInputStream(); OutputStream out = socket.getOutputStream(); ObjectInputStream objectInputStream = new ObjectInputStream(in); // DataOutputStream dos = new DataOutputStream(out); // int id = dis.readInt(); // System.out.println(\"client send id:\" + id); // // IUserService userService = new UserServiceImpl(); // User user = userService.getUserById(id); String methodName = objectInputStream.readUTF(); Class[] parameterTypes = (Class[])objectInputStream.readObject(); Object[] methodArgs = (Object[])objectInputStream.readObject(); // 方法实现在 UserServiceImpl 对象上 IUserService service = new UserServiceImpl(); Method method = service.getClass().getMethod(methodName, parameterTypes); User user = (User)method.invoke(service, methodArgs); // dos.writeInt(user.getId()); // dos.writeUTF(user.getName()); // dos.flush(); // 直接把返回对象写回给客户端 ObjectOutputStream objectOutputStream = new ObjectOutputStream(out); objectOutputStream.writeObject(user); objectOutputStream.flush(); socket.close(); server.close(); } } 任意服务的灵活支持 客户端直接传递Service到服务端，服务端获取注册服务的实现类，处理好了之后返回给客户端 不管多少种服务；只要约定好，客户端直接调用即可，基本不需要修改Stub相关代码; client 调用远程方法，就像调用本地方法一样（这样你不需要懂网络底层，直接服务端有什么，你就能用什么） client package rpc; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Client { public static void main(String[] args) throws Exception { // IUserService iUserService = (IUserService) Stub.getStub(IUserService.class); // System.out.println(iUserService.getUserById(12)); IProService iProService = (IProService) Stub.getStub(IProService.class); System.out.println(iProService.getProById(12)); } } Stub package rpc; import java.io.*; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.net.Socket; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Stub { public static Object getStub(Class clazz){ // 调用方法处理器 InvocationHandler h = new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 要连接的服务端IP地址和端口 String host = \"127.0.0.1\"; int port = 55533; // 与服务端建立连接 Socket socket = new Socket(host, port); // 类名,方法名，参数类型和列表（把类+方法传递给服务端） String className = clazz.getName(); String methodName = method.getName(); Class[] paramTypes = method.getParameterTypes(); ObjectOutputStream oos = new ObjectOutputStream(socket.getOutputStream()); oos.writeUTF(className); oos.writeUTF(methodName); oos.writeObject(paramTypes); oos.writeObject(args); oos.flush(); // 直接读取服务端返回的对象 ObjectInputStream objectInputStream = new ObjectInputStream(socket.getInputStream()); Object o = objectInputStream.readObject(); objectInputStream.close(); socket.close(); return o; } }; Object o = Proxy.newProxyInstance(clazz.getClassLoader(), new Class[]{clazz}, h); System.out.println(o.getClass().getInterfaces()[0]); return o; } @Deprecated public static IUserService getStub(){ // 调用方法处理器 InvocationHandler h = new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 要连接的服务端IP地址和端口 String host = \"127.0.0.1\"; int port = 55533; // 与服务端建立连接 Socket socket = new Socket(host, port); // 建立连接后获得输出流 ObjectOutputStream oos = new ObjectOutputStream(socket.getOutputStream()); // 方法名，参数类型和列表（把方法传递给服务端） String methodName = method.getName(); Class[] paramTypes = method.getParameterTypes(); oos.writeUTF(methodName); oos.writeObject(paramTypes); oos.writeObject(args); oos.flush(); // InputStream in = socket.getInputStream(); // DataInputStream dis = new DataInputStream(in); // int userId = dis.readInt(); // String userName = dis.readUTF(); // User user = new User(userId, userName); // 直接读取服务端返回的对象 ObjectInputStream objectInputStream = new ObjectInputStream(socket.getInputStream()); User user = (User) objectInputStream.readObject(); socket.close(); return user; } }; Object o = Proxy.newProxyInstance(IUserService.class.getClassLoader(), new Class[]{IUserService.class}, h); System.out.println(o.getClass().getInterfaces()[0]); return (IUserService)o; } @Deprecated public User getUserById(Integer id) throws Exception{ // 要连接的服务端IP地址和端口 String host = \"127.0.0.1\"; int port = 55533; // 与服务端建立连接 Socket socket = new Socket(host, port); // 建立连接后获得输出流 ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); DataOutputStream dos = new DataOutputStream(byteArrayOutputStream); dos.writeInt(id); socket.getOutputStream().write(byteArrayOutputStream.toByteArray()); socket.getOutputStream().flush(); InputStream in = socket.getInputStream(); DataInputStream dis = new DataInputStream(in); int userId = dis.readInt(); String userName = dis.readUTF(); User user = new User(userId, userName); socket.close(); return user; } } Server package rpc; import java.io.*; import java.lang.reflect.Method; import java.net.ServerSocket; import java.net.Socket; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Server { public static void main(String[] args) throws Exception { // 监听指定的端口 int port = 55533; ServerSocket server = new ServerSocket(port); // server将一直等待连接的到来 System.out.println(\"server将一直等待连接的到来\"); Socket socket = server.accept(); // 建立好连接后，从socket中获取输入流，并建立缓冲区进行读取 InputStream in = socket.getInputStream(); ObjectInputStream objectInputStream = new ObjectInputStream(in); String clazzName = objectInputStream.readUTF(); String methodName = objectInputStream.readUTF(); Class[] parameterTypes = (Class[])objectInputStream.readObject(); Object[] methodArgs = (Object[])objectInputStream.readObject(); Class clazz = null; // 从服务注册中找到具体的类, 这里写个假的 if(clazzName.equals(\"rpc.IUserService\")) { clazz = UserServiceImpl.class; } if(clazzName.equals(\"rpc.IProService\")) { clazz = ProServiceImpl.class; } Method method = clazz.getMethod(methodName, parameterTypes); Object o = method.invoke(clazz.newInstance(), methodArgs); OutputStream out = socket.getOutputStream(); // 直接把返回对象写回给客户端 ObjectOutputStream objectOutputStream = new ObjectOutputStream(out); objectOutputStream.writeObject(o); objectOutputStream.flush(); socket.close(); server.close(); } } RPC 序列化协议 上述代码中涉及到了对象的序列化，反序列化：把对象转换字节数组在网络种传输，然后又读取字节数组，再次转换为原始对象 序列化框架： java.io.Serializable Hessian google protobuf facebook thrift kyro json序列化框架：Jackson，google Gson，alibaba FastJson xmlrpc(xstream) 用序列化协议改写代码 Stub package rpc; import java.io.*; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.net.Socket; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Stub { public static Object getStub(Class clazz){ // 调用方法处理器 InvocationHandler h = new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 要连接的服务端IP地址和端口 String host = \"127.0.0.1\"; int port = 55533; // 与服务端建立连接 Socket socket = new Socket(host, port); // 构造请求服务器的对象 RpcRequest rpcRequest = new RpcRequest(clazz.getName(), method.getName(), method.getParameterTypes(), args); // 传递二进制给服务端 OutputStream outputStream = socket.getOutputStream(); outputStream.write(HessianSerializerUtil.serialize(rpcRequest)); socket.shutdownOutput(); // 直接读取服务端返回的二进制, 反序列化为对象返回 InputStream inputStream = socket.getInputStream(); byte[] bytes = readInputStream(inputStream); Object o = HessianSerializerUtil.deserialize(bytes); inputStream.close(); outputStream.close(); socket.close(); return o; } }; Object o = Proxy.newProxyInstance(clazz.getClassLoader(), new Class[]{clazz}, h); System.out.println(o.getClass().getInterfaces()[0]); return o; } public static byte[] readInputStream(InputStream inputStream) throws IOException { byte[] buffer = new byte[2048]; int len; ByteArrayOutputStream bos = new ByteArrayOutputStream(); while((len = inputStream.read(buffer)) != -1) { bos.write(buffer, 0, len); } return bos.toByteArray(); } } Server package rpc; import java.io.*; import java.lang.reflect.Method; import java.net.ServerSocket; import java.net.Socket; /** * @Author mubi * @Date 2020/5/18 23:18 */ public class Server { public static void main(String[] args) throws Exception { // 监听指定的端口 int port = 55533; ServerSocket server = new ServerSocket(port); // server将一直等待连接的到来 System.out.println(\"server将一直等待连接的到来\"); Socket socket = server.accept(); // 建立好连接后，从socket中获取客户端传递过来的对象 InputStream in = socket.getInputStream(); RpcRequest rpcRequest = HessianSerializerUtil.deserialize(readInputStream(in)); // System.out.println(\"rpcRequest:\" + rpcRequest); // 执行方法 Class clazz = null; // 从服务注册中找到具体的类, 这里写个假的 if(rpcRequest.getClassName().equals(\"rpc.IUserService\")) { clazz = UserServiceImpl.class; } if(rpcRequest.getClassName().equals(\"rpc.IProService\")) { clazz = ProServiceImpl.class; } Method method = clazz.getMethod(rpcRequest.getMethodName(), rpcRequest.getParamTypes()); Object o = method.invoke(clazz.newInstance(), rpcRequest.getArgs()); // 返回对象 二进制形式发送给客户端 OutputStream out = socket.getOutputStream(); out.write(HessianSerializerUtil.serialize(o)); out.flush(); socket.close(); server.close(); } public static byte[] readInputStream(InputStream inputStream) throws IOException { byte[] buffer = new byte[2048]; int len; ByteArrayOutputStream bos = new ByteArrayOutputStream(); while((len = inputStream.read(buffer)) != -1) { bos.write(buffer, 0, len); } return bos.toByteArray(); } } RPC 网络协议 通信协议 TCP/UDP Web Service Restful(http + json) RMI(Remote Method Invocation) JMS(Java Message Service) RPC(Remote Procedure Call) RPC采用的网络协议 RPC本身重点在于方法调用，可以用各种网络协议是实现，比如RMI,restful等，其中(RMI不能跨语言，Resful基于http：带宽占用高，效率低) RPC多用于服务器集群间的通信 回顾RPC 为什么需要服务注册与发现 随着服务数量的增多，各个服务之间的调用变得错综复杂，一个服务可能依赖外部多个服务，当一个服务的域名或IP地址改变了之后如何通知依赖方，或者依赖方如何快速的发现服务提供方的地址变化。 客户端与服务端自己维护：有多少个服务，客户端就要维护多少个(服务增减，负载均衡，心跳) 找个代理，客户端有需求找代理，代理维持这些服务，也能给客户通知；（可以看成代理模式） 服务注册就是维护一个登记簿，它管理系统内所有的服务地址。当新的服务启动后，它会向登记簿交待自己的地址信息。服务的依赖方直接向登记簿要Service Provider地址就行了 服务发现 Nginx Service Discovery blog 问题：Service instances have dynamically assigned network locations. Moreover, the set of service instances changes dynamically because of autoscaling, failures, and upgrades. Consequently, your client code needs to use a more elaborate service discovery mechanism. （服务实例是动态变化(扩缩容，失败，升级)的，且服务实例的网络地址是动态调整的；显然，客户端需要能及时正确的感知这些变化，需要一个可靠的服务发现机制）。 客户端实现 When using client‑side discovery, the client is responsible for determining the network locations of available service instances and load balancing requests across them. The client queries a service registry, which is a database of available service instances. The client then uses a load‑balancing algorithm to select one of the available service instances and makes a request.‘ 缺点： One significant drawback of this pattern is that it couples the client with the service registry. You must implement client‑side service discovery logic for each programming language and framework used by your service clients.（这种模式的一个重要缺点是它将客户端与服务注册中心耦合起来。客户端必须为服务端使用的每种编程语言和框架实现一套服务发现逻辑。） 服务端实现 The client makes a request to a service via a load balancer. The load balancer queries the service registry and routes each request to an available service instance. As with client‑side discovery, service instances are registered and deregistered with the service registry. 优缺点： The server‑side discovery pattern has several benefits and drawbacks. One great benefit of this pattern is that details of discovery are abstracted away from the client. Clients simply make requests to the load balancer. This eliminates the need to implement discovery logic for each programming language and framework used by your service clients. Also, as mentioned above, some deployment environments provide this functionality for free. This pattern also has some drawbacks, however. Unless the load balancer is provided by the deployment environment, it is yet another highly available system component that you need to set up and manage. 服务注册中心（Service Registry） It is a database containing the network locations of service instances. A service registry needs to be highly available and up to date. Clients can cache network locations obtained from the service registry. However, that information eventually becomes out of date and clients become unable to discover service instances. Consequently, a service registry consists of a cluster of servers that use a replication protocol to maintain consistency. Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-26 20:21:39 "},"content/distributed_design/soa.html":{"url":"content/distributed_design/soa.html","title":"微服务","keywords":"","body":"[TOC] SOA Service-oriented architecture (SOA)：面向服务架构 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2020-07-30 13:29:55 "},"content/thought_of_solve/thought.html":{"url":"content/thought_of_solve/thought.html","title":"剑指Offer解题思路(全)","keywords":"","body":"TreeviewCopyright @doctording all right reserved, powered by aleen42 1 二维数组中的查找 2 替换空格 3 从尾到头打印链表 4 重建二叉树 5 用两个栈实现队列 6 旋转数组的最小数字 7 斐波那契数列 (import) 8 跳台阶 9 变态跳台阶 10 矩形覆盖 11 二进制中1的个数 12 数值的整数次方 13 调整数组顺序使奇数位于偶数前面 （important） 14 链表中倒数第k个结点 15 反转链表 16 合并两个排序的链表 17 树的子结构（important） 18 二叉树的镜像 19 顺时针打印矩阵 20 包含min函数的栈 21 栈的压入、弹出序列 22 从上往下打印二叉树 23 二叉搜索树的后序遍历序列 24 二叉树中和为某一值的路径 25 复杂链表的复制 (important) 26 二叉搜索树与双向链表 27 字符串的排列 28 数组中出现次数超过一半的数字 29 最小的K个数 30 连续子数组的最大和 31 整数中1出现的次数（从1到n整数中1出现的次数） 32 把数组排成最小的数 33 丑数 34 第一个只出现一次的字符 35 数组中的逆序对（important） 36 两个链表的第一个公共结点 37 数字在排序数组中出现的次数 38 二叉树的深度 39 输入一棵二叉树，判断该二叉树是否是平衡二叉树 40 数组中只出现一次的数字 41 和为S的连续正数序列（important） 42 和为S的两个数字 43 左旋转字符串 44 翻转单词顺序列 45 扑克牌顺子 46 孩子们的游戏(圆圈中最后剩下的数) 47 求1+2+3+...+n 48 不用加减乘除做加法 49 把字符串转换成整数 (important) 50 数组中重复的数字 51 构建乘积数组 52 正则表达式匹配(important) 53 表示数值的字符串 54 字符流中第一个不重复的字符 55 链表中环的入口结点 56 删除链表中重复的结点 57 二叉树的下一个结点， 中序遍历顺序的下一个结点并且返回 58 对称的二叉树 59 按之字形顺序打印二叉树 60 把二叉树打印成多行 61 序列化二叉树 62 二叉搜索树的第k个结点 63 数据流中的中位数 64 滑动窗口的最大值 65 矩阵中的路径 66 机器人的运动范围 67 剪绳子 [TOC] 1 二维数组中的查找 有序查找 二分 2 替换空格 先统计增大的空间，然后从后往前替换 3 从尾到头打印链表 头插法将链表反转一下，然后遍历（这种方式会改变链表的结构） 当链表只读时，采用递归的方法（栈）来操作，就可以实现链表数据的反转了 4 重建二叉树 这类题目都采用递归，属于二叉树基础题 5 用两个栈实现队列 保持一个stack为空，通过两个栈转储，实现数据进出是队列形式的 6 旋转数组的最小数字 头尾往中间逼近的方法,直接遍历一遍，O(n)的做法，显然太low 二分查找的方法，不过有特殊情况，比如 [1 0 1 1 1] ，[1 1 1 0 1] 这种，需要单独顺序遍历 7 斐波那契数列 (import) 最直接的递归/动归， O(2^n), n的指数次方增长 利用变量,非递归，时间复杂度O(n) 快速幂的做法 f(n) = f(n - 1) + f(n - 2), 二阶的快速幂，时间复杂度O(logn),需要推算一下矩阵公式 8 跳台阶 同 斐波那契数列 9 变态跳台阶 数学公式推导, 同斐波那契数列 10 矩形覆盖 同 斐波那契数列 11 二进制中1的个数 经典问题，采用位运算n & (n-1)得到最右边的一个1 12 数值的整数次方 快速幂方法 边界，符号，double/float判零问题 位运算比除法，取模等效率高 13 调整数组顺序使奇数位于偶数前面 （important） 注意题目要求无序和有序的区别 无序 快排思路，维持头/尾两个指针，不断的交换到相遇,时间O(n), 空间O(1) 要求保持数据相对位置不变(无序的最优解不再满足需求，注意快排是不稳定的) 直接插入排序， 时间复杂度O(n^2), 空间复杂度O(1) 归并排序， 时间复杂度O(nlogn), 空间复杂度O(n) ?；归并排序是稳定的排序，归并排序需要O(n)的辅助空间 利用复杂空间，空间复杂度O(n), 时间复杂度O(n)（直接遍历一遍） 14 链表中倒数第k个结点 两个指针，保持距离k；那么一个链表尾部，一个就是倒数k 15 反转链表 直接遍历，头插法 递归法 16 合并两个排序的链表 每个链表一个游标，边比较/边连接，最后多的直接连接 递归思路，因为链表总是有序的，对两个链表头节点处理后，剩下的操作更前面的一样的 17 树的子结构（important） 注意子结构和子树的区别 子树的意思是包含了一个结点，就得包含这个结点下的所有节点，一棵大小为n的二叉树有n个子树，就是分别以每个结点为根的子树。 子结构的意思是包含了一个结点，可以只取左子树或者右子树，或者都不取。 子树问题 可以采用 序列化方法，而子结构不能采用序列化方法 此题 递归求解，要么根，要么与左子树匹配，要么与右子树匹配，递归需要注意 18 二叉树的镜像 递归： 子树先镜像，然后上层根再镜像 19 顺时针打印矩阵 一圈一圈的打印，可以封装成一个方法 20 包含min函数的栈 辅助栈方法 维持两个栈，一个普通栈，一个存放min的栈，两个栈对应起来 不用辅助栈 push(int elem)函数在栈中压入当前元素与当前栈中最小元素的差值，然后通过比较当前元素与当前栈中最小元素大小，并将它们中间的较小值压入。 pop()函数执行的时候，先pop出栈顶的两个值，这两个值分别是当前栈中最小值min和最后压入的元素与栈中最小值的差值diff 21 栈的压入、弹出序列 直接利用STL stack等结构, 去模拟栈的压入、弹出过程 22 从上往下打印二叉树 直接层次遍历 23 二叉搜索树的后序遍历序列 判断后续是否合法 问清楚有没有重复数字，搜索树是怎样的排序 根据后序：左 右 根的顺序，递归判断是否满足二叉树的大小关系 24 二叉树中和为某一值的路径 DFS 或 BFS 25 复杂链表的复制 (important) next 和 random 首先A B C D 变成 A A' B B' C C' D D' 通过1，则有：A'.random = A.random.next 然后遍历改变random, 遍历改变next，最后输出即可 26 二叉搜索树与双向链表 二叉树的非递归遍历(可以使用辅助栈) 27 字符串的排列 递归法，需要判断重复的串 可排序，然后判断，也可以采用set等数据结构 28 数组中出现次数超过一半的数字 cur, count，（每次取两个不一样的数删除)　最后验证 29 最小的K个数 快排思路 堆排序思路 O(nlogk)时间复杂度，适合处理海量数据,采用红黑树（stl中的set,multiset都是基于红黑树的） 30 连续子数组的最大和 动态规划 31 整数中1出现的次数（从1到n整数中1出现的次数） 遍历1到n,对每个数采用mod 10 取得1的个数，时间复杂度达到O(nlogn) 找规律的方法，时间复杂度达到O(logn), 参考如下的讲解 http://blog.csdn.net/yi_afly/article/details/52012593 32 把数组排成最小的数 两两组合排序，注意0 33 丑数 34 第一个只出现一次的字符 直接求解：每个字符都与后面的字符比较:空间O(1), 时间(O(n^2) hash记录，空间O(n), 时间O(n) 35 数组中的逆序对（important） 直接求解： 时间复杂度是O(n^2) 归并排序思路：O(n)的空间，时间复杂度为O(nlogn) 36 两个链表的第一个公共结点 单链表是否存在环 走一步，走两步,进一步可以找到第一个公共节点 直接利用map 将两个链表先处理成一样长的，然后再判断 37 数字在排序数组中出现的次数 二分查找，然后左右扩散开统计 38 二叉树的深度 递归 非递归实现(可以层次遍历) 39 输入一棵二叉树，判断该二叉树是否是平衡二叉树 每个节点都采用求深度的方法，这样遍历求解，重复计算量太大 后序遍历，递归判断每个节点是否平衡，因为先访问了左右子树，后访问根，所以需要用变量保存每个节点的深度 40 数组中只出现一次的数字 一个整型数组里除了两个数字之外，其他的数字都出现了两次，利用数的性质，异或运算 41 和为S的连续正数序列（important） 数学公式 42 和为S的两个数字 排序(看题目是否是有序的) + 二分查找， 时间O(nlogn)，空间O(1) hash；有序的话，前后逼近 扩展：寻找和为定值的任意多个数，递归/动归 43 左旋转字符串 三步翻转 改进三步翻转，用块交换 44 翻转单词顺序列 同 43 左旋转字符串 45 扑克牌顺子 统计个数为5，大小王个数 排序，逐一判断，减去大小王数目 46 孩子们的游戏(圆圈中最后剩下的数) 约瑟夫环 f(N,M)=(f(N−1,M)+M)%N f(N,M)表示，N个人报数，每报到M时杀掉那个人，最终胜利者的编号 f(N−1,M)表示，N-1个人报数，每报到M时杀掉那个人，最终胜利者的编号 f(11, 3) = 7, 可以看到7不断的往前面移动3即每杀掉一个人，其实就是把这个数组(环)向前移动了M位. 假设：n个人，最后胜利者是Pn位置；则经过一轮以后:变成n-1个人，最后胜利者位置是Pn-1 那么显然有： Pn = ( Pn-1 + k ) % n 所以有：f(N,M) = ( f(N−1, M ) + M ) % N 47 求1+2+3+...+n 数学公式 递归 考虑并发，并行流 48 不用加减乘除做加法 位运算模拟 异或得到想加结果（不进位） 与然后左移得到进位结果 5: 0101 7: 0111 0101 0101 ^ 0111 & 0111 = 0010 （加的结果） = 0101 49 把字符串转换成整数 (important) 注意最大负整数，最大正整数等特殊情况 2147483647 -2147483648 50 数组中重复的数字 时间复杂度/空间复杂度考虑 二分法思路 hash辅助 51 构建乘积数组 构建左部分乘积 和 右部分乘积序列 52 正则表达式匹配(important) 递归 ？，. 53 表示数值的字符串 各种特殊情况 54 字符流中第一个不重复的字符 55 链表中环的入口结点 链表环的判断 56 删除链表中重复的结点 链表删除节点模拟, 注意各种特殊情况 使用map遍历一边获取要删的原始值，再遍历一遍真正取删除节点，构造返回 递归 加辅助头节点,一次遍历 57 二叉树的下一个结点， 中序遍历顺序的下一个结点并且返回 58 对称的二叉树 对称二叉树概念：将一棵二叉树沿着根节点对折，如果两棵子树完全重合（对称节点要么都为null，要么数据域完全相等），那么该二叉树是一个对称二叉树。 1 递归求解 相当于在判断root->left, root->right 两棵树 是否对折相等 2 非递归，用两个队列，维持root->left, root->right,节点入队列顺序不一样，判断完全 59 按之字形顺序打印二叉树 按照层次遍历，加上标记, 奇数层(偶数层)左reverse操作（reverse不可取，太low） 偶数层栈，奇数层栈，利用栈和二叉树的性质处理（推荐） 60 把二叉树打印成多行 61 序列化二叉树 DFS BFS 62 二叉搜索树的第k个结点 非递归遍历(使用辅助栈和不使用辅助栈),中序遍历 63 数据流中的中位数 对于有限的数集，可以通过把所有观察值高低排序后找出正中间的一个作为中位数。如果观察值有偶数个，通常取最中间的两个数值的平均数作为中位数。 大顶堆和小顶堆。插入的时间效率是O(logn)，找中位数的时间效率是O(1)。 64 滑动窗口的最大值 利用滑动窗口的性质，双端队列处理 两个栈实现pop-push-max都是O(1)的空间换时间 65 矩阵中的路径 DFS 66 机器人的运动范围 DFS 67 剪绳子 动态规划 Copyright @doctording all right reserved，powered by Gitbook该文件修改时间： 2019-09-15 21:35:50 "}}